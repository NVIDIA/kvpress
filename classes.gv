digraph "classes" {
rankdir=BT
charset="utf-8"
"torch._export.db.examples.type_reflection_method.A" [color="black", fontcolor="black", label=<{A|<br ALIGN="LEFT"/>|func(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHContext" [color="black", fontcolor="black", label=<{AHContext|context_dict : Dict[str, Value]<br ALIGN="LEFT"/>features : List[AHFeature]<br ALIGN="LEFT"/>|add_feature(name: str, value: Value, is_categorical: bool): None<br ALIGN="LEFT"/>apply_operations(operations: List[AHOperation]): None<br ALIGN="LEFT"/>get_feature_names_csv(): str<br ALIGN="LEFT"/>get_feature_values_csv(): str<br ALIGN="LEFT"/>get_numerical_and_categorical_features(): Tuple[List[str], List[str]]<br ALIGN="LEFT"/>get_value(name: str): Value<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHFeature" [color="black", fontcolor="black", label=<{AHFeature|is_categorical : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>value : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHMetadata" [color="black", fontcolor="black", label=<{AHMetadata|choices : List[Choice]<br ALIGN="LEFT"/>device_capa : Tuple[int, int]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>shared_memory : Any<br ALIGN="LEFT"/>|to_dict(): Dict[str, Value]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHOperation" [color="black", fontcolor="black", label=<{AHOperation|func : Callable[[Any], Value]<br ALIGN="LEFT"/>is_categorical : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|apply_operation(data: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCache" [color="black", fontcolor="black", label=<{AOTAutogradCache|<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>get_remote_cache(): Optional[RemoteCache[JsonDataTy]]<br ALIGN="LEFT"/>load(dispatch_and_compile: Callable, mod: Union[torch.fx.GraphModule, torch._dynamo.utils.GmWrapper], args, aot_config: AOTConfig, cudagraphs: BoxedBool, local: bool, remote: bool): Callable<br ALIGN="LEFT"/>save(key: str, entry: AOTAutogradCacheEntry, remote: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheDetails" [color="black", fontcolor="black", label=<{AOTAutogradCacheDetails|aot_config<br ALIGN="LEFT"/>autograd_config : NoneType<br ALIGN="LEFT"/>deterministic_algorithms<br ALIGN="LEFT"/>disable_amp<br ALIGN="LEFT"/>grad_enabled<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheEntry" [color="black", fontcolor="black", label=<{AOTAutogradCacheEntry|aot_backward_graph_str : Optional[str]<br ALIGN="LEFT"/>aot_forward_graph_str : Optional[str]<br ALIGN="LEFT"/>aot_joint_graph_str : Optional[str]<br ALIGN="LEFT"/>backward_time_taken_ns : int<br ALIGN="LEFT"/>compiled_bw : Optional[CompiledBackward]<br ALIGN="LEFT"/>compiled_fw<br ALIGN="LEFT"/>dispatch_wrappers : List[CompilerWrapper]<br ALIGN="LEFT"/>forward_time_taken_ns : int<br ALIGN="LEFT"/>indices_of_inps_to_detach : List[int]<br ALIGN="LEFT"/>maybe_subclass_meta : Optional[SubclassMeta]<br ALIGN="LEFT"/>num_fw_outs_saved_for_bw : Optional[int]<br ALIGN="LEFT"/>runtime_metadata<br ALIGN="LEFT"/>|wrap_post_compile(args: List[torch.Tensor], aot_config: AOTConfig, fx_config: _CompileFxKwargs): Callable<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.AOTAutogradCacheInfo" [color="black", fontcolor="black", label=<{AOTAutogradCacheInfo|cache_key : str<br ALIGN="LEFT"/>start_time_ns : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCachePickler" [color="black", fontcolor="black", label=<{AOTAutogradCachePickler|dispatch_table : Dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.AOTConfig" [color="black", fontcolor="black", label=<{AOTConfig|aot_autograd_arg_pos_to_source : Optional[List[Source]]<br ALIGN="LEFT"/>aot_id : int<br ALIGN="LEFT"/>bw_compiler : Callable<br ALIGN="LEFT"/>cache_info : Optional[AOTAutogradCacheInfo]<br ALIGN="LEFT"/>decompositions : Dict[OpOverload, Callable]<br ALIGN="LEFT"/>dynamic_shapes : bool<br ALIGN="LEFT"/>enable_log : bool<br ALIGN="LEFT"/>fw_compiler : Callable<br ALIGN="LEFT"/>inference_compiler : Optional[Callable]<br ALIGN="LEFT"/>is_export : bool<br ALIGN="LEFT"/>keep_inference_input_mutations : bool<br ALIGN="LEFT"/>no_tangents : bool<br ALIGN="LEFT"/>num_params_buffers : int<br ALIGN="LEFT"/>partition_fn : Callable<br ALIGN="LEFT"/>pre_dispatch : bool<br ALIGN="LEFT"/>static_input_indices : Optional[List[int]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDedupeWrapper" [color="black", fontcolor="black", label=<{AOTDedupeWrapper|add_dupe_map : List[int]<br ALIGN="LEFT"/>keep_arg_mask : List[bool]<br ALIGN="LEFT"/>needs_post_compile : bool<br ALIGN="LEFT"/>old_input_metadata : List[InputAliasInfo]<br ALIGN="LEFT"/>|add_dupe_args(args)<br ALIGN="LEFT"/>post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>pre_compile(flat_fn, flat_args: List[Tensor], aot_config: AOTConfig): Tuple[Callable, List[Tensor], ViewAndMutationMeta]<br ALIGN="LEFT"/>remove_dupe_args(args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd" [color="black", fontcolor="black", label=<{AOTDispatchAutograd|<br ALIGN="LEFT"/>|post_compile(compiled_fw_func, compiled_bw_func, maybe_subclass_meta: Optional[SubclassMeta], num_symints_saved_for_bw_: int, backward_state_indices: List[int], disable_amp: bool, indices_of_inps_to_detach: List[int], lazy_backward_info: Optional[AutogradLazyBackwardCompileInfo], aot_config: AOTConfig)<br ALIGN="LEFT"/>process_runtime_tangent(x, meta: Union[PlainTensorMeta, SubclassCreationMeta])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.aot_autograd.AOTDispatchCompiler" [color="black", fontcolor="black", label=<{AOTDispatchCompiler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchSubclassWrapper" [color="black", fontcolor="black", label=<{AOTDispatchSubclassWrapper|fw_only : Optional[Callable]<br ALIGN="LEFT"/>maybe_subclass_meta : Optional[SubclassMeta]<br ALIGN="LEFT"/>num_fw_outs_saved_for_bw : Optional[int]<br ALIGN="LEFT"/>trace_joint : bool<br ALIGN="LEFT"/>|post_compile(compiled_fn, _aot_config: AOTConfig)<br ALIGN="LEFT"/>pre_compile(flat_fn, flat_args: List[Tensor], aot_config: AOTConfig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.package.package.AOTICompiledModel" [color="black", fontcolor="black", label=<{AOTICompiledModel|loader<br ALIGN="LEFT"/>|get_constant_fqns(): List[str]<br ALIGN="LEFT"/>get_metadata(): Dict[str, str]<br ALIGN="LEFT"/>load_constants(constants_map: Dict[str, torch.Tensor]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.repro.aoti.AOTIMinifierError" [color="black", fontcolor="red", label=<{AOTIMinifierError|original_exception<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.aot_autograd.aot_module.AOTModule" [color="black", fontcolor="black", label=<{AOTModule|orig_module<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTSyntheticBaseWrapper" [color="black", fontcolor="black", label=<{AOTSyntheticBaseWrapper|aliased_arg_idx_with_metadata_mutations : List[int]<br ALIGN="LEFT"/>needs_post_compile : bool<br ALIGN="LEFT"/>old_input_info<br ALIGN="LEFT"/>trace_joint : bool<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>pre_compile(flat_fn, flat_args: List[Any], aot_config: AOTConfig): Tuple[Callable, List[Tensor], ViewAndMutationMeta]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.asgd.ASGD" [color="black", fontcolor="black", label=<{ASGD|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.rewriter.AST_Rewriter" [color="black", fontcolor="black", label=<{AST_Rewriter|<br ALIGN="LEFT"/>|rewrite(fn: FunctionType)<br ALIGN="LEFT"/>visit_AnnAssign(node)<br ALIGN="LEFT"/>visit_Assert(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._trace.ATenExportArtifact" [color="black", fontcolor="black", label=<{ATenExportArtifact|constants : Dict[str, Union[torch.Tensor, FakeScriptObject, torch.ScriptObject]]<br ALIGN="LEFT"/>gm<br ALIGN="LEFT"/>sig<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.AbsTransform" [color="black", fontcolor="black", label=<{AbsTransform|codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.Access" [color="black", fontcolor="black", label=<{Access|aliases : List[str]<br ALIGN="LEFT"/>is_output : bool<br ALIGN="LEFT"/>operator : str<br ALIGN="LEFT"/>seq_num : int<br ALIGN="LEFT"/>stack_trace : StackSummary<br ALIGN="LEFT"/>stream : int<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.AccessType" [color="black", fontcolor="black", label=<{AccessType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.AccuracyError" [color="black", fontcolor="red", label=<{AccuracyError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.Action" [color="black", fontcolor="black", label=<{Action|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.activation_sparsifier.activation_sparsifier.ActivationSparsifier" [color="black", fontcolor="black", label=<{ActivationSparsifier|data_groups : Dict[str, Dict]<br ALIGN="LEFT"/>defaults : Dict[str, Any]<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>state : Dict[str, Any]<br ALIGN="LEFT"/>|get_mask(name: Optional[str], layer: Optional[nn.Module])<br ALIGN="LEFT"/>load_state_dict(state_dict: Dict[str, Any]): None<br ALIGN="LEFT"/>register_layer(layer: nn.Module, aggregate_fn, reduce_fn, mask_fn, features, feature_dim)<br ALIGN="LEFT"/>squash_mask(attach_sparsify_hook)<br ALIGN="LEFT"/>state_dict(): Dict[str, Any]<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>unregister_layer(name)<br ALIGN="LEFT"/>update_mask(name, data, configs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.ActivationWrapper" [color="black", fontcolor="black", label=<{ActivationWrapper|<br ALIGN="LEFT"/>|<I>forward</I>()<br ALIGN="LEFT"/>named_parameters(): Iterator[Tuple[str, torch.nn.Parameter]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ActivationsTestModel" [color="black", fontcolor="black", label=<{ActivationsTestModel|dequant<br ALIGN="LEFT"/>elu<br ALIGN="LEFT"/>hardswish<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.adadelta.Adadelta" [color="black", fontcolor="black", label=<{Adadelta|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim._adafactor.Adafactor" [color="black", fontcolor="black", label=<{Adafactor|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.adagrad.Adagrad" [color="black", fontcolor="black", label=<{Adagrad|<br ALIGN="LEFT"/>|share_memory()<br ALIGN="LEFT"/>step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.adam.Adam" [color="black", fontcolor="black", label=<{Adam|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.adamw.AdamW" [color="black", fontcolor="black", label=<{AdamW|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.adamax.Adamax" [color="black", fontcolor="black", label=<{Adamax|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool1d" [color="black", fontcolor="black", label=<{AdaptiveAvgPool1d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" [color="black", fontcolor="black", label=<{AdaptiveAvgPool2d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool3d" [color="black", fontcolor="black", label=<{AdaptiveAvgPool3d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss" [color="black", fontcolor="black", label=<{AdaptiveLogSoftmaxWithLoss|cutoffs : List[int]<br ALIGN="LEFT"/>div_value : float<br ALIGN="LEFT"/>head<br ALIGN="LEFT"/>head_bias : bool<br ALIGN="LEFT"/>head_size<br ALIGN="LEFT"/>in_features : int<br ALIGN="LEFT"/>n_classes : int<br ALIGN="LEFT"/>n_clusters<br ALIGN="LEFT"/>shortlist_size<br ALIGN="LEFT"/>tail<br ALIGN="LEFT"/>|forward(input_: Tensor, target_: Tensor): _ASMoutput<br ALIGN="LEFT"/>log_prob(input: Tensor): Tensor<br ALIGN="LEFT"/>predict(input: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveMaxPool1d" [color="black", fontcolor="black", label=<{AdaptiveMaxPool1d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveMaxPool2d" [color="black", fontcolor="black", label=<{AdaptiveMaxPool2d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AdaptiveMaxPool3d" [color="black", fontcolor="black", label=<{AdaptiveMaxPool3d|output_size : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.AddInplaceAdd" [color="black", fontcolor="black", label=<{AddInplaceAdd|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.AddMulScalar" [color="black", fontcolor="black", label=<{AddMulScalar|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.AddParenHandler" [color="black", fontcolor="black", label=<{AddParenHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._address.Address" [color="black", fontcolor="black", label=<{Address|absolute_address : int<br ALIGN="LEFT"/>fully_qualified_name : Optional[str]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>kind : Optional[str]<br ALIGN="LEFT"/>length : Optional[int]<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>offset_from_parent : Optional[int]<br ALIGN="LEFT"/>parent_index : int<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>relative_address : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.AffineTransform" [color="black", fontcolor="black", label=<{AffineTransform|bijective : bool<br ALIGN="LEFT"/>event_dim<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>sign<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Agent" [color="black", fontcolor="black", label=<{Agent|agent_rref : RRef<br ALIGN="LEFT"/>eps<br ALIGN="LEFT"/>ob_rrefs : list<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>policy<br ALIGN="LEFT"/>reward_threshold : float<br ALIGN="LEFT"/>rewards : dict<br ALIGN="LEFT"/>running_reward : int<br ALIGN="LEFT"/>saved_log_probs : dict<br ALIGN="LEFT"/>|finish_episode()<br ALIGN="LEFT"/>report_reward(ob_id, reward)<br ALIGN="LEFT"/>run_episode(n_steps)<br ALIGN="LEFT"/>select_action(ob_id, state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.AlgorithmSelectorCache" [color="black", fontcolor="black", label=<{AlgorithmSelectorCache|feedback_saver_fns : List[Callable[[Dict[ChoiceCaller, float], str, List[Any], List[ChoiceCaller]], None]]<br ALIGN="LEFT"/>precompile_cache : Dict[str, Callable[[], None]]<br ALIGN="LEFT"/>|add_feedback_saver(fn: Callable[[Dict[ChoiceCaller, float], str, List[Any], List[ChoiceCaller]], None])<br ALIGN="LEFT"/>benchmark_example_value(node)<br ALIGN="LEFT"/>generate_example_value(size, stride, device, dtype, extra_size)<br ALIGN="LEFT"/>key_of(node)<br ALIGN="LEFT"/>log_results(name: str, input_nodes: List[ir.IRNode], timings: Dict[ChoiceCaller, float], elapse: float, precompile_elapse: float)<br ALIGN="LEFT"/>make_benchmark_fn(choices, input_nodes, layout, input_gen_fns)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._python_dispatch.AliasInfo" [color="black", fontcolor="black", label=<{AliasInfo|alias_set : Set[str]<br ALIGN="LEFT"/>is_write : bool<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.AliasInfo" [color="black", fontcolor="black", label=<{AliasInfo|inplace_variant<br ALIGN="LEFT"/>method_variant<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>op : object<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AliasOfInputHandler" [color="black", fontcolor="black", label=<{AliasOfInputHandler|base_idx<br ALIGN="LEFT"/>functional_tensor<br ALIGN="LEFT"/>replay_views : bool<br ALIGN="LEFT"/>requires_grad<br ALIGN="LEFT"/>unwrap_out<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AliasOfIntermediateHandler" [color="black", fontcolor="black", label=<{AliasOfIntermediateHandler|base_idx<br ALIGN="LEFT"/>functional_tensor<br ALIGN="LEFT"/>replay_views : bool<br ALIGN="LEFT"/>requires_grad<br ALIGN="LEFT"/>unwrap_out<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.AliasViewInfo" [color="black", fontcolor="black", label=<{AliasViewInfo|<br ALIGN="LEFT"/>|regenerate_view(bases_list: List[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.AliasesNewOutput" [color="black", fontcolor="black", label=<{AliasesNewOutput|index : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.AliasesPriorGraphOutput" [color="black", fontcolor="black", label=<{AliasesPriorGraphOutput|index : Tuple<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.AllGather" [color="black", fontcolor="black", label=<{AllGather|<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_collectives.AllGatherResult" [color="black", fontcolor="black", label=<{AllGatherResult|all_gather_event : Optional[torch.Event]<br ALIGN="LEFT"/>all_gather_input_split_sizes : List[int]<br ALIGN="LEFT"/>all_gather_output<br ALIGN="LEFT"/>all_gather_work : Optional[dist.distributed_c10d.Work]<br ALIGN="LEFT"/>param_all_gather_input_dtypes : List[List[torch.dtype]]<br ALIGN="LEFT"/>param_all_gather_input_numels : List[List[int]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.AllGatherState" [color="black", fontcolor="black", label=<{AllGatherState|all_gather_result : AllGatherResult<br ALIGN="LEFT"/>event<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.rpc.api.AllGatherStates" [color="black", fontcolor="black", label=<{AllGatherStates|gathered_objects : dict<br ALIGN="LEFT"/>proceed_signal : Event<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.AllOrAnyReductionTypePromotionRule" [color="black", fontcolor="black", label=<{AllOrAnyReductionTypePromotionRule|<br ALIGN="LEFT"/>|preview_type_promotion(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.AllReduce" [color="black", fontcolor="black", label=<{AllReduce|op<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.AllReduceState" [color="black", fontcolor="black", label=<{AllReduceState|all_reduce_input<br ALIGN="LEFT"/>event<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.AllToAll" [color="black", fontcolor="black", label=<{AllToAll|<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.AllToAllBase" [color="black", fontcolor="black", label=<{AllToAllBase|<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.AllocFromPoolLine" [color="black", fontcolor="black", label=<{AllocFromPoolLine|is_first_pool_usage : bool<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.AllocateLine" [color="black", fontcolor="black", label=<{AllocateLine|node : Union<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>plan(state: MemoryPlanningState): MemoryPlanningLine<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.Allocation" [color="black", fontcolor="black", label=<{Allocation|allocated : bool<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>live_range<br ALIGN="LEFT"/>node : Union<br ALIGN="LEFT"/>offset : Optional[sympy.Expr]<br ALIGN="LEFT"/>pool : Optional[AllocationPool]<br ALIGN="LEFT"/>size_hint : int<br ALIGN="LEFT"/>symbolic_size : Expr<br ALIGN="LEFT"/>|codegen_alloc_from_pool(wrapper)<br ALIGN="LEFT"/>finalize(pool, offset)<br ALIGN="LEFT"/>get_live_ranges()<br ALIGN="LEFT"/>get_size_hint()<br ALIGN="LEFT"/>get_symbolic_size()<br ALIGN="LEFT"/>mark_allocated()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.AllocationPool" [color="black", fontcolor="black", label=<{AllocationPool|can_expand : bool<br ALIGN="LEFT"/>creation_cache : Dict[str, str]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>names_to_del : List[str]<br ALIGN="LEFT"/>restrict_live_range : Optional[LiveRange]<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>|allocate(block: Allocation, is_last: bool)<br ALIGN="LEFT"/>allocate_at_end(block)<br ALIGN="LEFT"/>codegen_create(wrapper, code: IndentedBuffer)<br ALIGN="LEFT"/>codegen_destroy(wrapper, code: IndentedBuffer)<br ALIGN="LEFT"/>finalize(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.AllocationPools" [color="black", fontcolor="black", label=<{AllocationPools|device_to_pools : Dict[torch.device, List[AllocationPool]]<br ALIGN="LEFT"/>|allocate(block: Allocation)<br ALIGN="LEFT"/>allocate_output(block: Allocation)<br ALIGN="LEFT"/>finalize()<br ALIGN="LEFT"/>get_pools(block)<br ALIGN="LEFT"/>pprint()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.AllocationTreeNode" [color="black", fontcolor="black", label=<{AllocationTreeNode|<br ALIGN="LEFT"/>|allocate(block: Allocation, is_last: bool): bool<br ALIGN="LEFT"/>finalize(pool, offset): AllocationTreeNode<br ALIGN="LEFT"/><I>get_live_ranges</I>(): LiveRanges<br ALIGN="LEFT"/><I>get_size_hint</I>(): int<br ALIGN="LEFT"/><I>get_symbolic_size</I>(): sympy.Expr<br ALIGN="LEFT"/>is_empty()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.AlphaDropout" [color="black", fontcolor="black", label=<{AlphaDropout|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.AlwaysWarnTypedStorageRemoval" [color="black", fontcolor="black", label=<{AlwaysWarnTypedStorageRemoval|always_warn<br ALIGN="LEFT"/>always_warn_restore : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.AlwaysWrapNestedWrappedModule" [color="black", fontcolor="black", label=<{AlwaysWrapNestedWrappedModule|<br ALIGN="LEFT"/>|init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.conflict.AmbiguityWarning" [color="black", fontcolor="red", label=<{AmbiguityWarning|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx._pass.Analysis" [color="black", fontcolor="black", label=<{Analysis|diagnostic_context<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>onnxfunction_dispatcher<br ALIGN="LEFT"/>|<I>analyze</I>(diagnostic_level: diagnostics.infra.Level): AnalysisResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx._pass.AnalysisResult" [color="black", fontcolor="black", label=<{AnalysisResult|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.specialized_attribute.Animal" [color="black", fontcolor="black", label=<{Animal|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.schema_type_annotation.AnnotateTypesWithSchema" [color="black", fontcolor="black", label=<{AnnotateTypesWithSchema|annotate_functionals : bool<br ALIGN="LEFT"/>annotate_get_attrs : bool<br ALIGN="LEFT"/>annotate_modules : bool<br ALIGN="LEFT"/>|call_function(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any])<br ALIGN="LEFT"/>call_module(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any])<br ALIGN="LEFT"/>get_attr(target: torch.fx.node.Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedConvBnModel" [color="black", fontcolor="black", label=<{AnnotatedConvBnModel|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [color="black", fontcolor="black", label=<{AnnotatedConvBnReLUModel|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>fuse_model()<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedConvModel" [color="black", fontcolor="black", label=<{AnnotatedConvModel|conv<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" [color="black", fontcolor="black", label=<{AnnotatedConvTransposeModel|conv<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel" [color="black", fontcolor="black", label=<{AnnotatedCustomConfigNestedModel|fc3<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedNestedModel" [color="black", fontcolor="black", label=<{AnnotatedNestedModel|fc3<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel" [color="black", fontcolor="black", label=<{AnnotatedSingleLayerLinearModel|fc1<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedSkipQuantModel" [color="black", fontcolor="black", label=<{AnnotatedSkipQuantModel|fc<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>sub<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>fuse_modules()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedSubNestedModel" [color="black", fontcolor="black", label=<{AnnotatedSubNestedModel|fc3<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel" [color="black", fontcolor="black", label=<{AnnotatedTwoLayerLinearModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.common.AotAutograd" [color="black", fontcolor="black", label=<{AotAutograd|kwargs : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codecache.AotCodeCompiler" [color="black", fontcolor="black", label=<{AotCodeCompiler|<br ALIGN="LEFT"/>|compile(graph: GraphLowering, source_code: str, serialized_extern_kernel_nodes: Optional[str], device_type: str, additional_files: List[str]): Union[List[str], str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.testing.AotEagerAndRecordGraphs" [color="black", fontcolor="black", label=<{AotEagerAndRecordGraphs|bw_graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>fw_graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._appdirs.AppDirs" [color="black", fontcolor="black", label=<{AppDirs|appauthor : NoneType<br ALIGN="LEFT"/>appname : NoneType<br ALIGN="LEFT"/>multipath : bool<br ALIGN="LEFT"/>roaming : bool<br ALIGN="LEFT"/>site_config_dir<br ALIGN="LEFT"/>site_data_dir<br ALIGN="LEFT"/>user_cache_dir<br ALIGN="LEFT"/>user_config_dir<br ALIGN="LEFT"/>user_data_dir<br ALIGN="LEFT"/>user_log_dir<br ALIGN="LEFT"/>user_state_dir<br ALIGN="LEFT"/>version : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.ApplyBroadcasting" [color="black", fontcolor="black", label=<{ApplyBroadcasting|input1<br ALIGN="LEFT"/>input2<br ALIGN="LEFT"/>res1<br ALIGN="LEFT"/>res2<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.autograd_function.AutogradFunctionApply.__call__.ApplyTemplate" [color="black", fontcolor="black", label=<{ApplyTemplate|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.Arg" [color="black", fontcolor="black", label=<{Arg|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.optimizer.ArgMappingException" [color="black", fontcolor="red", label=<{ArgMappingException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.operator_schemas.ArgsKwargsPair" [color="black", fontcolor="black", label=<{ArgsKwargsPair|args : Tuple[Any, ...]<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ArgsMismatchError" [color="black", fontcolor="red", label=<{ArgsMismatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.Argument" [color="black", fontcolor="black", label=<{Argument|as_bool : Annotated[bool, 170]<br ALIGN="LEFT"/>as_bools : Annotated[List[bool], 180]<br ALIGN="LEFT"/>as_custom_obj : Annotated[CustomObjArgument, 210]<br ALIGN="LEFT"/>as_device : Annotated[Device, 160]<br ALIGN="LEFT"/>as_float : Annotated[float, 80]<br ALIGN="LEFT"/>as_floats : Annotated[List[float], 90]<br ALIGN="LEFT"/>as_graph : Annotated[GraphArgument, 200]<br ALIGN="LEFT"/>as_int : Annotated[int, 50]<br ALIGN="LEFT"/>as_ints : Annotated[List[int], 70]<br ALIGN="LEFT"/>as_layout : Annotated[Layout, 150]<br ALIGN="LEFT"/>as_memory_format : Annotated[MemoryFormat, 140]<br ALIGN="LEFT"/>as_none : Annotated[bool, 10]<br ALIGN="LEFT"/>as_operator : Annotated[str, 220]<br ALIGN="LEFT"/>as_optional_tensors : Annotated[List[OptionalTensorArgument], 190]<br ALIGN="LEFT"/>as_scalar_type : Annotated[ScalarType, 130]<br ALIGN="LEFT"/>as_string : Annotated[str, 100]<br ALIGN="LEFT"/>as_strings : Annotated[List[str], 101]<br ALIGN="LEFT"/>as_sym_bool : Annotated[SymBoolArgument, 182]<br ALIGN="LEFT"/>as_sym_bools : Annotated[List[SymBoolArgument], 184]<br ALIGN="LEFT"/>as_sym_float : Annotated[SymFloatArgument, 230]<br ALIGN="LEFT"/>as_sym_floats : Annotated[List[SymFloatArgument], 240]<br ALIGN="LEFT"/>as_sym_int : Annotated[SymIntArgument, 110]<br ALIGN="LEFT"/>as_sym_ints : Annotated[List[SymIntArgument], 120]<br ALIGN="LEFT"/>as_tensor : Annotated[TensorArgument, 20]<br ALIGN="LEFT"/>as_tensors : Annotated[List[TensorArgument], 30]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.ArgumentHandler" [color="black", fontcolor="black", label=<{ArgumentHandler|dataptrs_read : Set[DataPtr]<br ALIGN="LEFT"/>dataptrs_written : Set[DataPtr]<br ALIGN="LEFT"/>outputs : Set[DataPtr]<br ALIGN="LEFT"/>tensor_aliases : Dict[DataPtr, List[str]]<br ALIGN="LEFT"/>|parse_inputs(schema: torch.FunctionSchema, args: Tuple[Any, ...], kwargs: Dict[str, Any]): None<br ALIGN="LEFT"/>parse_outputs(schema: torch.FunctionSchema, outputs: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact.Artifact" [color="black", fontcolor="black", label=<{Artifact|contents : Optional[_artifact_content.ArtifactContent]<br ALIGN="LEFT"/>description : Optional[_message.Message]<br ALIGN="LEFT"/>encoding : Optional[str]<br ALIGN="LEFT"/>hashes : Optional[Any]<br ALIGN="LEFT"/>last_modified_time_utc : Optional[str]<br ALIGN="LEFT"/>length : int<br ALIGN="LEFT"/>location : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>mime_type : Optional[str]<br ALIGN="LEFT"/>offset : Optional[int]<br ALIGN="LEFT"/>parent_index : int<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>roles : Optional[List[Literal['analysisTarget', 'attachment', 'responseFile', 'resultFile', 'standardStream', 'tracedFile', 'unmodified', 'modified', 'added', 'deleted', 'renamed', 'uncontrolled', 'driver', 'extension', 'translation', 'taxonomy', 'policy', 'referencedOnCommandLine', 'memoryContents', 'directory', 'userSpecifiedConfiguration', 'toolSpecifiedConfiguration', 'debugOutputFile']]]<br ALIGN="LEFT"/>source_language : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact_change.ArtifactChange" [color="black", fontcolor="black", label=<{ArtifactChange|artifact_location<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>replacements : List[_replacement.Replacement]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact_content.ArtifactContent" [color="black", fontcolor="black", label=<{ArtifactContent|binary : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>rendered : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>text : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact_location.ArtifactLocation" [color="black", fontcolor="black", label=<{ArtifactLocation|description : Optional[_message.Message]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>uri : Optional[str]<br ALIGN="LEFT"/>uri_base_id : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.AsStridedViewInfo" [color="black", fontcolor="black", label=<{AsStridedViewInfo|size : Sequence[Union[int, torch.SymInt]]<br ALIGN="LEFT"/>storage_offset : int<br ALIGN="LEFT"/>stride : Sequence[Union[int, torch.SymInt]]<br ALIGN="LEFT"/>|regenerate_view(bases_list: List[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.AssertRaisesContextIgnoreNotImplementedError" [color="black", fontcolor="black", label=<{AssertRaisesContextIgnoreNotImplementedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.AssertScalar" [color="black", fontcolor="black", label=<{AssertScalar|msg<br ALIGN="LEFT"/>scalar<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_unbacked_symbol_uses()<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.AssociativeScanHigherOrderVariable" [color="black", fontcolor="black", label=<{AssociativeScanHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.associative_scan.AssociativeScanOp" [color="black", fontcolor="black", label=<{AssociativeScanOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.assume_constant_result.AssumeConstantResult" [color="black", fontcolor="black", label=<{AssumeConstantResult|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>get_item(y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._lazy.closure.AsyncClosureHandler" [color="black", fontcolor="black", label=<{AsyncClosureHandler|<br ALIGN="LEFT"/>|run(closure)<br ALIGN="LEFT"/>start_event_loop()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._functional_collectives.AsyncCollectiveTensor" [color="black", fontcolor="black", label=<{AsyncCollectiveTensor|completed : bool<br ALIGN="LEFT"/>elem<br ALIGN="LEFT"/>|numpy()<br ALIGN="LEFT"/>tolist()<br ALIGN="LEFT"/>trigger_wait()<br ALIGN="LEFT"/>wait(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.async_compile.AsyncCompile" [color="black", fontcolor="black", label=<{AsyncCompile|<br ALIGN="LEFT"/>|cpp(source_code: str)<br ALIGN="LEFT"/>cpp_pybinding(argtypes: List[str], source_code: str)<br ALIGN="LEFT"/>cuda(source_code, dst_file_ext, aot_compile)<br ALIGN="LEFT"/>halide(meta: HalideMeta, source_code: str)<br ALIGN="LEFT"/>multi_kernel(): Any<br ALIGN="LEFT"/>pool(): ThreadPoolExecutor<br ALIGN="LEFT"/>process_pool(): SubprocPool<br ALIGN="LEFT"/>rocm(source_code, dst_file_ext, aot_compile)<br ALIGN="LEFT"/>submit(task: Callable[..., Any]): Any<br ALIGN="LEFT"/>triton(kernel_name: str, source_code: str, device_str: str)<br ALIGN="LEFT"/>wait(scope: Dict[str, Any]): None<br ALIGN="LEFT"/>warm_pool(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.AsyncExecutionClass" [color="black", fontcolor="black", label=<{AsyncExecutionClass|<br ALIGN="LEFT"/>|bound_async_add(to, x, y, z)<br ALIGN="LEFT"/>class_async_add(to, x, y, z)<br ALIGN="LEFT"/>static_async_add(to, x, y, z)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.staging.AsyncStager" [color="black", fontcolor="black", label=<{AsyncStager|should_synchronize_after_execute<br ALIGN="LEFT"/>|<I>stage</I>(state_dict: STATE_DICT_TYPE): STATE_DICT_TYPE<br ALIGN="LEFT"/><I>synchronize_staging</I>(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._attachment.Attachment" [color="black", fontcolor="black", label=<{Attachment|artifact_location<br ALIGN="LEFT"/>description : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>rectangles : Optional[List[_rectangle.Rectangle]]<br ALIGN="LEFT"/>regions : Optional[List[_region.Region]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.Attention" [color="black", fontcolor="black", label=<{Attention|dropout_p<br ALIGN="LEFT"/>head_dim<br ALIGN="LEFT"/>n_heads<br ALIGN="LEFT"/>resid_dropout<br ALIGN="LEFT"/>use_attn_mask<br ALIGN="LEFT"/>wk<br ALIGN="LEFT"/>wo<br ALIGN="LEFT"/>wq<br ALIGN="LEFT"/>wv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer.__init__.AttrProxy" [color="black", fontcolor="black", label=<{AttrProxy|<br ALIGN="LEFT"/>|get_base(): Module<br ALIGN="LEFT"/>reset_proxy_mapping(base: Module, path: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.AttrProxySource" [color="black", fontcolor="black", label=<{AttrProxySource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.AttrSource" [color="black", fontcolor="black", label=<{AttrSource|member : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.proxy.Attribute" [color="black", fontcolor="black", label=<{Attribute|attr : str<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.AttributeMutation" [color="black", fontcolor="black", label=<{AttributeMutation|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.AttributeMutationError" [color="black", fontcolor="red", label=<{AttributeMutationError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.AttributeMutationExisting" [color="black", fontcolor="black", label=<{AttributeMutationExisting|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.AttributeMutationNew" [color="black", fontcolor="black", label=<{AttributeMutationNew|cls_source : Optional[Source]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._schemas.AttributeParameter" [color="black", fontcolor="black", label=<{AttributeParameter|default : ir.Attr \| None<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>required : bool<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|has_default(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._check.AttributeTypeIsSupportedChecker" [color="black", fontcolor="black", label=<{AttributeTypeIsSupportedChecker|class_level_annotations : list<br ALIGN="LEFT"/>visiting_class_level_ann : bool<br ALIGN="LEFT"/>|check(nn_module: torch.nn.Module): None<br ALIGN="LEFT"/>visit_AnnAssign(node)<br ALIGN="LEFT"/>visit_Assign(node)<br ALIGN="LEFT"/>visit_Call(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.AutoDynamic" [color="black", fontcolor="black", label=<{AutoDynamic|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.AutoFunctionalizeHigherOrderVariable" [color="black", fontcolor="black", label=<{AutoFunctionalizeHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.AutoFunctionalized" [color="black", fontcolor="black", label=<{AutoFunctionalized|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.AutoFunctionalizedV2" [color="black", fontcolor="black", label=<{AutoFunctionalizedV2|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic.AutoHeuristic" [color="black", fontcolor="black", label=<{AutoHeuristic|augment_context : Optional[List[AHOperation]]<br ALIGN="LEFT"/>choices : List[Choice]<br ALIGN="LEFT"/>collected_feedback : Dict[Choice, Feedback]<br ALIGN="LEFT"/>context<br ALIGN="LEFT"/>fallback : Callable[[], Choice]<br ALIGN="LEFT"/>feedback : Optional[LocalFeedback]<br ALIGN="LEFT"/>log_path : str<br ALIGN="LEFT"/>metadata<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>precondition : Optional[Callable[[AHMetadata, AHContext], bool]]<br ALIGN="LEFT"/>|get_choice(): Choice<br ALIGN="LEFT"/>get_collected_feedback(choice: Choice): Any<br ALIGN="LEFT"/>get_default_log_path(): str<br ALIGN="LEFT"/>get_device_identifier(): str<br ALIGN="LEFT"/>get_top_k_choices(top_k: int, always_included: Optional[List[str]]): Optional[List[Choice]]<br ALIGN="LEFT"/>satisfies_precondition(): bool<br ALIGN="LEFT"/>save_data(choice: Choice, feedback_val: Feedback): None<br ALIGN="LEFT"/>serialize_metadata(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic.AutoHeuristicSelectAlgorithm" [color="black", fontcolor="black", label=<{AutoHeuristicSelectAlgorithm|choicestr2choice : Dict[str, ChoiceCaller]<br ALIGN="LEFT"/>input_nodes : List[Any]<br ALIGN="LEFT"/>|get_choice_caller(): Optional[ChoiceCaller]<br ALIGN="LEFT"/>get_top_k_choices_caller(top_k: int, always_included: Optional[List[str]]): Optional[List[ChoiceCaller]]<br ALIGN="LEFT"/>register_global_feedback(input_nodes: List[Any], choices: List[ChoiceCaller]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.AutoUnset" [color="black", fontcolor="black", label=<{AutoUnset|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autocast_test_lists.AutocastCPUTestLists" [color="black", fontcolor="black", label=<{AutocastCPUTestLists|methods_expect_builtin_promote : list<br ALIGN="LEFT"/>nn_16 : list<br ALIGN="LEFT"/>nn_fp32 : list<br ALIGN="LEFT"/>torch_16 : list<br ALIGN="LEFT"/>torch_expect_builtin_promote : list<br ALIGN="LEFT"/>torch_fp32 : list<br ALIGN="LEFT"/>torch_need_autocast_promote : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.AutocastModeVariable" [color="black", fontcolor="black", label=<{AutocastModeVariable|target_values<br ALIGN="LEFT"/>|create(func, args, kwargs)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autocast_test_lists.AutocastTestLists" [color="black", fontcolor="black", label=<{AutocastTestLists|banned : list<br ALIGN="LEFT"/>linalg_fp16 : list<br ALIGN="LEFT"/>methods_expect_builtin_promote : list<br ALIGN="LEFT"/>methods_fp16 : list<br ALIGN="LEFT"/>methods_fp32 : list<br ALIGN="LEFT"/>nn_fp16 : list<br ALIGN="LEFT"/>nn_fp32 : list<br ALIGN="LEFT"/>torch_expect_builtin_promote : list<br ALIGN="LEFT"/>torch_fp16 : list<br ALIGN="LEFT"/>torch_fp32 : list<br ALIGN="LEFT"/>torch_need_autocast_promote : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.compiled_autograd.AutogradCompilerInstance" [color="black", fontcolor="black", label=<{AutogradCompilerInstance|aot_graph_cls_name : Optional[str]<br ALIGN="LEFT"/>aot_graph_infos : Dict[int, Dict[str, Any]]<br ALIGN="LEFT"/>close<br ALIGN="LEFT"/>compiler_fn<br ALIGN="LEFT"/>fake_tensor_mode<br ALIGN="LEFT"/>fx_tracer<br ALIGN="LEFT"/>hooks_proxy : Optional[Proxy]<br ALIGN="LEFT"/>proxy_mode<br ALIGN="LEFT"/>shape_env<br ALIGN="LEFT"/>stack : ExitStack<br ALIGN="LEFT"/>|begin_capture(inputs: List[torch.Tensor], sizes: List[int], scalars: List[Union[int, float]], origins: List[List[Tuple[int, str]]])<br ALIGN="LEFT"/>bind_backward_state(index: int)<br ALIGN="LEFT"/>bind_tensors_to_proxies(tensors, proxies, origins: Optional[List[Tuple[int, str]]])<br ALIGN="LEFT"/>dce()<br ALIGN="LEFT"/>end_capture(outputs)<br ALIGN="LEFT"/>get_all_nodes(args)<br ALIGN="LEFT"/>is_placeholder(node)<br ALIGN="LEFT"/>is_sym_node(node)<br ALIGN="LEFT"/>move_graph_nodes_to_cuda(graph): List[int]<br ALIGN="LEFT"/>post_acc_grad_hook(input, hook_id)<br ALIGN="LEFT"/>post_hook(outputs, inputs, hook_id)<br ALIGN="LEFT"/>pre_hook(inputs, hook_id)<br ALIGN="LEFT"/>proxy_call_backward(inputs, output_metadatas, saved_tensors, backward_idx: int)<br ALIGN="LEFT"/>proxy_call_hook(hook)<br ALIGN="LEFT"/>rename_aot_dispatcher_nodes()<br ALIGN="LEFT"/>reorder_accumulate_grad_nodes()<br ALIGN="LEFT"/>reorder_post_acc_grad_hook_nodes()<br ALIGN="LEFT"/>reorder_post_hook_nodes()<br ALIGN="LEFT"/>reorder_pre_hook_nodes_to_mimic_eager()<br ALIGN="LEFT"/>reorder_pre_hook_nodes_to_schedule_asap()<br ALIGN="LEFT"/>reorder_tensor_pre_hook_nodes()<br ALIGN="LEFT"/>set_node_origin(node_name: str, nodecall_index: int, pyobj: Optional[torch.autograd.Function])<br ALIGN="LEFT"/>source(name, idx): GetItemSource<br ALIGN="LEFT"/>tensor_pre_hook(inputs, hook_id, i: int)<br ALIGN="LEFT"/>to_proxy(t)<br ALIGN="LEFT"/>wrap_fake(x, source)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.AutogradEngineVariable" [color="black", fontcolor="black", label=<{AutogradEngineVariable|<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.autograd_function.AutogradFunction" [color="black", fontcolor="black", label=<{AutogradFunction|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.autograd_function.AutogradFunctionApply" [color="black", fontcolor="black", label=<{AutogradFunctionApply|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.AutogradFunctionApplyVariable" [color="black", fontcolor="black", label=<{AutogradFunctionApplyVariable|bwd_graph<br ALIGN="LEFT"/>fwd_graph<br ALIGN="LEFT"/>parent_source<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.AutogradFunctionContextVariable" [color="black", fontcolor="black", label=<{AutogradFunctionContextVariable|inference : bool<br ALIGN="LEFT"/>needs_input_grad : NoneType<br ALIGN="LEFT"/>non_differentiable : NoneType, tuple<br ALIGN="LEFT"/>proxy : NoneType<br ALIGN="LEFT"/>saved_tensors : NoneType<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.AutogradFunctionVariable" [color="black", fontcolor="black", label=<{AutogradFunctionVariable|fn_cls<br ALIGN="LEFT"/>|call_apply(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>call_backward(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AutogradLazyBackwardCompileInfo" [color="black", fontcolor="black", label=<{AutogradLazyBackwardCompileInfo|bw_module : Callable<br ALIGN="LEFT"/>placeholder_list : List[Any]<br ALIGN="LEFT"/>saved_compile_context : Optional[CompileContext]<br ALIGN="LEFT"/>saved_context : Optional[TracingContext]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._safeguard.AutogradStateOpsFailSafeguard" [color="black", fontcolor="black", label=<{AutogradStateOpsFailSafeguard|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.AutotuneArgs" [color="black", fontcolor="black", label=<{AutotuneArgs|expected : Optional[torch.Tensor]<br ALIGN="LEFT"/>extern<br ALIGN="LEFT"/>triton<br ALIGN="LEFT"/>|from_choice_args(example_inputs: List[torch.Tensor], example_inputs_extern: List[torch.Tensor], out: torch.Tensor, out_extern: torch.Tensor, expected: Optional[torch.Tensor]): _T<br ALIGN="LEFT"/>get_benchmark_tensors(extern): BenchmarkTensors<br ALIGN="LEFT"/>verify()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.autotune_cache.AutotuneCache" [color="black", fontcolor="black", label=<{AutotuneCache|configs_hash : str<br ALIGN="LEFT"/>local_cache : Optional[Tuple[RemoteCache[JsonDataTy], str]]<br ALIGN="LEFT"/>remote_cache : Optional[Tuple[RemoteCache[JsonDataTy], str]]<br ALIGN="LEFT"/>|create(inductor_meta: _InductorMetaTy, filename: str, configs_hash: str): Optional[AutotuneCache]<br ALIGN="LEFT"/>read_best(inductor_meta: _InductorMetaTy, configs: List[Config]): Optional[Config]<br ALIGN="LEFT"/>save(config: Config, time_taken_ns: int, found_by_coordesc: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.autotune_cache.AutotuneCacheBundler" [color="black", fontcolor="black", label=<{AutotuneCacheBundler|<br ALIGN="LEFT"/>|begin_compile(inductor_meta: _InductorMetaTy): None<br ALIGN="LEFT"/>end_compile(): None<br ALIGN="LEFT"/>put(filename: str, data: JsonDataTy): None<br ALIGN="LEFT"/>sync(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.AutotuneHint" [color="black", fontcolor="black", label=<{AutotuneHint|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.AverageMeter" [color="black", fontcolor="black", label=<{AverageMeter|avg : int<br ALIGN="LEFT"/>count : int<br ALIGN="LEFT"/>fmt : str<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>sum : int<br ALIGN="LEFT"/>val : int<br ALIGN="LEFT"/>|reset()<br ALIGN="LEFT"/>update(val, n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.swa_utils.AveragedModel" [color="black", fontcolor="black", label=<{AveragedModel|avg_fn : Optional[Callable[[Tensor, Tensor, Union[Tensor, int]], Tensor]]<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>multi_avg_fn : Optional[Callable[[PARAM_LIST, PARAM_LIST, Union[Tensor, int]], None]]<br ALIGN="LEFT"/>n_averaged<br ALIGN="LEFT"/>use_buffers : bool<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>update_parameters(model: Module)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AvgPool1d" [color="black", fontcolor="black", label=<{AvgPool1d|ceil_mode : bool<br ALIGN="LEFT"/>count_include_pad : bool<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AvgPool2d" [color="black", fontcolor="black", label=<{AvgPool2d|ceil_mode : bool<br ALIGN="LEFT"/>count_include_pad : bool<br ALIGN="LEFT"/>divisor_override : Optional[int]<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.AvgPool3d" [color="black", fontcolor="black", label=<{AvgPool3d|ceil_mode : bool<br ALIGN="LEFT"/>count_include_pad : bool<br ALIGN="LEFT"/>divisor_override : Optional[int]<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._util.AxisError" [color="black", fontcolor="red", label=<{AxisError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.loss.BCELoss" [color="black", fontcolor="black", label=<{BCELoss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.BCEWithLogitsLoss" [color="black", fontcolor="black", label=<{BCEWithLogitsLoss|pos_weight : Optional[Tensor]<br ALIGN="LEFT"/>weight : Optional[Tensor]<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.BFloat16Storage" [color="black", fontcolor="black", label=<{BFloat16Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.BFloat16Storage" [color="black", fontcolor="black", label=<{BFloat16Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d" [color="black", fontcolor="black", label=<{BNReLU2d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(bn_relu, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU2d" [color="black", fontcolor="black", label=<{BNReLU2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d" [color="black", fontcolor="black", label=<{BNReLU3d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(bn_relu, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU3d" [color="black", fontcolor="black", label=<{BNReLU3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.BVar" [color="black", fontcolor="black", label=<{BVar|c<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d.Backend" [color="black", fontcolor="black", label=<{Backend|GLOO : str<br ALIGN="LEFT"/>MPI : str<br ALIGN="LEFT"/>NCCL : str<br ALIGN="LEFT"/>UCC : str<br ALIGN="LEFT"/>UNDEFINED : str<br ALIGN="LEFT"/>XCCL : str<br ALIGN="LEFT"/>backend_capability : Dict[str, List[str]]<br ALIGN="LEFT"/>backend_list : list<br ALIGN="LEFT"/>backend_type_map : Dict[str, ProcessGroup.BackendType]<br ALIGN="LEFT"/>default_device_backend_map : Dict[str, str]<br ALIGN="LEFT"/>|register_backend(name, func, extended_api, devices: Optional[Union[str, List[str]]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.BackendCompilerFailed" [color="black", fontcolor="red", label=<{BackendCompilerFailed|backend_name<br ALIGN="LEFT"/>inner_exception<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.backend_config.backend_config.BackendConfig" [color="black", fontcolor="black", label=<{BackendConfig|configs<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|from_dict(backend_config_dict: Dict[str, Any]): BackendConfig<br ALIGN="LEFT"/>set_backend_pattern_config(config: BackendPatternConfig): BackendConfig<br ALIGN="LEFT"/>set_backend_pattern_configs(configs: List[BackendPatternConfig]): BackendConfig<br ALIGN="LEFT"/>set_name(name: str): BackendConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d.BackendConfig" [color="black", fontcolor="black", label=<{BackendConfig|device_backend_map : Dict[str, Backend], dict<br ALIGN="LEFT"/>|get_device_backend_map(): Dict[str, Backend]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.BackendFeature" [color="black", fontcolor="black", label=<{BackendFeature|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.backend_config.backend_config.BackendPatternConfig" [color="black", fontcolor="black", label=<{BackendPatternConfig|dtype_configs : List[DTypeConfig]<br ALIGN="LEFT"/>fused_module : Optional[Type[torch.nn.Module]]<br ALIGN="LEFT"/>fuser_method : Optional[Callable]<br ALIGN="LEFT"/>observation_type : OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT<br ALIGN="LEFT"/>pattern : Optional[Pattern], Union<br ALIGN="LEFT"/>qat_module : Optional[Type[torch.nn.Module]]<br ALIGN="LEFT"/>reference_quantized_module : Optional[Type[torch.nn.Module]]<br ALIGN="LEFT"/>root_module : Optional[Type[torch.nn.Module]]<br ALIGN="LEFT"/>|add_dtype_config(dtype_config: DTypeConfig): BackendPatternConfig<br ALIGN="LEFT"/>from_dict(backend_pattern_config_dict: Dict[str, Any]): BackendPatternConfig<br ALIGN="LEFT"/>set_dtype_configs(dtype_configs: List[DTypeConfig]): BackendPatternConfig<br ALIGN="LEFT"/>set_fused_module(fused_module: Type[torch.nn.Module]): BackendPatternConfig<br ALIGN="LEFT"/>set_fuser_method(fuser_method: Callable): BackendPatternConfig<br ALIGN="LEFT"/>set_observation_type(observation_type: ObservationType): BackendPatternConfig<br ALIGN="LEFT"/>set_pattern(pattern: Pattern): BackendPatternConfig<br ALIGN="LEFT"/>set_qat_module(qat_module: Type[torch.nn.Module]): BackendPatternConfig<br ALIGN="LEFT"/>set_reference_quantized_module(reference_quantized_module: Type[torch.nn.Module]): BackendPatternConfig<br ALIGN="LEFT"/>set_root_module(root_module: Type[torch.nn.Module]): BackendPatternConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.graph_region_tracker.BackwardBfsArgIter" [color="black", fontcolor="black", label=<{BackwardBfsArgIter|<br ALIGN="LEFT"/>|add_children(node: Node): None<br ALIGN="LEFT"/>create(origin: Node): 'BackwardBfsArgIter'<br ALIGN="LEFT"/>next(): Optional[Node]<br ALIGN="LEFT"/>peek(): Optional[Node]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function.BackwardCFunction" [color="black", fontcolor="black", label=<{BackwardCFunction|<br ALIGN="LEFT"/>|apply()<br ALIGN="LEFT"/>apply_jvp()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hooks.BackwardHook" [color="black", fontcolor="black", label=<{BackwardHook|grad_outputs : NoneType, tuple<br ALIGN="LEFT"/>input_tensors_index : NoneType, list<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>n_inputs : int<br ALIGN="LEFT"/>n_outputs : int<br ALIGN="LEFT"/>output_tensors_index : NoneType, list<br ALIGN="LEFT"/>user_hooks<br ALIGN="LEFT"/>user_pre_hooks<br ALIGN="LEFT"/>|setup_input_hook(args)<br ALIGN="LEFT"/>setup_output_hook(args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules._functions.BackwardHookFunction" [color="black", fontcolor="black", label=<{BackwardHookFunction|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.BackwardHookVariable" [color="black", fontcolor="black", label=<{BackwardHookVariable|module<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>user_hooks<br ALIGN="LEFT"/>user_pre_hooks<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>create(tx, module: VariableTracker, user_hooks: VariableTracker, user_pre_hooks: VariableTracker)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.BackwardPrefetch" [color="black", fontcolor="black", label=<{BackwardPrefetch|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.BackwardSignature" [color="black", fontcolor="black", label=<{BackwardSignature|gradients_to_parameters : Dict[str, str]<br ALIGN="LEFT"/>gradients_to_user_inputs : Dict[str, str]<br ALIGN="LEFT"/>loss_output : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental._backward_state.BackwardState" [color="black", fontcolor="black", label=<{BackwardState|proxy<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.BackwardStateGraphArg" [color="black", fontcolor="black", label=<{BackwardStateGraphArg|<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.BackwardStateSource" [color="black", fontcolor="black", label=<{BackwardStateSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims_common.wrappers.backwards_not_supported.BackwardsNotSupported" [color="black", fontcolor="black", label=<{BackwardsNotSupported|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, args_spec)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.BadModule" [color="black", fontcolor="black", label=<{BadModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_gather_object.Bar" [color="black", fontcolor="black", label=<{Bar|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.Barrier" [color="black", fontcolor="black", label=<{Barrier|barrier_id : int<br ALIGN="LEFT"/>|init()<br ALIGN="LEFT"/>sync(wait_for, timeout)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.BaseConstant" [color="black", fontcolor="black", label=<{BaseConstant|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>|get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_scheduler.base_data_scheduler.BaseDataScheduler" [color="black", fontcolor="black", label=<{BaseDataScheduler|base_param<br ALIGN="LEFT"/>data_sparsifier<br ALIGN="LEFT"/>last_epoch : int<br ALIGN="LEFT"/>schedule_param : str<br ALIGN="LEFT"/>verbose : bool<br ALIGN="LEFT"/>|get_last_param()<br ALIGN="LEFT"/><I>get_schedule_param</I>()<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" [color="black", fontcolor="black", label=<{BaseDataSparsifier|data_groups : Dict[str, Dict]<br ALIGN="LEFT"/>|add_data(name: str, data, reuse_mask)<br ALIGN="LEFT"/>get_data(name: str, return_original: bool)<br ALIGN="LEFT"/>get_mask(name: str)<br ALIGN="LEFT"/>load_state_dict(state_dict, strict)<br ALIGN="LEFT"/><I>prepare</I>(model, config)<br ALIGN="LEFT"/>squash_mask()<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/><I>update_mask</I>(name, data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.BaseFunctionalizeAPI" [color="black", fontcolor="black", label=<{BaseFunctionalizeAPI|<br ALIGN="LEFT"/>|<I>commit_update</I>(tensor): None<br ALIGN="LEFT"/><I>functionalize</I>(inner_f: Callable): Callable<br ALIGN="LEFT"/><I>mark_mutation_hidden_from_autograd</I>(tensor): None<br ALIGN="LEFT"/><I>redispatch_to_next</I>(): ContextManager<br ALIGN="LEFT"/><I>replace</I>(input_tensor, output_tensor): None<br ALIGN="LEFT"/><I>sync</I>(tensor): None<br ALIGN="LEFT"/><I>unwrap_tensors</I>(args: Union[torch.Tensor, Tuple[torch.Tensor, ...]]): Any<br ALIGN="LEFT"/><I>wrap_tensors</I>(args: Tuple[Any]): Tuple[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.BaseListVariable" [color="black", fontcolor="black", label=<{BaseListVariable|items : List[VariableTracker]<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>cls_for(obj)<br ALIGN="LEFT"/>cls_for_instance(obj)<br ALIGN="LEFT"/>debug_repr_helper(prefix, suffix)<br ALIGN="LEFT"/>getitem_const(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>list_compare(tx: 'InstructionTranslator', op, left, right)<br ALIGN="LEFT"/>modified(items)<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.prune.BasePruningMethod" [color="black", fontcolor="black", label=<{BasePruningMethod|<br ALIGN="LEFT"/>|apply(module, name)<br ALIGN="LEFT"/>apply_mask(module)<br ALIGN="LEFT"/><I>compute_mask</I>(t, default_mask)<br ALIGN="LEFT"/>prune(t, default_mask, importance_scores)<br ALIGN="LEFT"/>remove(module)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.scheduler.base_scheduler.BaseScheduler" [color="black", fontcolor="black", label=<{BaseScheduler|base_sl<br ALIGN="LEFT"/>last_epoch : int<br ALIGN="LEFT"/>sparsifier<br ALIGN="LEFT"/>verbose : bool<br ALIGN="LEFT"/>|get_last_sl()<br ALIGN="LEFT"/>get_sl()<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>print_sl(is_verbose, group, sl, epoch)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step(epoch)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.BaseSchedulerNode" [color="black", fontcolor="black", label=<{BaseSchedulerNode|ancestors<br ALIGN="LEFT"/>debug_device_str : Callable[[BaseSchedulerNode], List[str]]<br ALIGN="LEFT"/>group : Tuple[torch.device, Tuple[Tuple[sympy.Expr, ...], ...]]<br ALIGN="LEFT"/>last_usage<br ALIGN="LEFT"/>max_order : int<br ALIGN="LEFT"/>min_order : int<br ALIGN="LEFT"/>mpi_node<br ALIGN="LEFT"/>node : Optional[ir.Operation]<br ALIGN="LEFT"/>outputs : List[SchedulerBuffer]<br ALIGN="LEFT"/>outputs_by_name : Dict[str, SchedulerBuffer]<br ALIGN="LEFT"/>read_writes<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>unmet_dependencies : OrderedSet[Dep]<br ALIGN="LEFT"/>written : bool<br ALIGN="LEFT"/>|add_fake_dep(dep: Dep): None<br ALIGN="LEFT"/>can_inplace(read_dep: dependencies.Dep): bool<br ALIGN="LEFT"/>codegen_originating_info(buffer: IndentedBuffer, only_once: bool): None<br ALIGN="LEFT"/>debug_str(): str<br ALIGN="LEFT"/>debug_str_extra(): str<br ALIGN="LEFT"/>debug_str_short(): str<br ALIGN="LEFT"/>decide_inplace_update(): None<br ALIGN="LEFT"/>get_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_estimated_runtime(): float<br ALIGN="LEFT"/>get_first_name(): str<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_nodes(): Sequence[BaseSchedulerNode]<br ALIGN="LEFT"/>get_operation_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_output(buf_name: str): SchedulerBuffer<br ALIGN="LEFT"/>get_outputs(): Sequence[SchedulerBuffer]<br ALIGN="LEFT"/>get_prologue_template_epilogue(nodes: List[BaseSchedulerNode]): Tuple[List[BaseSchedulerNode], BaseSchedulerNode, List[BaseSchedulerNode]]<br ALIGN="LEFT"/>get_read_buffer_sizes(): int<br ALIGN="LEFT"/>get_read_write_buffers_sizes(): int<br ALIGN="LEFT"/>get_read_write_buffers_sizes_impl(include_reads: bool, include_writes: bool): int<br ALIGN="LEFT"/>get_template_node(): Optional[ir.TemplateBuffer]<br ALIGN="LEFT"/>get_template_node_or_throw(): ir.TemplateBuffer<br ALIGN="LEFT"/>get_write_buffer_sizes(): int<br ALIGN="LEFT"/>has_aliasing_or_mutation(): bool<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>is_cpu(): bool<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>is_foreach(): bool<br ALIGN="LEFT"/>is_gpu(): bool<br ALIGN="LEFT"/>is_reduction(): bool<br ALIGN="LEFT"/>is_split_scan(): bool<br ALIGN="LEFT"/>is_template(): bool<br ALIGN="LEFT"/>log_details(): None<br ALIGN="LEFT"/>mark_run(): None<br ALIGN="LEFT"/>prune_deps(): None<br ALIGN="LEFT"/>prune_redundant_deps(name_to_fused_node: Dict[str, BaseSchedulerNode]): None<br ALIGN="LEFT"/>prune_weak_deps(): None<br ALIGN="LEFT"/>reorder_loops_by_dep_pair(self_dep: MemoryDep, other_dep: MemoryDep): None<br ALIGN="LEFT"/>set_last_usage(future_used_buffers: OrderedSet[str], mutation_real_name: Dict[str, str]): None<br ALIGN="LEFT"/>set_read_writes(rw: dependencies.ReadWrites): None<br ALIGN="LEFT"/>update_mutated_names(renames: Dict[str, str]): None<br ALIGN="LEFT"/>used_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>used_or_aliased_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.BaseScheduling" [color="black", fontcolor="black", label=<{BaseScheduling|<br ALIGN="LEFT"/>|<I>benchmark_combo_kernel</I>(node_list: Sequence[BaseSchedulerNode]): Tuple[float, float, str]<br ALIGN="LEFT"/><I>benchmark_fused_nodes</I>(nodes: Sequence[BaseSchedulerNode]): Tuple[float, str]<br ALIGN="LEFT"/><I>can_fuse_horizontal</I>(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/><I>can_fuse_vertical</I>(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/><I>codegen_node</I>(node: Union[FusedSchedulerNode, SchedulerNode]): None<br ALIGN="LEFT"/><I>codegen_sync</I>(): None<br ALIGN="LEFT"/><I>codegen_template</I>(template_node: BaseSchedulerNode, epilogue_nodes: Sequence[BaseSchedulerNode], prologue_nodes: Sequence[BaseSchedulerNode]): Optional[str]<br ALIGN="LEFT"/><I>flush</I>(): None<br ALIGN="LEFT"/>fuse(node1: BaseSchedulerNode, node2: BaseSchedulerNode): FusedSchedulerNode<br ALIGN="LEFT"/>get_backend_features(device: torch.device): Sequence[BackendFeature]<br ALIGN="LEFT"/>get_fusion_pair_priority(node1: BaseSchedulerNode, node2: BaseSchedulerNode): int<br ALIGN="LEFT"/><I>group_fn</I>(sizes: Sequence[Sequence[sympy.Expr]]): Tuple[Tuple[sympy.Expr, ...], ...]<br ALIGN="LEFT"/>ready_to_flush(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [color="black", fontcolor="black", label=<{BaseSparsifier|config : list<br ALIGN="LEFT"/>defaults : Dict[str, Any]<br ALIGN="LEFT"/>enable_mask_update : bool<br ALIGN="LEFT"/>groups : List[Dict[str, Any]]<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>state : Dict[str, Dict]<br ALIGN="LEFT"/>|convert(module: nn.Module, mapping: Optional[Dict[Type[nn.Module], Type[nn.Module]]], inplace: bool, parameterization: Type[nn.Module])<br ALIGN="LEFT"/>load_state_dict(state_dict: Dict[str, Any], strict: bool)<br ALIGN="LEFT"/>make_config_from_model(model: nn.Module, SUPPORTED_MODULES: Set[Type]): None<br ALIGN="LEFT"/>prepare(model, config)<br ALIGN="LEFT"/>squash_mask(params_to_keep: Optional[Tuple[str, ...]], params_to_keep_per_layer: Optional[Dict[str, Tuple[str, ...]]])<br ALIGN="LEFT"/>state_dict(): Dict[str, Any]<br ALIGN="LEFT"/>step(use_path: bool): None<br ALIGN="LEFT"/><I>update_mask</I>(module: nn.Module, tensor_name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" [color="black", fontcolor="black", label=<{BaseStructuredSparsifier|patterns : NoneType, dict<br ALIGN="LEFT"/>traced<br ALIGN="LEFT"/>|make_config_from_model(model: nn.Module, SUPPORTED_MODULES: Optional[Set[Type]]): None<br ALIGN="LEFT"/>prune(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._python_dispatch.BaseTorchDispatchMode" [color="black", fontcolor="black", label=<{BaseTorchDispatchMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.overrides.BaseTorchFunctionMode" [color="black", fontcolor="black", label=<{BaseTorchFunctionMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.torch.BaseTorchVariable" [color="black", fontcolor="black", label=<{BaseTorchVariable|value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>can_constant_fold_through()<br ALIGN="LEFT"/>create_with_source(value, source)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.BaseUserFunctionVariable" [color="black", fontcolor="black", label=<{BaseUserFunctionVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>closure_vars(tx)<br ALIGN="LEFT"/>get_filename()<br ALIGN="LEFT"/>get_name()<br ALIGN="LEFT"/>inspect_parameter_names()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.BaseView" [color="black", fontcolor="black", label=<{BaseView|data<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_layout(): Layout<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_pointwise_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_storage_numel()<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[Symbol]<br ALIGN="LEFT"/>has_exceeded_max_reads(): bool<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>is_module_buffer(): bool<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/><I>make_reindexer</I>(): Callable[[Sequence[Expr]], Sequence[Expr]]<br ALIGN="LEFT"/>mark_reuse(users: int): None<br ALIGN="LEFT"/>realize(): Optional[str]<br ALIGN="LEFT"/>realize_hint()<br ALIGN="LEFT"/>unwrap_view()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._utils.BasicEvaluation" [color="black", fontcolor="black", label=<{BasicEvaluation|cuda_events : List[_KinetoEvent]<br ALIGN="LEFT"/>event_keys<br ALIGN="LEFT"/>events<br ALIGN="LEFT"/>metrics : Dict[EventKey, EventMetrics]<br ALIGN="LEFT"/>profile<br ALIGN="LEFT"/>queue_depth_list : list<br ALIGN="LEFT"/>|compute_idle_time()<br ALIGN="LEFT"/>compute_queue_depth()<br ALIGN="LEFT"/>compute_self_time()<br ALIGN="LEFT"/>get_optimizable_events(length: int, print_enable: bool)<br ALIGN="LEFT"/>rank_events(length)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchAddPostGradFusion" [color="black", fontcolor="black", label=<{BatchAddPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchClampPreGradFusion" [color="black", fontcolor="black", label=<{BatchClampPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchDetachPreGradFusion" [color="black", fontcolor="black", label=<{BatchDetachPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchDivPostGradFusion" [color="black", fontcolor="black", label=<{BatchDivPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [color="black", fontcolor="black", label=<{BatchFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchLayernormFusion" [color="black", fontcolor="black", label=<{BatchLayernormFusion|<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchLinearLHSFusion" [color="black", fontcolor="black", label=<{BatchLinearLHSFusion|<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node): Optional[Tuple[str, bool, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchMathOpsPreGradFusion" [color="black", fontcolor="black", label=<{BatchMathOpsPreGradFusion|op<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchMulPostGradFusion" [color="black", fontcolor="black", label=<{BatchMulPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchNanToNumPreGradFusion" [color="black", fontcolor="black", label=<{BatchNanToNumPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" [color="black", fontcolor="black", label=<{BatchNorm1d|bias<br ALIGN="LEFT"/>num_batches_tracked<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d" [color="black", fontcolor="black", label=<{BatchNorm2d|<br ALIGN="LEFT"/>|forward(input: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" [color="black", fontcolor="black", label=<{BatchNorm2d|bias<br ALIGN="LEFT"/>num_batches_tracked<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d" [color="black", fontcolor="black", label=<{BatchNorm3d|<br ALIGN="LEFT"/>|forward(input: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm3d" [color="black", fontcolor="black", label=<{BatchNorm3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.BatchNormNet" [color="black", fontcolor="black", label=<{BatchNormNet|bn<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.BatchNormQuantizeHandler" [color="black", fontcolor="black", label=<{BatchNormQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" [color="black", fontcolor="black", label=<{BatchPointwiseMathOpsPostGradFusion|op<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" [color="black", fontcolor="black", label=<{BatchPointwiseOpsFusionFactory|op<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPostGradFusion" [color="black", fontcolor="black", label=<{BatchPointwiseOpsPostGradFusion|op<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPreGradFusion" [color="black", fontcolor="black", label=<{BatchPointwiseOpsPreGradFusion|op<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchReLuPostGradFusion" [color="black", fontcolor="black", label=<{BatchReLuPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchReLuPreGradFusion" [color="black", fontcolor="black", label=<{BatchReLuPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.sampler.BatchSampler" [color="black", fontcolor="black", label=<{BatchSampler|batch_size : int<br ALIGN="LEFT"/>drop_last : bool<br ALIGN="LEFT"/>sampler : Union[Sampler[int], Iterable[int]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSigmoidPostGradFusion" [color="black", fontcolor="black", label=<{BatchSigmoidPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSigmoidPreGradFusion" [color="black", fontcolor="black", label=<{BatchSigmoidPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSubPostGradFusion" [color="black", fontcolor="black", label=<{BatchSubPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchTanhPostGradFusion" [color="black", fontcolor="black", label=<{BatchTanhPostGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.BatchTanhPreGradFusion" [color="black", fontcolor="black", label=<{BatchTanhPreGradFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.parameter_server_test.BatchUpdateParameterServer" [color="black", fontcolor="black", label=<{BatchUpdateParameterServer|batch_update_size<br ALIGN="LEFT"/>curr_update_size : int<br ALIGN="LEFT"/>future_model<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>|get_model()<br ALIGN="LEFT"/>update_and_fetch_model(ps_rref, grads)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.grouping.BatcherIterDataPipe" [color="black", fontcolor="black", label=<{BatcherIterDataPipe|batch_size : int<br ALIGN="LEFT"/>datapipe<br ALIGN="LEFT"/>drop_last : bool<br ALIGN="LEFT"/>wrapper_class : Type[DataChunk]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.grouping.BatcherMapDataPipe" [color="black", fontcolor="black", label=<{BatcherMapDataPipe|batch_size : int<br ALIGN="LEFT"/>datapipe<br ALIGN="LEFT"/>drop_last : bool<br ALIGN="LEFT"/>wrapper_class : Type[DataChunk]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autotune_process.BenchmarkRequest" [color="black", fontcolor="black", label=<{BenchmarkRequest|extra_args : Iterable[Any]<br ALIGN="LEFT"/>input_tensor_meta : Union[TensorMeta, List[TensorMeta]]<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>output_tensor_meta : Union[TensorMeta, List[TensorMeta]]<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/><I>cleanup_run_fn</I>(): None<br ALIGN="LEFT"/><I>do_bench</I>(fn): float<br ALIGN="LEFT"/><I>make_run_fn</I>(): Callable[[], None]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.BenchmarkTensors" [color="black", fontcolor="black", label=<{BenchmarkTensors|input_tensors : List[torch.Tensor]<br ALIGN="LEFT"/>output_tensor : Optional[torch.Tensor]<br ALIGN="LEFT"/>|unpack()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.benchmarking.Benchmarker" [color="black", fontcolor="black", label=<{Benchmarker|<br ALIGN="LEFT"/>|benchmark(fn: Callable[..., Any], fn_args: Tuple[Any, ...], fn_kwargs: Dict[str, Any]): float<br ALIGN="LEFT"/>benchmark_cpu(_callable: Callable[[], Any], warmup: int, rep: int): float<br ALIGN="LEFT"/><I>benchmark_gpu</I>(): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.bernoulli.Bernoulli" [color="black", fontcolor="black", label=<{Bernoulli|arg_constraints : dict<br ALIGN="LEFT"/>has_enumerate_support : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>enumerate_support(expand)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.beta.Beta" [color="black", fontcolor="black", label=<{Beta|arg_constraints : dict<br ALIGN="LEFT"/>concentration0<br ALIGN="LEFT"/>concentration1<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.parametrization.BiasHook" [color="black", fontcolor="black", label=<{BiasHook|param<br ALIGN="LEFT"/>prune_bias<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.linear.Bilinear" [color="black", fontcolor="black", label=<{Bilinear|bias<br ALIGN="LEFT"/>in1_features : int<br ALIGN="LEFT"/>in2_features : int<br ALIGN="LEFT"/>out_features : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input1: Tensor, input2: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinConstraintD" [color="black", fontcolor="black", label=<{BinConstraintD|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinConstraintT" [color="black", fontcolor="black", label=<{BinConstraintT|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinaryConstraint" [color="black", fontcolor="black", label=<{BinaryConstraint|lhs<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>rhs<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.op_fuzzers.binary.BinaryOpFuzzer" [color="black", fontcolor="black", label=<{BinaryOpFuzzer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.BinaryOpQuantizeHandler" [color="black", fontcolor="black", label=<{BinaryOpQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.op_fuzzers.sparse_binary.BinaryOpSparseFuzzer" [color="black", fontcolor="black", label=<{BinaryOpSparseFuzzer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.BinarySubsystem" [color="black", fontcolor="black", label=<{BinarySubsystem|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.BinaryUfuncInfo" [color="black", fontcolor="black", label=<{BinaryUfuncInfo|always_returns_bool : bool<br ALIGN="LEFT"/>lhs_make_tensor_kwargs : NoneType, dict<br ALIGN="LEFT"/>rhs_make_tensor_kwargs : NoneType, dict<br ALIGN="LEFT"/>sample_kwargs<br ALIGN="LEFT"/>supports_one_python_scalar : bool<br ALIGN="LEFT"/>supports_rhs_python_scalar : bool<br ALIGN="LEFT"/>supports_two_python_scalars : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.quantization._register_quantization_binary_fusion.BinaryUnaryAttr" [color="black", fontcolor="black", label=<{BinaryUnaryAttr|algorithm_attr : str<br ALIGN="LEFT"/>alpha : float<br ALIGN="LEFT"/>binary_op_name : str<br ALIGN="LEFT"/>scalars_attr : list<br ALIGN="LEFT"/>unary_op_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.BindInputStep" [color="black", fontcolor="black", label=<{BindInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.binomial.Binomial" [color="black", fontcolor="black", label=<{Binomial|arg_constraints : dict<br ALIGN="LEFT"/>has_enumerate_support : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>total_count<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>enumerate_support(expand)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.BisectSubsystem" [color="black", fontcolor="black", label=<{BisectSubsystem|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator.BisectValidationException" [color="black", fontcolor="red", label=<{BisectValidationException|details : str<br ALIGN="LEFT"/>msg : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.BisectionResult" [color="black", fontcolor="black", label=<{BisectionResult|backend : str<br ALIGN="LEFT"/>bisect_number : Optional[int]<br ALIGN="LEFT"/>debug_info : Optional[str]<br ALIGN="LEFT"/>subsystem : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.make_opaque_bitwise_fn.BitwiseFn" [color="black", fontcolor="black", label=<{BitwiseFn|<br ALIGN="LEFT"/>|eval(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.attention.flex_attention.BlockMask" [color="black", fontcolor="black", label=<{BlockMask|BLOCK_SIZE : Tuple[int, int]<br ALIGN="LEFT"/>full_kv_indices : Optional[Tensor]<br ALIGN="LEFT"/>full_kv_num_blocks : Optional[Tensor]<br ALIGN="LEFT"/>full_q_indices : Optional[Tensor]<br ALIGN="LEFT"/>full_q_num_blocks : Optional[Tensor]<br ALIGN="LEFT"/>kv_indices<br ALIGN="LEFT"/>kv_num_blocks<br ALIGN="LEFT"/>mask_mod : Callable<br ALIGN="LEFT"/>q_indices : Optional[Tensor]<br ALIGN="LEFT"/>q_num_blocks : Optional[Tensor]<br ALIGN="LEFT"/>seq_lengths : Tuple[int, int]<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|as_tuple(flatten: bool)<br ALIGN="LEFT"/>from_kv_blocks(kv_num_blocks: Tensor, kv_indices: Tensor, full_kv_num_blocks: Optional[Tensor], full_kv_indices: Optional[Tensor], BLOCK_SIZE: Union[int, Tuple[int, int]], mask_mod: Optional[_mask_mod_signature], seq_lengths: Optional[Tuple[int, int]])<br ALIGN="LEFT"/>numel()<br ALIGN="LEFT"/>sparsity(): float<br ALIGN="LEFT"/>to(device: Union[torch.device, str]): 'BlockMask'<br ALIGN="LEFT"/>to_dense(): Tensor<br ALIGN="LEFT"/>to_string(grid_size, limit)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.BlockParameters" [color="black", fontcolor="black", label=<{BlockParameters|block_shape : List[sympy.Expr]<br ALIGN="LEFT"/>offsets : List[sympy.Expr]<br ALIGN="LEFT"/>shape : List[sympy.Expr]<br ALIGN="LEFT"/>strides : List[sympy.Expr]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.block_analysis.BlockPatternMatcher" [color="black", fontcolor="black", label=<{BlockPatternMatcher|<br ALIGN="LEFT"/>|get_slice_numels(dims: List[Expr]): List[Expr]<br ALIGN="LEFT"/>get_subexpr_involving_symbol(expr: Expr, symbol: Symbol): Expr<br ALIGN="LEFT"/>match_mod_div_block_expr(index: Expr, index_var: Symbol, numel: Expr, num_dims: int): Optional[Tuple[List[Expr], List[Expr], List[Expr]]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.BlockPtrOptions" [color="black", fontcolor="black", label=<{BlockPtrOptions|block_shape<br ALIGN="LEFT"/>broadcast_shape : Sequence[sympy.Expr]<br ALIGN="LEFT"/>broadcasting_dims : List[bool]<br ALIGN="LEFT"/>constant_offset : Expr<br ALIGN="LEFT"/>final_shape : Sequence[sympy.Expr]<br ALIGN="LEFT"/>mask_vars : OrderedSet[str]<br ALIGN="LEFT"/>offsets<br ALIGN="LEFT"/>order : List[int]<br ALIGN="LEFT"/>params<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>strides<br ALIGN="LEFT"/>|advance_roffset()<br ALIGN="LEFT"/>boundary_check()<br ALIGN="LEFT"/>codegen_broadcast_and_reshape(value: str, initial_shape: Sequence[sympy.Expr], final_shape: Sequence[sympy.Expr], allow_implicit: bool): str<br ALIGN="LEFT"/>compute_boundary_check(get_max_block: Callable[[str], int]): None<br ALIGN="LEFT"/>create(): BlockPtrOptions<br ALIGN="LEFT"/>format(name: str, roffset): str<br ALIGN="LEFT"/>has_indirect()<br ALIGN="LEFT"/>has_mask()<br ALIGN="LEFT"/>has_rindex(): bool<br ALIGN="LEFT"/>has_rmask()<br ALIGN="LEFT"/>has_tmpmask()<br ALIGN="LEFT"/>replace_roffset(expr: sympy.Expr, replacement: sympy.Expr): sympy.Expr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.BlockStackEntry" [color="black", fontcolor="black", label=<{BlockStackEntry|inst<br ALIGN="LEFT"/>stack_index : Optional[int]<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>with_context : Optional[Union[ContextWrappingVariable, GenericContextWrappingVariable]]<br ALIGN="LEFT"/>|can_restore()<br ALIGN="LEFT"/>exit(tx, is_graph_break)<br ALIGN="LEFT"/>resume_fn()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.staging.BlockingAsyncStager" [color="black", fontcolor="black", label=<{BlockingAsyncStager|cache_staged_state_dict : bool<br ALIGN="LEFT"/>state_dict_cache : Optional[STATE_DICT_TYPE], tuple<br ALIGN="LEFT"/>type_check : bool<br ALIGN="LEFT"/>|stage(state_dict: STATE_DICT_TYPE): STATE_DICT_TYPE<br ALIGN="LEFT"/><I>synchronize_staging</I>(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.BoolStorage" [color="black", fontcolor="black", label=<{BoolStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.BoolStorage" [color="black", fontcolor="black", label=<{BoolStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing.Boolean" [color="black", fontcolor="black", label=<{Boolean|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._comparison.BooleanPair" [color="black", fontcolor="black", label=<{BooleanPair|<br ALIGN="LEFT"/>|compare(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.bounds.BoundVars" [color="black", fontcolor="black", label=<{BoundVars|loop_body<br ALIGN="LEFT"/>replacement_vals<br ALIGN="LEFT"/>unbounded_vars<br ALIGN="LEFT"/>|get_bounds(): Dict[torch.fx.Node, ValueRanges[Expr]]<br ALIGN="LEFT"/>get_index(name: str): ValueRanges[Expr]<br ALIGN="LEFT"/>masked_subblock(subblock: LoopBodyBlock, env: Dict[torch.fx.Node, ValueRanges[Expr]], mask: Any, value: Any, submodules: Dict[str, Callable[..., Any]]): ValueRanges[Expr]<br ALIGN="LEFT"/>set_indirect(old: Expr, new: ValueRanges[Expr]): ValueRanges[Expr]<br ALIGN="LEFT"/>swap_submodules(submodules: Dict[str, Callable[..., Any]]): Dict[str, Callable[..., ValueRanges[Expr]]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.BoxedBool" [color="black", fontcolor="black", label=<{BoxedBool|value : bool<br ALIGN="LEFT"/>|disable(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.BoxedDeviceIndex" [color="black", fontcolor="black", label=<{BoxedDeviceIndex|value : Optional[int]<br ALIGN="LEFT"/>|set(device_idx: Optional[int])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.BracesBuffer" [color="black", fontcolor="black", label=<{BracesBuffer|is_vec : bool<br ALIGN="LEFT"/>|indent(offset)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.Broadcast" [color="black", fontcolor="black", label=<{Broadcast|dim<br ALIGN="LEFT"/>dim_size : int<br ALIGN="LEFT"/>|inputs(): Iterable[DimSpec]<br ALIGN="LEFT"/>new(dim: DimSpec, dim_size: int): DimSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.Broadcast" [color="black", fontcolor="black", label=<{Broadcast|src<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel._functions.Broadcast" [color="black", fontcolor="black", label=<{Broadcast|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, target_gpus)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._jit_internal.BroadcastingListCls" [color="black", fontcolor="black", label=<{BroadcastingListCls|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader" [color="black", fontcolor="black", label=<{BroadcastingTorchSaveReader|checkpoint_id : Optional[Union[str, os.PathLike, None]], Optional[Union[str, os.PathLike]]<br ALIGN="LEFT"/>coordinator_rank : int<br ALIGN="LEFT"/>is_coordinator : bool<br ALIGN="LEFT"/>|prepare_global_plan(global_plan: List[LoadPlan]): List[LoadPlan]<br ALIGN="LEFT"/>prepare_local_plan(plan: LoadPlan): LoadPlan<br ALIGN="LEFT"/>read_data(plan: LoadPlan, planner: LoadPlanner): Future[None]<br ALIGN="LEFT"/>read_metadata(): Metadata<br ALIGN="LEFT"/>reset(checkpoint_id: Union[str, os.PathLike, None]): None<br ALIGN="LEFT"/>set_up_storage_reader(metadata: Metadata, is_coordinator: bool): None<br ALIGN="LEFT"/>validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.BuckTargetWriter" [color="black", fontcolor="black", label=<{BuckTargetWriter|cmd_line_path : str<br ALIGN="LEFT"/>path : str<br ALIGN="LEFT"/>py_file<br ALIGN="LEFT"/>subdir<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|build()<br ALIGN="LEFT"/>write(print_msg)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.distributed.Bucket" [color="black", fontcolor="black", label=<{Bucket|nodes : List[fx.Node]<br ALIGN="LEFT"/>opcount_increased_to_capture_external_output : int<br ALIGN="LEFT"/>param_ids : List<br ALIGN="LEFT"/>params : List[str]<br ALIGN="LEFT"/>paramsize_before_opcount_increase : int<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Buffer" [color="black", fontcolor="black", label=<{Buffer|dtype<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/><I>decide_layout</I>()<br ALIGN="LEFT"/>freeze_layout()<br ALIGN="LEFT"/>freeze_layout_with_exact_strides(exact_strides, allow_padding): None<br ALIGN="LEFT"/>freeze_layout_with_fill_order(order): None<br ALIGN="LEFT"/>freeze_layout_with_same_order(stride): None<br ALIGN="LEFT"/>freeze_layout_with_stride_order(order, allow_padding): None<br ALIGN="LEFT"/>get_defining_op(): Optional[Operation]<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>get_layout(): Layout<br ALIGN="LEFT"/>get_mutation_names(): Sequence[str]<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_offset(): Expr<br ALIGN="LEFT"/>get_output_spec(): OutputSpec<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_storage_numel()<br ALIGN="LEFT"/>get_stride(): List[Expr]<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>is_zero_elements()<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/><I>realize</I>(): Optional[str]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parameter.Buffer" [color="black", fontcolor="black", label=<{Buffer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.BufferGroup" [color="black", fontcolor="black", label=<{BufferGroup|allocation : Optional[Allocation]<br ALIGN="LEFT"/>is_output : bool<br ALIGN="LEFT"/>live_range<br ALIGN="LEFT"/>names : list<br ALIGN="LEFT"/>node : Union<br ALIGN="LEFT"/>|make_allocation()<br ALIGN="LEFT"/>sym_nbytes()<br ALIGN="LEFT"/>update_usage(timestep: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.memory.estimate_peak_memory.BufferInfo" [color="black", fontcolor="black", label=<{BufferInfo|buffer : Union[SchedulerBuffer, FreeableInputBuffer]<br ALIGN="LEFT"/>end_step : int<br ALIGN="LEFT"/>size_alloc : int<br ALIGN="LEFT"/>size_free : int<br ALIGN="LEFT"/>start_step : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.memory.topological_sort_lpmf.BufferInfo" [color="black", fontcolor="black", label=<{BufferInfo|outdegree : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.BufferMutationSpec" [color="black", fontcolor="black", label=<{BufferMutationSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>buffer_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.cpp_extension.BuildExtension" [color="black", fontcolor="black", label=<{BuildExtension|cflags : NoneType<br ALIGN="LEFT"/>force : bool<br ALIGN="LEFT"/>no_python_abi_suffix<br ALIGN="LEFT"/>use_ninja : bool<br ALIGN="LEFT"/>|build_extensions(): None<br ALIGN="LEFT"/>finalize_options(): None<br ALIGN="LEFT"/>get_ext_filename(ext_name)<br ALIGN="LEFT"/>with_options()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cpp_builder.BuildOptionsBase" [color="black", fontcolor="black", label=<{BuildOptionsBase|<br ALIGN="LEFT"/>|get_aot_mode(): bool<br ALIGN="LEFT"/>get_cflags(): List[str]<br ALIGN="LEFT"/>get_compile_only(): bool<br ALIGN="LEFT"/>get_compiler(): str<br ALIGN="LEFT"/>get_definations(): List[str]<br ALIGN="LEFT"/>get_include_dirs(): List[str]<br ALIGN="LEFT"/>get_ldflags(): List[str]<br ALIGN="LEFT"/>get_libraries(): List[str]<br ALIGN="LEFT"/>get_libraries_dirs(): List[str]<br ALIGN="LEFT"/>get_passthough_args(): List[str]<br ALIGN="LEFT"/>get_use_absolute_path(): bool<br ALIGN="LEFT"/>save_flags_to_file(file: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.frontend.Builder" [color="black", fontcolor="black", label=<{Builder|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builtin.BuiltinVariable" [color="black", fontcolor="black", label=<{BuiltinVariable|call_float<br ALIGN="LEFT"/>call_function_handler_cache : dict<br ALIGN="LEFT"/>call_iand<br ALIGN="LEFT"/>call_int<br ALIGN="LEFT"/>call_ior<br ALIGN="LEFT"/>call_list<br ALIGN="LEFT"/>call_max<br ALIGN="LEFT"/>call_min<br ALIGN="LEFT"/>call_tuple<br ALIGN="LEFT"/>fn<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_abs(tx: 'InstructionTranslator', arg: 'VariableTracker')<br ALIGN="LEFT"/>call_and_(tx: 'InstructionTranslator', a, b)<br ALIGN="LEFT"/>call_callable(tx: 'InstructionTranslator', arg)<br ALIGN="LEFT"/>call_cast(_)<br ALIGN="LEFT"/>call_contains(tx: 'InstructionTranslator', a: VariableTracker, b: VariableTracker)<br ALIGN="LEFT"/>call_custom_dict(tx: 'InstructionTranslator', user_cls)<br ALIGN="LEFT"/>call_custom_dict_fromkeys(tx: 'InstructionTranslator', user_cls)<br ALIGN="LEFT"/>call_deepcopy(tx: 'InstructionTranslator', x)<br ALIGN="LEFT"/>call_delattr(tx: 'InstructionTranslator', obj: VariableTracker, name_var: VariableTracker)<br ALIGN="LEFT"/>call_dict(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_filter(tx: 'InstructionTranslator', fn, seq)<br ALIGN="LEFT"/>call_format(tx: 'InstructionTranslator', _format_string)<br ALIGN="LEFT"/>call_frozenset(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_getattr(tx: 'InstructionTranslator', obj: VariableTracker, name_var: VariableTracker, default)<br ALIGN="LEFT"/>call_getitem(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', obj, attr)<br ALIGN="LEFT"/>call_id(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_index(tx: 'InstructionTranslator', arg: 'VariableTracker')<br ALIGN="LEFT"/>call_isinstance(tx: 'InstructionTranslator', arg, isinstance_type)<br ALIGN="LEFT"/>call_issubclass(tx: 'InstructionTranslator', left_ty, right_ty)<br ALIGN="LEFT"/>call_iter(tx: 'InstructionTranslator', obj)<br ALIGN="LEFT"/>call_len(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_map(tx: 'InstructionTranslator', fn)<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_neg(tx: 'InstructionTranslator', a)<br ALIGN="LEFT"/>call_next(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>call_not_(tx: 'InstructionTranslator', a)<br ALIGN="LEFT"/>call_or_(tx: 'InstructionTranslator', a, b)<br ALIGN="LEFT"/>call_pos(tx: 'InstructionTranslator', arg: 'VariableTracker')<br ALIGN="LEFT"/>call_range(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_reversed(tx: 'InstructionTranslator', obj: VariableTracker)<br ALIGN="LEFT"/>call_round(tx: 'InstructionTranslator', arg)<br ALIGN="LEFT"/>call_set(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_setattr(tx: 'InstructionTranslator', obj: VariableTracker, name_var: VariableTracker, val: VariableTracker)<br ALIGN="LEFT"/>call_slice(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>call_sorted(tx: 'InstructionTranslator', obj: VariableTracker)<br ALIGN="LEFT"/>call_str(tx: 'InstructionTranslator', arg)<br ALIGN="LEFT"/>call_super(tx: 'InstructionTranslator', a, b)<br ALIGN="LEFT"/>call_type(tx: 'InstructionTranslator', obj: VariableTracker)<br ALIGN="LEFT"/>call_zip(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>can_constant_fold_through()<br ALIGN="LEFT"/>can_insert_in_graph()<br ALIGN="LEFT"/>constant_args()<br ALIGN="LEFT"/>create_with_source(value, source)<br ALIGN="LEFT"/>has_constant_handler(args, kwargs)<br ALIGN="LEFT"/>python_and_tensor_constant_only()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>tensor_args()<br ALIGN="LEFT"/>tensor_args_type(arg_types)<br ALIGN="LEFT"/>unwrap_unspec_args_kwargs(args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.BypassAOTAutogradCache" [color="black", fontcolor="red", label=<{BypassAOTAutogradCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codecache.BypassFxGraphCache" [color="black", fontcolor="red", label=<{BypassFxGraphCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ByteStorage" [color="black", fontcolor="black", label=<{ByteStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ByteStorage" [color="black", fontcolor="black", label=<{ByteStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.BytecodeDistpatchTableMeta" [color="black", fontcolor="black", label=<{BytecodeDistpatchTableMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.types.BytecodeHook" [color="black", fontcolor="black", label=<{BytecodeHook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._memory_viz.Bytes" [color="black", fontcolor="black", label=<{Bytes|value<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.BytesIOContext" [color="black", fontcolor="black", label=<{BytesIOContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.BytesStorageMetadata" [color="black", fontcolor="black", label=<{BytesStorageMetadata|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend" [color="black", fontcolor="black", label=<{C10dRendezvousBackend|name<br ALIGN="LEFT"/>|get_state(): Optional[Tuple[bytes, Token]]<br ALIGN="LEFT"/>set_state(state: bytes, token: Optional[Token]): Optional[Tuple[bytes, Token, bool]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.CELU" [color="black", fontcolor="black", label=<{CELU|alpha : float<br ALIGN="LEFT"/>inplace : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.ck_universal_gemm_template.CKGemmTemplate" [color="black", fontcolor="black", label=<{CKGemmTemplate|alpha : float<br ALIGN="LEFT"/>beta : float<br ALIGN="LEFT"/>gemm_template : str<br ALIGN="LEFT"/>is_batched<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>standalone_runner_template : str<br ALIGN="LEFT"/>|add_ck_gemm_choices(choices, layout, input_nodes, alpha, beta, input_reorder)<br ALIGN="LEFT"/>emit_ck_instance(op: 'CKGemmOperation')<br ALIGN="LEFT"/>filter_op(op: 'CKGemmOperation')<br ALIGN="LEFT"/>gen_ops()<br ALIGN="LEFT"/>globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/>inline_utils()<br ALIGN="LEFT"/>render(kernel: ROCmTemplateKernel, op: 'CKGemmOperation'): str<br ALIGN="LEFT"/>size_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.ck_conv_template.CKGroupedConvFwdTemplate" [color="black", fontcolor="black", label=<{CKGroupedConvFwdTemplate|conv_template : str<br ALIGN="LEFT"/>dilation<br ALIGN="LEFT"/>groups<br ALIGN="LEFT"/>n_spatial_dimensions<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>padding<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>|add_ck_conv_choices(choices, layout, input_nodes)<br ALIGN="LEFT"/>emit_ck_instance(op: 'CKGroupedConvFwdOp'): Tuple[str, str]<br ALIGN="LEFT"/>filter_op(op: 'CKGroupedConvFwdOp')<br ALIGN="LEFT"/>gen_ops()<br ALIGN="LEFT"/>globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/>render(kernel: ROCmTemplateKernel, op: 'CKGroupedConvFwdOp'): str<br ALIGN="LEFT"/>size_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.ck_template.CKTemplate" [color="black", fontcolor="black", label=<{CKTemplate|<br ALIGN="LEFT"/>|globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/>torch_type_to_ck(node: IRNode, ptr: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.timer.CPPTimer" [color="black", fontcolor="black", label=<{CPPTimer|<br ALIGN="LEFT"/>|timeit(number: int): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.CPUDeviceBenchmarkMixin" [color="black", fontcolor="black", label=<{CPUDeviceBenchmarkMixin|<br ALIGN="LEFT"/>|do_bench(fn): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.CPUOffload" [color="black", fontcolor="black", label=<{CPUOffload|offload_params : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.CPUOffloadPolicy" [color="black", fontcolor="black", label=<{CPUOffloadPolicy|pin_memory : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.CPUTestBase" [color="black", fontcolor="black", label=<{CPUTestBase|device_type : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.CSE" [color="black", fontcolor="black", label=<{CSE|invalidated_stores<br ALIGN="LEFT"/>iter_buffer_ids : count<br ALIGN="LEFT"/>name_prefix : str<br ALIGN="LEFT"/>prefix : str<br ALIGN="LEFT"/>reduction_cache : dict<br ALIGN="LEFT"/>store_cache : dict<br ALIGN="LEFT"/>suffix : str<br ALIGN="LEFT"/>varname_map : dict<br ALIGN="LEFT"/>|augment_key(cache_key: object): object<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>contains(cache_key): bool<br ALIGN="LEFT"/>generate(buffer: IndentedBuffer, expr: Union[str, CSEVariable, OpsValue, IndentedBuffer, DeferredLineBase]): CSEVariable<br ALIGN="LEFT"/>get(cache_key: object): CSEVariable<br ALIGN="LEFT"/>invalidate(keep_vars: Union[OrderedSet[str], OrderedSet[Never]])<br ALIGN="LEFT"/>namedvar(name: str, bounds: ValueRanges[Any], dtype: Optional[torch.dtype]): CSEVariable<br ALIGN="LEFT"/>newvar(bounds: ValueRanges[Any], dtype: Optional[torch.dtype]): CSEVariable<br ALIGN="LEFT"/>put(cache_key: object, val: CSEVariable): None<br ALIGN="LEFT"/>try_get(cache_key: object): Optional[CSEVariable]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.dialect.common.cse_pass.CSEPass" [color="black", fontcolor="black", label=<{CSEPass|banned_ops : NoneType, set<br ALIGN="LEFT"/>|call(graph_module: GraphModule): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.Kernel.__enter__.CSEProxy" [color="black", fontcolor="black", label=<{CSEProxy|vr_analysis<br ALIGN="LEFT"/>|bucketize(values: CSEVariable, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: CSEVariable, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[CSEVariable]): CSEVariable<br ALIGN="LEFT"/>check_bounds(expr: sympy.Expr, size: sympy.Expr, lower: bool, upper: bool)<br ALIGN="LEFT"/>indirect_indexing(var: CSEVariable, size: Union[sympy.Expr, int], check: bool, wrap_neg)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr): CSEVariable<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[CSEVariable, Tuple[CSEVariable, ...]]): Union[CSEVariable, Tuple[CSEVariable, ...]]<br ALIGN="LEFT"/>scan(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[CSEVariable, ...], Tuple[CSEVariable, ...]], Tuple[CSEVariable, ...]], values: Tuple[CSEVariable, ...]): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>sort(dtypes: Tuple[torch.dtype, ...], values: Tuple[CSEVariable, ...], stable: bool, descending: bool): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: CSEVariable, mode: StoreMode): None<br ALIGN="LEFT"/>store_reduction(name: str, index: sympy.Expr, value: CSEVariable)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonKernel._lift_helper.CSEProxy" [color="black", fontcolor="black", label=<{CSEProxy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.CSEVariable" [color="black", fontcolor="black", label=<{CSEVariable|bounds : ValueRanges[Any]<br ALIGN="LEFT"/>dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>use_count : int<br ALIGN="LEFT"/>|<I>update_on_args</I>(name, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.CTCLoss" [color="black", fontcolor="black", label=<{CTCLoss|blank : int<br ALIGN="LEFT"/>zero_infinity : bool<br ALIGN="LEFT"/>|forward(log_probs: Tensor, targets: Tensor, input_lengths: Tensor, target_lengths: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.CUDABenchmarkRequest" [color="black", fontcolor="black", label=<{CUDABenchmarkRequest|DLL : Optional[DLLWrapper]<br ALIGN="LEFT"/>hash_key : str<br ALIGN="LEFT"/>source_code : str<br ALIGN="LEFT"/>source_file : str<br ALIGN="LEFT"/>workspace : NoneType, Optional[torch.Tensor]<br ALIGN="LEFT"/>workspace_size : int<br ALIGN="LEFT"/>|cleanup_run_fn(): None<br ALIGN="LEFT"/>ensure_dll_loaded()<br ALIGN="LEFT"/>make_run_fn(): Callable[[], None]<br ALIGN="LEFT"/>precompile()<br ALIGN="LEFT"/>update_workspace_size(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_cpp_scheduling.CUDACPPScheduling" [color="black", fontcolor="black", label=<{CUDACPPScheduling|scheduler<br ALIGN="LEFT"/>|can_fuse_vertical(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>codegen_template(template_node: BaseSchedulerNode, epilogue_nodes: Sequence[BaseSchedulerNode], prologue_nodes: Sequence[BaseSchedulerNode])<br ALIGN="LEFT"/>define_kernel(src_code: str, node_schedule): str<br ALIGN="LEFT"/>get_backend_features(device)<br ALIGN="LEFT"/>group_fn(sizes)<br ALIGN="LEFT"/>is_cuda_cpp_template(node: BaseSchedulerNode): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CUDACodeCache" [color="black", fontcolor="black", label=<{CUDACodeCache|cache : Dict[str, CacheEntry]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>|compile(source_code: str, dst_file_ext: str, extra_args: Optional[List[str]]): Tuple[str, str, str]<br ALIGN="LEFT"/>load(source_code: str, dst_file_ext: str): Tuple[DLLWrapper, str, str]<br ALIGN="LEFT"/>write(source_code: str, dst_file_ext: str): Tuple[str, str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" [color="black", fontcolor="black", label=<{CUDACombinedScheduling|<br ALIGN="LEFT"/>|benchmark_combo_kernel(node_list)<br ALIGN="LEFT"/>benchmark_fused_nodes(nodes)<br ALIGN="LEFT"/>can_fuse_horizontal(node1: BaseSchedulerNode, node2: BaseSchedulerNode)<br ALIGN="LEFT"/>can_fuse_vertical(node1: BaseSchedulerNode, node2: BaseSchedulerNode)<br ALIGN="LEFT"/>choose_node_backend(node: BaseSchedulerNode): BaseScheduling<br ALIGN="LEFT"/>codegen_combo_kernel()<br ALIGN="LEFT"/>codegen_node(node: Union[FusedSchedulerNode, SchedulerNode])<br ALIGN="LEFT"/>codegen_sync()<br ALIGN="LEFT"/>codegen_template(template_node: BaseSchedulerNode, epilogue_nodes: Sequence[BaseSchedulerNode], prologue_nodes: Sequence[BaseSchedulerNode])<br ALIGN="LEFT"/>flush()<br ALIGN="LEFT"/>generate_kernel_code_from_nodes(nodes, benchmark_kernel)<br ALIGN="LEFT"/>get_backend_features(device)<br ALIGN="LEFT"/>group_fn(sizes)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.exc.CUDACompileError" [color="black", fontcolor="red", label=<{CUDACompileError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_utils.CUDACompileSourceCapturingContext" [color="black", fontcolor="black", label=<{CUDACompileSourceCapturingContext|sources : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.device_op_overrides.CUDADeviceOpOverrides" [color="black", fontcolor="black", label=<{CUDADeviceOpOverrides|<br ALIGN="LEFT"/>|abi_compatible_header()<br ALIGN="LEFT"/>aoti_get_stream()<br ALIGN="LEFT"/>cpp_aoti_device_guard()<br ALIGN="LEFT"/>cpp_aoti_stream_guard()<br ALIGN="LEFT"/>cpp_device_guard()<br ALIGN="LEFT"/>cpp_device_ptr()<br ALIGN="LEFT"/>cpp_getStreamFromExternal()<br ALIGN="LEFT"/>cpp_kernel_type()<br ALIGN="LEFT"/>cpp_stream_guard()<br ALIGN="LEFT"/>cpp_stream_type()<br ALIGN="LEFT"/>device_guard(device_idx)<br ALIGN="LEFT"/>import_get_raw_stream_as(name)<br ALIGN="LEFT"/>kernel_driver()<br ALIGN="LEFT"/>kernel_header()<br ALIGN="LEFT"/>set_device(device_idx)<br ALIGN="LEFT"/>synchronize()<br ALIGN="LEFT"/>tma_descriptor_helpers()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.CUDADeviceVariable" [color="black", fontcolor="black", label=<{CUDADeviceVariable|target_values<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', device)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.graphs.CUDAGraph" [color="black", fontcolor="black", label=<{CUDAGraph|<br ALIGN="LEFT"/>|capture_begin(pool, capture_error_mode)<br ALIGN="LEFT"/>capture_end()<br ALIGN="LEFT"/>debug_dump(debug_path)<br ALIGN="LEFT"/>enable_debug_mode()<br ALIGN="LEFT"/>pool()<br ALIGN="LEFT"/>replay()<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.CUDAGraphNode" [color="black", fontcolor="black", label=<{CUDAGraphNode|cached_tensor_outputs : OutputList[Optional[Tensor]]<br ALIGN="LEFT"/>checkpointed_caching_state : Optional[AllocatorState]<br ALIGN="LEFT"/>children : Dict[FunctionID, List[CUDAGraphNode]]<br ALIGN="LEFT"/>cuda_graphs_pool : Tuple[int, int]<br ALIGN="LEFT"/>cudagraph_managed_idxs : List[int]<br ALIGN="LEFT"/>device : int<br ALIGN="LEFT"/>expanded_dims : List[List[int]]<br ALIGN="LEFT"/>expected_dead_indices_after_graph : List[PathOutputIndex], list<br ALIGN="LEFT"/>expected_dead_indices_before_graph : List[PathOutputIndex], list<br ALIGN="LEFT"/>graph : Optional[torch.cuda.CUDAGraph]<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>live_cudagraph_managed_path_refs : InputList[Optional[PathOutputIndex]]<br ALIGN="LEFT"/>live_indices_after_graph : List[PathOutputIndex]<br ALIGN="LEFT"/>non_managed_static_input_idxs : LevelList[int]<br ALIGN="LEFT"/>non_static_input_idx : LevelList[int]<br ALIGN="LEFT"/>output_storage_alias : OutputList[Optional[OutputAliasInfo]]<br ALIGN="LEFT"/>outputs_metadata : OutputList[Union[Dict[str, Any], int, None]]<br ALIGN="LEFT"/>outputs_weakrefs : OutputList[Optional[StorageWeakRefWrapper]]<br ALIGN="LEFT"/>parent<br ALIGN="LEFT"/>path_stacktraces : LevelList[Optional[StackTraces]]<br ALIGN="LEFT"/>path_weakrefs : LevelList[OutputList[Optional[StorageWeakRefWrapper]]]<br ALIGN="LEFT"/>preserved_aliased_inputs : InputList[bool]<br ALIGN="LEFT"/>reconstructed_inputs : List[InputType]<br ALIGN="LEFT"/>recorded_liveness_after_graph : LevelList[OutputList[bool]], list<br ALIGN="LEFT"/>recorded_liveness_before_graph : LevelList[OutputList[bool]], list<br ALIGN="LEFT"/>recording_outputs : NoneType, Optional[OutputType]<br ALIGN="LEFT"/>rerecord_if_static_inputs_change : bool<br ALIGN="LEFT"/>stack_traces : Optional[StackTraces]<br ALIGN="LEFT"/>static_input_data_ptrs : InputList[Optional[int]]<br ALIGN="LEFT"/>static_input_idxs : List[int]<br ALIGN="LEFT"/>static_inputs_stable : bool<br ALIGN="LEFT"/>static_output_tensors : OutputList[Optional[Tensor]]<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>tensor_weakrefs : OutputList[Optional[TensorWeakRef]]<br ALIGN="LEFT"/>unaliased_in_all_paths : OutputList[bool]<br ALIGN="LEFT"/>wrapped_function<br ALIGN="LEFT"/>|add_child(function_id: FunctionID, node: CUDAGraphNode): None<br ALIGN="LEFT"/>all_outputs_are_dead(): bool<br ALIGN="LEFT"/>check_invariants(inputs: List[InputType]): Tuple[CheckInvariantStatus, Callable[..., str]]<br ALIGN="LEFT"/>check_static_inputs_are_stable(new_inputs: List[InputType]): None<br ALIGN="LEFT"/><I>clear_path_state</I>(): None<br ALIGN="LEFT"/>create_storage(metadata: Dict[str, Any]): torch.types.Storage<br ALIGN="LEFT"/>data_ptrs_dead_since_invocation(): List[int]<br ALIGN="LEFT"/>debug_assert_invariants(expected_liveness: List[List[bool]], newly_dead: List[PathOutputIndex]): None<br ALIGN="LEFT"/>debug_check_invariants_after_invocation(): None<br ALIGN="LEFT"/>debug_check_invariants_before_invocation(): None<br ALIGN="LEFT"/>get_output_refcount(index: int): int<br ALIGN="LEFT"/>num_descendants(): int<br ALIGN="LEFT"/>path_live_weakrefs(): Iterator[StorageWeakRefWrapper]<br ALIGN="LEFT"/>prepare_alias_info_for_tensor_construction(out_alias_info: Optional[OutputAliasInfo], metadata: Union[Dict[str, Any], int, None]): Union[UntypedStorage, None, int]<br ALIGN="LEFT"/>prepare_storages_for_construction(): List[Union[UntypedStorage, None, int]]<br ALIGN="LEFT"/>reconstruct_outputs(): OutputType<br ALIGN="LEFT"/>remove_node_cached_tensors(): None<br ALIGN="LEFT"/>remove_path_cached_tensors(): None<br ALIGN="LEFT"/>run(new_inputs: List[InputType]): OutputType<br ALIGN="LEFT"/>run_first_inputs(new_inputs: List[InputType]): OutputType<br ALIGN="LEFT"/>run_graph(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.CUDAGraphTreeManager" [color="black", fontcolor="black", label=<{CUDAGraphTreeManager|cuda_graphs_thread_pool<br ALIGN="LEFT"/>current_gen : int<br ALIGN="LEFT"/>current_node<br ALIGN="LEFT"/>debug_checkpointing_counter : int<br ALIGN="LEFT"/>debug_fail_counter : int<br ALIGN="LEFT"/>device_index : int<br ALIGN="LEFT"/>disable_invalidate_aliases : bool<br ALIGN="LEFT"/>func_counter : count<br ALIGN="LEFT"/>graph : NoneType, Optional[torch.cuda.CUDAGraph]<br ALIGN="LEFT"/>graph_counter : count<br ALIGN="LEFT"/>id_to_mode : Dict[FunctionID, CompilationMode]<br ALIGN="LEFT"/>ids_to_funcs : Dict[FunctionID, WrappedFunction]<br ALIGN="LEFT"/>ids_to_stack_traces : Dict[FunctionID, Optional[StackTraces]]<br ALIGN="LEFT"/>in_recording<br ALIGN="LEFT"/>in_warmup<br ALIGN="LEFT"/>mode : BACKWARD, Optional[CompilationMode]<br ALIGN="LEFT"/>non_cudagraph_managed_mutation_hint : Dict[Optional[GraphID], Dict[FunctionID, bool]]<br ALIGN="LEFT"/>num_rerecord : Dict[Optional[GraphID], Dict[FunctionID, int]]<br ALIGN="LEFT"/>path_state : EXECUTION, NONE, RECORDING, WARMUP<br ALIGN="LEFT"/>roots : Dict[FunctionID, List[CUDAGraphNode]], NoneType<br ALIGN="LEFT"/>running_forwards_with_pending_backwards : bool<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>warmed_up_functions : OrderedSet[FunctionID]<br ALIGN="LEFT"/>warmup_node_counter : count<br ALIGN="LEFT"/>warned_functions : OrderedSet[FunctionID]<br ALIGN="LEFT"/>warned_mutation : OrderedSet[FunctionID]<br ALIGN="LEFT"/>|add_function(model: ModelType, inputs: List[InputType], static_input_idxs: Sequence[int], stack_traces: Optional[StackTraces], mode: CompilationMode, constants: Tuple[torch.Tensor, ...], placeholders: Tuple[PlaceholderInfo, ...], mutated_input_idxs: Tuple[int, ...]): Tuple[ModelType, OutputType]<br ALIGN="LEFT"/>apply_checkpoint_execution_state_in_allocator(): None<br ALIGN="LEFT"/>can_start_new_generation(): bool<br ALIGN="LEFT"/>check_warn_on_unable_to_start_executing(function_id: FunctionID): None<br ALIGN="LEFT"/>clear_current_path_state_and_set_to_none(): None<br ALIGN="LEFT"/>dealloc_current_path_weakrefs(): None<br ALIGN="LEFT"/>exceed_rerecord_limit(node_id: Optional[GraphID], function_id: FunctionID): bool<br ALIGN="LEFT"/>execute_node(node: CUDAGraphNode, new_inputs: List[InputType]): OutputType<br ALIGN="LEFT"/>format_dealloc_msg(stack_trace: Optional[str]): str<br ALIGN="LEFT"/>get_curr_generation(): int<br ALIGN="LEFT"/>get_roots(): Iterator[CUDAGraphNode]<br ALIGN="LEFT"/>in_new_torch_compile_invocation(): bool<br ALIGN="LEFT"/>live_cudagraph_pool_storages_in_curr_execution(): List[StorageWeakRefPointer]<br ALIGN="LEFT"/>new_func_id(): FunctionID<br ALIGN="LEFT"/>new_graph_id(): GraphID<br ALIGN="LEFT"/>new_warmup_node_id(): GraphID<br ALIGN="LEFT"/>record_function(new_inputs: List[InputType], function_id: FunctionID): OutputType<br ALIGN="LEFT"/>run(new_inputs: List[InputType], function_id: FunctionID): OutputType<br ALIGN="LEFT"/>run_eager(new_inputs: List[InputType], function_id: FunctionID): OutputType<br ALIGN="LEFT"/>set_to_running_backward(): None<br ALIGN="LEFT"/>shutdown(): None<br ALIGN="LEFT"/>try_end_curr_execution(): None<br ALIGN="LEFT"/>try_end_curr_recording(function_id: FunctionID): None<br ALIGN="LEFT"/>try_end_curr_warmup(function_id: FunctionID): None<br ALIGN="LEFT"/>update_generation(): None<br ALIGN="LEFT"/>user_invoked_mark_step(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDAKernel" [color="black", fontcolor="black", label=<{CUDAKernel|layout_args : Dict[str, LayoutArg]<br ALIGN="LEFT"/>named_nodes : Dict[str, IRNode]<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>|add_layout_arg(symbol: ValidLayoutSymbols, node: IRNode, attr: ValidLayoutAttrs, dim: int)<br ALIGN="LEFT"/>find_layout_arg(node: IRNode, attr: ValidLayoutAttrs, dim: int): Optional[LayoutArg]<br ALIGN="LEFT"/>find_ld_idx(node: IRNode): int<br ALIGN="LEFT"/>find_symbol(node: IRNode, attr: ValidLayoutAttrs, dim: int): Optional[str]<br ALIGN="LEFT"/>get_layout_args(): Tuple[Union[Expr, int], ...]<br ALIGN="LEFT"/>init_layout_args(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.memory.CUDAPluggableAllocator" [color="black", fontcolor="black", label=<{CUDAPluggableAllocator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims_common.CUDARngStateHelper" [color="black", fontcolor="black", label=<{CUDARngStateHelper|<br ALIGN="LEFT"/>|get_torch_state_as_tuple(fake_mode)<br ALIGN="LEFT"/>set_new_offset(relative_offset)<br ALIGN="LEFT"/>set_torch_state_tensor(seed, offset)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda._sanitizer.CUDASanitizer" [color="black", fontcolor="black", label=<{CUDASanitizer|dispatch<br ALIGN="LEFT"/>enabled : bool<br ALIGN="LEFT"/>|disable()<br ALIGN="LEFT"/>enable()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda._sanitizer.CUDASanitizerDispatchMode" [color="black", fontcolor="black", label=<{CUDASanitizerDispatchMode|event_handler<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.CUDASanitizerErrors" [color="black", fontcolor="red", label=<{CUDASanitizerErrors|errors : List[SynchronizationError]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_template.CUDATemplate" [color="black", fontcolor="black", label=<{CUDATemplate|index_counter : count<br ALIGN="LEFT"/>input_nodes : List[Buffer]<br ALIGN="LEFT"/>input_reorder : Optional[List[int]]<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>|generate(description): CUDATemplateCaller<br ALIGN="LEFT"/>globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/><I>render</I>(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.CUDATemplateBuffer" [color="black", fontcolor="black", label=<{CUDATemplateBuffer|template : object<br ALIGN="LEFT"/>workspace_size : int<br ALIGN="LEFT"/>|get_workspace_size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDATemplateCaller" [color="black", fontcolor="black", label=<{CUDATemplateCaller|bmreq<br ALIGN="LEFT"/>category : str<br ALIGN="LEFT"/>info_kwargs : Optional[Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]]<br ALIGN="LEFT"/>make_kernel_render : Callable[[CUDATemplateBuffer, Optional[List[IRNode]]], str]<br ALIGN="LEFT"/>template : str<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/>call_name(): str<br ALIGN="LEFT"/>hash_key(): str<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]<br ALIGN="LEFT"/>output_node(): TensorBox<br ALIGN="LEFT"/>precompile(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDATemplateKernel" [color="black", fontcolor="black", label=<{CUDATemplateKernel|kernel_name<br ALIGN="LEFT"/>signature : str<br ALIGN="LEFT"/>|arg_name(node: IRNode): Optional[str]<br ALIGN="LEFT"/>call_kernel(name: str, node: 'CUDATemplateBuffer'): None<br ALIGN="LEFT"/>check_not_null(node: IRNode): str<br ALIGN="LEFT"/>cutlass_dtype(node: IRNode, default_dtype): Optional[str]<br ALIGN="LEFT"/>def_kernel(inputs: List[IRNode], outputs: List[IRNode], names_str: str, input_reorder: Optional[List[int]]): str<br ALIGN="LEFT"/>dtype(node: IRNode): Optional[str]<br ALIGN="LEFT"/>get_signature(): str<br ALIGN="LEFT"/>max_valid_index(node: IRNode, default)<br ALIGN="LEFT"/>offset(node: IRNode): str<br ALIGN="LEFT"/>ptr(node: IRNode): str<br ALIGN="LEFT"/>row_or_column_stride(node: IRNode, default_value: int): str<br ALIGN="LEFT"/>size(node: IRNode, start_index: int, end_index: Optional[int], default_value: int): str<br ALIGN="LEFT"/>stride(node: IRNode, index: int, default_value: int): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.CUDATestBase" [color="black", fontcolor="black", label=<{CUDATestBase|cudnn_version : ClassVar[Any]<br ALIGN="LEFT"/>device_type : str<br ALIGN="LEFT"/>no_cudnn : ClassVar[bool]<br ALIGN="LEFT"/>no_magma : ClassVar[bool]<br ALIGN="LEFT"/>primary_device : ClassVar[str]<br ALIGN="LEFT"/>|get_all_devices()<br ALIGN="LEFT"/>get_primary_device()<br ALIGN="LEFT"/>has_cudnn()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.CUDAWarmupNode" [color="black", fontcolor="black", label=<{CUDAWarmupNode|already_warm : bool<br ALIGN="LEFT"/>cuda_graphs_pool : Tuple[int, int]<br ALIGN="LEFT"/>device_index : int<br ALIGN="LEFT"/>existing_cuda_graph : Optional[torch.cuda.CUDAGraph]<br ALIGN="LEFT"/>has_run : bool<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>outputs_weakrefs : List[Optional[StorageWeakRefWrapper]]<br ALIGN="LEFT"/>parent : Optional[Union[CUDAGraphNode, CUDAWarmupNode]]<br ALIGN="LEFT"/>stack_traces : Optional[StackTraces]<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>tensor_weakrefs : List[Optional[TensorWeakRef]]<br ALIGN="LEFT"/>wrapped_function<br ALIGN="LEFT"/>|all_outputs_are_dead(): bool<br ALIGN="LEFT"/>path_live_weakrefs(): Iterator[StorageWeakRefWrapper]<br ALIGN="LEFT"/>run(new_inputs: Any): OutputType<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASS2xGemmTemplate" [color="black", fontcolor="black", label=<{CUTLASS2xGemmTemplate|<br ALIGN="LEFT"/>|add_cutlass_gemm_choices(choices: List[ChoiceCaller], layout: ir.Layout, input_nodes: List[Buffer], alpha: Union[float, int], beta: Union[float, int], input_reorder: Optional[List[int]]): None<br ALIGN="LEFT"/>render_gemm_arguments(instance_type: str, argument_template: str, epilogue_template: str, should_swap_xw: bool, X: IRNode, W: IRNode, Bias: IRNode, Meta: IRNode, Y: IRNode, alpha: float, beta: float, kernel: CUDATemplateKernel, epilogue_args): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASS3xGemmTemplate" [color="black", fontcolor="black", label=<{CUTLASS3xGemmTemplate|<br ALIGN="LEFT"/>|add_cutlass_gemm_choices(choices: List[ChoiceCaller], layout: ir.Layout, input_nodes: List[Buffer], alpha: Union[float, int], beta: Union[float, int], input_reorder: Optional[List[int]]): None<br ALIGN="LEFT"/>render_gemm_arguments(argument_template: str, epilogue_template: str, should_swap_xw: bool, X: IRNode, W: IRNode, Bias: IRNode, Y: IRNode, alpha: float, beta: float, kernel: CUDATemplateKernel, epilogue_args): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_utils.CUTLASSArgs" [color="black", fontcolor="black", label=<{CUTLASSArgs|architectures : Optional[str]<br ALIGN="LEFT"/>build_dir : str<br ALIGN="LEFT"/>cuda_version : Optional[str]<br ALIGN="LEFT"/>curr_build_dir : str<br ALIGN="LEFT"/>disable_full_archs_compilation : bool<br ALIGN="LEFT"/>filter_by_cc : bool<br ALIGN="LEFT"/>generator_target : str<br ALIGN="LEFT"/>ignore_kernels : str<br ALIGN="LEFT"/>interface_dir : NoneType<br ALIGN="LEFT"/>kernel_filter_file : NoneType<br ALIGN="LEFT"/>kernels : str<br ALIGN="LEFT"/>operations : str<br ALIGN="LEFT"/>selected_kernel_list : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_epilogue_gen.CUTLASSEVTOpNotImplementedError" [color="black", fontcolor="red", label=<{CUTLASSEVTOpNotImplementedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASSGemmTemplate" [color="black", fontcolor="black", label=<{CUTLASSGemmTemplate|alpha : float<br ALIGN="LEFT"/>beta : float<br ALIGN="LEFT"/>|<I>add_cutlass_gemm_choices</I>(choices: List[ChoiceCaller], layout: ir.Layout, input_nodes: List[Buffer], alpha: Union[float, int], beta: Union[float, int], input_reorder: Optional[List[int]]): None<br ALIGN="LEFT"/>cutlass_layout(torch_layout: ir.Layout): 'Optional[cutlass_lib.LayoutType]'<br ALIGN="LEFT"/>filter_op(op: 'cutlass_library.gemm_op.GemmOperation'): 'cutlass_library.gemm_op.GemmOperation'<br ALIGN="LEFT"/>fix_op_layout(op: 'cutlass_library.gemm_op.GemmOperation', X: Buffer, W: Buffer, Bias: Optional[Buffer], Y: Union[Buffer, ReinterpretView]): 'cutlass_library.gemm_op.GemmOperation'<br ALIGN="LEFT"/>flip_cutlass_layout(cutlass_layout: 'cutlass_lib.LayoutType'): 'cutlass_lib.LayoutType'<br ALIGN="LEFT"/>gemm_mode(): str<br ALIGN="LEFT"/>gen_ops(): 'List[Tuple[str, cutlass_gemm_op.GemmOperation]]'<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/>layout_match(torch_layout: ir.Layout, cutlass_layout: 'cutlass_lib.LayoutType'): bool<br ALIGN="LEFT"/>render(kernel: CUDATemplateKernel, op: 'cutlass_gemm_op.GemmOperation', template_buffer_node: Optional[CUDATemplateBuffer]): str<br ALIGN="LEFT"/>set_alignment(torch_layout, op_element): bool<br ALIGN="LEFT"/>should_swap_XW(bias: IRNode): bool<br ALIGN="LEFT"/>swap_XW(op: 'cutlass_library.gemm_op.GemmOperation'): 'cutlass_library.gemm_op.GemmOperation'<br ALIGN="LEFT"/>test_call_statement(kernel, input_nodes, names_str: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_template.CUTLASSTemplate" [color="black", fontcolor="black", label=<{CUTLASSTemplate|<br ALIGN="LEFT"/>|cute_int(int_str: str, var_name: str): str<br ALIGN="LEFT"/>cutlass_sparse_meta_type_cast(node: IRNode, ptr: str): str<br ALIGN="LEFT"/>cutlass_type_cast(node: IRNode, ptr: str): str<br ALIGN="LEFT"/>globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CacheBase" [color="black", fontcolor="black", label=<{CacheBase|system : dict<br ALIGN="LEFT"/>|get_global_cache_path(): Optional[Path]<br ALIGN="LEFT"/>get_local_cache(): Dict[str, Any]<br ALIGN="LEFT"/>get_local_cache_path(): Path<br ALIGN="LEFT"/>get_system(): Dict[str, Any]<br ALIGN="LEFT"/>update_local_cache(local_cache: Dict[str, Any]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CUDACodeCache.CacheEntry" [color="black", fontcolor="black", label=<{CacheEntry|input_path : str<br ALIGN="LEFT"/>output_path : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codecache.ROCmCodeCache.CacheEntry" [color="black", fontcolor="black", label=<{CacheEntry|input_path : str<br ALIGN="LEFT"/>output_path : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.cache_size.CacheSizeRelevantForFrame" [color="black", fontcolor="black", label=<{CacheSizeRelevantForFrame|num_cache_entries : int<br ALIGN="LEFT"/>num_cache_entries_with_same_id_matched_objs : int<br ALIGN="LEFT"/>|will_compilation_exceed(limit: int): bool<br ALIGN="LEFT"/>will_compilation_exceed_accumulated_limit(): bool<br ALIGN="LEFT"/>will_compilation_exceed_specific_limit(limit: int): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.CachedMethod" [color="black", fontcolor="black", label=<{CachedMethod|<br ALIGN="LEFT"/>|clear_cache(self): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.metrics.CachedMetricsDeltas" [color="black", fontcolor="black", label=<{CachedMetricsDeltas|cpp_to_dtype_count : int<br ALIGN="LEFT"/>generated_cpp_vec_kernel_count : int<br ALIGN="LEFT"/>generated_kernel_count : int<br ALIGN="LEFT"/>ir_nodes_pre_fusion : int<br ALIGN="LEFT"/>num_bytes_accessed : int<br ALIGN="LEFT"/>num_matches_for_scatter_upon_const_tensor : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.metrics.CachedMetricsHelper" [color="black", fontcolor="black", label=<{CachedMetricsHelper|cached_metrics : dict<br ALIGN="LEFT"/>|apply_deltas(delta: CachedMetricsDeltas)<br ALIGN="LEFT"/>get_deltas(): CachedMetricsDeltas<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.triton_heuristics.CachingAutotuner" [color="black", fontcolor="black", label=<{CachingAutotuner|autotune_time_taken_ns : int<br ALIGN="LEFT"/>configs : NoneType<br ALIGN="LEFT"/>coordesc_tuner<br ALIGN="LEFT"/>cuda_kernel_saved : bool<br ALIGN="LEFT"/>custom_kernel : bool<br ALIGN="LEFT"/>device_props : DeviceProperties<br ALIGN="LEFT"/>dump_launch_params<br ALIGN="LEFT"/>filename : Optional[str]<br ALIGN="LEFT"/>fn<br ALIGN="LEFT"/>heuristic_type<br ALIGN="LEFT"/>inductor_meta : NoneType, dict<br ALIGN="LEFT"/>kernel_hash : str<br ALIGN="LEFT"/>launchers : list<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>mutated_arg_names : List[str]<br ALIGN="LEFT"/>optimize_mem<br ALIGN="LEFT"/>precompile_time_taken_ns : int<br ALIGN="LEFT"/>reset_to_zero_arg_names : NoneType, list<br ALIGN="LEFT"/>save_cache_hook<br ALIGN="LEFT"/>size_hints : NoneType<br ALIGN="LEFT"/>triton_interpret<br ALIGN="LEFT"/>triton_meta<br ALIGN="LEFT"/>|autotune_to_one_config()<br ALIGN="LEFT"/>bench(launcher)<br ALIGN="LEFT"/>benchmark_all_configs()<br ALIGN="LEFT"/>clone_args(): Tuple[List[Any], Dict[str, Any]]<br ALIGN="LEFT"/>coordinate_descent_tuning(launcher)<br ALIGN="LEFT"/>copy_args_to_cpu_if_needed()<br ALIGN="LEFT"/>get_device_interface()<br ALIGN="LEFT"/>maybe_clone_args(exclude: Container[str]): Tuple[List[Any], Dict[str, Any]]<br ALIGN="LEFT"/>precompile(warm_cache_only)<br ALIGN="LEFT"/>reset_to_zero_args()<br ALIGN="LEFT"/>restore_args_from_cpu(cpu_copies)<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>save_gpu_kernel(grid, stream, launcher)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcConv" [color="black", fontcolor="black", label=<{CalcConv|c_out<br ALIGN="LEFT"/>conv_result<br ALIGN="LEFT"/>dilation<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>kernel<br ALIGN="LEFT"/>matching_constraint<br ALIGN="LEFT"/>padding<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcMaxPool" [color="black", fontcolor="black", label=<{CalcMaxPool|dilation<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>kernel<br ALIGN="LEFT"/>matching_constraint<br ALIGN="LEFT"/>maxpool_result<br ALIGN="LEFT"/>padding<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcProduct" [color="black", fontcolor="black", label=<{CalcProduct|dims_to_flatten<br ALIGN="LEFT"/>end<br ALIGN="LEFT"/>flattened<br ALIGN="LEFT"/>start<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallFunction" [color="black", fontcolor="black", label=<{CallFunction|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.CallFunctionNoArgsSource" [color="black", fontcolor="black", label=<{CallFunctionNoArgsSource|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallFunctionVarArgs" [color="black", fontcolor="black", label=<{CallFunctionVarArgs|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallMethod" [color="black", fontcolor="black", label=<{CallMethod|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.CallMethodItemSource" [color="black", fontcolor="black", label=<{CallMethodItemSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.CallMethodKey" [color="black", fontcolor="black", label=<{CallMethodKey|name : str<br ALIGN="LEFT"/>|get(o: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallMethodVarArgs" [color="black", fontcolor="black", label=<{CallMethodVarArgs|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallModule" [color="black", fontcolor="black", label=<{CallModule|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.CallModuleVarArgs" [color="black", fontcolor="black", label=<{CallModuleVarArgs|op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.torchbind.CallTorchBind" [color="black", fontcolor="black", label=<{CallTorchBind|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.CallTorchbindHigherOrderVariable" [color="black", fontcolor="black", label=<{CallTorchbindHigherOrderVariable|method_name<br ALIGN="LEFT"/>script_obj_var<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._utils.CallbackRegistry" [color="black", fontcolor="black", label=<{CallbackRegistry|callback_list : List[Callable[P, None]]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|add_callback(cb: Callable[P, None]): None<br ALIGN="LEFT"/>fire_callbacks(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils._stubs.CallgrindModuleType" [color="black", fontcolor="black", label=<{CallgrindModuleType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [color="black", fontcolor="black", label=<{CallgrindStats|baseline_exclusive_stats<br ALIGN="LEFT"/>baseline_inclusive_stats<br ALIGN="LEFT"/>built_with_debug_symbols : bool<br ALIGN="LEFT"/>number_per_run : int<br ALIGN="LEFT"/>stmt_callgrind_out : Optional[str]<br ALIGN="LEFT"/>stmt_exclusive_stats<br ALIGN="LEFT"/>stmt_inclusive_stats<br ALIGN="LEFT"/>task_spec<br ALIGN="LEFT"/>|as_standardized(): 'CallgrindStats'<br ALIGN="LEFT"/>counts(): int<br ALIGN="LEFT"/>delta(other: 'CallgrindStats', inclusive: bool): FunctionCounts<br ALIGN="LEFT"/>stats(inclusive: bool): FunctionCounts<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.CanReshape" [color="black", fontcolor="black", label=<{CanReshape|src<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.CandidateTiling" [color="black", fontcolor="black", label=<{CandidateTiling|name : Optional[str]<br ALIGN="LEFT"/>score : int<br ALIGN="LEFT"/>tiling : Tuple[sympy.Expr, sympy.Expr]<br ALIGN="LEFT"/>|is_good_size(s)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.CantSplit" [color="black", fontcolor="red", label=<{CantSplit|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.infra.partitioner.CapabilityBasedPartitioner" [color="black", fontcolor="black", label=<{CapabilityBasedPartitioner|allowed_single_node_partition_ops : NoneType, list<br ALIGN="LEFT"/>allows_single_node_partition : bool<br ALIGN="LEFT"/>dependency_viewer<br ALIGN="LEFT"/>graph_module<br ALIGN="LEFT"/>non_compute_ops : NoneType, list<br ALIGN="LEFT"/>operator_support<br ALIGN="LEFT"/>|fuse_partitions(partitions: List[Partition], prefix: str): GraphModule<br ALIGN="LEFT"/>partition_and_fuse(prefix: str): GraphModule<br ALIGN="LEFT"/>propose_partitions(): List[Partition]<br ALIGN="LEFT"/>remove_bookend_non_compute_ops(partitions: List[Partition])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.Capture" [color="black", fontcolor="black", label=<{Capture|columns<br ALIGN="LEFT"/>ctx : dict<br ALIGN="LEFT"/>|apply_ops_2(dataframe)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureA" [color="black", fontcolor="black", label=<{CaptureA|<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureAdd" [color="black", fontcolor="black", label=<{CaptureAdd|ctx<br ALIGN="LEFT"/>left<br ALIGN="LEFT"/>right<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureCall" [color="black", fontcolor="black", label=<{CaptureCall|callable<br ALIGN="LEFT"/>ctx : dict<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureControl" [color="black", fontcolor="black", label=<{CaptureControl|disabled : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrame" [color="black", fontcolor="black", label=<{CaptureDataFrame|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrameWithDataPipeOps" [color="black", fontcolor="black", label=<{CaptureDataFrameWithDataPipeOps|<br ALIGN="LEFT"/>|as_datapipe()<br ALIGN="LEFT"/>batch(batch_size, drop_last: bool, wrapper_class)<br ALIGN="LEFT"/>collate()<br ALIGN="LEFT"/>filter()<br ALIGN="LEFT"/>groupby(group_key_fn)<br ALIGN="LEFT"/>raw_iterator()<br ALIGN="LEFT"/>shuffle()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureF" [color="black", fontcolor="black", label=<{CaptureF|ctx : dict<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureGetAttr" [color="black", fontcolor="black", label=<{CaptureGetAttr|ctx<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>src<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureGetItem" [color="black", fontcolor="black", label=<{CaptureGetItem|ctx<br ALIGN="LEFT"/>key<br ALIGN="LEFT"/>left<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.LoopBodyBlock.__init__.CaptureIndexing" [color="black", fontcolor="black", label=<{CaptureIndexing|<br ALIGN="LEFT"/>|bucketize(values: T, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[T]): T<br ALIGN="LEFT"/>check_bounds(index, size, lower, upper)<br ALIGN="LEFT"/>frexp(value_proxy)<br ALIGN="LEFT"/>index_expr(index, dtype)<br ALIGN="LEFT"/>indirect_indexing(index_proxy, size, check, wrap_neg)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>load_seed(name: str, index: int)<br ALIGN="LEFT"/>masked(mask_proxy, masked_body: Callable[..., Any], other_proxy)<br ALIGN="LEFT"/>output(result)<br ALIGN="LEFT"/>reduction(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>scan(dtype_proxy, combine_fn: Callable[[Tuple[Any, ...], Tuple[Any, ...]], Tuple[Any, ...]], value_proxy)<br ALIGN="LEFT"/>sort(dtypes, values, stable, descending)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>store_reduction(name, index, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureInitial" [color="black", fontcolor="black", label=<{CaptureInitial|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureLikeMock" [color="black", fontcolor="black", label=<{CaptureLikeMock|attribute<br ALIGN="LEFT"/>get_target<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>save<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._get_debug_context_and_cb.CaptureLogs" [color="black", fontcolor="black", label=<{CaptureLogs|logs : NoneType, list<br ALIGN="LEFT"/>tbs : NoneType, list<br ALIGN="LEFT"/>|get_context_manager()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureMul" [color="black", fontcolor="black", label=<{CaptureMul|ctx<br ALIGN="LEFT"/>left<br ALIGN="LEFT"/>right<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureSetItem" [color="black", fontcolor="black", label=<{CaptureSetItem|ctx<br ALIGN="LEFT"/>key<br ALIGN="LEFT"/>left<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.CaptureStrategy" [color="black", fontcolor="black", label=<{CaptureStrategy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._draft_export.CaptureStructuredTrace" [color="black", fontcolor="black", label=<{CaptureStructuredTrace|logger : NoneType, RootLogger<br ALIGN="LEFT"/>logs : List[Tuple[str, Dict[str, Any]]], list<br ALIGN="LEFT"/>prev_get_dtrace : bool<br ALIGN="LEFT"/>specific_log_keys : List[str]<br ALIGN="LEFT"/>|emit(record: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureSub" [color="black", fontcolor="black", label=<{CaptureSub|ctx<br ALIGN="LEFT"/>left<br ALIGN="LEFT"/>right<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureVariable" [color="black", fontcolor="black", label=<{CaptureVariable|ctx<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>names_idx : int<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|apply_ops(dataframe)<br ALIGN="LEFT"/>execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureVariableAssign" [color="black", fontcolor="black", label=<{CaptureVariableAssign|<br ALIGN="LEFT"/>|execute()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._traceback.CapturedTraceback" [color="black", fontcolor="black", label=<{CapturedTraceback|skip : int<br ALIGN="LEFT"/>tb : NoneType<br ALIGN="LEFT"/>|cleanup()<br ALIGN="LEFT"/>extract()<br ALIGN="LEFT"/>format()<br ALIGN="LEFT"/>format_all(tbs)<br ALIGN="LEFT"/>summary()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.CatQuantizeHandler" [color="black", fontcolor="black", label=<{CatQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.CatTransform" [color="black", fontcolor="black", label=<{CatTransform|bijective<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>lengths : list<br ALIGN="LEFT"/>transforms : List[Transform]<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>event_dim()<br ALIGN="LEFT"/>length()<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.CatchErrorsWrapper" [color="black", fontcolor="black", label=<{CatchErrorsWrapper|hooks<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.CatchWarningsCtxManagerVariable" [color="black", fontcolor="black", label=<{CatchWarningsCtxManagerVariable|catch_warnings_args<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', catch_warnings_args)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>reconstruct(cg)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.categorical.Categorical" [color="black", fontcolor="black", label=<{Categorical|arg_constraints : dict<br ALIGN="LEFT"/>has_enumerate_support : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>enumerate_support(expand)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.Category" [color="black", fontcolor="black", label=<{Category|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.CategoryDict" [color="black", fontcolor="black", label=<{CategoryDict|<br ALIGN="LEFT"/>|get(key: Key, version: int): Optional[Category]<br ALIGN="LEFT"/>set_by_id(key: TensorKey, category: Category): None<br ALIGN="LEFT"/>set_by_key(key: TensorKey, category: Category): None<br ALIGN="LEFT"/>set_by_version(key: TensorKey, version: int, category: Category): None<br ALIGN="LEFT"/>setdefault_by_version(key: TensorKey, version: int, category: Category): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.CategoryElement" [color="black", fontcolor="black", label=<{CategoryElement|by_id : Optional[Category]<br ALIGN="LEFT"/>by_key : Dict[TensorKey, Category]<br ALIGN="LEFT"/>by_version : Dict[TensorAndID, Category]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.cauchy.Cauchy" [color="black", fontcolor="black", label=<{Cauchy|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.attention.bias.CausalBias" [color="black", fontcolor="black", label=<{CausalBias|seq_len_kv : int<br ALIGN="LEFT"/>seq_len_q : int<br ALIGN="LEFT"/>variant<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.attention.bias.CausalVariant" [color="black", fontcolor="black", label=<{CausalVariant|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.CeilDiv" [color="black", fontcolor="black", label=<{CeilDiv|is_integer : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.CeilToInt" [color="black", fontcolor="black", label=<{CeilToInt|is_integer : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.CellVariable" [color="black", fontcolor="black", label=<{CellVariable|local_name : Optional[str]<br ALIGN="LEFT"/>pre_existing_contents : Optional[VariableTracker]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.dataset.ChainDataset" [color="black", fontcolor="black", label=<{ChainDataset|datasets : Iterable[Dataset]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.ChainedScheduler" [color="black", fontcolor="black", label=<{ChainedScheduler|optimizer : Optional[Optimizer]<br ALIGN="LEFT"/>|load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.ChainedSource" [color="black", fontcolor="black", label=<{ChainedSource|base<br ALIGN="LEFT"/>|is_dict_key()<br ALIGN="LEFT"/>is_ephemeral()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.channelshuffle.ChannelShuffle" [color="black", fontcolor="black", label=<{ChannelShuffle|groups : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.CharStorage" [color="black", fontcolor="black", label=<{CharStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.CharStorage" [color="black", fontcolor="black", label=<{CharStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.CheckFunctionManager" [color="black", fontcolor="black", label=<{CheckFunctionManager|guard_manager<br ALIGN="LEFT"/>output_graph : NoneType<br ALIGN="LEFT"/>torch_function_mode_stack : NoneType<br ALIGN="LEFT"/>|compile_check_fn(builder, guards_out, guard_fail_fn)<br ALIGN="LEFT"/>id_ref(obj, obj_str)<br ALIGN="LEFT"/>invalidate(obj_str)<br ALIGN="LEFT"/>lookup_weakrefs(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.CheckInvariantStatus" [color="black", fontcolor="black", label=<{CheckInvariantStatus|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint.CheckpointError" [color="black", fontcolor="red", label=<{CheckpointError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.api.CheckpointException" [color="black", fontcolor="red", label=<{CheckpointException|failures<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint.CheckpointFunction" [color="black", fontcolor="black", label=<{CheckpointFunction|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, run_function, preserve_rng_state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.CheckpointHigherOrderVariable" [color="black", fontcolor="black", label=<{CheckpointHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.CheckpointImpl" [color="black", fontcolor="black", label=<{CheckpointImpl|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint.CheckpointPolicy" [color="black", fontcolor="black", label=<{CheckpointPolicy|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.CheckpointWrapper" [color="black", fontcolor="black", label=<{CheckpointWrapper|checkpoint_fn : partial<br ALIGN="LEFT"/>checkpoint_impl<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.Checkpointable" [color="black", fontcolor="black", label=<{Checkpointable|<br ALIGN="LEFT"/>|<I>copy_graphstate</I>(): T<br ALIGN="LEFT"/><I>restore_graphstate</I>(state: T)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.chi2.Chi2" [color="black", fontcolor="black", label=<{Chi2|arg_constraints : dict<br ALIGN="LEFT"/>df<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.errors.ChildFailedError" [color="black", fontcolor="red", label=<{ChildFailedError|failures : Dict[GlobalRank, ProcessFailure]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|format_msg(boarder_delim, section_delim)<br ALIGN="LEFT"/>get_first_failure(): Tuple[GlobalRank, ProcessFailure]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ChoiceCaller" [color="black", fontcolor="black", label=<{ChoiceCaller|description : str<br ALIGN="LEFT"/>input_nodes : List[Buffer]<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|autoheuristic_id(): str<br ALIGN="LEFT"/>benchmark(): float<br ALIGN="LEFT"/><I>call_name</I>(): str<br ALIGN="LEFT"/><I>hash_key</I>(): str<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]<br ALIGN="LEFT"/><I>output_node</I>(): TensorBox<br ALIGN="LEFT"/><I>to_callable</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.ChromiumEventLogger" [color="black", fontcolor="black", label=<{ChromiumEventLogger|id_ : str<br ALIGN="LEFT"/>tls : _local<br ALIGN="LEFT"/>|add_event_data(event_name: str): None<br ALIGN="LEFT"/>get_event_data(): Dict[str, Any]<br ALIGN="LEFT"/>get_pt2_compile_substack()<br ALIGN="LEFT"/>get_stack(): List[str]<br ALIGN="LEFT"/>get_top(): Optional[str]<br ALIGN="LEFT"/>log_event_end(event_name: str, time_ns: int, metadata: Dict[str, Any], start_time_ns: int, log_pt2_compile_event: bool): None<br ALIGN="LEFT"/>log_event_start(event_name: str, time_ns: int, metadata: Dict[str, Any], log_pt2_compile_event: bool): None<br ALIGN="LEFT"/>log_instant_event(event_name: str, time_ns: int, metadata: Optional[Dict[str, Any]], log_pt2_compile_event: bool): None<br ALIGN="LEFT"/>reset(): None<br ALIGN="LEFT"/>try_add_event_data(event_name: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_spec.chunk_sharding_spec.ChunkShardingSpec" [color="black", fontcolor="black", label=<{ChunkShardingSpec|ShardingDim : Union<br ALIGN="LEFT"/>dim : Union<br ALIGN="LEFT"/>placements : List[Union[torch.distributed._remote_device, str]]<br ALIGN="LEFT"/>|build_metadata(tensor_sizes: torch.Size, tensor_properties: sharded_tensor_meta.TensorProperties): sharded_tensor_meta.ShardedTensorMetadata<br ALIGN="LEFT"/>shard(tensor: torch.Tensor, src_rank: int, process_group): 'ShardedTensor'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.ChunkStorageMetadata" [color="black", fontcolor="black", label=<{ChunkStorageMetadata|offsets<br ALIGN="LEFT"/>sizes<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.CircularPad1d" [color="black", fontcolor="black", label=<{CircularPad1d|padding : Tuple[int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.CircularPad2d" [color="black", fontcolor="black", label=<{CircularPad2d|padding : Tuple[int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.CircularPad3d" [color="black", fontcolor="black", label=<{CircularPad3d|padding : Tuple[int, int, int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.class_method.ClassMethod" [color="black", fontcolor="black", label=<{ClassMethod|linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>method(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.CleanDiv" [color="black", fontcolor="black", label=<{CleanDiv|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.CleanupHook" [color="black", fontcolor="black", label=<{CleanupHook|name : str<br ALIGN="LEFT"/>scope : Dict[str, Any]<br ALIGN="LEFT"/>|create(scope, name, val)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.CleanupManager" [color="black", fontcolor="black", label=<{CleanupManager|count : int<br ALIGN="LEFT"/>instance : ClassVar[CleanupManager]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.ClearCacheOnAllocateMixin" [color="black", fontcolor="black", label=<{ClearCacheOnAllocateMixin|<br ALIGN="LEFT"/>|allocate(block: Allocation, is_last: bool)<br ALIGN="LEFT"/>clear_cache()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._lazy.closure.ClosureHandler" [color="black", fontcolor="black", label=<{ClosureHandler|<br ALIGN="LEFT"/>|run(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CodeCacheFuture" [color="black", fontcolor="black", label=<{CodeCacheFuture|<br ALIGN="LEFT"/>|<I>result</I>(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.code_context.CodeContextDict" [color="black", fontcolor="black", label=<{CodeContextDict|code_context<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>get_context(code: types.CodeType): Dict[str, Any]<br ALIGN="LEFT"/>has_context(code: types.CodeType): bool<br ALIGN="LEFT"/>pop_context(code: types.CodeType): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._code_flow.CodeFlow" [color="black", fontcolor="black", label=<{CodeFlow|message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>thread_flows : List[_thread_flow.ThreadFlow]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph.CodeGen" [color="black", fontcolor="black", label=<{CodeGen|<br ALIGN="LEFT"/>|additional_globals(): List[Tuple[str, Any]]<br ALIGN="LEFT"/>gen_fn_def(free_vars: List[str], maybe_return_annotation: str): str<br ALIGN="LEFT"/>generate_output(output_args: Argument): str<br ALIGN="LEFT"/>process_inputs(): Any<br ALIGN="LEFT"/>process_outputs(outputs: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.CodeGen" [color="black", fontcolor="black", label=<{CodeGen|exit_stack : ExitStack<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.pgo.CodeId" [color="black", fontcolor="black", label=<{CodeId|filename : str<br ALIGN="LEFT"/>firstlineno : int<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|make(code: types.CodeType): CodeId<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.CodeState" [color="black", fontcolor="black", label=<{CodeState|automatic_dynamic : DefaultDict[str, FrameStateSizeEntry]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.callable.CollatorIterDataPipe" [color="black", fontcolor="black", label=<{CollatorIterDataPipe|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.passes.collect_tracepoints_pass.CollectTracepointsPass" [color="black", fontcolor="black", label=<{CollectTracepointsPass|sig<br ALIGN="LEFT"/>specs : Dict[str, ModuleCallSignature]<br ALIGN="LEFT"/>|call(gm: torch.fx.GraphModule): Optional[PassResult]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.Collective" [color="black", fontcolor="black", label=<{Collective|<br ALIGN="LEFT"/>|join(rank, data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.CollectiveFunctionRewriteVariable" [color="black", fontcolor="black", label=<{CollectiveFunctionRewriteVariable|replacement_var<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>can_rewrite(variable)<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', old_fn, source)<br ALIGN="LEFT"/>rewrite(tx: 'InstructionTranslator', fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.compare.Colorize" [color="black", fontcolor="black", label=<{Colorize|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.ColwiseParallel" [color="black", fontcolor="black", label=<{ColwiseParallel|desired_input_layouts : tuple<br ALIGN="LEFT"/>input_layouts : tuple<br ALIGN="LEFT"/>output_layouts : tuple<br ALIGN="LEFT"/>use_local_output : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.masked._ops._combine_input_and_mask.Combine" [color="black", fontcolor="black", label=<{Combine|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input, mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel" [color="black", fontcolor="black", label=<{ComboKernel|MAX_NUM_ARGS : int<br ALIGN="LEFT"/>block_args : List[str], list<br ALIGN="LEFT"/>block_size_1d : int<br ALIGN="LEFT"/>block_size_2d : int<br ALIGN="LEFT"/>block_size_reduce : int<br ALIGN="LEFT"/>dispatch_class : Optional[Union[Type[ComboKernel.SequentialDispatch], Type[ComboKernel.RoundRobinDispatch]]]<br ALIGN="LEFT"/>dynamic_shape_args : List[str]<br ALIGN="LEFT"/>enable_autotune : bool<br ALIGN="LEFT"/>grids : List[List[int]]<br ALIGN="LEFT"/>iter_vars_count : count<br ALIGN="LEFT"/>min_x_blocks_list : List[Union[int, str]]<br ALIGN="LEFT"/>mixed_sizes : bool<br ALIGN="LEFT"/>num_warps : int<br ALIGN="LEFT"/>sub_kernels : List[TritonKernel]<br ALIGN="LEFT"/>x_numels_list : List[Union[int, str]]<br ALIGN="LEFT"/>|add_blockd_to_args(argdefs: List[str]): List[str]<br ALIGN="LEFT"/>add_numel_to_args(argdefs: List[str], signature: List[Any]): List[str]<br ALIGN="LEFT"/>add_numel_to_call_args_and_grid(name: str, call_args: List[Any], arg_types: List[Any], grid: List[Any]): None<br ALIGN="LEFT"/>add_numel_to_call_args_and_grid_benchmark(extra_args: List[Any], grid: Union[List[Any], Tuple[Any, ...]]): None<br ALIGN="LEFT"/>call_kernel(code: IndentedBuffer, name: str): None<br ALIGN="LEFT"/>codegen_blocks(code: IndentedBuffer): None<br ALIGN="LEFT"/>codegen_kernel(name: Optional[str]): str<br ALIGN="LEFT"/>codegen_kernel_benchmark(num_gb: float, grid: Optional[List[Any]]): IndentedBuffer<br ALIGN="LEFT"/>codegen_static_numels_sub_kernel(code: IndentedBuffer, sub_kernel: TritonKernel, num: int): List[str]<br ALIGN="LEFT"/>create_sub_kernel(triton_kernel: TritonKernel): TritonKernel<br ALIGN="LEFT"/>create_triton_kernel(tiling: Dict[str, sympy.Expr], features: SIMDKernelFeatures, optimize_mask: bool): TritonKernel<br ALIGN="LEFT"/>get_default_meta(): Dict[str, int]<br ALIGN="LEFT"/>get_mutated_args_sub_kernels(): List[str]<br ALIGN="LEFT"/>grid_no_autotune(grid: Union[Tuple[Any], List[Any]], num_kernels: int, min_blocks: int, is_sequential: bool): List[int]<br ALIGN="LEFT"/>horizontal_partition(nodes: List[BaseSchedulerNode], triton_scheduling: SIMDScheduling, kernel_map: Dict[BaseSchedulerNode, TritonKernel], node_info_map: Dict[BaseSchedulerNode, Tuple[Any, Any, Any, Any]], custom_algorithm: bool): List[List[BaseSchedulerNode]]<br ALIGN="LEFT"/>imports_for_benchmark_kernel(): str<br ALIGN="LEFT"/>jit_line(heuristics: str, size_hints: Dict[str, int], selected_kernel: TritonKernel, signature: List[Any], argdefs: List[str], pointwise_with_reduce: bool): str<br ALIGN="LEFT"/>min_x_blocks_sub_kernel(sub_kernel: TritonKernel, num: int): None<br ALIGN="LEFT"/>select_combo_heuristics(heuristics_list: List[str], size_hints_list: List[Dict[str, int]]): Tuple[str, Dict[str, int], TritonKernel]<br ALIGN="LEFT"/>select_dispatch_strategy(): None<br ALIGN="LEFT"/>select_heuristics(sub_kernel: TritonKernel): Tuple[str, Dict[str, int]]<br ALIGN="LEFT"/>uniquify_block_sizes(code: IndentedBuffer, num_kernel: int, uniquify: List[str]): IndentedBuffer<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.ddp_fusion.CommBlock" [color="black", fontcolor="black", label=<{CommBlock|comm_node<br ALIGN="LEFT"/>inputs : List[fx.Node]<br ALIGN="LEFT"/>node_list : List[fx.Node]<br ALIGN="LEFT"/>outputs : OrderedSet[fx.Node]<br ALIGN="LEFT"/>shape : Union[torch.Size, List[torch.Size]]<br ALIGN="LEFT"/>wait_nodes : List[fx.Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.CommBufferAllocateLine" [color="black", fontcolor="black", label=<{CommBufferAllocateLine|<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>make_allocation_line(comm_buffer_type, group_name, wrapper, name, device, dtype, shape, stride)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.CommBufferFreeLine" [color="black", fontcolor="black", label=<{CommBufferFreeLine|<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.CommBufferLayout" [color="black", fontcolor="black", label=<{CommBufferLayout|comm_buffer_type<br ALIGN="LEFT"/>group_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.CommBufferLine" [color="black", fontcolor="black", label=<{CommBufferLine|comm_buffer_type<br ALIGN="LEFT"/>group_name<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>wrapper<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.CommBufferType" [color="black", fontcolor="black", label=<{CommBufferType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.debug._comm_mode.CommDebugMode" [color="black", fontcolor="black", label=<{CommDebugMode|advanced_module_tracker<br ALIGN="LEFT"/>comm_counts : Dict[Any, int]<br ALIGN="LEFT"/>comm_module_counts : dict<br ALIGN="LEFT"/>comm_module_operation_counts : dict<br ALIGN="LEFT"/>comm_registry : set<br ALIGN="LEFT"/>|generate_comm_debug_tracing_table(noise_level)<br ALIGN="LEFT"/>generate_json_dump(file_name, noise_level)<br ALIGN="LEFT"/>get_comm_counts(): Dict[Any, int]<br ALIGN="LEFT"/>get_parameter_info(): Dict[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_sharding_info(): Dict[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_total_counts(): int<br ALIGN="LEFT"/>log_comm_debug_tracing_table_to_file(file_name, noise_level)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.CommonDdpComparisonTest" [color="black", fontcolor="black", label=<{CommonDdpComparisonTest|world_size<br ALIGN="LEFT"/>|get_remote_grads(rref, context_id)<br ALIGN="LEFT"/>trainer_name(rank)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.CommonDistAutogradTest" [color="black", fontcolor="black", label=<{CommonDistAutogradTest|dst_rank<br ALIGN="LEFT"/>|context_cleanup_test_helper(rpc_args, func, nested)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.CommonListMethodsVariable" [color="black", fontcolor="black", label=<{CommonListMethodsVariable|<br ALIGN="LEFT"/>|call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.CommonRemoteModuleTest" [color="black", fontcolor="black", label=<{CommonRemoteModuleTest|world_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._state_dict_utils.CompanionMismatch" [color="black", fontcolor="red", label=<{CompanionMismatch|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.compare.Compare" [color="black", fontcolor="black", label=<{Compare|<br ALIGN="LEFT"/>|colorize(rowwise)<br ALIGN="LEFT"/>extend_results(results)<br ALIGN="LEFT"/>highlight_warnings()<br ALIGN="LEFT"/>print()<br ALIGN="LEFT"/>trim_significant_figures()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.callback.CompilationCallbackHandler" [color="black", fontcolor="black", label=<{CompilationCallbackHandler|end_callbacks : List[Callable[[], None]]<br ALIGN="LEFT"/>start_callbacks : List[Callable[[], None]]<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>install_callbacks(): Generator[None, Any, Any]<br ALIGN="LEFT"/>register_end_callback(callback: Callable[[], None]): Callable[[], None]<br ALIGN="LEFT"/>register_start_callback(callback: Callable[[], None]): Callable[[], None]<br ALIGN="LEFT"/>remove_end_callback(callback: Callable[[], None]): None<br ALIGN="LEFT"/>remove_start_callback(callback: Callable[[], None]): None<br ALIGN="LEFT"/>run_end_callbacks(): None<br ALIGN="LEFT"/>run_start_callbacks(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.CompilationMetrics" [color="black", fontcolor="black", label=<{CompilationMetrics|accumulated_cache_size : Optional[int]<br ALIGN="LEFT"/>aot_autograd_cumulative_compile_time_us : Optional[int]<br ALIGN="LEFT"/>backend_compile_time_s : Optional[float]<br ALIGN="LEFT"/>backward_cumulative_compile_time_us : Optional[int]<br ALIGN="LEFT"/>cache_size : Optional[int]<br ALIGN="LEFT"/>co_filename : Optional[str]<br ALIGN="LEFT"/>co_firstlineno : Optional[int]<br ALIGN="LEFT"/>co_name : Optional[str]<br ALIGN="LEFT"/>code_gen_time_s : Optional[float]<br ALIGN="LEFT"/>compile_id : Optional[str]<br ALIGN="LEFT"/>compile_time_autotune_time_us : Optional[int]<br ALIGN="LEFT"/>compliant_custom_ops : Optional[Set[str]]<br ALIGN="LEFT"/>config_inline_inbuilt_nn_modules : Optional[bool]<br ALIGN="LEFT"/>config_suppress_errors : Optional[bool]<br ALIGN="LEFT"/>cuda_synchronize_time_us : Optional[int]<br ALIGN="LEFT"/>cuda_version : Optional[str]<br ALIGN="LEFT"/>distributed_ephemeral_timeout_us : Optional[int]<br ALIGN="LEFT"/>duration_us : Optional[int]<br ALIGN="LEFT"/>dynamo_compile_time_before_restart_us : Optional[int]<br ALIGN="LEFT"/>dynamo_config : Optional[str]<br ALIGN="LEFT"/>dynamo_cumulative_compile_time_us : Optional[int]<br ALIGN="LEFT"/>dynamo_time_before_restart_s : Optional[float]<br ALIGN="LEFT"/>end_time_us : Optional[int]<br ALIGN="LEFT"/>entire_frame_compile_time_s : Optional[float]<br ALIGN="LEFT"/>fail_reason : Optional[str]<br ALIGN="LEFT"/>fail_type : Optional[str]<br ALIGN="LEFT"/>fail_user_frame_filename : Optional[str]<br ALIGN="LEFT"/>fail_user_frame_lineno : Optional[int]<br ALIGN="LEFT"/>feature_usage : Optional[dict[str, bool]]<br ALIGN="LEFT"/>frame_key : Optional[str]<br ALIGN="LEFT"/>graph_input_count : Optional[int]<br ALIGN="LEFT"/>graph_node_count : Optional[int]<br ALIGN="LEFT"/>graph_op_count : Optional[int]<br ALIGN="LEFT"/>guard_count : Optional[int]<br ALIGN="LEFT"/>has_guarded_code : Optional[bool]<br ALIGN="LEFT"/>inductor_code_gen_cumulative_compile_time_us : Optional[int]<br ALIGN="LEFT"/>inductor_compile_time_s : Optional[float]<br ALIGN="LEFT"/>inductor_config : Optional[str]<br ALIGN="LEFT"/>inductor_cumulative_compile_time_us : Optional[int]<br ALIGN="LEFT"/>inductor_fx_remote_cache_backend_type : Optional[str]<br ALIGN="LEFT"/>inductor_fx_remote_cache_hit_count : Optional[int]<br ALIGN="LEFT"/>inductor_fx_remote_cache_hit_keys : Optional[str]<br ALIGN="LEFT"/>inductor_fx_remote_cache_miss_count : Optional[int]<br ALIGN="LEFT"/>inductor_fx_remote_cache_miss_keys : Optional[str]<br ALIGN="LEFT"/>is_forward : Optional[bool]<br ALIGN="LEFT"/>joint_graph_pass_time_us : Optional[int]<br ALIGN="LEFT"/>log_format_version : int<br ALIGN="LEFT"/>non_compliant_ops : Optional[Set[str]]<br ALIGN="LEFT"/>num_triton_bundles : Optional[int]<br ALIGN="LEFT"/>post_grad_pass_time_us : Optional[int]<br ALIGN="LEFT"/>pre_grad_pass_time_us : Optional[int]<br ALIGN="LEFT"/>remote_cache_time_saved_s : Optional[float]<br ALIGN="LEFT"/>remote_cache_version : Optional[int]<br ALIGN="LEFT"/>remote_fx_graph_cache_get_time_ms : Optional[int]<br ALIGN="LEFT"/>remote_fx_graph_cache_get_time_us : Optional[int]<br ALIGN="LEFT"/>remote_fx_graph_cache_put_time_ms : Optional[int]<br ALIGN="LEFT"/>remote_fx_graph_cache_put_time_us : Optional[int]<br ALIGN="LEFT"/>restart_reasons : Optional[Set[str]]<br ALIGN="LEFT"/>runtime_cudagraphify_time_us : Optional[int]<br ALIGN="LEFT"/>runtime_triton_autotune_time_us : Optional[int]<br ALIGN="LEFT"/>shape_env_guard_count : Optional[int]<br ALIGN="LEFT"/>specialize_float : Optional[bool]<br ALIGN="LEFT"/>start_time : Optional[float]<br ALIGN="LEFT"/>start_time_us : Optional[int]<br ALIGN="LEFT"/>structured_logging_overhead_s : Optional[float]<br ALIGN="LEFT"/>structured_logging_overhead_us : Optional[int]<br ALIGN="LEFT"/>triton_compile_time_us : Optional[int]<br ALIGN="LEFT"/>triton_version : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.CompilationMode" [color="black", fontcolor="black", label=<{CompilationMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.CompileCollectiveRestartAnalysis" [color="black", fontcolor="red", label=<{CompileCollectiveRestartAnalysis|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.CompileContext" [color="black", fontcolor="black", label=<{CompileContext|attempt : int<br ALIGN="LEFT"/>compile_id : Optional[CompileId]<br ALIGN="LEFT"/>shape_env_guards : List[str]<br ALIGN="LEFT"/>|current_compile_id()<br ALIGN="LEFT"/>current_trace_id()<br ALIGN="LEFT"/>get(): CompileContext<br ALIGN="LEFT"/>try_get(): Optional[CompileContext]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.testing.CompileCounter" [color="black", fontcolor="black", label=<{CompileCounter|frame_count : int<br ALIGN="LEFT"/>op_count : int<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.testing.CompileCounterWithBackend" [color="black", fontcolor="black", label=<{CompileCounterWithBackend|backend : str<br ALIGN="LEFT"/>frame_count : int<br ALIGN="LEFT"/>graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>op_count : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.CompileId" [color="black", fontcolor="black", label=<{CompileId|frame_compile_id : int<br ALIGN="LEFT"/>frame_id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.CompileTimeInstructionCounter" [color="black", fontcolor="black", label=<{CompileTimeInstructionCounter|<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>end(): None<br ALIGN="LEFT"/>record()<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>value(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.output_code.CompiledAOTI" [color="black", fontcolor="black", label=<{CompiledAOTI|filename : Union[str, List[str]]<br ALIGN="LEFT"/>|<I>post_compile</I>(example_inputs: Sequence[InputType], cudagraphs: BoxedBool, constants: CompiledFxGraphConstants): None<br ALIGN="LEFT"/><I>set_triton_bundle</I>(triton_bundle: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.CompiledBackward" [color="black", fontcolor="black", label=<{CompiledBackward|backward_state_indices : List[int]<br ALIGN="LEFT"/>num_symints_saved_for_bw_ : int<br ALIGN="LEFT"/>|is_backward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.registry.CompiledFn" [color="black", fontcolor="black", label=<{CompiledFn|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.CompiledForward" [color="black", fontcolor="black", label=<{CompiledForward|<br ALIGN="LEFT"/>|is_backward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd.post_compile.CompiledFunction" [color="black", fontcolor="black", label=<{CompiledFunction|compiled_bw<br ALIGN="LEFT"/>compiled_fw<br ALIGN="LEFT"/>maybe_subclass_metadata : Optional[SubclassMeta]<br ALIGN="LEFT"/>metadata<br ALIGN="LEFT"/>num_symints_saved_for_bw<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd.post_compile.CompiledFunction._double_backward.CompiledFunctionBackward" [color="black", fontcolor="black", label=<{CompiledFunctionBackward|<br ALIGN="LEFT"/>|backward(double_ctx)<br ALIGN="LEFT"/>forward(double_ctx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.output_code.CompiledFxGraph" [color="black", fontcolor="black", label=<{CompiledFxGraph|allocated_constant_name : Optional[Dict[str, str]]<br ALIGN="LEFT"/>boxed_forward_device_index : Optional[BoxedDeviceIndex]<br ALIGN="LEFT"/>cache_key : str<br ALIGN="LEFT"/>cache_linemap : Optional[List[Tuple[int, str]]]<br ALIGN="LEFT"/>constants : Optional[Dict[str, torch.Tensor]]<br ALIGN="LEFT"/>counter_deltas : Counter[str]<br ALIGN="LEFT"/>cudagraph_info : Optional[CudagraphCachedInfo]<br ALIGN="LEFT"/>current_callable : Optional[Callable[..., Any]]<br ALIGN="LEFT"/>device_idxs : OrderedSet[int]<br ALIGN="LEFT"/>device_types : OrderedSet[str]<br ALIGN="LEFT"/>disabled_cudagraphs_reason : Optional[str]<br ALIGN="LEFT"/>fx_kwargs<br ALIGN="LEFT"/>guards_expr : Optional[str]<br ALIGN="LEFT"/>inputs_to_check : Sequence[int]<br ALIGN="LEFT"/>metrics_deltas<br ALIGN="LEFT"/>mutated_input_idxs : OrderedSet[int]<br ALIGN="LEFT"/>mutated_inputs : OrderedSet[str]<br ALIGN="LEFT"/>output_strides : Optional[List[Optional[Tuple[_StrideExprStr, ...]]]]<br ALIGN="LEFT"/>source_code : str<br ALIGN="LEFT"/>torchbind_constants : Dict[str, torch._C.ScriptObject]<br ALIGN="LEFT"/>|after_deserialization(constants: CompiledFxGraphConstants): str<br ALIGN="LEFT"/>post_compile(example_inputs: Sequence[InputType], cudagraphs: BoxedBool, constants: CompiledFxGraphConstants): None<br ALIGN="LEFT"/>prepare_for_serialization(): None<br ALIGN="LEFT"/>set_triton_bundle(triton_bundle: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.output_code.CompiledFxGraphConstants" [color="black", fontcolor="black", label=<{CompiledFxGraphConstants|<br ALIGN="LEFT"/>|unwrap(g: CompiledFxGraph): Dict[str, torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.output_code.CompiledFxGraphConstantsWithGm" [color="black", fontcolor="black", label=<{CompiledFxGraphConstantsWithGm|gm<br ALIGN="LEFT"/>|unwrap(g: CompiledFxGraph): Dict[str, torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.CompilerBisector" [color="black", fontcolor="black", label=<{CompilerBisector|bisection_enabled : bool<br ALIGN="LEFT"/>|advance_backend(curr_backend: str): Optional[str]<br ALIGN="LEFT"/>advance_subsystem(curr_backend: str, curr_subsystem: Subsystem): Optional[Subsystem]<br ALIGN="LEFT"/>delete_bisect_status(): None<br ALIGN="LEFT"/>disable_subsystem(backend: str, subsystem: str, debug_info: Optional[Callable[[], str]]): bool<br ALIGN="LEFT"/>do_bisect(fn: Callable[[], bool], cli_interface: bool): Optional[BisectionResult]<br ALIGN="LEFT"/>get_backend(): Optional[str]<br ALIGN="LEFT"/>get_bisect_range(backend_name: str, subsystem_name: str): Tuple[int, int]<br ALIGN="LEFT"/>get_config_change(config_name: str): Optional[Dict[str, object]]<br ALIGN="LEFT"/>get_dir(): str<br ALIGN="LEFT"/>get_run_state(backend_name: str, subsystem_name: str): Optional[str]<br ALIGN="LEFT"/>get_subsystem(): Optional[str]<br ALIGN="LEFT"/>get_subsystem_object(backend_name: str, subsystem_name: str): Subsystem<br ALIGN="LEFT"/>get_system_counter(name: str, increment: bool): int<br ALIGN="LEFT"/>initialize_system(): None<br ALIGN="LEFT"/>process_subsystem(curr_backend: str, curr_subsystem: Subsystem, fn: Callable[[], bool], cli_interface: bool): bool<br ALIGN="LEFT"/>read_lines_from_file(file_path: str): List[str]<br ALIGN="LEFT"/>set_config_values(backend: str, subsystem: str, config_data: Dict[str, object]): None<br ALIGN="LEFT"/>update_bisect_range(backend_name: str, subsystem_name: str, low: int, high: int): None<br ALIGN="LEFT"/>update_bisect_status(backend_name: str, subsystem_name: str): None<br ALIGN="LEFT"/>update_config_change(backend: str, subsystem: ConfigChange): None<br ALIGN="LEFT"/>update_run_state(backend_name: str, subsystem: Subsystem, run_state: str): None<br ALIGN="LEFT"/>write_lines_to_file(file_path: str, lines: List[str]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [color="black", fontcolor="black", label=<{CompilerWrapper|<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config): Callable<br ALIGN="LEFT"/>pre_compile(flat_fn, flat_args: List[Tensor], aot_config: AOTConfig): Tuple[Callable, List[Tensor], ViewAndMutationMeta]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ComplexDoubleStorage" [color="black", fontcolor="black", label=<{ComplexDoubleStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ComplexDoubleStorage" [color="black", fontcolor="black", label=<{ComplexDoubleStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ComplexFloatStorage" [color="black", fontcolor="black", label=<{ComplexFloatStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ComplexFloatStorage" [color="black", fontcolor="black", label=<{ComplexFloatStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ComplexView" [color="black", fontcolor="black", label=<{ComplexView|<br ALIGN="LEFT"/>|get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.split_utils.Component" [color="black", fontcolor="black", label=<{Component|constructor_args : List[str]<br ALIGN="LEFT"/>getattr_maps : Dict[torch.fx.Node, torch.fx.Node]<br ALIGN="LEFT"/>gm : Optional[torch.fx.GraphModule]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>input_placeholders : List<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>order : int<br ALIGN="LEFT"/>orig_inputs : List<br ALIGN="LEFT"/>orig_outputs : List<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.composable_quantizer.ComposableQuantizer" [color="black", fontcolor="black", label=<{ComposableQuantizer|quantizers : List[Quantizer]<br ALIGN="LEFT"/>|annotate(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/>transform_for_annotation(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/><I>validate</I>(model: torch.fx.GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.ComposeTransform" [color="black", fontcolor="black", label=<{ComposeTransform|inv<br ALIGN="LEFT"/>parts : List[Transform]<br ALIGN="LEFT"/>|bijective()<br ALIGN="LEFT"/>codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>sign()<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.composite_compliance.generate_cct_and_mode.CompositeCompliantTensor" [color="black", fontcolor="black", label=<{CompositeCompliantTensor|elem<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.composite_compliance.generate_cct_and_mode.CompositeCompliantTensorMode" [color="black", fontcolor="black", label=<{CompositeCompliantTensorMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.CompositeModel" [color="black", fontcolor="black", label=<{CompositeModel|l1<br ALIGN="LEFT"/>l2<br ALIGN="LEFT"/>u1<br ALIGN="LEFT"/>u2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.CompositeParamModel" [color="black", fontcolor="black", label=<{CompositeParamModel|l<br ALIGN="LEFT"/>p<br ALIGN="LEFT"/>u1<br ALIGN="LEFT"/>u2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.comptime.ComptimeContext" [color="black", fontcolor="black", label=<{ComptimeContext|<br ALIGN="LEFT"/>|assert_static(val)<br ALIGN="LEFT"/>get_local(name: str): ComptimeVar<br ALIGN="LEFT"/>graph()<br ALIGN="LEFT"/>graph_break(msg)<br ALIGN="LEFT"/>parent()<br ALIGN="LEFT"/>print(val)<br ALIGN="LEFT"/>print_bt()<br ALIGN="LEFT"/>print_disas()<br ALIGN="LEFT"/>print_graph()<br ALIGN="LEFT"/>print_guards()<br ALIGN="LEFT"/>print_locals()<br ALIGN="LEFT"/>print_value_stack()<br ALIGN="LEFT"/>sleep(sec)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.comptime.ComptimeVar" [color="black", fontcolor="black", label=<{ComptimeVar|<br ALIGN="LEFT"/>|as_fake()<br ALIGN="LEFT"/>as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>force_static()<br ALIGN="LEFT"/>is_dynamic()<br ALIGN="LEFT"/>is_proxy()<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>size(dim: Optional[int]): Union[int, torch.SymInt]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.ComptimeVariable" [color="black", fontcolor="black", label=<{ComptimeVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/><I>reconstruct</I>(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ComputedBuffer" [color="black", fontcolor="black", label=<{ComputedBuffer|data<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>origin_node : Field<br ALIGN="LEFT"/>origins : Field<br ALIGN="LEFT"/>traceback : Field<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>decide_layout(): None<br ALIGN="LEFT"/>get_computed_buffer_name(): Optional[str]<br ALIGN="LEFT"/>get_default_sizes_body(): Tuple[Tuple[List[sympy.Expr], List[sympy.Expr]], LoopBody, Tuple[List[sympy.Expr], List[sympy.Expr]]]<br ALIGN="LEFT"/>get_fill_order(): Optional[List[int]]<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>get_store_function(): Callable[..., OpsValue]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>is_no_op(): bool<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>simplify_and_reorder(extra_indexing_constraints: Optional[Tuple[Dict[Any, Any], List[Any]]], recompute_sizes_body_func: Optional[Callable[..., Any]]): Tuple[Tuple[List[sympy.Expr], List[sympy.Expr]], LoopBody]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.ConcatDataFramesPipe" [color="black", fontcolor="black", label=<{ConcatDataFramesPipe|n_batch : int<br ALIGN="LEFT"/>source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.dataset.ConcatDataset" [color="black", fontcolor="black", label=<{ConcatDataset|cummulative_sizes<br ALIGN="LEFT"/>cumulative_sizes : List[int]<br ALIGN="LEFT"/>datasets : List[Dataset[_T_co]]<br ALIGN="LEFT"/>|cumsum(sequence)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ConcatKernel" [color="black", fontcolor="black", label=<{ConcatKernel|inputs : list<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|can_realize_into_without_copy(src, dst)<br ALIGN="LEFT"/>create(inputs, dim)<br ALIGN="LEFT"/>realize_into(src, dst)<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining.ConcaterIterDataPipe" [color="black", fontcolor="black", label=<{ConcaterIterDataPipe|datapipes : Tuple[IterDataPipe]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.combining.ConcaterMapDataPipe" [color="black", fontcolor="black", label=<{ConcaterMapDataPipe|datapipes : Tuple[MapDataPipe]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.fx_minifier.ConcreteProp" [color="black", fontcolor="black", label=<{ConcreteProp|pbar : tqdm<br ALIGN="LEFT"/>seen_storages : set<br ALIGN="LEFT"/>skip_offload : bool<br ALIGN="LEFT"/>writer : NoneType<br ALIGN="LEFT"/>|propagate()<br ALIGN="LEFT"/>run_node(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._recursive.ConcreteTypeStore" [color="black", fontcolor="black", label=<{ConcreteTypeStore|methods_compiled : Set[torch._C.ConcreteModuleType]<br ALIGN="LEFT"/>type_store : Dict[Type[Module], List[torch._C.ConcreteModuleType]]<br ALIGN="LEFT"/>|get_or_create_concrete_type(nn_module)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.cond.CondAutogradOp" [color="black", fontcolor="black", label=<{CondAutogradOp|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, pred, fw_true_graph, fw_false_graph, joint_true_graph, joint_false_graph)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.cond_branch_class_method.CondBranchClassMethod" [color="black", fontcolor="black", label=<{CondBranchClassMethod|subm<br ALIGN="LEFT"/>|bar(x)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.cond_branch_nested_function.CondBranchNestedFunction" [color="black", fontcolor="black", label=<{CondBranchNestedFunction|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.cond_branch_nonlocal_variables.CondBranchNonlocalVariables" [color="black", fontcolor="black", label=<{CondBranchNonlocalVariables|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.cond_closed_over_variable.CondClosedOverVariable" [color="black", fontcolor="black", label=<{CondClosedOverVariable|<br ALIGN="LEFT"/>|forward(pred, x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.CondHigherOrderVariable" [color="black", fontcolor="black", label=<{CondHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.cond.CondOp" [color="black", fontcolor="black", label=<{CondOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.CondOpArgsMismatchError" [color="black", fontcolor="red", label=<{CondOpArgsMismatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.cond_operands.CondOperands" [color="black", fontcolor="black", label=<{CondOperands|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.cond_predicate.CondPredicate" [color="black", fontcolor="black", label=<{CondPredicate|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.Conditional" [color="black", fontcolor="black", label=<{Conditional|false_subgraph : Optional[Subgraph]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>operands : Optional[List[TensorBox]]<br ALIGN="LEFT"/>outputs : Optional[List[MultiOutput]]<br ALIGN="LEFT"/>predicate : Optional[IRNode]<br ALIGN="LEFT"/>true_subgraph : Optional[Subgraph]<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(predicate: TensorBox, true_fn: Subgraph, false_fn: Subgraph, operands: List[TensorBox])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.Config" [color="black", fontcolor="black", label=<{Config|expr_count : Dict[str, int]<br ALIGN="LEFT"/>expr_to_name : Dict[str, str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._config_module.Config" [color="black", fontcolor="black", label=<{Config|default : Any<br ALIGN="LEFT"/>env_name_default : Optional[str]<br ALIGN="LEFT"/>env_name_force : Optional[str]<br ALIGN="LEFT"/>justknob : Optional[str]<br ALIGN="LEFT"/>value_type : Optional[type]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.ConfigChange" [color="black", fontcolor="black", label=<{ConfigChange|config_field : str<br ALIGN="LEFT"/>config_name : str<br ALIGN="LEFT"/>config_value : object<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._config_module.ConfigModule" [color="black", fontcolor="black", label=<{ConfigModule|<br ALIGN="LEFT"/>|codegen_config(): str<br ALIGN="LEFT"/>get_config_copy(): Dict[str, Any]<br ALIGN="LEFT"/>get_hash(): bytes<br ALIGN="LEFT"/>get_type(config_name: str): type<br ALIGN="LEFT"/>load_config(maybe_pickled_config: Union[bytes, Dict[str, Any]]): None<br ALIGN="LEFT"/>patch(arg1: Optional[Union[str, Dict[str, Any]]], arg2: Any): 'ContextDecorator'<br ALIGN="LEFT"/>save_config(): bytes<br ALIGN="LEFT"/>save_config_portable(): Dict[str, Any]<br ALIGN="LEFT"/>shallow_copy_dict(): Dict[str, Any]<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._config_module.install_config_module.ConfigModuleInstance" [color="black", fontcolor="black", label=<{ConfigModuleInstance|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._config_module.ConfigModule.patch.ConfigPatch" [color="black", fontcolor="black", label=<{ConfigPatch|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler._get_quantize_handler_cls.ConfigurableQuantizeHandler" [color="black", fontcolor="black", label=<{ConfigurableQuantizeHandler|dtype_configs<br ALIGN="LEFT"/>observation_type<br ALIGN="LEFT"/>|is_general_tensor_value_op(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._configuration_override.ConfigurationOverride" [color="black", fontcolor="black", label=<{ConfigurationOverride|configuration<br ALIGN="LEFT"/>descriptor<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.Conj" [color="black", fontcolor="black", label=<{Conj|conjucts<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.multiprocessing.queue.ConnectionWrapper" [color="black", fontcolor="black", label=<{ConnectionWrapper|conn<br ALIGN="LEFT"/>|recv()<br ALIGN="LEFT"/>send(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.metrics.api.ConsoleMetricHandler" [color="black", fontcolor="black", label=<{ConsoleMetricHandler|<br ALIGN="LEFT"/>|emit(metric_data: MetricData)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.ConstDictKeySource" [color="black", fontcolor="black", label=<{ConstDictKeySource|<br ALIGN="LEFT"/>|is_dict_key()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.ConstDictVariable" [color="black", fontcolor="black", label=<{ConstDictVariable|items<br ALIGN="LEFT"/>original_items<br ALIGN="LEFT"/>should_reconstruct_all : bool<br ALIGN="LEFT"/>user_cls : dict<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_hasattr(tx, name)<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>getitem_const(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>getitem_const_raise_exception_if_absent(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>has_new_items()<br ALIGN="LEFT"/>is_new_item(value, other)<br ALIGN="LEFT"/>keys_as_python_constant()<br ALIGN="LEFT"/>len()<br ALIGN="LEFT"/>maybe_getitem_const(arg: VariableTracker)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script.ConstMap" [color="black", fontcolor="black", label=<{ConstMap|const_mapping<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Constant" [color="black", fontcolor="black", label=<{Constant|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>value : Any<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/><I>realize</I>(): Optional[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.graph_signature.ConstantArgument" [color="black", fontcolor="black", label=<{ConstantArgument|name : str<br ALIGN="LEFT"/>value : Union[int, float, bool, str, None]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.passes.lift_constants_pass.ConstantAttrMap" [color="black", fontcolor="black", label=<{ConstantAttrMap|<br ALIGN="LEFT"/>|add(key: Union[torch.Tensor, torch.ScriptObject, FakeScriptObject], value: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ConstantBuffer" [color="black", fontcolor="black", label=<{ConstantBuffer|override_device : Optional[torch.device]<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.custom_tensor.ConstantExtraMetadataTensor" [color="black", fontcolor="black", label=<{ConstantExtraMetadataTensor|constant_attribute : int<br ALIGN="LEFT"/>elem<br ALIGN="LEFT"/>|add_constant(a)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.constant_folding.ConstantFolder" [color="black", fontcolor="black", label=<{ConstantFolder|deferred_value : object<br ALIGN="LEFT"/>lifted_constant_names : Optional[List[str]]<br ALIGN="LEFT"/>node_replacements : Dict[torch.fx.Node, Any]<br ALIGN="LEFT"/>replaced_uses : Dict[torch.fx.Node, int]<br ALIGN="LEFT"/>skip_constructors : bool<br ALIGN="LEFT"/>unknown_value : object<br ALIGN="LEFT"/>user_to_last_uses : defaultdict<br ALIGN="LEFT"/>|add_node_replacement(node: torch.fx.Node, tensor: torch.Tensor): None<br ALIGN="LEFT"/>insert_placerholder_values(env: Dict[torch.fx.Node, Any]): None<br ALIGN="LEFT"/>insertable_tensor_check(tensor: torch.Tensor): bool<br ALIGN="LEFT"/>is_impure(node: torch.fx.node.Node): bool<br ALIGN="LEFT"/>node_to_last_non_output_use(): Dict[torch.fx.Node, List[torch.fx.Node]]<br ALIGN="LEFT"/>run(): Any<br ALIGN="LEFT"/>run_node(node: torch.fx.Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.passes.constant_folding.ConstantFolder" [color="black", fontcolor="black", label=<{ConstantFolder|node_replacements : Dict[torch.fx.Node, Any]<br ALIGN="LEFT"/>replaced_uses : Dict[torch.fx.Node, int]<br ALIGN="LEFT"/>skip_constructors : bool<br ALIGN="LEFT"/>unknown_value : object<br ALIGN="LEFT"/>user_to_last_uses : defaultdict<br ALIGN="LEFT"/>|add_node_replacement(node: torch.fx.Node, tensor: torch.Tensor): None<br ALIGN="LEFT"/>insertable_tensor_check(tensor: torch.Tensor): bool<br ALIGN="LEFT"/>is_impure(node: torch.fx.Node): bool<br ALIGN="LEFT"/>node_to_last_non_output_use()<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>run_node(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental._constant_symnode.ConstantIntNode" [color="black", fontcolor="black", label=<{ConstantIntNode|val : int<br ALIGN="LEFT"/>|clone(): 'ConstantIntNode'<br ALIGN="LEFT"/>constant_int(): int<br ALIGN="LEFT"/>eq(other: Any): Any<br ALIGN="LEFT"/>ge(other: Any): Any<br ALIGN="LEFT"/>gt(other: Any): Any<br ALIGN="LEFT"/>is_bool(): bool<br ALIGN="LEFT"/>is_constant(): bool<br ALIGN="LEFT"/>is_float(): bool<br ALIGN="LEFT"/>is_int(): bool<br ALIGN="LEFT"/>is_nested_int(): bool<br ALIGN="LEFT"/>is_symbolic(): bool<br ALIGN="LEFT"/>le(other: Any): Any<br ALIGN="LEFT"/>lt(other: Any): Any<br ALIGN="LEFT"/>maybe_as_int(): int<br ALIGN="LEFT"/>mul(other: Any): Any<br ALIGN="LEFT"/>ne(other: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.ConstantLR" [color="black", fontcolor="black", label=<{ConstantLR|factor : float<br ALIGN="LEFT"/>total_iters : int<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.ConstantLikeVariable" [color="black", fontcolor="black", label=<{ConstantLikeVariable|value<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding.ConstantPad1d" [color="black", fontcolor="black", label=<{ConstantPad1d|padding : Tuple[int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ConstantPad2d" [color="black", fontcolor="black", label=<{ConstantPad2d|padding : Tuple[int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ConstantPad3d" [color="black", fontcolor="black", label=<{ConstantPad3d|padding : Tuple[int, int, int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.ConstantRegexMatchVariable" [color="black", fontcolor="black", label=<{ConstantRegexMatchVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.ConstantSource" [color="black", fontcolor="black", label=<{ConstantSource|source_name : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/><I>make_guard</I>(fn)<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.ConstantValue" [color="black", fontcolor="black", label=<{ConstantValue|as_bool : Annotated[bool, 50]<br ALIGN="LEFT"/>as_float : Annotated[float, 30]<br ALIGN="LEFT"/>as_int : Annotated[int, 20]<br ALIGN="LEFT"/>as_none : Annotated[bool, 10]<br ALIGN="LEFT"/>as_string : Annotated[str, 40]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" [color="black", fontcolor="black", label=<{ConstantVariable|items<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>const_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>create(value): VariableTracker<br ALIGN="LEFT"/>getitem_const(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>is_base_literal(obj)<br ALIGN="LEFT"/>is_literal(obj)<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.constrain_as_size_example.ConstrainAsSizeExample" [color="black", fontcolor="black", label=<{ConstrainAsSizeExample|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.constrain_as_value_example.ConstrainAsValueExample" [color="black", fontcolor="black", label=<{ConstrainAsValueExample|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.Constraint" [color="black", fontcolor="black", label=<{Constraint|warn_only : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [color="black", fontcolor="black", label=<{Constraint|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints.Constraint" [color="black", fontcolor="black", label=<{Constraint|event_dim : int<br ALIGN="LEFT"/>is_discrete : bool<br ALIGN="LEFT"/>|<I>check</I>(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint_generator.ConstraintGenerator" [color="black", fontcolor="black", label=<{ConstraintGenerator|constraints : list<br ALIGN="LEFT"/>graph : NoneType<br ALIGN="LEFT"/>symbol_dict : dict<br ALIGN="LEFT"/>traced<br ALIGN="LEFT"/>traced_params : dict<br ALIGN="LEFT"/>|generate_constraints(counter)<br ALIGN="LEFT"/>generate_constraints_node(n: Node, counter)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraint_registry.ConstraintRegistry" [color="black", fontcolor="black", label=<{ConstraintRegistry|<br ALIGN="LEFT"/>|register(constraint, factory)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ConstraintViolationError" [color="black", fontcolor="red", label=<{ConstraintViolationError|args : tuple<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.masked.maskedtensor.core.MaskedTensor._from_values.Constructor" [color="black", fontcolor="black", label=<{Constructor|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, data, mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.post_grad.ConstructorMoverPass" [color="black", fontcolor="black", label=<{ConstructorMoverPass|allow_outputs : bool<br ALIGN="LEFT"/>target : str<br ALIGN="LEFT"/>|allow_cpu_device(node: fx.Node): bool<br ALIGN="LEFT"/>cannot_be_moved(node: fx.Node): bool<br ALIGN="LEFT"/>find_movable_constructors(graph: fx.Graph, constructors: List[fx.Node]): OrderedSet[fx.Node]<br ALIGN="LEFT"/>get_cpu_indeg_count(graph: fx.Graph): Dict[fx.Node, int]<br ALIGN="LEFT"/>get_node_device(node: fx.Node): Optional[torch.device]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.container.Container" [color="black", fontcolor="black", label=<{Container|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._content_store.ContentStoreReader" [color="black", fontcolor="black", label=<{ContentStoreReader|loc : str<br ALIGN="LEFT"/>storage_cache : Optional[Dict[Optional[torch.device], Dict[str, StorageWeakRef]]], defaultdict<br ALIGN="LEFT"/>|read_storage(h: str): torch.UntypedStorage<br ALIGN="LEFT"/>read_tensor(name: str): torch.Tensor<br ALIGN="LEFT"/>read_tensor_metadata(name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._content_store.ContentStoreWriter" [color="black", fontcolor="black", label=<{ContentStoreWriter|loc : str<br ALIGN="LEFT"/>seen_storage_hashes : Set[str]<br ALIGN="LEFT"/>stable_hash : bool<br ALIGN="LEFT"/>|compute_tensor_metadata(t: torch.Tensor, h)<br ALIGN="LEFT"/>write_storage(storage: torch.UntypedStorage): str<br ALIGN="LEFT"/>write_tensor(name: str, t: torch.Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._config_module.ContextDecorator" [color="black", fontcolor="black", label=<{ContextDecorator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.ContextMangerState" [color="black", fontcolor="black", label=<{ContextMangerState|cleanup_fn : Optional[Callable]<br ALIGN="LEFT"/>proxy : Optional[torch.fx.Proxy]<br ALIGN="LEFT"/>|cleanup()<br ALIGN="LEFT"/>cleanup_assert()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.ContextProp" [color="black", fontcolor="black", label=<{ContextProp|getter<br ALIGN="LEFT"/>setter<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [color="black", fontcolor="black", label=<{ContextWrappingVariable|initial_values : NoneType<br ALIGN="LEFT"/>state : NoneType<br ALIGN="LEFT"/>target_values<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>exit_on_graph_break()<br ALIGN="LEFT"/><I>fn_name</I>()<br ALIGN="LEFT"/><I>module_name</I>()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>reconstruct_type(codegen)<br ALIGN="LEFT"/>set_cleanup_hook(tx: 'InstructionTranslator', fn)<br ALIGN="LEFT"/>supports_graph_breaks()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.resume_execution.ContinueExecutionCache" [color="black", fontcolor="black", label=<{ContinueExecutionCache|cache<br ALIGN="LEFT"/>generated_code_metadata<br ALIGN="LEFT"/>|generate(code, lineno, offset: int, setup_fn_target_offsets: Tuple[int, ...], nstack: int, argnames: Tuple[str, ...], argnames_null: Tuple[str, ...], setup_fns: Tuple[ReenterWith, ...], stack_ctx_vars: Tuple[Tuple[int, Tuple[Any]], ...], argnames_ctx_vars: Tuple[Tuple[str, Tuple[Any]], ...], null_idxes: Tuple[int, ...]): types.CodeType<br ALIGN="LEFT"/>generate_based_on_original_code_object(code, lineno, offset: int, setup_fn_target_offsets: Tuple[int, ...])<br ALIGN="LEFT"/>lookup(code, lineno)<br ALIGN="LEFT"/>unreachable_codes(code_options): List[Instruction]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.continuous_bernoulli.ContinuousBernoulli" [color="black", fontcolor="black", label=<{ContinuousBernoulli|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ControlFlow" [color="black", fontcolor="black", label=<{ControlFlow|<br ALIGN="LEFT"/>|example_inputs()<br ALIGN="LEFT"/>forward(xs: torch.Tensor, pred1: torch.Tensor, pred2: torch.Tensor, y: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.ControlFlowToyModel" [color="black", fontcolor="black", label=<{ControlFlowToyModel|lin1<br ALIGN="LEFT"/>lin2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv1d" [color="black", fontcolor="black", label=<{Conv1d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.Conv1d" [color="black", fontcolor="black", label=<{Conv1d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.Conv1d" [color="black", fontcolor="black", label=<{Conv1d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.conv.Conv1d" [color="black", fontcolor="black", label=<{Conv1d|<br ALIGN="LEFT"/>|from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.Conv1d" [color="black", fontcolor="black", label=<{Conv1d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.conv.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.Conv2d" [color="black", fontcolor="black", label=<{Conv2d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dActivation" [color="black", fontcolor="black", label=<{Conv2dActivation|conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dBias" [color="black", fontcolor="black", label=<{Conv2dBias|conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.Conv2dBiasFollowedByBatchNorm2dPattern" [color="black", fontcolor="black", label=<{Conv2dBiasFollowedByBatchNorm2dPattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>skip<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dPadBias" [color="black", fontcolor="black", label=<{Conv2dPadBias|act1<br ALIGN="LEFT"/>act2<br ALIGN="LEFT"/>conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dPool" [color="black", fontcolor="black", label=<{Conv2dPool|af1<br ALIGN="LEFT"/>conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>conv2d3<br ALIGN="LEFT"/>maxpool<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dPoolFlatten" [color="black", fontcolor="black", label=<{Conv2dPoolFlatten|af1<br ALIGN="LEFT"/>avg_pool<br ALIGN="LEFT"/>conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>flatten<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [color="black", fontcolor="black", label=<{Conv2dPoolFlattenFunctional|af1<br ALIGN="LEFT"/>avg_pool<br ALIGN="LEFT"/>conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dPropAnnotaton" [color="black", fontcolor="black", label=<{Conv2dPropAnnotaton|conv<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dThenConv1d" [color="black", fontcolor="black", label=<{Conv2dThenConv1d|conv1d<br ALIGN="LEFT"/>conv2d<br ALIGN="LEFT"/>|example_inputs()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithCat" [color="black", fontcolor="black", label=<{Conv2dWithCat|conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithObsSharingOps" [color="black", fontcolor="black", label=<{Conv2dWithObsSharingOps|adaptive_avg_pool2d<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>hardtanh<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoCat" [color="black", fontcolor="black", label=<{Conv2dWithTwoCat|conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>|forward(x1, x2, x3, x4)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinear" [color="black", fontcolor="black", label=<{Conv2dWithTwoLinear|conv<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinearPermute" [color="black", fontcolor="black", label=<{Conv2dWithTwoLinearPermute|conv<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv3d" [color="black", fontcolor="black", label=<{Conv3d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.Conv3d" [color="black", fontcolor="black", label=<{Conv3d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.Conv3d" [color="black", fontcolor="black", label=<{Conv3d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.conv.Conv3d" [color="black", fontcolor="black", label=<{Conv3d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.Conv3d" [color="black", fontcolor="black", label=<{Conv3d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAdd2d" [color="black", fontcolor="black", label=<{ConvAdd2d|<br ALIGN="LEFT"/>|forward(input, extra_input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvAdd2d" [color="black", fontcolor="black", label=<{ConvAdd2d|add<br ALIGN="LEFT"/>|forward(x1, x2)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAddReLU2d" [color="black", fontcolor="black", label=<{ConvAddReLU2d|<br ALIGN="LEFT"/>|forward(input, extra_input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvAddReLU2d" [color="black", fontcolor="black", label=<{ConvAddReLU2d|add<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x1, x2)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.pre_grad.fuse_conv_bn.ConvBNFusion" [color="black", fontcolor="black", label=<{ConvBNFusion|bn_bias : NoneType<br ALIGN="LEFT"/>bn_eps : NoneType<br ALIGN="LEFT"/>bn_module : NoneType<br ALIGN="LEFT"/>bn_nodes : list<br ALIGN="LEFT"/>bn_running_mean : NoneType<br ALIGN="LEFT"/>bn_running_var : NoneType<br ALIGN="LEFT"/>bn_weight : NoneType<br ALIGN="LEFT"/>conv_module<br ALIGN="LEFT"/>fusion_enabled : bool<br ALIGN="LEFT"/>|add_bn_node(bn_node)<br ALIGN="LEFT"/>disable_fusion()<br ALIGN="LEFT"/>is_fusion_enabled()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvBNReLU" [color="black", fontcolor="black", label=<{ConvBNReLU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn1d" [color="black", fontcolor="black", label=<{ConvBn1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn1d" [color="black", fontcolor="black", label=<{ConvBn1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn2d" [color="black", fontcolor="black", label=<{ConvBn2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn2d" [color="black", fontcolor="black", label=<{ConvBn2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn3d" [color="black", fontcolor="black", label=<{ConvBn3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn3d" [color="black", fontcolor="black", label=<{ConvBn3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvBnAddReluModel" [color="black", fontcolor="black", label=<{ConvBnAddReluModel|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>left_conv : bool<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>two_conv : bool<br ALIGN="LEFT"/>use_torch_add : bool<br ALIGN="LEFT"/>with_bn : bool<br ALIGN="LEFT"/>with_relu : bool<br ALIGN="LEFT"/>|forward(x1, x2)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvBnModel" [color="black", fontcolor="black", label=<{ConvBnModel|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU1d" [color="black", fontcolor="black", label=<{ConvBnReLU1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d" [color="black", fontcolor="black", label=<{ConvBnReLU1d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU2d" [color="black", fontcolor="black", label=<{ConvBnReLU2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d" [color="black", fontcolor="black", label=<{ConvBnReLU2d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvBnReLU2dAndLinearReLU" [color="black", fontcolor="black", label=<{ConvBnReLU2dAndLinearReLU|conv_bn_relu<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU3d" [color="black", fontcolor="black", label=<{ConvBnReLU3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d" [color="black", fontcolor="black", label=<{ConvBnReLU3d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvBnReLUModel" [color="black", fontcolor="black", label=<{ConvBnReLUModel|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.kernel.conv.ConvLayoutParams" [color="black", fontcolor="black", label=<{ConvLayoutParams|dilation : tuple[int, ...]<br ALIGN="LEFT"/>groups : int<br ALIGN="LEFT"/>output_padding : tuple[int, ...]<br ALIGN="LEFT"/>padding : tuple[int, ...]<br ALIGN="LEFT"/>stride : tuple[int, ...]<br ALIGN="LEFT"/>transposed : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvLinearWPermute" [color="black", fontcolor="black", label=<{ConvLinearWPermute|conv<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvMaxPool2d" [color="black", fontcolor="black", label=<{ConvMaxPool2d|conv<br ALIGN="LEFT"/>pool<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvModel" [color="black", fontcolor="black", label=<{ConvModel|conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.conv_expanded_weights.ConvPerSampleGrad" [color="black", fontcolor="black", label=<{ConvPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, kwarg_names, conv_fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.ConvPoolArgs2d" [color="black", fontcolor="black", label=<{ConvPoolArgs2d|dilation_h : int<br ALIGN="LEFT"/>dilation_w : int<br ALIGN="LEFT"/>group : int<br ALIGN="LEFT"/>kernel_h : int<br ALIGN="LEFT"/>kernel_w : int<br ALIGN="LEFT"/>pad_b : int<br ALIGN="LEFT"/>pad_l : int<br ALIGN="LEFT"/>pad_r : int<br ALIGN="LEFT"/>pad_t : int<br ALIGN="LEFT"/>stride_h : int<br ALIGN="LEFT"/>stride_w : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d" [color="black", fontcolor="black", label=<{ConvReLU1d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU1d" [color="black", fontcolor="black", label=<{ConvReLU1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d" [color="black", fontcolor="black", label=<{ConvReLU1d|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d" [color="black", fontcolor="black", label=<{ConvReLU2d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU2d" [color="black", fontcolor="black", label=<{ConvReLU2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d" [color="black", fontcolor="black", label=<{ConvReLU2d|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d" [color="black", fontcolor="black", label=<{ConvReLU3d|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU3d" [color="black", fontcolor="black", label=<{ConvReLU3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d" [color="black", fontcolor="black", label=<{ConvReLU3d|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvReluAddModel" [color="black", fontcolor="black", label=<{ConvReluAddModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvReluConvModel" [color="black", fontcolor="black", label=<{ConvReluConvModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvReluModel" [color="black", fontcolor="black", label=<{ConvReluModel|fc<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.ConvReluQuantizeHandler" [color="black", fontcolor="black", label=<{ConvReluQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [color="black", fontcolor="black", label=<{ConvTWithBNRelu|bn<br ALIGN="LEFT"/>convt<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose1d" [color="black", fontcolor="black", label=<{ConvTranspose1d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose1d" [color="black", fontcolor="black", label=<{ConvTranspose1d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor, output_size: Optional[List[int]]): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose1d" [color="black", fontcolor="black", label=<{ConvTranspose1d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_reference(ref_qconvt, output_scale, output_zero_point)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.ConvTranspose1d" [color="black", fontcolor="black", label=<{ConvTranspose1d|<br ALIGN="LEFT"/>|forward(input: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose2d" [color="black", fontcolor="black", label=<{ConvTranspose2d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose2d" [color="black", fontcolor="black", label=<{ConvTranspose2d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor, output_size: Optional[List[int]]): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose2d" [color="black", fontcolor="black", label=<{ConvTranspose2d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_reference(ref_qconvt, output_scale, output_zero_point)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" [color="black", fontcolor="black", label=<{ConvTranspose2d|<br ALIGN="LEFT"/>|forward(input: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose3d" [color="black", fontcolor="black", label=<{ConvTranspose3d|<br ALIGN="LEFT"/>|forward(input: Tensor, reduce_range: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose3d" [color="black", fontcolor="black", label=<{ConvTranspose3d|<br ALIGN="LEFT"/>|forward(x: torch.Tensor, output_size: Optional[List[int]]): torch.Tensor<br ALIGN="LEFT"/>from_float(float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose3d" [color="black", fontcolor="black", label=<{ConvTranspose3d|<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>from_reference(ref_qconvt, output_scale, output_zero_point)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.ConvTranspose3d" [color="black", fontcolor="black", label=<{ConvTranspose3d|<br ALIGN="LEFT"/>|forward(input: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ConvTransposeModel" [color="black", fontcolor="black", label=<{ConvTransposeModel|conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvWithAdaptiveAvgPool2d" [color="black", fontcolor="black", label=<{ConvWithAdaptiveAvgPool2d|adaptive_avg_pool2d<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [color="black", fontcolor="black", label=<{ConvWithBNRelu|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._conversion.Conversion" [color="black", fontcolor="black", label=<{Conversion|analysis_tool_log_files : Optional[List[_artifact_location.ArtifactLocation]]<br ALIGN="LEFT"/>invocation : Optional[_invocation.Invocation]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>tool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._errors.ConversionError" [color="black", fontcolor="red", label=<{ConversionError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.ConvertComplexToRealRepresentationInputStep" [color="black", fontcolor="black", label=<{ConvertComplexToRealRepresentationInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.ConvertComplexToRealRepresentationOutputStep" [color="black", fontcolor="black", label=<{ConvertComplexToRealRepresentationOutputStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.custom_config.ConvertCustomConfig" [color="black", fontcolor="black", label=<{ConvertCustomConfig|observed_to_quantized_mapping : Dict[QuantType, Dict[Type, Type]]<br ALIGN="LEFT"/>preserved_attributes : List[str]<br ALIGN="LEFT"/>|from_dict(convert_custom_config_dict: Dict[str, Any]): ConvertCustomConfig<br ALIGN="LEFT"/>set_observed_to_quantized_mapping(observed_class: Type, quantized_class: Type, quant_type: QuantType): ConvertCustomConfig<br ALIGN="LEFT"/>set_preserved_attributes(attributes: List[str]): ConvertCustomConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.ConvertFrame" [color="black", fontcolor="black", label=<{ConvertFrame|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.ConvertFrameAssert" [color="black", fontcolor="black", label=<{ConvertFrameAssert|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.ConvertFrameProtocol" [color="black", fontcolor="black", label=<{ConvertFrameProtocol|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ConvertIntKey" [color="black", fontcolor="black", label=<{ConvertIntKey|<br ALIGN="LEFT"/>|get(b: bool): Union[int, SymInt]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.ConvertIntSource" [color="black", fontcolor="black", label=<{ConvertIntSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.fx_to_pattern.Converter" [color="black", fontcolor="black", label=<{Converter|call_method<br ALIGN="LEFT"/>call_module<br ALIGN="LEFT"/>get_attr<br ALIGN="LEFT"/>|call_function(target: str, args: Sequence[Any], kwargs: Mapping[str, Any]): PatternExpr<br ALIGN="LEFT"/>placeholder(target: str, args: Sequence[Any], kwargs: Mapping[str, Any]): Union[ExclusiveKeywordArg, KeywordArg]<br ALIGN="LEFT"/>run_node(n: torch.fx.Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.ConvolutionBinary" [color="black", fontcolor="black", label=<{ConvolutionBinary|cpp_constant_args : tuple<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x: 'TensorBox', other: 'TensorBox', weight: 'TensorBox', bias: 'TensorBox', padding_: List[int], stride_: List[int], dilation_: List[int], groups: int, binary_attr: str, binary_alpha: Optional[float], unary_attr: Optional[str], unary_scalars: Optional[List[Any]], unary_algorithm: Optional[str])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.ConvolutionBinaryInplace" [color="black", fontcolor="black", label=<{ConvolutionBinaryInplace|mutation_outputs : list<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x: 'TensorBox', other: 'TensorBox', weight: 'TensorBox', bias: 'TensorBox', padding_: List[int], stride_: List[int], dilation_: List[int], groups: int, binary_attr: str, binary_alpha: Optional[float], unary_attr: Optional[str], unary_scalars: Optional[List[Any]], unary_algorithm: Optional[str])<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.ConvolutionTransposeUnary" [color="black", fontcolor="black", label=<{ConvolutionTransposeUnary|<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x: 'TensorBox', weight: 'TensorBox', bias: 'TensorBox', padding_: List[int], output_padding_: List[int], stride_: List[int], dilation_: List[int], groups_: int, attr, scalars: Optional[List[Any]], algorithm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.ConvolutionUnary" [color="black", fontcolor="black", label=<{ConvolutionUnary|<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x: 'TensorBox', weight: 'TensorBox', bias: 'TensorBox', padding_: List[int], stride_: List[int], dilation_: List[int], groups: int, attr, scalars: Optional[List[Any]], algorithm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.CooperativeReductionWorkspaceCache" [color="black", fontcolor="black", label=<{CooperativeReductionWorkspaceCache|args<br ALIGN="LEFT"/>current_loop : list<br ALIGN="LEFT"/>loop_count : int<br ALIGN="LEFT"/>prior_loop : list<br ALIGN="LEFT"/>ready_for_reuse : defaultdict<br ALIGN="LEFT"/>store_count : int<br ALIGN="LEFT"/>|allocate(nbytes: sympy.Expr)<br ALIGN="LEFT"/>increment_store_count()<br ALIGN="LEFT"/>on_loop_end()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.coordinate_descent_tuner.CoordescTuner" [color="black", fontcolor="black", label=<{CoordescTuner|cached_benchmark_results : dict<br ALIGN="LEFT"/>inductor_meta : dict<br ALIGN="LEFT"/>is_mm : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>size_hints : NoneType<br ALIGN="LEFT"/>tunable_fields<br ALIGN="LEFT"/>|autotune(func: Callable[['triton.Config'], float], baseline_config: 'triton.Config', baseline_timing: Optional[float]): 'triton.Config'<br ALIGN="LEFT"/>cache_benchmark_result(config, timing)<br ALIGN="LEFT"/>call_func(func, config)<br ALIGN="LEFT"/>check_all_tuning_directions(func: Callable[['triton.Config'], float], best_config, best_timing)<br ALIGN="LEFT"/>compare_config(func, candidate_config, best_config, best_timing)<br ALIGN="LEFT"/>get_config_max(prefix: str): int<br ALIGN="LEFT"/>get_neighbour_values(name, orig_val, radius, include_self)<br ALIGN="LEFT"/>get_warpsmax()<br ALIGN="LEFT"/>has_improvement(baseline, test)<br ALIGN="LEFT"/>lookup_in_cache(config)<br ALIGN="LEFT"/>value_too_large(name: str, val: int): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.clone_graph.CopyGraph" [color="black", fontcolor="black", label=<{CopyGraph|<br ALIGN="LEFT"/>|run_node(old_node: torch.fx.Node): torch.fx.Node<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CopyIfCallgrind" [color="black", fontcolor="black", label=<{CopyIfCallgrind|serialization<br ALIGN="LEFT"/>setup<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|unwrap_all(globals: Dict[str, Any]): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.CopyNodeQuantizeHandler" [color="black", fontcolor="black", label=<{CopyNodeQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._coreml.preprocess.CoreMLComputeUnit" [color="black", fontcolor="black", label=<{CoreMLComputeUnit|ALL : str<br ALIGN="LEFT"/>CPU : str<br ALIGN="LEFT"/>CPUAndGPU : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._coreml.preprocess.CoreMLQuantizationMode" [color="black", fontcolor="black", label=<{CoreMLQuantizationMode|LINEAR : str<br ALIGN="LEFT"/>LINEAR_SYMMETRIC : str<br ALIGN="LEFT"/>NONE : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.CorrCholeskyTransform" [color="black", fontcolor="black", label=<{CorrCholeskyTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y, intermediates)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.CosineAnnealingLR" [color="black", fontcolor="black", label=<{CosineAnnealingLR|T_max : int<br ALIGN="LEFT"/>eta_min : float<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts" [color="black", fontcolor="black", label=<{CosineAnnealingWarmRestarts|T_0 : int<br ALIGN="LEFT"/>T_cur : int<br ALIGN="LEFT"/>T_i : int<br ALIGN="LEFT"/>T_mult : int<br ALIGN="LEFT"/>eta_min : float<br ALIGN="LEFT"/>last_epoch<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>step(epoch)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.CosineEmbeddingLoss" [color="black", fontcolor="black", label=<{CosineEmbeddingLoss|margin : float<br ALIGN="LEFT"/>|forward(input1: Tensor, input2: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.distance.CosineSimilarity" [color="black", fontcolor="black", label=<{CosineSimilarity|dim : int<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>|forward(x1: Tensor, x2: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.CountIteratorVariable" [color="black", fontcolor="black", label=<{CountIteratorVariable|item : NoneType, int<br ALIGN="LEFT"/>step : int<br ALIGN="LEFT"/>|next_variable(tx)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.CountOps" [color="black", fontcolor="black", label=<{CountOps|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autotune_process.CppBenchmarkRequest" [color="black", fontcolor="black", label=<{CppBenchmarkRequest|DLL : Optional[Union[CDLL, ModuleType]]<br ALIGN="LEFT"/>hash_key<br ALIGN="LEFT"/>source_code : str<br ALIGN="LEFT"/>|cleanup_run_fn(): None<br ALIGN="LEFT"/>make_run_fn(): Callable[[], None]<br ALIGN="LEFT"/>precompile()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_bmm_template.CppBmmTemplate" [color="black", fontcolor="black", label=<{CppBmmTemplate|b_index : Symbol<br ALIGN="LEFT"/>render_options : dict<br ALIGN="LEFT"/>|check_if_block_weight(W, micro_gemm)<br ALIGN="LEFT"/>codegen_gemm_stub_def()<br ALIGN="LEFT"/>codegen_multi_thread_gemm()<br ALIGN="LEFT"/>codegen_single_thread_gemm()<br ALIGN="LEFT"/>get_default_reindexers(epilogue_nodes)<br ALIGN="LEFT"/>get_gemm_function_call(kernel: CppTemplateKernel, function_name: str, placeholder: str, b_index: int): str<br ALIGN="LEFT"/>get_options(kernel: CppTemplateKernel, template_buffer_node: Optional[ir.CppTemplateBuffer], flag_template_buffer_has_other_users: Optional[bool], epilogue_nodes: Optional[List[ir.IRNode]]): Dict[str, Any]<br ALIGN="LEFT"/>get_padded_size(n, block_n, k, should_block_weight)<br ALIGN="LEFT"/>render(kernel: CppTemplateKernel, template_buffer_node: Optional[ir.CppTemplateBuffer], flag_template_buffer_has_other_users: Optional[bool], epilogue_nodes: Optional[List[ir.IRNode]]): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cpp_builder.CppBuilder" [color="black", fontcolor="black", label=<{CppBuilder|<br ALIGN="LEFT"/>|build(): Tuple[bytes, str]<br ALIGN="LEFT"/>get_command_line(): str<br ALIGN="LEFT"/>get_target_file_path(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_utils.CppCSEVariable" [color="black", fontcolor="black", label=<{CppCSEVariable|dependent_itervars<br ALIGN="LEFT"/>dtype : NoneType<br ALIGN="LEFT"/>is_vec : bool<br ALIGN="LEFT"/>|depends_on(itervar: sympy.Symbol)<br ALIGN="LEFT"/>update_on_args(name, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CppCodeCache" [color="black", fontcolor="black", label=<{CppCodeCache|cache : Dict[str, Callable[[], Union[CDLL, ModuleType]]]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>cpp_compile_command_flags : Dict[str, Any]<br ALIGN="LEFT"/>|load(source_code: str, device_type: str): Any<br ALIGN="LEFT"/>load_async(source_code: str, device_type: str, submit_fn: Any, extra_flags: Sequence[str]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.exc.CppCompileError" [color="black", fontcolor="red", label=<{CppCompileError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_flex_attention_template.CppFlexAttentionTemplate" [color="black", fontcolor="black", label=<{CppFlexAttentionTemplate|extra_sizevars : list<br ALIGN="LEFT"/>fake_buffers<br ALIGN="LEFT"/>has_other_buffer<br ALIGN="LEFT"/>kernel_input_name_to_buffer<br ALIGN="LEFT"/>kv_block_size<br ALIGN="LEFT"/>len_mask_other<br ALIGN="LEFT"/>len_score_other<br ALIGN="LEFT"/>mask_buf_idx : NoneType<br ALIGN="LEFT"/>mask_buf_name : NoneType<br ALIGN="LEFT"/>mask_mod<br ALIGN="LEFT"/>mask_mod_other_buffers : NoneType<br ALIGN="LEFT"/>no_full_kv_block<br ALIGN="LEFT"/>other_buf_start_idx : int<br ALIGN="LEFT"/>other_buffer_input_offset : int<br ALIGN="LEFT"/>other_ptr_data : dict<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>score_buf_idx : NoneType<br ALIGN="LEFT"/>score_buf_name : NoneType<br ALIGN="LEFT"/>score_mod<br ALIGN="LEFT"/>score_mod_other_buffers : NoneType<br ALIGN="LEFT"/>|add_choices(choices, input_nodes, layout, scale, score_mod, mask_mod, kv_block_size, has_other_buffer, no_full_kv_block, fake_buffers, len_score_other, len_mask_other, kernel_input_name_to_buffer)<br ALIGN="LEFT"/>apply_score_mod(score, b, h, q_idx, kv_idx)<br ALIGN="LEFT"/>codegen_allocate_buffer(buffer_name: str, buffer_dtype, buffer_size)<br ALIGN="LEFT"/>codegen_brgemm_pack_function(kernel_name: str)<br ALIGN="LEFT"/>codegen_softmax_fusion(kernel_name: str)<br ALIGN="LEFT"/>generate_other_buffer(buf_list, start_offset, len_attr, kernel_args)<br ALIGN="LEFT"/>modification(subgraph_buffer, output_name, output_idx)<br ALIGN="LEFT"/>render(kernel, template_buffer_node: Optional[ir.CppTemplateBuffer], epilogue_nodes: Optional[List[ir.IRNode]]): str<br ALIGN="LEFT"/>update_kernel_args(kernel_args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.CppFunctionalizeAPI" [color="black", fontcolor="black", label=<{CppFunctionalizeAPI|<br ALIGN="LEFT"/>|commit_update(tensor): None<br ALIGN="LEFT"/>functionalize(inner_f: Callable): Callable<br ALIGN="LEFT"/>mark_mutation_hidden_from_autograd(tensor): None<br ALIGN="LEFT"/>redispatch_to_next(): ContextManager<br ALIGN="LEFT"/>replace(input_tensor, output_tensor): None<br ALIGN="LEFT"/>sync(tensor): None<br ALIGN="LEFT"/>unwrap_tensors(args: Union[torch.Tensor, Tuple[torch.Tensor, ...]]): Union[torch.Tensor, Tuple[torch.Tensor, ...]]<br ALIGN="LEFT"/>wrap_tensors(args: Tuple[Any]): Tuple[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_gemm_template.CppGemmTemplate" [color="black", fontcolor="black", label=<{CppGemmTemplate|alpha : int<br ALIGN="LEFT"/>beta : int<br ALIGN="LEFT"/>cache_blocking<br ALIGN="LEFT"/>has_bias : bool<br ALIGN="LEFT"/>is_dynamic_M<br ALIGN="LEFT"/>k<br ALIGN="LEFT"/>m<br ALIGN="LEFT"/>n<br ALIGN="LEFT"/>padded_n<br ALIGN="LEFT"/>register_blocking : GemmBlocking<br ALIGN="LEFT"/>render_options : dict<br ALIGN="LEFT"/>should_block_weights : bool<br ALIGN="LEFT"/>thread_blocking<br ALIGN="LEFT"/>|add_choices(choices, layout, input_nodes, beta, alpha, has_bias, trans_w, input_indices, epilogue_creator: Optional[Callable[[ir.Buffer], ir.Pointwise]])<br ALIGN="LEFT"/>block_weight(W, new_size, padding)<br ALIGN="LEFT"/>check_if_block_weight(W, micro_gemm)<br ALIGN="LEFT"/>codegen_blocks(num_threads, N, K, micro_gemm, is_dynamic_M, kernel, GemmOut, config, L1_cache_size, L2_cache_size, X, W)<br ALIGN="LEFT"/>codegen_gemm_stub_def()<br ALIGN="LEFT"/>codegen_m_loop_params()<br ALIGN="LEFT"/>codegen_microkernel_def()<br ALIGN="LEFT"/>codegen_multi_threads_params()<br ALIGN="LEFT"/>codegen_n_loop_params()<br ALIGN="LEFT"/>codegen_single_thread_params(is_dynamic_M)<br ALIGN="LEFT"/>get_default_reindexers(epilogue_nodes)<br ALIGN="LEFT"/>get_options(kernel: CppTemplateKernel, template_buffer_node: Optional[ir.CppTemplateBuffer], flag_template_buffer_has_other_users: Optional[bool], epilogue_nodes: Optional[List[ir.IRNode]]): Dict[str, Any]<br ALIGN="LEFT"/>get_padded_size(n, block_n, k, should_block_weight)<br ALIGN="LEFT"/>log_blockings()<br ALIGN="LEFT"/>make_cache_blocking_cache()<br ALIGN="LEFT"/>make_thread_blocking_cache()<br ALIGN="LEFT"/>maybe_k_slicing()<br ALIGN="LEFT"/>pack_vnni_weight(W, micro_gemm, new_size)<br ALIGN="LEFT"/>prep_weight(inputs, layout: ir.Layout, micro_gemm: CppMicroGemm, should_block_weight: bool)<br ALIGN="LEFT"/>render(kernel: CppTemplateKernel, template_buffer_node: Optional[ir.CppTemplateBuffer], flag_template_buffer_has_other_users: Optional[bool], epilogue_nodes: Optional[List[ir.IRNode]]): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppKernel" [color="black", fontcolor="black", label=<{CppKernel|active_ranges : dict[sympy.Expr, Tuple[sympy.Expr, ...]]<br ALIGN="LEFT"/>assert_function<br ALIGN="LEFT"/>call_ranges : Optional[Tuple[sympy.Expr, ...]]<br ALIGN="LEFT"/>compute : NoneType<br ALIGN="LEFT"/>cse<br ALIGN="LEFT"/>inner_itervars : List[sympy.Symbol]<br ALIGN="LEFT"/>is_reduction : bool<br ALIGN="LEFT"/>itervars : List[sympy.Symbol]<br ALIGN="LEFT"/>loads : NoneType<br ALIGN="LEFT"/>local_reduction_init<br ALIGN="LEFT"/>local_reduction_stores<br ALIGN="LEFT"/>newvar_prefix : str<br ALIGN="LEFT"/>non_parallel_reduction_prefix<br ALIGN="LEFT"/>num_threads<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>parallel_reduction_prefix<br ALIGN="LEFT"/>parallel_reduction_suffix<br ALIGN="LEFT"/>poststores<br ALIGN="LEFT"/>preloads<br ALIGN="LEFT"/>ranges : List[sympy.Expr]<br ALIGN="LEFT"/>reduction_cse<br ALIGN="LEFT"/>reduction_depth : NoneType<br ALIGN="LEFT"/>reduction_omp_dec : Dict[Tuple[str, str], str]<br ALIGN="LEFT"/>reduction_prefix<br ALIGN="LEFT"/>reduction_prefix_generators : List[Callable]<br ALIGN="LEFT"/>reduction_suffix<br ALIGN="LEFT"/>reduction_var_names : List[str]<br ALIGN="LEFT"/>sexpr<br ALIGN="LEFT"/>stores : NoneType<br ALIGN="LEFT"/>suffix : str<br ALIGN="LEFT"/>weight_recps_cse<br ALIGN="LEFT"/>|cache_dtype_convert(dst, dst_dtype, src, src_dtype)<br ALIGN="LEFT"/>check_bounds(expr: sympy.Expr, size: sympy.Expr, lower: bool, upper: bool)<br ALIGN="LEFT"/>codegen_conditions(code: BracesBuffer, prefix: Optional[str], var: Optional[sympy.Symbol])<br ALIGN="LEFT"/>codegen_loops(code, worksharing)<br ALIGN="LEFT"/>codegen_loops_impl(loop_nest, code, worksharing)<br ALIGN="LEFT"/>create_cse_var()<br ALIGN="LEFT"/>decide_parallel_depth(max_parallel_depth, threads)<br ALIGN="LEFT"/>finalize_reduction_prefix(size: Optional[int])<br ALIGN="LEFT"/>gen_body(code: Optional[BracesBuffer])<br ALIGN="LEFT"/>get_to_dtype_expr(src, dtype, src_dtype)<br ALIGN="LEFT"/>index_depends_on(index: sympy.Expr, itervar: sympy.Symbol)<br ALIGN="LEFT"/>index_indirect_depends_on(index: sympy.Expr, itervar: sympy.Symbol)<br ALIGN="LEFT"/>index_to_str(index: sympy.Expr): str<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>masked(mask)<br ALIGN="LEFT"/>reduction(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>scale_index_with_offset(index: sympy.Expr, scale, itervar_idx, offset)<br ALIGN="LEFT"/>set_ranges(lengths, reduction_lengths)<br ALIGN="LEFT"/>size_hint()<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>store_reduction(name, index, value)<br ALIGN="LEFT"/>update_stores_with_parallel_reduction()<br ALIGN="LEFT"/>var_ranges()<br ALIGN="LEFT"/>write_to_suffix()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppKernelProxy" [color="black", fontcolor="black", label=<{CppKernelProxy|call_ranges : NoneType<br ALIGN="LEFT"/>kernel_group<br ALIGN="LEFT"/>kernels : List[CppKernel], list<br ALIGN="LEFT"/>loop_nest : NoneType<br ALIGN="LEFT"/>picked_vec_isa<br ALIGN="LEFT"/>reduction_suffix<br ALIGN="LEFT"/>|aggregate_reduction_buffers(inner_loop_reduction_outer_not: bool, outer_loop: Optional['LoopLevel'])<br ALIGN="LEFT"/>codegen_functions(fn_list, var_sizes_list)<br ALIGN="LEFT"/>codegen_loop_bodies(loop_bodies, var_sizes_list)<br ALIGN="LEFT"/>codegen_loops(code, worksharing)<br ALIGN="LEFT"/>codegen_nodes(nodes: List[SchedulerNode])<br ALIGN="LEFT"/>data_type_propagation(nodes)<br ALIGN="LEFT"/>gen_body(code: Optional[BracesBuffer])<br ALIGN="LEFT"/>is_lowp_fp_scheduler(scheduler_node: SchedulerNode)<br ALIGN="LEFT"/>legalize_lowp_fp_dtype(nodes)<br ALIGN="LEFT"/>legalize_lowp_fp_dtype_loopbody(loop_body: LoopBody)<br ALIGN="LEFT"/>update_stores_with_parallel_reduction()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroBrgemm" [color="black", fontcolor="black", label=<{CppMicroBrgemm|TEMPLATE_ENTRY : str<br ALIGN="LEFT"/>|codegen_define(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>codegen_finalize(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>get_b_layout()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemm" [color="black", fontcolor="black", label=<{CppMicroGemm|DECLARE_KERNEL : str<br ALIGN="LEFT"/>alpha : int<br ALIGN="LEFT"/>compute_dtype<br ALIGN="LEFT"/>input2_dtype<br ALIGN="LEFT"/>input_dtype<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>output_dtype<br ALIGN="LEFT"/>register_blocking<br ALIGN="LEFT"/>|codegen_call(kernel: CppTemplateKernel, A: ir.Buffer, B: ir.Buffer, C: ir.Buffer, accum: bool): str<br ALIGN="LEFT"/><I>codegen_define</I>(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>codegen_finalize(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>codegen_init(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>get_b_layout(): LayoutType<br ALIGN="LEFT"/>get_common_options()<br ALIGN="LEFT"/>get_kernel_declaration()<br ALIGN="LEFT"/>get_kernel_extra_args(): str<br ALIGN="LEFT"/>get_kernel_extra_args_declare(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmAMX" [color="black", fontcolor="black", label=<{CppMicroGemmAMX|TEMPLATE_ENTRY : str<br ALIGN="LEFT"/>TEMPLATE_KERNEL : str<br ALIGN="LEFT"/>|codegen_define(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>codegen_finalize(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>codegen_init(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>get_b_layout()<br ALIGN="LEFT"/>get_kernel_extra_args(): str<br ALIGN="LEFT"/>get_kernel_extra_args_declare(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmConfig" [color="black", fontcolor="black", label=<{CppMicroGemmConfig|compute_dtype<br ALIGN="LEFT"/>extra_check : Optional[Callable[..., bool]]<br ALIGN="LEFT"/>input2_dtype<br ALIGN="LEFT"/>input_dtype<br ALIGN="LEFT"/>output_dtype<br ALIGN="LEFT"/>register_blocking : GemmBlocking<br ALIGN="LEFT"/>vec_isa_cls : Type[VecISA]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmFP32Vec" [color="black", fontcolor="black", label=<{CppMicroGemmFP32Vec|TEMPLATE_ENTRY : str<br ALIGN="LEFT"/>TEMPLATE_KERNEL : str<br ALIGN="LEFT"/>|codegen_define(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmRef" [color="black", fontcolor="black", label=<{CppMicroGemmRef|TEMPLATE_ENTRY : str<br ALIGN="LEFT"/>|codegen_define(kernel: CppTemplateKernel): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cpp_builder.CppOptions" [color="black", fontcolor="black", label=<{CppOptions|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.metrics.CppOuterLoopFusedCount" [color="black", fontcolor="black", label=<{CppOuterLoopFusedCount|inner_kernel_number : int<br ALIGN="LEFT"/>local_buffer_number : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppOverrides" [color="black", fontcolor="black", label=<{CppOverrides|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>acosh(x)<br ALIGN="LEFT"/>add(a, b)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>asinh(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>atan2(x, y)<br ALIGN="LEFT"/>atanh(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_left_shift(a, b)<br ALIGN="LEFT"/>bitwise_not(a)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>bitwise_right_shift(a, b)<br ALIGN="LEFT"/>bitwise_xor(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>constant(val, dtype)<br ALIGN="LEFT"/>copysign(x, y)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>erf(x)<br ALIGN="LEFT"/>erfc(x)<br ALIGN="LEFT"/>erfinv(x)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>exp2(x)<br ALIGN="LEFT"/>expm1(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>fmod(a, b)<br ALIGN="LEFT"/>frexp(x)<br ALIGN="LEFT"/>hypot(x, y)<br ALIGN="LEFT"/>index_expr(expr, dtype)<br ALIGN="LEFT"/>isinf(x)<br ALIGN="LEFT"/>isnan(x)<br ALIGN="LEFT"/>lgamma(x)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log10(x)<br ALIGN="LEFT"/>log1p(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>logical_and(a, b)<br ALIGN="LEFT"/>logical_not(a)<br ALIGN="LEFT"/>logical_or(a, b)<br ALIGN="LEFT"/>logical_xor(a, b)<br ALIGN="LEFT"/>masked(mask, body, other)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>mod(a, b)<br ALIGN="LEFT"/>mul(a, b)<br ALIGN="LEFT"/>neg(x)<br ALIGN="LEFT"/>nextafter(x, y)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>rand(seed: sympy.Expr, offset: sympy.Expr)<br ALIGN="LEFT"/>randint64(seed: sympy.Expr, offset: sympy.Expr, low, high)<br ALIGN="LEFT"/>randn(seed: sympy.Expr, offset: sympy.Expr)<br ALIGN="LEFT"/>relu(x)<br ALIGN="LEFT"/>round(x)<br ALIGN="LEFT"/>rsqrt(x)<br ALIGN="LEFT"/>sigmoid(x)<br ALIGN="LEFT"/>sign(x)<br ALIGN="LEFT"/>signbit(x)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>sub(a, b)<br ALIGN="LEFT"/>tan(x)<br ALIGN="LEFT"/>tanh(x)<br ALIGN="LEFT"/>to_dtype(x, dtype, src_dtype, use_compute_types)<br ALIGN="LEFT"/>to_dtype_bitcast(x, dtype, src_dtype)<br ALIGN="LEFT"/>trunc(x)<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>where(a, b, c)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.printers.CppPrinter" [color="black", fontcolor="black", label=<{CppPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_utils.CppPrinter" [color="black", fontcolor="black", label=<{CppPrinter|<br ALIGN="LEFT"/>|doprint(expr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CppPythonBindingsCodeCache" [color="black", fontcolor="black", label=<{CppPythonBindingsCodeCache|cache : Dict[str, Callable[[], Union[CDLL, ModuleType]]]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>call_entry_function : str<br ALIGN="LEFT"/>cpp_compile_command_flags : dict<br ALIGN="LEFT"/>entry_function : str<br ALIGN="LEFT"/>extra_parse_arg : str<br ALIGN="LEFT"/>suffix_template<br ALIGN="LEFT"/>|load_pybinding(): Any<br ALIGN="LEFT"/>load_pybinding_async(argtypes: List[str], source_code: str, device_type: str, num_outputs: int, submit_fn: Any, extra_flags: Sequence[str]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppScheduling" [color="black", fontcolor="black", label=<{CppScheduling|MAX_FUSED_KERNEL_ARGS_NUM : int<br ALIGN="LEFT"/>backend_features : dict<br ALIGN="LEFT"/>kernel_group : Union[CppWrapperKernelGroup, KernelGroup]<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>|can_fuse_horizontal(node1, node2)<br ALIGN="LEFT"/>can_fuse_vertical(node1, node2)<br ALIGN="LEFT"/>can_fuse_vertical_outer_loop(node1, node2)<br ALIGN="LEFT"/>codegen_node(node: Union[OuterLoopFusedSchedulerNode, FusedSchedulerNode, SchedulerNode])<br ALIGN="LEFT"/>codegen_outer_loop_node(node: OuterLoopFusedSchedulerNode)<br ALIGN="LEFT"/><I>codegen_sync</I>()<br ALIGN="LEFT"/>codegen_template(template_node: BaseSchedulerNode, epilogue_nodes: Sequence[BaseSchedulerNode], prologue_nodes: Sequence[BaseSchedulerNode])<br ALIGN="LEFT"/>define_kernel(src_code, nodes, kernel_args)<br ALIGN="LEFT"/>flush()<br ALIGN="LEFT"/>fuse(node1, node2)<br ALIGN="LEFT"/>get_backend_features(device: torch.device)<br ALIGN="LEFT"/>get_fusion_pair_priority(node1, node2)<br ALIGN="LEFT"/>group_fn(sizes)<br ALIGN="LEFT"/>is_cpp_template(node: BaseSchedulerNode): bool<br ALIGN="LEFT"/>ready_to_flush()<br ALIGN="LEFT"/>reset_kernel_group()<br ALIGN="LEFT"/>try_loop_split(nodes: List[SchedulerNode])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_template.CppTemplate" [color="black", fontcolor="black", label=<{CppTemplate|epilogue_creator : Optional[Callable[[ir.Buffer], ir.Pointwise]]<br ALIGN="LEFT"/>index_counter : count<br ALIGN="LEFT"/>input_nodes<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>num_threads : int<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>|generate()<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/><I>render</I>(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.CppTemplateBuffer" [color="black", fontcolor="black", label=<{CppTemplateBuffer|choice<br ALIGN="LEFT"/>template<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_template_kernel.CppTemplateCaller" [color="black", fontcolor="black", label=<{CppTemplateCaller|bmreq<br ALIGN="LEFT"/>category : str<br ALIGN="LEFT"/>info_kwargs : Optional[Dict[str, Union[ir.PrimitiveInfoType, List[ir.PrimitiveInfoType]]]]<br ALIGN="LEFT"/>make_kernel_render : Callable[[ir.CppTemplateBuffer, bool, Optional[List[ir.IRNode]]], str]<br ALIGN="LEFT"/>template : str<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/>hash_key(): str<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[ir.PrimitiveInfoType, List[ir.PrimitiveInfoType]]]<br ALIGN="LEFT"/>output_node(): ir.TensorBox<br ALIGN="LEFT"/>precompile(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_template_kernel.CppTemplateKernel" [color="black", fontcolor="black", label=<{CppTemplateKernel|args<br ALIGN="LEFT"/>kernel_name<br ALIGN="LEFT"/>local_buffers : dict<br ALIGN="LEFT"/>render_hooks : dict<br ALIGN="LEFT"/>|acc_dtype(node: ir.Buffer): str<br ALIGN="LEFT"/>call_kernel(name: str, node: ir.CppTemplateBuffer)<br ALIGN="LEFT"/>def_kernel(inputs: Dict[str, ir.Buffer], outputs: Dict[str, ir.Buffer], aliases: Optional[Dict[str, str]], function_name: str, extra_sizevars: Optional[List[sympy.Expr]], placeholder: str): str<br ALIGN="LEFT"/>define_buffer(name, sizes: List[Any], dtype): str<br ALIGN="LEFT"/>dtype(node: ir.Buffer): str<br ALIGN="LEFT"/>index(node: ir.Buffer, indices: List[Any]): str<br ALIGN="LEFT"/>maybe_codegen_profile(): str<br ALIGN="LEFT"/>permute(node, dims)<br ALIGN="LEFT"/>reinit_buffer_if_null(name)<br ALIGN="LEFT"/>release_buffer(name)<br ALIGN="LEFT"/>render(template)<br ALIGN="LEFT"/>select(node, dim: int, idx: int): ir.ReinterpretView<br ALIGN="LEFT"/>size(node: ir.Buffer, dim: int): str<br ALIGN="LEFT"/>slice_nd(node, ranges: List[Tuple[Any, Any]]): ir.ReinterpretView<br ALIGN="LEFT"/>store_output(dst: ir.Buffer, src: ir.Buffer, orig_src: Optional[ir.Buffer], epilogue_nodes: Optional[List[ir.IRNode]], offsets: Optional[List[Any]], reindexers: Optional[List[Optional[Callable[[List[Any]], List[Any]]]]])<br ALIGN="LEFT"/>store_pointwise_nodes(dst: ir.Buffer, nodes: List[ir.IRNode], offsets: Optional[List[sympy.Expr]], reindexers: Optional[List[Optional[Callable[[List[Any]], List[Any]]]]]): str<br ALIGN="LEFT"/>stride(node: ir.Buffer, dim: int): str<br ALIGN="LEFT"/>unroll_pragma(unroll)<br ALIGN="LEFT"/>view(node, sizes: List[Any]): ir.View<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppTile2DKernel" [color="black", fontcolor="black", label=<{CppTile2DKernel|inner_is_tiling_idx : bool<br ALIGN="LEFT"/>inner_num_elems<br ALIGN="LEFT"/>inner_tail_size : NoneType<br ALIGN="LEFT"/>num_elems<br ALIGN="LEFT"/>outer_idx<br ALIGN="LEFT"/>outer_num_elems<br ALIGN="LEFT"/>outer_tail_size : NoneType<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>tail_size : NoneType<br ALIGN="LEFT"/>tiling_idx<br ALIGN="LEFT"/>tiling_indices<br ALIGN="LEFT"/>|codegen_inner_loops(code)<br ALIGN="LEFT"/>gen_transposed_tile_load_store(name, var, index, is_store)<br ALIGN="LEFT"/>inner_itervar()<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>need_vec_transpose(index)<br ALIGN="LEFT"/>set_ranges(group, reduction_group)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>transform_indexing(index: sympy.Expr): sympy.Expr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppTile2DOverrides" [color="black", fontcolor="black", label=<{CppTile2DOverrides|<br ALIGN="LEFT"/>|index_expr(expr, dtype)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cpp_builder.CppTorchDeviceOptions" [color="black", fontcolor="black", label=<{CppTorchDeviceOptions|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpp_builder.CppTorchOptions" [color="black", fontcolor="black", label=<{CppTorchOptions|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppVecKernel" [color="black", fontcolor="black", label=<{CppVecKernel|is_reduction : bool<br ALIGN="LEFT"/>num_elems<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>reduction_var_names<br ALIGN="LEFT"/>tail_size : NoneType<br ALIGN="LEFT"/>tiling_factor<br ALIGN="LEFT"/>tiling_idx<br ALIGN="LEFT"/>vec_isa<br ALIGN="LEFT"/>weight_recp_vec_range<br ALIGN="LEFT"/>weight_recps_val<br ALIGN="LEFT"/>|arange(index: CppCSEVariable, stride: sympy.Symbol): CppCSEVariable<br ALIGN="LEFT"/>broadcast(scalar_var: CppCSEVariable): CppCSEVariable<br ALIGN="LEFT"/>get_to_dtype_expr(src, dtype, src_dtype)<br ALIGN="LEFT"/>indirect_assert(var, lower, upper, mask)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>reduction(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>reduction_acc_type_vec(reduction_type, dtype)<br ALIGN="LEFT"/>reduction_combine_vec(reduction_type, var, next_value, use_weight_recps, index: Optional[sympy.Symbol], horizontal_reduction: Optional[bool], src_dtype: Optional[torch.dtype])<br ALIGN="LEFT"/>reduction_init_vec(reduction_type, dtype)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>store_reduction(name, index, value)<br ALIGN="LEFT"/>welford_weight_reciprocal_vec(dtype, num_threads)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppVecOverrides" [color="black", fontcolor="black", label=<{CppVecOverrides|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>acosh(x)<br ALIGN="LEFT"/>add(a, b)<br ALIGN="LEFT"/>and_(x, y)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>asinh(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>atan2(a, b)<br ALIGN="LEFT"/>atanh(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_left_shift(a, b)<br ALIGN="LEFT"/>bitwise_not(a)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>bitwise_right_shift(a, b)<br ALIGN="LEFT"/>bitwise_xor(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>copysign(a, b)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>eq(x, y)<br ALIGN="LEFT"/>erf(x)<br ALIGN="LEFT"/>erfc(x)<br ALIGN="LEFT"/>erfinv(x)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>exp2(x)<br ALIGN="LEFT"/>expm1(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>fmod(a, b)<br ALIGN="LEFT"/>frexp(x)<br ALIGN="LEFT"/>ge(x, y)<br ALIGN="LEFT"/>gt(x, y)<br ALIGN="LEFT"/>hypot(a, b)<br ALIGN="LEFT"/>index_expr(expr, dtype)<br ALIGN="LEFT"/>le(x, y)<br ALIGN="LEFT"/>lgamma(x)<br ALIGN="LEFT"/>load_seed(name, offset)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log10(x)<br ALIGN="LEFT"/>log1p(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>logical_and(a, b)<br ALIGN="LEFT"/>logical_not(a)<br ALIGN="LEFT"/>logical_or(a, b)<br ALIGN="LEFT"/>logical_xor(a, b)<br ALIGN="LEFT"/>lt(x, y)<br ALIGN="LEFT"/>masked(mask, body, other)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>mul(a, b)<br ALIGN="LEFT"/>ne(x, y)<br ALIGN="LEFT"/>neg(x)<br ALIGN="LEFT"/>nextafter(x, y)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>rand(seed, offset)<br ALIGN="LEFT"/>randint64(seed, offset, low, high)<br ALIGN="LEFT"/>randn(seed, offset)<br ALIGN="LEFT"/>reciprocal(a)<br ALIGN="LEFT"/>relu(x)<br ALIGN="LEFT"/>remainder(a, b)<br ALIGN="LEFT"/>round(x)<br ALIGN="LEFT"/>rsqrt(x)<br ALIGN="LEFT"/>scalarize(scalar_func)<br ALIGN="LEFT"/>sigmoid(x)<br ALIGN="LEFT"/>sign(x)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>square(a)<br ALIGN="LEFT"/>sub(a, b)<br ALIGN="LEFT"/>tan(a)<br ALIGN="LEFT"/>tanh(a)<br ALIGN="LEFT"/>to_dtype(x, dtype, src_dtype, use_compute_dtypes)<br ALIGN="LEFT"/>truediv(a, b)<br ALIGN="LEFT"/>trunc(x)<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>where(a, b, c)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CppWrapperCodeCache" [color="black", fontcolor="black", label=<{CppWrapperCodeCache|cache : Dict[str, Callable[[], Union[CDLL, ModuleType]]]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>call_entry_function : str<br ALIGN="LEFT"/>cpp_compile_command_flags : dict<br ALIGN="LEFT"/>entry_function : str<br ALIGN="LEFT"/>extra_parse_arg<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.exc.CppWrapperCodegenError" [color="black", fontcolor="red", label=<{CppWrapperCodegenError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [color="black", fontcolor="black", label=<{CppWrapperCpu|arg_var_id : count<br ALIGN="LEFT"/>cached_output_id : count<br ALIGN="LEFT"/>comment : str<br ALIGN="LEFT"/>custom_op_wrapper_loaded : bool<br ALIGN="LEFT"/>declare : str<br ALIGN="LEFT"/>declare_maybe_reference : str<br ALIGN="LEFT"/>declared_int_array_vars<br ALIGN="LEFT"/>device : str<br ALIGN="LEFT"/>device_codegen<br ALIGN="LEFT"/>ending : str<br ALIGN="LEFT"/>initialized_kernels : Dict[str, Kernel]<br ALIGN="LEFT"/>int_array_id : count<br ALIGN="LEFT"/>kernel_callsite_id : count<br ALIGN="LEFT"/>none_str : str<br ALIGN="LEFT"/>output_is_tensor : dict<br ALIGN="LEFT"/>prefix<br ALIGN="LEFT"/>scalar_to_tensor_id : count<br ALIGN="LEFT"/>supports_intermediate_hooks : bool<br ALIGN="LEFT"/>tmp_tensor_id : count<br ALIGN="LEFT"/>used_cached_devices<br ALIGN="LEFT"/>used_cached_dtypes<br ALIGN="LEFT"/>used_cached_layouts<br ALIGN="LEFT"/>used_cached_memory_formats<br ALIGN="LEFT"/>used_cond_predicate<br ALIGN="LEFT"/>var_array_id : count<br ALIGN="LEFT"/>|add_benchmark_harness(output)<br ALIGN="LEFT"/>c_type_for_prim_type(val, type_): str<br ALIGN="LEFT"/>codegen_alloc_from_pool(name, offset, dtype, shape, stride): str<br ALIGN="LEFT"/>codegen_conditional(conditional)<br ALIGN="LEFT"/>codegen_const_run_driver()<br ALIGN="LEFT"/>codegen_cpp_sizevar(x: Expr): str<br ALIGN="LEFT"/>codegen_device(device)<br ALIGN="LEFT"/>codegen_device_copy(src, dst, non_blocking: bool)<br ALIGN="LEFT"/>codegen_dtype(dtype)<br ALIGN="LEFT"/>codegen_dynamic_scalar(node)<br ALIGN="LEFT"/>codegen_exact_buffer_reuse(old_name: str, new_name: str, del_line: str)<br ALIGN="LEFT"/>codegen_input_size_var_decl(code: IndentedBuffer, name)<br ALIGN="LEFT"/>codegen_input_stride_var_decl(code: IndentedBuffer, name)<br ALIGN="LEFT"/>codegen_input_symbol_assignment(name: str, value: ir.TensorBox, bound_vars: OrderedSet[sympy.Symbol])<br ALIGN="LEFT"/>codegen_int_array_var(int_array: str, writeline: Callable[..., None], known_statically, graph)<br ALIGN="LEFT"/><I>codegen_invoke_subgraph</I>(invoke_subgraph)<br ALIGN="LEFT"/>codegen_layout(layout)<br ALIGN="LEFT"/>codegen_memory_format(memory_format)<br ALIGN="LEFT"/>codegen_model_constructor()<br ALIGN="LEFT"/>codegen_model_kernels()<br ALIGN="LEFT"/><I>codegen_multi_output</I>(name, value)<br ALIGN="LEFT"/>codegen_reinterpret_view(data, size, stride, offset, writeline: Callable[..., None], dtype): str<br ALIGN="LEFT"/>codegen_scalar_to_tensor(output: str)<br ALIGN="LEFT"/>codegen_shape_tuple(shape: Sequence[Expr]): str<br ALIGN="LEFT"/>codegen_sizevar(x: Expr): str<br ALIGN="LEFT"/>codegen_subgraph(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_subgraph_prefix(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_subgraph_suffix(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_tensor_dtype_var_decl(code: IndentedBuffer, name)<br ALIGN="LEFT"/>codegen_tensor_item(dtype: torch.dtype, tensor: str, scalar: str, indented_buffer)<br ALIGN="LEFT"/>codegen_tuple_access(basename: str, name: str, index: str): str<br ALIGN="LEFT"/>codegen_while_loop(while_loop)<br ALIGN="LEFT"/>create(is_subgraph: bool, subgraph_name: str, parent_wrapper: PythonWrapperCodegen)<br ALIGN="LEFT"/>create_tmp_raii_handle_var(base_handle)<br ALIGN="LEFT"/>define_kernel(kernel_name: str, kernel_body: str, metadata: Optional[str], gpu)<br ALIGN="LEFT"/>ensure_size_computed(sym: sympy.Symbol)<br ALIGN="LEFT"/>finalize_prefix()<br ALIGN="LEFT"/>generate(is_inference)<br ALIGN="LEFT"/>generate_before_suffix(result)<br ALIGN="LEFT"/>generate_c_shim_extern_kernel_alloc(extern_kernel, args)<br ALIGN="LEFT"/>generate_c_shim_extern_kernel_call(kernel, args)<br ALIGN="LEFT"/>generate_c_shim_fallback_kernel(fallback_kernel, args)<br ALIGN="LEFT"/>generate_end(result)<br ALIGN="LEFT"/><I>generate_end_graph</I>()<br ALIGN="LEFT"/>generate_extern_kernel_alloc(extern_kernel, args)<br ALIGN="LEFT"/>generate_extern_kernel_args_decl_if_needed(op_overload, raw_args, output_args: Optional[List[str]], raw_outputs: Optional[List[ir.Buffer]])<br ALIGN="LEFT"/>generate_extern_kernel_out(kernel: str, out: str, out_view: Optional[str], args: List[str])<br ALIGN="LEFT"/>generate_fallback_kernel(fallback_kernel, args)<br ALIGN="LEFT"/>generate_fallback_kernel_with_runtime_lookup(buf_name: str, python_kernel_name: str, cpp_kernel_name: str, codegen_args: List[str], op_overload: Optional[torch._ops.OpOverload], raw_args, outputs)<br ALIGN="LEFT"/>generate_fallback_kernel_with_runtime_lookup_aot(op_overload, raw_args, output_args: Optional[List[str]], raw_outputs: Optional[List[ir.Buffer]])<br ALIGN="LEFT"/>generate_fallback_kernel_with_runtime_lookup_jit(buf_name: str, python_kernel_name: str, cpp_kernel_name: str, codegen_args: List[str], op_overload: Optional[torch._ops.OpOverload], raw_args, output_args: Optional[List[str]], raw_outputs: Optional[List[ir.Buffer]])<br ALIGN="LEFT"/>generate_float_value(val)<br ALIGN="LEFT"/>generate_index_put_fallback(kernel, x, indices, values, accumulate)<br ALIGN="LEFT"/>generate_inf_and_nan_checker(nodes)<br ALIGN="LEFT"/>generate_input_output_runtime_checks()<br ALIGN="LEFT"/>generate_kernel_call(kernel_name: str, call_args, grid, device_index, gpu, triton, arg_types, raw_args, grid_fn: str, triton_meta, autotune_configs, grid_extra_kwargs)<br ALIGN="LEFT"/>generate_numel_expr(kernel_name: str, tree, suffix: Optional[str])<br ALIGN="LEFT"/>generate_profiler_mark_wrapper_call(stack)<br ALIGN="LEFT"/>generate_py_arg(py_args_var, idx, raw_arg, arg_type)<br ALIGN="LEFT"/><I>generate_reset_kernel_saved_flags</I>()<br ALIGN="LEFT"/>generate_return(output_refs: List[str])<br ALIGN="LEFT"/><I>generate_save_uncompiled_kernels</I>()<br ALIGN="LEFT"/>generate_scatter_fallback(output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs)<br ALIGN="LEFT"/>generate_scoped_gil_acquire(declarations_before_scope, lines_in_scope)<br ALIGN="LEFT"/><I>generate_start_graph</I>()<br ALIGN="LEFT"/>get_c_shim_func_name(kernel)<br ALIGN="LEFT"/>get_output_refs()<br ALIGN="LEFT"/>include_extra_header(header: str)<br ALIGN="LEFT"/>load_custom_op_wrapper()<br ALIGN="LEFT"/>make_allocation(name, device, dtype, shape, stride)<br ALIGN="LEFT"/>make_buffer_allocation(buffer)<br ALIGN="LEFT"/>make_buffer_free(buffer)<br ALIGN="LEFT"/>make_free_by_names(names_to_del: List[str])<br ALIGN="LEFT"/>mark_output_type()<br ALIGN="LEFT"/>prepare_triton_kernel_call(device_index, call_args)<br ALIGN="LEFT"/>val_to_arg_str(val, type_): str<br ALIGN="LEFT"/>val_to_arg_str_for_prim_type(val, type_): str<br ALIGN="LEFT"/>write_constant(name, hashed)<br ALIGN="LEFT"/>write_header()<br ALIGN="LEFT"/>write_input_output_info(info_kind: str, idx: int, name: str)<br ALIGN="LEFT"/>write_prefix()<br ALIGN="LEFT"/>write_wrapper_decl()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_cpu_array_ref.CppWrapperCpuArrayRef" [color="black", fontcolor="black", label=<{CppWrapperCpuArrayRef|allow_stack_allocation : Optional[bool]<br ALIGN="LEFT"/>arg_var_id : count<br ALIGN="LEFT"/>cached_output_id : count<br ALIGN="LEFT"/>custom_op_wrapper_loaded : bool<br ALIGN="LEFT"/>device : str<br ALIGN="LEFT"/>int_array_id : count<br ALIGN="LEFT"/>kernel_callsite_id : count<br ALIGN="LEFT"/>lines<br ALIGN="LEFT"/>scalar_to_tensor_id : count<br ALIGN="LEFT"/>stack_allocated_buffers : Dict[BufferName, BufferLike]<br ALIGN="LEFT"/>supports_intermediate_hooks : bool<br ALIGN="LEFT"/>tmp_tensor_id : count<br ALIGN="LEFT"/>var_array_id : count<br ALIGN="LEFT"/>|can_stack_allocate_buffer(buffer)<br ALIGN="LEFT"/>codegen_device_copy(src, dst, non_blocking: bool)<br ALIGN="LEFT"/>codegen_input_numel_asserts()<br ALIGN="LEFT"/>codegen_reinterpret_view(data, size, stride, offset, writeline: Callable[..., None], dtype): str<br ALIGN="LEFT"/>codegen_tensor_item(dtype: torch.dtype, tensor: str, scalar: str, indented_buffer)<br ALIGN="LEFT"/>create(is_subgraph: bool, subgraph_name: str, parent_wrapper: PythonWrapperCodegen)<br ALIGN="LEFT"/>create_tmp_raii_handle_var(base_handle)<br ALIGN="LEFT"/>generate_c_shim_extern_kernel_call(kernel, args)<br ALIGN="LEFT"/>generate_fallback_kernel_with_runtime_lookup(buf_name: str, python_kernel_name: str, cpp_kernel_name: str, codegen_args: List[str], op_overload: Optional[torch._ops.OpOverload], raw_args, outputs)<br ALIGN="LEFT"/>generate_index_put_fallback(kernel, x, indices, values, accumulate)<br ALIGN="LEFT"/>generate_kernel_call(kernel_name: str, call_args, grid, device_index, gpu, triton, arg_types, raw_args, grid_fn: str, triton_meta, autotune_configs, grid_extra_kwargs)<br ALIGN="LEFT"/>generate_return(output_refs: List[str])<br ALIGN="LEFT"/>generate_scatter_fallback(output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs)<br ALIGN="LEFT"/>get_input_cpp_type(input)<br ALIGN="LEFT"/>is_safe_to_use_borrow_arrayref_tensor_as_tensor()<br ALIGN="LEFT"/>make_allocation(name, device, dtype, shape, stride, buffer_if_can_stack_allocate)<br ALIGN="LEFT"/>make_buffer_allocation(buffer)<br ALIGN="LEFT"/>make_buffer_free(buffer)<br ALIGN="LEFT"/>make_buffer_reuse(old: BufferLike, new: BufferLike, delete_old: bool)<br ALIGN="LEFT"/>memory_plan()<br ALIGN="LEFT"/>memory_plan_reuse()<br ALIGN="LEFT"/>val_to_arg_str(val, type_): str<br ALIGN="LEFT"/>write_header()<br ALIGN="LEFT"/>write_wrapper_decl()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_gpu.CppWrapperGpu" [color="black", fontcolor="black", label=<{CppWrapperGpu|device : str<br ALIGN="LEFT"/>device_codegen<br ALIGN="LEFT"/>grid_id : count<br ALIGN="LEFT"/>|codegen_inputs()<br ALIGN="LEFT"/>create(is_subgraph: bool, subgraph_name: str, parent_wrapper: PythonWrapperCodegen)<br ALIGN="LEFT"/>define_kernel(kernel_name: str, kernel_body: str, metadata: Optional[str], gpu)<br ALIGN="LEFT"/>generate(is_inference)<br ALIGN="LEFT"/>generate_args_decl(call_args, arg_types, arg_signatures)<br ALIGN="LEFT"/>generate_default_grid(kernel_name: str, grid_args: List[Any], gpu: bool, grid_callable: Optional[Callable[..., Any]])<br ALIGN="LEFT"/>generate_kernel_call(kernel_name: str, call_args, grid, device_index, gpu, triton, arg_types, raw_args, grid_fn: str, triton_meta, autotune_configs, grid_extra_kwargs)<br ALIGN="LEFT"/>generate_load_kernel_once(kernel_name: str, graph: 'GraphLowering')<br ALIGN="LEFT"/>generate_tma_descriptor(desc)<br ALIGN="LEFT"/>generate_user_defined_triton_kernel(kernel_name: str, raw_args: List[Any], grid: List[Any], configs, triton_meta, constexprs)<br ALIGN="LEFT"/>make_zero_buffer(name)<br ALIGN="LEFT"/>write_get_raw_stream(device_idx: int, graph): str<br ALIGN="LEFT"/>write_header()<br ALIGN="LEFT"/>write_tma_descriptor_helpers_once()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.CppWrapperKernelArgs" [color="black", fontcolor="black", label=<{CppWrapperKernelArgs|<br ALIGN="LEFT"/>|wrap_size_arg(size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.CppWrapperKernelGroup" [color="black", fontcolor="black", label=<{CppWrapperKernelGroup|args<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpu_device_op_overrides.CpuDeviceOpOverrides" [color="black", fontcolor="black", label=<{CpuDeviceOpOverrides|<br ALIGN="LEFT"/>|device_guard(device_idx)<br ALIGN="LEFT"/>import_get_raw_stream_as(name)<br ALIGN="LEFT"/>set_device(device_idx)<br ALIGN="LEFT"/>synchronize()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CpuDeviceProperties" [color="black", fontcolor="black", label=<{CpuDeviceProperties|multi_processor_count : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CpuInterface" [color="black", fontcolor="black", label=<{CpuInterface|<br ALIGN="LEFT"/>|current_device()<br ALIGN="LEFT"/>get_compute_capability(device: _device_t): str<br ALIGN="LEFT"/>get_raw_stream(device_idx): int<br ALIGN="LEFT"/>is_available(): bool<br ALIGN="LEFT"/><I>synchronize</I>(device: _device_t)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.CreateTMADescriptorVariable" [color="black", fontcolor="black", label=<{CreateTMADescriptorVariable|rank : int<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.CriterionTest" [color="black", fontcolor="black", label=<{CriterionTest|check_batched_grad<br ALIGN="LEFT"/>check_bfloat16<br ALIGN="LEFT"/>check_complex<br ALIGN="LEFT"/>check_forward_only<br ALIGN="LEFT"/>check_gradgrad<br ALIGN="LEFT"/>check_half<br ALIGN="LEFT"/>constructor_args<br ALIGN="LEFT"/>default_dtype<br ALIGN="LEFT"/>extra_args<br ALIGN="LEFT"/>should_test_cuda<br ALIGN="LEFT"/>test_cpu<br ALIGN="LEFT"/>tf32_precision<br ALIGN="LEFT"/>with_tf32<br ALIGN="LEFT"/>|test_cuda(test_case, dtype, extra_args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.CrossEntropyLoss" [color="black", fontcolor="black", label=<{CrossEntropyLoss|ignore_index : int<br ALIGN="LEFT"/>label_smoothing : float<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules._functions.CrossMapLRN2d" [color="black", fontcolor="black", label=<{CrossMapLRN2d|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input, size, alpha, beta, k)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.normalization.CrossMapLRN2d" [color="black", fontcolor="black", label=<{CrossMapLRN2d|alpha : float<br ALIGN="LEFT"/>beta : float<br ALIGN="LEFT"/>k : float<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_utils.CrossRefFakeMode" [color="black", fontcolor="black", label=<{CrossRefFakeMode|check_aliasing : bool<br ALIGN="LEFT"/>check_strides : bool<br ALIGN="LEFT"/>ignore_op_fn : NoneType<br ALIGN="LEFT"/>only_check_ops_with_meta : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.CrossRefMode" [color="black", fontcolor="black", label=<{CrossRefMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.autograd_function.CtxCustomSave" [color="black", fontcolor="black", label=<{CtxCustomSave|<br ALIGN="LEFT"/>|save_for_backward()<br ALIGN="LEFT"/>save_for_forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.autograd_function.CtxWithSavedTensors" [color="black", fontcolor="black", label=<{CtxWithSavedTensors|saved_tensors<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.wrapDeterministicFlagAPITest.wrapper.CuBLASConfigGuard" [color="black", fontcolor="black", label=<{CuBLASConfigGuard|cublas_config_restore : NoneType<br ALIGN="LEFT"/>cublas_var_name : str<br ALIGN="LEFT"/>is_cuda10_2_or_higher<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.CubeGenVmap" [color="black", fontcolor="black", label=<{CubeGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, grad_output, grad_saved)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>jvp(ctx, input_tangent)<br ALIGN="LEFT"/>setup_context(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.scheduler.cubic_scheduler.CubicSL" [color="black", fontcolor="black", label=<{CubicSL|delta_t : list<br ALIGN="LEFT"/>init_sl : list<br ALIGN="LEFT"/>init_t : list<br ALIGN="LEFT"/>initially_zero : list<br ALIGN="LEFT"/>sparsifier<br ALIGN="LEFT"/>total_t : list<br ALIGN="LEFT"/>|get_sl()<br ALIGN="LEFT"/>sparsity_compute_fn(s_0, s_f, t, t_0, dt, n, initially_zero)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.CudaDdpComparisonTest" [color="black", fontcolor="black", label=<{CudaDdpComparisonTest|<br ALIGN="LEFT"/>|test_ddp_dist_autograd_local_vs_remote_gpu()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.CudaDistAutogradTest" [color="black", fontcolor="black", label=<{CudaDistAutogradTest|<br ALIGN="LEFT"/>|test_gpu_simple()<br ALIGN="LEFT"/>test_gpu_to_cpu_continuation()<br ALIGN="LEFT"/>test_gpu_to_cpu_continuation_gpu_root()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.CudaError" [color="black", fontcolor="red", label=<{CudaError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.backends.cudagraphs.CudaGraphsSupport" [color="black", fontcolor="black", label=<{CudaGraphsSupport|<br ALIGN="LEFT"/>|is_node_supported(submodules, node: torch.fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CudaInterface" [color="black", fontcolor="black", label=<{CudaInterface|Event<br ALIGN="LEFT"/>Stream<br ALIGN="LEFT"/>current_device : staticmethod<br ALIGN="LEFT"/>current_stream : staticmethod<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>device_count : staticmethod<br ALIGN="LEFT"/>exchange_device : staticmethod<br ALIGN="LEFT"/>get_device_properties : staticmethod<br ALIGN="LEFT"/>get_raw_stream : staticmethod<br ALIGN="LEFT"/>is_bf16_supported : staticmethod<br ALIGN="LEFT"/>maybe_exchange_device : staticmethod<br ALIGN="LEFT"/>memory_allocated : staticmethod<br ALIGN="LEFT"/>set_device : staticmethod<br ALIGN="LEFT"/>set_stream : staticmethod<br ALIGN="LEFT"/>stream : staticmethod<br ALIGN="LEFT"/>synchronize : staticmethod<br ALIGN="LEFT"/>|get_compute_capability(device: _device_t)<br ALIGN="LEFT"/>is_available(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.CudaKernelParamCache" [color="black", fontcolor="black", label=<{CudaKernelParamCache|cache : Dict[str, Dict[str, str]]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>|get(key: str): Optional[Dict[str, str]]<br ALIGN="LEFT"/>get_keys(): KeysView[str]<br ALIGN="LEFT"/>set(key: str, params: Dict[str, str], cubin: str, bin_type: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.CudaMemoryLeakCheck" [color="black", fontcolor="black", label=<{CudaMemoryLeakCheck|caching_allocator_befores : list<br ALIGN="LEFT"/>driver_befores : list<br ALIGN="LEFT"/>name : NoneType<br ALIGN="LEFT"/>testcase<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.CudaNonDefaultStream" [color="black", fontcolor="black", label=<{CudaNonDefaultStream|beforeStreams : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.CudaRemoteModuleTest" [color="black", fontcolor="black", label=<{CudaRemoteModuleTest|<br ALIGN="LEFT"/>|test_input_moved_to_cuda_device()<br ALIGN="LEFT"/>test_input_moved_to_cuda_device_script()<br ALIGN="LEFT"/>test_invalid_devices()<br ALIGN="LEFT"/>test_valid_device()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.CudaRpcTest" [color="black", fontcolor="black", label=<{CudaRpcTest|<br ALIGN="LEFT"/>|test_profiler_remote_cuda()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.CudaSyncGuard" [color="black", fontcolor="black", label=<{CudaSyncGuard|debug_mode_restore<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.CudagraphCachedInfo" [color="black", fontcolor="black", label=<{CudagraphCachedInfo|cudagraph_fail_reasons : List[str]<br ALIGN="LEFT"/>placeholders : Sequence[PlaceholderInfo]<br ALIGN="LEFT"/>stack_traces : List[Optional[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.backends.cudagraphs.CudagraphsBackend" [color="black", fontcolor="black", label=<{CudagraphsBackend|compiler_name : str<br ALIGN="LEFT"/>|reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.cudnn.CudnnModule" [color="black", fontcolor="black", label=<{CudnnModule|allow_tf32<br ALIGN="LEFT"/>benchmark<br ALIGN="LEFT"/>benchmark_limit : NoneType<br ALIGN="LEFT"/>deterministic<br ALIGN="LEFT"/>enabled<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.CumulativeDistributionTransform" [color="black", fontcolor="black", label=<{CumulativeDistributionTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>distribution<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>sign : int<br ALIGN="LEFT"/>|log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.CurrentState" [color="black", fontcolor="black", label=<{CurrentState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.decomp_utils.CustomDecompTable" [color="black", fontcolor="black", label=<{CustomDecompTable|decomp_table : dict<br ALIGN="LEFT"/>deleted_custom_ops : set<br ALIGN="LEFT"/>has_materialized : bool<br ALIGN="LEFT"/>|copy(): 'CustomDecompTable'<br ALIGN="LEFT"/>items()<br ALIGN="LEFT"/>keys()<br ALIGN="LEFT"/>materialize(): Dict[torch._ops.OperatorBase, Callable]<br ALIGN="LEFT"/>pop()<br ALIGN="LEFT"/>update(other_dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base._SplitterBase._draw_graph_based_on_node_support.CustomDrawer" [color="black", fontcolor="black", label=<{CustomDrawer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.CustomException" [color="black", fontcolor="red", label=<{CustomException|bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.prune.CustomFromMask" [color="black", fontcolor="black", label=<{CustomFromMask|PRUNING_TYPE : str<br ALIGN="LEFT"/>mask<br ALIGN="LEFT"/>|apply(module, name, mask)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.autograd_function.CustomFunctionHigherOrderOperator" [color="black", fontcolor="black", label=<{CustomFunctionHigherOrderOperator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.custom_graph_pass.CustomGraphPass" [color="black", fontcolor="black", label=<{CustomGraphPass|<br ALIGN="LEFT"/>|<I>uuid</I>(): Optional[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.CustomModuleQuantizeHandler" [color="black", fontcolor="black", label=<{CustomModuleQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.CustomObjArgument" [color="black", fontcolor="black", label=<{CustomObjArgument|class_fqn : Annotated[str, 20]<br ALIGN="LEFT"/>name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.CustomObjArgument" [color="black", fontcolor="black", label=<{CustomObjArgument|class_fqn : str<br ALIGN="LEFT"/>fake_val : Optional[FakeScriptObject]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._custom_op.impl.CustomOp" [color="black", fontcolor="black", label=<{CustomOp|<br ALIGN="LEFT"/>|impl(device_types: typing.Union[str, typing.Iterable[str]], _stacklevel): typing.Callable<br ALIGN="LEFT"/>impl_abstract(_stacklevel): typing.Callable<br ALIGN="LEFT"/>impl_backward(output_differentiability, _stacklevel)<br ALIGN="LEFT"/>impl_factory(): typing.Callable<br ALIGN="LEFT"/>impl_save_for_backward(_stacklevel)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.custom_ops.CustomOpDef" [color="black", fontcolor="black", label=<{CustomOpDef|<br ALIGN="LEFT"/>|register_autograd(): None<br ALIGN="LEFT"/>register_fake(): Callable<br ALIGN="LEFT"/>register_kernel(): Callable<br ALIGN="LEFT"/>register_torch_dispatch(): Callable<br ALIGN="LEFT"/>register_vmap(func: Optional[Callable])<br ALIGN="LEFT"/>set_kernel_enabled(device_type: str, enabled: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.wrap.CustomPolicy" [color="black", fontcolor="black", label=<{CustomPolicy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.CustomizedDictVariable" [color="black", fontcolor="black", label=<{CustomizedDictVariable|call_hasattr<br ALIGN="LEFT"/>|<I>as_proxy</I>()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create(user_cls, args, kwargs, options)<br ALIGN="LEFT"/>is_matching_cls(cls)<br ALIGN="LEFT"/>is_matching_cls_hf(cls)<br ALIGN="LEFT"/>is_matching_object(obj)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>wrap(builder, obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_epilogue_gen.CutlassEVTEpilogueArgumentFormatter" [color="black", fontcolor="black", label=<{CutlassEVTEpilogueArgumentFormatter|accumulator_node_name : str<br ALIGN="LEFT"/>aliases : Dict[str, str]<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>var_counter : int<br ALIGN="LEFT"/>|getvalue(result): str<br ALIGN="LEFT"/>ir_to_evt_argument_string(template_output_node_name: str, epilogue_nodes: List[IRNode]): str<br ALIGN="LEFT"/>reduction(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_epilogue_gen.CutlassEVTEpilogueTypeFormatter" [color="black", fontcolor="black", label=<{CutlassEVTEpilogueTypeFormatter|accumulator_node_name<br ALIGN="LEFT"/>aliases : dict<br ALIGN="LEFT"/>evt_type_name<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>var_counter : int<br ALIGN="LEFT"/>|getvalue(result): str<br ALIGN="LEFT"/>ir_to_evt_string(template_output_node_name: str, evt_type_name: str, epilogue_nodes: List[IRNode])<br ALIGN="LEFT"/>reduction(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.CycleIteratorVariable" [color="black", fontcolor="black", label=<{CycleIteratorVariable|item : Optional[VariableTracker]<br ALIGN="LEFT"/>iterator : NoneType<br ALIGN="LEFT"/>saved : Optional[List[VariableTracker]]<br ALIGN="LEFT"/>saved_index : int<br ALIGN="LEFT"/>|next_variable(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.CyclicLR" [color="black", fontcolor="black", label=<{CyclicLR|base_lrs : list<br ALIGN="LEFT"/>base_momentums : list<br ALIGN="LEFT"/>cycle_momentum : bool<br ALIGN="LEFT"/>gamma : float<br ALIGN="LEFT"/>max_lrs : list<br ALIGN="LEFT"/>max_momentums : list<br ALIGN="LEFT"/>mode : Literal['triangular', 'triangular2', 'exp_range']<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>scale_mode : Literal['cycle', 'iterations'], str<br ALIGN="LEFT"/>step_ratio<br ALIGN="LEFT"/>total_size<br ALIGN="LEFT"/>use_beta1<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>scale_fn(x): float<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.utils.data.cycling_iterator.CyclingIterator" [color="black", fontcolor="black", label=<{CyclingIterator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.accelerator_partitioner.DAG" [color="black", fontcolor="black", label=<{DAG|nodes : List[DAGNode]<br ALIGN="LEFT"/>|create_node(submodule_node: Node, input_nodes: List[Node], output_nodes: List[Node], logical_devices: List[int], size_bytes: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.accelerator_partitioner.DAGNode" [color="black", fontcolor="black", label=<{DAGNode|input_nodes : List[Node]<br ALIGN="LEFT"/>logical_device_ids : List[int]<br ALIGN="LEFT"/>output_nodes : List[Node]<br ALIGN="LEFT"/>size_bytes : int<br ALIGN="LEFT"/>submodule_node<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._composable.replicate.DDP" [color="black", fontcolor="black", label=<{DDP|<br ALIGN="LEFT"/>|register_comm_hook(): None<br ALIGN="LEFT"/>set_requires_gradient_sync(requires_gradient_sync: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.DDPCommHookType" [color="black", fontcolor="black", label=<{DDPCommHookType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.DDPMeshInfo" [color="black", fontcolor="black", label=<{DDPMeshInfo|replicate_mesh_rank : int<br ALIGN="LEFT"/>replicate_mesh_size : int<br ALIGN="LEFT"/>replicate_process_group<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.backends.distributed.DDPOptimizer" [color="black", fontcolor="black", label=<{DDPOptimizer|backend_compile_fn<br ALIGN="LEFT"/>bucket_bytes_cap : int<br ALIGN="LEFT"/>buckets : list<br ALIGN="LEFT"/>first_bucket_cap<br ALIGN="LEFT"/>|add_module_params_to_bucket(mod, bucket, processed_modules, prefix)<br ALIGN="LEFT"/>add_param(bucket, param, name)<br ALIGN="LEFT"/>add_param_args(bucket, node)<br ALIGN="LEFT"/>compile_fn(gm: fx.GraphModule, example_inputs: List[torch.Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DDPUnevenTestInput" [color="black", fontcolor="black", label=<{DDPUnevenTestInput|hook : Optional[Callable]<br ALIGN="LEFT"/>inp : Union[torch.tensor, tuple]<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>state : Optional[Any]<br ALIGN="LEFT"/>sync_interval : int<br ALIGN="LEFT"/>throw_on_early_termination : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.DEVICEInitMode" [color="black", fontcolor="black", label=<{DEVICEInitMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe.DFIterDataPipe" [color="black", fontcolor="black", label=<{DFIterDataPipe|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.DGreatestUpperBound" [color="black", fontcolor="black", label=<{DGreatestUpperBound|res<br ALIGN="LEFT"/>rhs1<br ALIGN="LEFT"/>rhs2<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.dlpack.DLDeviceType" [color="black", fontcolor="black", label=<{DLDeviceType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codecache.DLLWrapper" [color="black", fontcolor="black", label=<{DLLWrapper|DLL<br ALIGN="LEFT"/>is_open : bool<br ALIGN="LEFT"/>lib_path : str<br ALIGN="LEFT"/>|close(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms._quantization.quantization.DQuantType" [color="black", fontcolor="black", label=<{DQuantType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._api.DTensor" [color="black", fontcolor="black", label=<{DTensor|device_mesh<br ALIGN="LEFT"/>placements<br ALIGN="LEFT"/>|from_local(local_tensor: torch.Tensor, device_mesh: Optional[DeviceMesh], placements: Optional[Sequence[Placement]]): 'DTensor'<br ALIGN="LEFT"/>full_tensor(): torch.Tensor<br ALIGN="LEFT"/>redistribute(device_mesh: Optional[DeviceMesh], placements: Optional[Sequence[Placement]]): 'DTensor'<br ALIGN="LEFT"/>to_local(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.DTensorConverter" [color="black", fontcolor="black", label=<{DTensorConverter|args : Tuple[object, ...]<br ALIGN="LEFT"/>flatten_args : List[object]<br ALIGN="LEFT"/>flatten_args_spec<br ALIGN="LEFT"/>flatten_kwargs : List[object]<br ALIGN="LEFT"/>flatten_kwargs_spec<br ALIGN="LEFT"/>hit : int<br ALIGN="LEFT"/>kwargs : Dict[str, object]<br ALIGN="LEFT"/>mesh<br ALIGN="LEFT"/>miss : int<br ALIGN="LEFT"/>sharding_combs : Iterator[Sequence[Placement]]<br ALIGN="LEFT"/>|gen_sharding_choices_for_arg(arg: torch.Tensor): Sequence[Placement]<br ALIGN="LEFT"/>is_supported_tensor(t: torch.Tensor): bool<br ALIGN="LEFT"/>successful(): bool<br ALIGN="LEFT"/>to_dist_tensor(t: torch.Tensor, mesh: DeviceMesh, placements: List[Placement]): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.fsdp.DTensorExtensions" [color="black", fontcolor="black", label=<{DTensorExtensions|compute_stream : NoneType<br ALIGN="LEFT"/>device_handle<br ALIGN="LEFT"/>post_unflatten_transform : NoneType<br ALIGN="LEFT"/>|all_gather_dtensor(tensor: DTensor, parent_mesh: Optional[DeviceMesh]): torch.Tensor<br ALIGN="LEFT"/>chunk_dtensor(tensor: torch.Tensor, rank: int, device_mesh: DeviceMesh): torch.Tensor<br ALIGN="LEFT"/>chunk_tensor(tensor: torch.Tensor, rank: int, world_size: int, num_devices_per_node: int, pg: dist.ProcessGroup, device: Optional[torch.device]): torch.Tensor<br ALIGN="LEFT"/>post_unflatten_transform(tensor: torch.Tensor, param_extension: Any): torch.Tensor<br ALIGN="LEFT"/>pre_flatten_transform(tensor: torch.Tensor): Tuple[torch.Tensor, Optional[Any]]<br ALIGN="LEFT"/>pre_load_state_dict_transform(tensor: torch.Tensor): Tuple[torch.Tensor, List[Shard]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.DTensorOpTestBase" [color="black", fontcolor="black", label=<{DTensorOpTestBase|device_type<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|build_device_mesh()<br ALIGN="LEFT"/>setUp(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._dtensor_spec.DTensorSpec" [color="black", fontcolor="black", label=<{DTensorSpec|device_mesh<br ALIGN="LEFT"/>dim_map<br ALIGN="LEFT"/>mesh<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>num_shards<br ALIGN="LEFT"/>num_shards_map<br ALIGN="LEFT"/>placements : Tuple[Placement, ...]<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>sums<br ALIGN="LEFT"/>tensor_meta : Optional[TensorMeta]<br ALIGN="LEFT"/>|from_dim_map(mesh: DeviceMesh, dim_map: List[int], sums: List[int], tensor_meta: Optional[TensorMeta]): 'DTensorSpec'<br ALIGN="LEFT"/>is_replicated(): bool<br ALIGN="LEFT"/>is_sharded(): bool<br ALIGN="LEFT"/>shallow_copy_with_tensor_meta(tensor_meta: Optional[TensorMeta]): 'DTensorSpec'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.DTensorTestBase" [color="black", fontcolor="black", label=<{DTensorTestBase|backend<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|build_device_mesh(): DeviceMesh<br ALIGN="LEFT"/>destroy_pg(): None<br ALIGN="LEFT"/>init_pg(eager_init): None<br ALIGN="LEFT"/>run_subtests()<br ALIGN="LEFT"/>setUp(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._dtypes.DType" [color="black", fontcolor="black", label=<{DType|itemsize<br ALIGN="LEFT"/>kind<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>typecode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.backend_config.backend_config.DTypeConfig" [color="black", fontcolor="black", label=<{DTypeConfig|bias_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>input_dtype<br ALIGN="LEFT"/>input_dtype_with_constraints<br ALIGN="LEFT"/>is_dynamic : Optional[bool]<br ALIGN="LEFT"/>output_dtype<br ALIGN="LEFT"/>output_dtype_with_constraints<br ALIGN="LEFT"/>weight_dtype<br ALIGN="LEFT"/>weight_dtype_with_constraints<br ALIGN="LEFT"/>|from_dict(dtype_config_dict: Dict[str, Any]): DTypeConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dtype_propagation.DTypeVar" [color="black", fontcolor="black", label=<{DTypeVar|dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.backend_config.backend_config.DTypeWithConstraints" [color="black", fontcolor="black", label=<{DTypeWithConstraints|dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>quant_max_upper_bound : Optional[Union[int, float, None]]<br ALIGN="LEFT"/>quant_min_lower_bound : Optional[Union[int, float, None]]<br ALIGN="LEFT"/>scale_exact_match : Optional[float]<br ALIGN="LEFT"/>scale_max_upper_bound : Optional[Union[int, float, None]]<br ALIGN="LEFT"/>scale_min_lower_bound : Optional[Union[int, float, None]]<br ALIGN="LEFT"/>zero_point_exact_match : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.DVar" [color="black", fontcolor="black", label=<{DVar|c<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe.DataChunk" [color="black", fontcolor="black", label=<{DataChunk|items : Iterable[_T]<br ALIGN="LEFT"/>|as_str(indent: str): str<br ALIGN="LEFT"/>raw_iterator(): Iterator[_T]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.structures.DataChunkDF" [color="black", fontcolor="black", label=<{DataChunkDF|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.DataDependentOutputException" [color="black", fontcolor="red", label=<{DataDependentOutputException|func<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.DataFlowEdge" [color="black", fontcolor="black", label=<{DataFlowEdge|input_version : Optional[int]<br ALIGN="LEFT"/>is_allocation<br ALIGN="LEFT"/>is_deletion<br ALIGN="LEFT"/>mutated : Optional[bool]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.DataFlowGraph" [color="black", fontcolor="black", label=<{DataFlowGraph|flow_nodes<br ALIGN="LEFT"/>leaf_events<br ALIGN="LEFT"/>|bump(key: TensorKey): None<br ALIGN="LEFT"/>delete(key: TensorKey): None<br ALIGN="LEFT"/>lookup(key: TensorKey): int<br ALIGN="LEFT"/>validate()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.DataFlowNode" [color="black", fontcolor="black", label=<{DataFlowNode|inputs<br ALIGN="LEFT"/>intermediates<br ALIGN="LEFT"/>outputs<br ALIGN="LEFT"/>start_time<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracedOps" [color="black", fontcolor="black", label=<{DataFrameTracedOps|output_var<br ALIGN="LEFT"/>source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracer" [color="black", fontcolor="black", label=<{DataFrameTracer|source_datapipe : Optional[Any]<br ALIGN="LEFT"/>|is_shardable()<br ALIGN="LEFT"/><I>set_shuffle_settings</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.DataFramesAsTuplesPipe" [color="black", fontcolor="black", label=<{DataFramesAsTuplesPipe|source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.dataloader.DataLoader" [color="black", fontcolor="black", label=<{DataLoader|batch_sampler : Optional[Union[Sampler[List], Iterable[List], None]]<br ALIGN="LEFT"/>batch_size : Optional[int]<br ALIGN="LEFT"/>collate_fn : Optional[_collate_fn_t]<br ALIGN="LEFT"/>dataset : Dataset[_T_co]<br ALIGN="LEFT"/>drop_last : bool<br ALIGN="LEFT"/>generator : NoneType<br ALIGN="LEFT"/>in_order : bool<br ALIGN="LEFT"/>multiprocessing_context<br ALIGN="LEFT"/>num_workers : int<br ALIGN="LEFT"/>persistent_workers : bool<br ALIGN="LEFT"/>pin_memory : bool<br ALIGN="LEFT"/>pin_memory_device : str<br ALIGN="LEFT"/>prefetch_factor : Optional[int]<br ALIGN="LEFT"/>sampler : Union[Sampler, Iterable]<br ALIGN="LEFT"/>timeout : float<br ALIGN="LEFT"/>worker_init_fn : Optional[_worker_init_fn_t]<br ALIGN="LEFT"/>|check_worker_number_rationality()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.data_norm_sparsifier.DataNormSparsifier" [color="black", fontcolor="black", label=<{DataNormSparsifier|norm : str<br ALIGN="LEFT"/>|update_mask(name, data, sparsity_level, sparse_block_shape, zeros_per_block)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel.data_parallel.DataParallel" [color="black", fontcolor="black", label=<{DataParallel|device_ids : list<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>module : T<br ALIGN="LEFT"/>output_device : NoneType, int<br ALIGN="LEFT"/>src_device_obj<br ALIGN="LEFT"/>|forward(): Any<br ALIGN="LEFT"/>gather(outputs: Any, output_device: Union[int, torch.device]): Any<br ALIGN="LEFT"/>parallel_apply(replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any): List[Any]<br ALIGN="LEFT"/>replicate(module: T, device_ids: Sequence[Union[int, torch.device]]): List[T]<br ALIGN="LEFT"/>scatter(inputs: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]], device_ids: Sequence[Union[int, torch.device]]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.DataParallelMeshInfo" [color="black", fontcolor="black", label=<{DataParallelMeshInfo|mesh<br ALIGN="LEFT"/>replicate_mesh_dim : Optional[int]<br ALIGN="LEFT"/>shard_mesh_dim : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.DataProcessorChoiceCallerWrapper" [color="black", fontcolor="black", label=<{DataProcessorChoiceCallerWrapper|<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/>output_node(): ir.TensorBox<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.DataProcessorTemplateWrapper" [color="black", fontcolor="black", label=<{DataProcessorTemplateWrapper|<br ALIGN="LEFT"/>|generate()<br ALIGN="LEFT"/>maybe_append_choice(choices)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.DataPtrVariable" [color="black", fontcolor="black", label=<{DataPtrVariable|from_tensor<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.DataTypePropagation" [color="black", fontcolor="black", label=<{DataTypePropagation|body<br ALIGN="LEFT"/>graphs : Dict[Union[Callable[..., Any], str], Any]<br ALIGN="LEFT"/>|deduce_node_dtype(node: torch.fx.Node)<br ALIGN="LEFT"/>deduce_node_dtype_by_inputs(node: torch.fx.Node)<br ALIGN="LEFT"/>deduce_node_dtype_by_subgraph(node: torch.fx.Node)<br ALIGN="LEFT"/>propagate()<br ALIGN="LEFT"/>propagate_graph(graph: torch.fx.Graph)<br ALIGN="LEFT"/>propagate_loopbody(body)<br ALIGN="LEFT"/>propagate_scheduler_node(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataset.Dataset" [color="black", fontcolor="black", label=<{Dataset|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest" [color="black", fontcolor="black", label=<{DdpComparisonTest|<br ALIGN="LEFT"/>|test_ddp_comparison()<br ALIGN="LEFT"/>test_ddp_comparison_uneven_inputs()<br ALIGN="LEFT"/>test_ddp_dist_autograd_local_vs_remote()<br ALIGN="LEFT"/>test_ddp_dist_autograd_sparse_grads()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpMode" [color="black", fontcolor="black", label=<{DdpMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest" [color="black", fontcolor="black", label=<{DdpUnderDistAutogradTest|world_size<br ALIGN="LEFT"/>|do_test_on_master(ddp_mode: DdpMode, simulate_uneven_inputs: bool, remote_em_rref: rpc.RRef, remote_net_rref: rpc.RRef)<br ALIGN="LEFT"/>remote_worker_name(): str<br ALIGN="LEFT"/>test_backward_ddp_inside()<br ALIGN="LEFT"/>test_backward_ddp_outside()<br ALIGN="LEFT"/>test_backward_ddp_outside_uneven_inputs()<br ALIGN="LEFT"/>test_backward_no_ddp()<br ALIGN="LEFT"/>trainer_name(rank)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [color="black", fontcolor="black", label=<{DeFusedEmbeddingBagLinear|bagging_op<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>emb<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(input: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" [color="black", fontcolor="black", label=<{DeQuantStub|qconfig : NoneType<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.DeQuantize" [color="black", fontcolor="black", label=<{DeQuantize|<br ALIGN="LEFT"/>|forward(Xq)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.DeallocFromPoolLine" [color="black", fontcolor="black", label=<{DeallocFromPoolLine|is_last_pool_usage : bool<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.DebugAssertWrapper" [color="black", fontcolor="black", label=<{DebugAssertWrapper|flat_requires_grad : List[Optional[bool]]<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.triton_heuristics.DebugAutotuner" [color="black", fontcolor="black", label=<{DebugAutotuner|cached : NoneType, tuple<br ALIGN="LEFT"/>precompile_time_taken_ns<br ALIGN="LEFT"/>regex_filter : str<br ALIGN="LEFT"/>with_bandwidth_info : bool<br ALIGN="LEFT"/>with_profiler : bool<br ALIGN="LEFT"/>|run()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.debug.DebugContext" [color="black", fontcolor="black", label=<{DebugContext|<br ALIGN="LEFT"/>|copy(new_path: str): None<br ALIGN="LEFT"/>create_debug_dir(folder_name: str): Optional[str]<br ALIGN="LEFT"/>filename(suffix: str): str<br ALIGN="LEFT"/>fopen(filename: str, write_mode: str): IO[Any]<br ALIGN="LEFT"/>fopen_context(filename: str, write_mode: str): Iterator[IO[Any]]<br ALIGN="LEFT"/>upload_tar(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.DebugDirManager" [color="black", fontcolor="black", label=<{DebugDirManager|counter : count<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>new_name : str<br ALIGN="LEFT"/>prev_debug_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.debug.DebugFormatter" [color="black", fontcolor="black", label=<{DebugFormatter|filename<br ALIGN="LEFT"/>fopen<br ALIGN="LEFT"/>fopen_context<br ALIGN="LEFT"/>handler<br ALIGN="LEFT"/>|draw_orig_fx_graph(gm: torch.fx.GraphModule, nodes: SchedulerNodeList): None<br ALIGN="LEFT"/>fx_graph(gm: torch.fx.GraphModule, inputs: List[torch.Tensor]): None<br ALIGN="LEFT"/>fx_graph_transformed(gm: torch.fx.GraphModule, inputs: List[torch.Tensor]): None<br ALIGN="LEFT"/>graph_diagram(nodes: SchedulerNodeList): None<br ALIGN="LEFT"/>ir_post_fusion(nodes: SchedulerNodeList): None<br ALIGN="LEFT"/>ir_pre_fusion(nodes: SchedulerNodeList): None<br ALIGN="LEFT"/>log_autotuning_results(name: str, input_nodes: List[ir.IRNode], timings: Dict['ChoiceCaller', float], elapse: float, precompile_elapse: float): None<br ALIGN="LEFT"/>output_code(filename: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.compilers.DebugInterpreter" [color="black", fontcolor="black", label=<{DebugInterpreter|symbol_mapping<br ALIGN="LEFT"/>|run()<br ALIGN="LEFT"/>run_node(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.debug_utils.DebugPrinterManager" [color="black", fontcolor="black", label=<{DebugPrinterManager|arg_signatures : Optional[List[type]]<br ALIGN="LEFT"/>args_to_print_or_save : Optional[List[str]]<br ALIGN="LEFT"/>debug_printer_level : OFF<br ALIGN="LEFT"/>filtered_kernel_names_to_print : list<br ALIGN="LEFT"/>kernel : NoneType<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>kernel_type : NoneType<br ALIGN="LEFT"/>|codegen_intermediate_tensor_value_print(args_to_print, kernel_name, before_launch, arg_signatures: Optional[List[type]]): None<br ALIGN="LEFT"/>codegen_intermediate_tensor_value_save(args_to_save, kernel_name, before_launch, arg_signatures: Optional[List[type]]): None<br ALIGN="LEFT"/>codegen_model_inputs_value_print(input_args_to_print: List[str]): None<br ALIGN="LEFT"/>set_printer_args(args_to_print_or_save: List[str], kernel_name: str, arg_signatures: Optional[List[type]], kernel, kernel_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.DebuggingVariable" [color="black", fontcolor="black", label=<{DebuggingVariable|value<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>can_reorder_logs(fn, args, kwargs): True<br ALIGN="LEFT"/>is_reorderable_logging_function(obj)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.utils.decoder.Decoder" [color="black", fontcolor="black", label=<{Decoder|handlers : list<br ALIGN="LEFT"/>key_fn<br ALIGN="LEFT"/>|add_handler()<br ALIGN="LEFT"/>decode(data)<br ALIGN="LEFT"/>decode1(key, data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.decomposition_skip.DecompSkip" [color="black", fontcolor="black", label=<{DecompSkip|new_op_name : str<br ALIGN="LEFT"/>new_op_schema : str<br ALIGN="LEFT"/>onnxscript_function : Callable<br ALIGN="LEFT"/>op_callable : Callable<br ALIGN="LEFT"/>|<I>abstract</I>()<br ALIGN="LEFT"/><I>register</I>(export_options: torch.onnx.ExportOptions)<br ALIGN="LEFT"/>register_custom_op()<br ALIGN="LEFT"/>replacement()<br ALIGN="LEFT"/><I>unregister</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.decomp.Decompose" [color="black", fontcolor="black", label=<{Decompose|allow_fake_constant : bool \| None<br ALIGN="LEFT"/>decomposition_table : Mapping[torch._ops.OpOverload, Callable]<br ALIGN="LEFT"/>enable_dynamic_axes : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor.DecompositionInterpreter" [color="black", fontcolor="black", label=<{DecompositionInterpreter|decomposition_table : dict<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>new_graph<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|get_attr(target: str, args: Tuple[object, ...], kwargs: Dict[str, object]): object<br ALIGN="LEFT"/>output(target: str, args: Tuple[object, ...], kwargs: Dict[str, object]): object<br ALIGN="LEFT"/>placeholder(target: str, args: Tuple[object, ...], kwargs: Dict[str, object]): object<br ALIGN="LEFT"/>run(): object<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.DecorateInfo" [color="black", fontcolor="black", label=<{DecorateInfo|active_if : bool<br ALIGN="LEFT"/>cls_name : NoneType<br ALIGN="LEFT"/>decorators : list<br ALIGN="LEFT"/>device_type : NoneType<br ALIGN="LEFT"/>dtypes : NoneType<br ALIGN="LEFT"/>test_name : NoneType<br ALIGN="LEFT"/>|is_active(cls_name, test_name, device_type, dtype, param_kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.decorator.Decorator" [color="black", fontcolor="black", label=<{Decorator|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.Scheduler.compute_dependencies.DedupList" [color="black", fontcolor="black", label=<{DedupList|items : list<br ALIGN="LEFT"/>membership<br ALIGN="LEFT"/>|append(node_user: T): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.checkpoint.DefaultDeviceType" [color="black", fontcolor="black", label=<{DefaultDeviceType|<br ALIGN="LEFT"/>|get_device_type(): str<br ALIGN="LEFT"/>set_device_type(device: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.DefaultDictVariable" [color="black", fontcolor="black", label=<{DefaultDictVariable|default_factory : NoneType<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>is_supported_arg(arg)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.fuse_handler.DefaultFuseHandler" [color="black", fontcolor="black", label=<{DefaultFuseHandler|<br ALIGN="LEFT"/>|fuse(load_arg: Callable, named_modules: Dict[str, torch.nn.Module], fused_graph: Graph, root_node: Node, extra_inputs: List[Any], matched_node_pattern: NodePattern, fuse_custom_config: FuseCustomConfig, fuser_method_mapping: Dict[Pattern, Union[torch.nn.Sequential, Callable]], is_qat: bool): Node<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.default_planner.DefaultLoadPlanner" [color="black", fontcolor="black", label=<{DefaultLoadPlanner|allow_partial_load : bool<br ALIGN="LEFT"/>flatten_sharded_tensors : bool<br ALIGN="LEFT"/>flatten_state_dict : bool<br ALIGN="LEFT"/>is_coordinator : bool<br ALIGN="LEFT"/>mappings : Dict<br ALIGN="LEFT"/>metadata : Optional[Metadata]<br ALIGN="LEFT"/>original_state_dict : Dict<br ALIGN="LEFT"/>state_dict : Dict, dict<br ALIGN="LEFT"/>|<I>commit_tensor</I>(read_item: ReadItem, tensor: torch.Tensor): None<br ALIGN="LEFT"/>create_global_plan(global_plan: List[LoadPlan]): List[LoadPlan]<br ALIGN="LEFT"/>create_local_plan(): LoadPlan<br ALIGN="LEFT"/>finish_plan(new_plan: LoadPlan): LoadPlan<br ALIGN="LEFT"/>load_bytes(read_item: ReadItem, value: io.BytesIO): None<br ALIGN="LEFT"/>lookup_tensor(index: MetadataIndex): torch.Tensor<br ALIGN="LEFT"/>resolve_tensor(read_item: ReadItem)<br ALIGN="LEFT"/>set_up_planner(state_dict: STATE_DICT_TYPE, metadata: Optional[Metadata], is_coordinator: bool): None<br ALIGN="LEFT"/>transform_tensor(read_item: ReadItem, tensor: torch.Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs" [color="black", fontcolor="black", label=<{DefaultLogsSpecs|root_log_dir<br ALIGN="LEFT"/>|reify(envs: Dict[int, Dict[str, str]]): LogsDest<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.DefaultNodeQuantizeHandler" [color="black", fontcolor="black", label=<{DefaultNodeQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.default_planner.DefaultSavePlanner" [color="black", fontcolor="black", label=<{DefaultSavePlanner|dedup_save_to_lowest_rank : bool<br ALIGN="LEFT"/>flatten_sharded_tensors : bool<br ALIGN="LEFT"/>flatten_state_dict : bool<br ALIGN="LEFT"/>global_plan : list<br ALIGN="LEFT"/>is_coordinator : bool<br ALIGN="LEFT"/>mappings : Dict<br ALIGN="LEFT"/>metadata<br ALIGN="LEFT"/>plan<br ALIGN="LEFT"/>state_dict : Dict<br ALIGN="LEFT"/>|create_global_plan(all_plans: List[SavePlan]): Tuple[List[SavePlan], Metadata]<br ALIGN="LEFT"/>create_local_plan(): SavePlan<br ALIGN="LEFT"/>finish_plan(new_plan: SavePlan): SavePlan<br ALIGN="LEFT"/>lookup_object(index: MetadataIndex): Any<br ALIGN="LEFT"/>resolve_data(write_item: WriteItem): Union[torch.Tensor, io.BytesIO]<br ALIGN="LEFT"/>set_up_planner(state_dict: STATE_DICT_TYPE, storage_meta: Optional[StorageMeta], is_coordinator: bool): None<br ALIGN="LEFT"/>transform_object(write_item: WriteItem, object: Any)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms._comm_hooks.default_hooks.DefaultState" [color="black", fontcolor="black", label=<{DefaultState|gradient_postdivide_factor<br ALIGN="LEFT"/>gradient_predivide_factor : float<br ALIGN="LEFT"/>process_group<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.DefaultsSource" [color="black", fontcolor="black", label=<{DefaultsSource|field : str<br ALIGN="LEFT"/>idx_key : Union[int, str]<br ALIGN="LEFT"/>is_kw : bool<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.DeferredCudaCallError" [color="black", fontcolor="red", label=<{DeferredCudaCallError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_gpu.DeferredGpuDefaultGrid" [color="black", fontcolor="black", label=<{DeferredGpuDefaultGrid|grid<br ALIGN="LEFT"/>grid_callable : Optional[Callable[..., Any]]<br ALIGN="LEFT"/>grid_extra_kwargs : dict<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_gpu.DeferredGpuGridLine" [color="black", fontcolor="black", label=<{DeferredGpuGridLine|autotune_configs<br ALIGN="LEFT"/>grid<br ALIGN="LEFT"/>grid_var : str<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_wrapper_gpu.DeferredGpuKernelLine" [color="black", fontcolor="black", label=<{DeferredGpuKernelLine|additional_files : List[str]<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>keys : Tuple[str, ...]<br ALIGN="LEFT"/>line_template : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.DeferredLine" [color="black", fontcolor="black", label=<{DeferredLine|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.DeferredLineBase" [color="black", fontcolor="black", label=<{DeferredLineBase|line : str<br ALIGN="LEFT"/>|lstrip()<br ALIGN="LEFT"/>with_prefix(prefix)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.mtia.DeferredMtiaCallError" [color="black", fontcolor="red", label=<{DeferredMtiaCallError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.DelayGraphBreakVariable" [color="black", fontcolor="black", label=<{DelayGraphBreakVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.DelayReplaceLine" [color="black", fontcolor="black", label=<{DelayReplaceLine|key : str<br ALIGN="LEFT"/>value_fn : Callable[[], str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.guards.DeletedGuardManagerWrapper" [color="black", fontcolor="black", label=<{DeletedGuardManagerWrapper|diff_guard_root : NoneType<br ALIGN="LEFT"/>invalidation_reason<br ALIGN="LEFT"/>|populate_diff_guard_manager()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.DeletedVariable" [color="black", fontcolor="black", label=<{DeletedVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining.DemultiplexerIterDataPipe" [color="black", fontcolor="black", label=<{DemultiplexerIterDataPipe|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.DenseTopMLP" [color="black", fontcolor="black", label=<{DenseTopMLP|dense_mlp<br ALIGN="LEFT"/>top_mlp<br ALIGN="LEFT"/>|forward(sparse_feature: torch.Tensor, dense: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies.Dep" [color="black", fontcolor="black", label=<{Dep|index : Expr<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|<I>get_numel</I>(): sympy.Expr<br ALIGN="LEFT"/><I>has_unbacked_symbols</I>(): bool<br ALIGN="LEFT"/><I>is_contiguous</I>(): bool<br ALIGN="LEFT"/>normalize_with_stride_order(prefix)<br ALIGN="LEFT"/><I>numbytes_hint</I>()<br ALIGN="LEFT"/><I>rename</I>(renames: Dict[str, str]): 'Dep'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.DequeVariable" [color="black", fontcolor="black", label=<{DequeVariable|maxlen : NoneType<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.DerivedQuantizationSpec" [color="black", fontcolor="black", label=<{DerivedQuantizationSpec|ch_axis : Optional[int]<br ALIGN="LEFT"/>derive_qparams_fn : Callable[[List[ObserverOrFakeQuantize]], Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>derived_from : List[EdgeOrNode]<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>is_dynamic : bool<br ALIGN="LEFT"/>qscheme : Optional[torch.qscheme]<br ALIGN="LEFT"/>quant_max : Optional[int]<br ALIGN="LEFT"/>quant_min : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.DetachExecutor" [color="black", fontcolor="black", label=<{DetachExecutor|value_remap : dict<br ALIGN="LEFT"/>|call_function(target, args, kwargs)<br ALIGN="LEFT"/>call_module(target, args, kwargs)<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.KernelTemplate._template_from_string.DetailedTemplateSyntaxError" [color="black", fontcolor="red", label=<{DetailedTemplateSyntaxError|original_error<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.DetectorBase" [color="black", fontcolor="black", label=<{DetectorBase|detector_config_info : NoneType<br ALIGN="LEFT"/>|<I>determine_observer_insert_points</I>(model): Dict<br ALIGN="LEFT"/><I>generate_detector_report</I>(model): Tuple[str, Dict[str, Any]]<br ALIGN="LEFT"/><I>get_detector_name</I>(): str<br ALIGN="LEFT"/><I>get_qconfig_info</I>(model): Dict[str, DetectorQConfigInfo]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.DetectorQConfigInfo" [color="black", fontcolor="black", label=<{DetectorQConfigInfo|is_activation_dynamic : bool<br ALIGN="LEFT"/>is_equalization_recommended : bool<br ALIGN="LEFT"/>is_weight_per_channel : bool<br ALIGN="LEFT"/>module_fqn : str<br ALIGN="LEFT"/>|generate_equalization_qconfig(): EqualizationQConfig<br ALIGN="LEFT"/>generate_quantization_qconfig(module: torch.nn.Module): QConfig<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.DeterministicAlgorithmsVariable" [color="black", fontcolor="black", label=<{DeterministicAlgorithmsVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_value)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.DeterministicGuard" [color="black", fontcolor="black", label=<{DeterministicGuard|deterministic<br ALIGN="LEFT"/>deterministic_restore<br ALIGN="LEFT"/>fill_uninitialized_memory : bool<br ALIGN="LEFT"/>fill_uninitialized_memory_restore : bool<br ALIGN="LEFT"/>warn_only : bool<br ALIGN="LEFT"/>warn_only_restore<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.Device" [color="black", fontcolor="black", label=<{Device|available_mem_bytes : int<br ALIGN="LEFT"/>logical_id : int<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.Device" [color="black", fontcolor="black", label=<{Device|index : Optional[Annotated[Optional[int], 20]]<br ALIGN="LEFT"/>type : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.DeviceCodegen" [color="black", fontcolor="black", label=<{DeviceCodegen|cpp_wrapper_codegen : type<br ALIGN="LEFT"/>scheduling : Any<br ALIGN="LEFT"/>wrapper_codegen : type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._lazy.device_context.DeviceContext" [color="black", fontcolor="black", label=<{DeviceContext|async_closure_handler<br ALIGN="LEFT"/>async_step_closures : list<br ALIGN="LEFT"/>closure_handler<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>step_closures : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._device.DeviceContext" [color="black", fontcolor="black", label=<{DeviceContext|device<br ALIGN="LEFT"/>old_device<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.DeviceCopy" [color="black", fontcolor="black", label=<{DeviceCopy|<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(x, device, non_blocking)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceGuard" [color="black", fontcolor="black", label=<{DeviceGuard|device_interface : Type[DeviceInterface]<br ALIGN="LEFT"/>idx : Optional[int]<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceInterface" [color="black", fontcolor="black", label=<{DeviceInterface|<br ALIGN="LEFT"/>|<I>current_device</I>()<br ALIGN="LEFT"/><I>current_stream</I>()<br ALIGN="LEFT"/><I>device_count</I>()<br ALIGN="LEFT"/><I>exchange_device</I>(device: int): int<br ALIGN="LEFT"/><I>get_compute_capability</I>(device: _device_t)<br ALIGN="LEFT"/>get_device_properties(device: _device_t)<br ALIGN="LEFT"/><I>get_raw_stream</I>(device_idx: int): int<br ALIGN="LEFT"/><I>is_available</I>(): bool<br ALIGN="LEFT"/><I>is_bf16_supported</I>(including_emulation: bool)<br ALIGN="LEFT"/><I>maybe_exchange_device</I>(device: int): int<br ALIGN="LEFT"/><I>memory_allocated</I>(device: _device_t): int<br ALIGN="LEFT"/><I>set_device</I>(device: _device_t)<br ALIGN="LEFT"/><I>set_stream</I>(stream: torch.Stream)<br ALIGN="LEFT"/><I>stream</I>(stream: torch.Stream)<br ALIGN="LEFT"/><I>synchronize</I>(device: _device_t)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" [color="black", fontcolor="black", label=<{DeviceMesh|device_type : str<br ALIGN="LEFT"/>mesh<br ALIGN="LEFT"/>mesh_dim_names : Optional[Tuple[str, ...]]<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|from_group(group: Union[ProcessGroup, List[ProcessGroup]], device_type: str, mesh: Optional[Union[torch.Tensor, 'ArrayLike']]): 'DeviceMesh'<br ALIGN="LEFT"/>get_all_groups(): List[ProcessGroup]<br ALIGN="LEFT"/>get_coordinate(): Optional[List[int]]<br ALIGN="LEFT"/>get_group(mesh_dim: Optional[Union[int, str]]): ProcessGroup<br ALIGN="LEFT"/>get_local_rank(mesh_dim: Optional[Union[int, str]]): int<br ALIGN="LEFT"/>get_rank(): int<br ALIGN="LEFT"/>size(mesh_dim: Optional[int]): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.DeviceMeshVariable" [color="black", fontcolor="black", label=<{DeviceMeshVariable|<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_device_mesh(value)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.DeviceOpOverrides" [color="black", fontcolor="black", label=<{DeviceOpOverrides|<br ALIGN="LEFT"/>|<I>abi_compatible_header</I>()<br ALIGN="LEFT"/><I>aoti_get_stream</I>()<br ALIGN="LEFT"/><I>cpp_aoti_device_guard</I>()<br ALIGN="LEFT"/><I>cpp_aoti_stream_guard</I>()<br ALIGN="LEFT"/><I>cpp_device_guard</I>()<br ALIGN="LEFT"/><I>cpp_device_ptr</I>()<br ALIGN="LEFT"/><I>cpp_getStreamFromExternal</I>()<br ALIGN="LEFT"/><I>cpp_kernel_type</I>()<br ALIGN="LEFT"/><I>cpp_stream_guard</I>()<br ALIGN="LEFT"/><I>cpp_stream_type</I>()<br ALIGN="LEFT"/><I>device_guard</I>(device_idx)<br ALIGN="LEFT"/><I>import_get_raw_stream_as</I>(name)<br ALIGN="LEFT"/><I>kernel_driver</I>()<br ALIGN="LEFT"/><I>kernel_header</I>()<br ALIGN="LEFT"/><I>set_device</I>(device_idx)<br ALIGN="LEFT"/><I>synchronize</I>()<br ALIGN="LEFT"/><I>tma_descriptor_helpers</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_spec.api.DevicePlacementSpec" [color="black", fontcolor="black", label=<{DevicePlacementSpec|device<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.DeviceProperties" [color="black", fontcolor="black", label=<{DeviceProperties|cc : int<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>major : Optional[int]<br ALIGN="LEFT"/>max_threads_per_multi_processor : Optional[int]<br ALIGN="LEFT"/>multi_processor_count : int<br ALIGN="LEFT"/>regs_per_multiprocessor : Optional[int]<br ALIGN="LEFT"/>type : str<br ALIGN="LEFT"/>warp_size : Optional[int]<br ALIGN="LEFT"/>|create(device): DeviceProperties<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.DeviceTypeTestBase" [color="black", fontcolor="black", label=<{DeviceTypeTestBase|device_type : str<br ALIGN="LEFT"/>precision<br ALIGN="LEFT"/>rel_tol<br ALIGN="LEFT"/>|get_all_devices()<br ALIGN="LEFT"/>get_primary_device()<br ALIGN="LEFT"/>instantiate_test(name, test)<br ALIGN="LEFT"/>run(result)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._digraph.DiGraph" [color="black", fontcolor="black", label=<{DiGraph|edges<br ALIGN="LEFT"/>nodes<br ALIGN="LEFT"/>|add_edge(u, v)<br ALIGN="LEFT"/>add_node(n)<br ALIGN="LEFT"/>all_paths(src: str, dst: str)<br ALIGN="LEFT"/>backward_transitive_closure(src: str): Set[str]<br ALIGN="LEFT"/>first_path(dst: str): List[str]<br ALIGN="LEFT"/>forward_transitive_closure(src: str): Set[str]<br ALIGN="LEFT"/>predecessors(n)<br ALIGN="LEFT"/>successors(n)<br ALIGN="LEFT"/>to_dot(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.DiagTensorBelow" [color="black", fontcolor="black", label=<{DiagTensorBelow|diag<br ALIGN="LEFT"/>handled_ops : dict<br ALIGN="LEFT"/>|get_wrapper_properties(diag, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.diagnostics.Diagnostic" [color="black", fontcolor="black", label=<{Diagnostic|logger : Logger<br ALIGN="LEFT"/>|log(level: int, message: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.context.Diagnostic" [color="black", fontcolor="black", label=<{Diagnostic|additional_messages : list[str]<br ALIGN="LEFT"/>graphs : list[infra.Graph]<br ALIGN="LEFT"/>level<br ALIGN="LEFT"/>locations : list[infra.Location]<br ALIGN="LEFT"/>logger : Logger<br ALIGN="LEFT"/>message : str \| None<br ALIGN="LEFT"/>rule<br ALIGN="LEFT"/>source_exception : Exception \| None<br ALIGN="LEFT"/>stacks : list[infra.Stack]<br ALIGN="LEFT"/>tags : list[infra.Tag]<br ALIGN="LEFT"/>thread_flow_locations : list[infra.ThreadFlowLocation]<br ALIGN="LEFT"/>|debug(message: str): None<br ALIGN="LEFT"/>error(message: str): None<br ALIGN="LEFT"/>info(message: str): None<br ALIGN="LEFT"/>log(level: int, message: str): None<br ALIGN="LEFT"/>log_section(level: int, message: str): Generator[None, None, None]<br ALIGN="LEFT"/>log_source_exception(level: int, exception: Exception): None<br ALIGN="LEFT"/>record_python_call(fn: Callable, state: Mapping[str, str], message: str \| None, frames_to_skip: int): infra.ThreadFlowLocation<br ALIGN="LEFT"/>record_python_call_stack(frames_to_skip: int): infra.Stack<br ALIGN="LEFT"/>sarif(): sarif.Result<br ALIGN="LEFT"/>warning(message: str): None<br ALIGN="LEFT"/>with_graph(graph: infra.Graph): Self<br ALIGN="LEFT"/>with_location(location: infra.Location): Self<br ALIGN="LEFT"/>with_stack(stack: infra.Stack): Self<br ALIGN="LEFT"/>with_thread_flow_location(location: infra.ThreadFlowLocation): Self<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" [color="black", fontcolor="black", label=<{DiagnosticContext|logger : Logger<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.context.DiagnosticContext" [color="black", fontcolor="black", label=<{DiagnosticContext|diagnostics : list[_Diagnostic]<br ALIGN="LEFT"/>logger : Logger<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>options<br ALIGN="LEFT"/>version : str<br ALIGN="LEFT"/>|add_inflight_diagnostic(diagnostic: _Diagnostic): Generator[_Diagnostic, None, None]<br ALIGN="LEFT"/>dump(file_path: str, compress: bool): None<br ALIGN="LEFT"/>inflight_diagnostic(rule: infra.Rule \| None): _Diagnostic<br ALIGN="LEFT"/>log(diagnostic: _Diagnostic): None<br ALIGN="LEFT"/>log_and_raise_if_error(diagnostic: _Diagnostic): None<br ALIGN="LEFT"/>pop_inflight_diagnostic(): _Diagnostic<br ALIGN="LEFT"/>push_inflight_diagnostic(diagnostic: _Diagnostic): None<br ALIGN="LEFT"/>sarif(): sarif.Run<br ALIGN="LEFT"/>sarif_log(): sarif.SarifLog<br ALIGN="LEFT"/>to_json(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.DiagnosticOptions" [color="black", fontcolor="black", label=<{DiagnosticOptions|verbosity_level : int<br ALIGN="LEFT"/>warnings_as_errors : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.DictKeys" [color="black", fontcolor="black", label=<{DictKeys|kv : str<br ALIGN="LEFT"/>set_items<br ALIGN="LEFT"/>view_items_vt<br ALIGN="LEFT"/>|call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DictOutputModule" [color="black", fontcolor="black", label=<{DictOutputModule|module<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.DictValues" [color="black", fontcolor="black", label=<{DictValues|kv : str<br ALIGN="LEFT"/>view_items_vt<br ALIGN="LEFT"/>|python_type()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.DictView" [color="black", fontcolor="black", label=<{DictView|dv_dict<br ALIGN="LEFT"/>kv : Optional[str]<br ALIGN="LEFT"/>view_items<br ALIGN="LEFT"/>view_items_vt<br ALIGN="LEFT"/>|call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dictionary.Dictionary" [color="black", fontcolor="black", label=<{Dictionary|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.DimConstraints" [color="black", fontcolor="black", label=<{DimConstraints|<br ALIGN="LEFT"/>|add(expr: SympyBoolean): bool<br ALIGN="LEFT"/>add_equality(source: Source, expr: sympy.Expr): None<br ALIGN="LEFT"/>forced_specializations(): Dict[str, sympy.Expr]<br ALIGN="LEFT"/>prettify_results(original_signature: inspect.Signature, dynamic_shapes: Union[Dict[str, Any], Tuple[Any], List[Any]], constraint_violation_error: object, forced_specializations: Dict[str, str]): str<br ALIGN="LEFT"/>rewrite_with_congruences(s: sympy.Symbol, expr: _SympyT): _SympyT<br ALIGN="LEFT"/>solve(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.DimDynamic" [color="black", fontcolor="black", label=<{DimDynamic|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.DimOrder" [color="black", fontcolor="black", label=<{DimOrder|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.DimSpec" [color="black", fontcolor="black", label=<{DimSpec|<br ALIGN="LEFT"/>|inputs(): Iterable['DimSpec']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.DimensionInfo" [color="black", fontcolor="black", label=<{DimensionInfo|expr : Optional[sympy.Expr]<br ALIGN="LEFT"/>size : Expr<br ALIGN="LEFT"/>stride : Expr<br ALIGN="LEFT"/>|index_str(replacements, zero_vars)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.file_structure_representation.Directory" [color="black", fontcolor="black", label=<{Directory|children : Dict[str, Directory]<br ALIGN="LEFT"/>is_dir : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|has_file(filename: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._directory_reader.DirectoryReader" [color="black", fontcolor="black", label=<{DirectoryReader|directory<br ALIGN="LEFT"/>|get_all_records()<br ALIGN="LEFT"/>get_record(name)<br ALIGN="LEFT"/>get_storage_from_record(name, numel, dtype)<br ALIGN="LEFT"/>has_record(path)<br ALIGN="LEFT"/>serialization_id()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.dirichlet.Dirichlet" [color="black", fontcolor="black", label=<{Dirichlet|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.CompilerBisector.do_bisect.DisableBisect" [color="black", fontcolor="black", label=<{DisableBisect|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.DisableContext" [color="black", fontcolor="black", label=<{DisableContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd_kernel_features.DisableReduction" [color="black", fontcolor="black", label=<{DisableReduction|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.DisabledSavedTensorsHooksVariable" [color="black", fontcolor="black", label=<{DisabledSavedTensorsHooksVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_value)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.Disj" [color="black", fontcolor="black", label=<{Disj|disjuncts<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.DispatchCacheInfo" [color="black", fontcolor="black", label=<{DispatchCacheInfo|bypasses : Dict[str, int]<br ALIGN="LEFT"/>hits : int<br ALIGN="LEFT"/>misses : int<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._errors.DispatchError" [color="black", fontcolor="red", label=<{DispatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.match.Dispatcher" [color="black", fontcolor="black", label=<{Dispatcher|funcs : dict<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>ordering : list<br ALIGN="LEFT"/>|add(signature, func)<br ALIGN="LEFT"/>register()<br ALIGN="LEFT"/>resolve(args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.dispatcher.Dispatcher" [color="black", fontcolor="black", label=<{Dispatcher|doc : NoneType<br ALIGN="LEFT"/>funcs : dict<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>ordering<br ALIGN="LEFT"/>|add(signature, func)<br ALIGN="LEFT"/>dispatch()<br ALIGN="LEFT"/>dispatch_iter()<br ALIGN="LEFT"/>get_func_annotations(func)<br ALIGN="LEFT"/>get_func_params(func)<br ALIGN="LEFT"/>help()<br ALIGN="LEFT"/>register()<br ALIGN="LEFT"/>reorder(on_ambiguity)<br ALIGN="LEFT"/>resolve(types)<br ALIGN="LEFT"/>source()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest" [color="black", fontcolor="black", label=<{DistAutogradTest|hook_called_times : int<br ALIGN="LEFT"/>|test_async_dist_autograd()<br ALIGN="LEFT"/>test_autograd_context()<br ALIGN="LEFT"/>test_backward_accumulate_grads()<br ALIGN="LEFT"/>test_backward_autograd_engine_error()<br ALIGN="LEFT"/>test_backward_complex_python_udf()<br ALIGN="LEFT"/>test_backward_different_dtypes()<br ALIGN="LEFT"/>test_backward_different_tensor_dims()<br ALIGN="LEFT"/>test_backward_invalid_args()<br ALIGN="LEFT"/>test_backward_multiple_output_tensors()<br ALIGN="LEFT"/>test_backward_multiple_roots()<br ALIGN="LEFT"/>test_backward_multiple_round_trips()<br ALIGN="LEFT"/>test_backward_no_grad_on_tensor()<br ALIGN="LEFT"/>test_backward_node_failure()<br ALIGN="LEFT"/>test_backward_node_failure_python_udf()<br ALIGN="LEFT"/>test_backward_python_udf_error()<br ALIGN="LEFT"/>test_backward_rref()<br ALIGN="LEFT"/>test_backward_rref_multi()<br ALIGN="LEFT"/>test_backward_rref_nested()<br ALIGN="LEFT"/>test_backward_simple()<br ALIGN="LEFT"/>test_backward_simple_python_udf()<br ALIGN="LEFT"/>test_backward_simple_script_call()<br ALIGN="LEFT"/>test_backward_simple_self()<br ALIGN="LEFT"/>test_backward_unused_send_function()<br ALIGN="LEFT"/>test_backward_unused_tensors()<br ALIGN="LEFT"/>test_backward_verify_hooks()<br ALIGN="LEFT"/>test_backward_without_context()<br ALIGN="LEFT"/>test_backward_without_rpc()<br ALIGN="LEFT"/>test_backwards_nested_python_udf()<br ALIGN="LEFT"/>test_clean_context_during_backward()<br ALIGN="LEFT"/>test_context_cleanup_nested_rpc()<br ALIGN="LEFT"/>test_context_cleanup_no_tensors()<br ALIGN="LEFT"/>test_context_cleanup_tensor_no_grad()<br ALIGN="LEFT"/>test_context_cleanup_tensor_with_grad()<br ALIGN="LEFT"/>test_debug_info()<br ALIGN="LEFT"/>test_dist_autograd_profiling()<br ALIGN="LEFT"/>test_error_in_context()<br ALIGN="LEFT"/>test_grad_copy_sparse_indices_extra_ref()<br ALIGN="LEFT"/>test_grad_only_on_return_value()<br ALIGN="LEFT"/>test_grad_only_on_return_value_remote()<br ALIGN="LEFT"/>test_graph_for_builtin_call()<br ALIGN="LEFT"/>test_graph_for_builtin_remote_call()<br ALIGN="LEFT"/>test_graph_for_py_nested_call()<br ALIGN="LEFT"/>test_graph_for_py_nested_call_itself()<br ALIGN="LEFT"/>test_graph_for_py_nested_remote_call()<br ALIGN="LEFT"/>test_graph_for_py_nested_remote_call_itself()<br ALIGN="LEFT"/>test_graph_for_python_call()<br ALIGN="LEFT"/>test_graph_for_python_remote_call()<br ALIGN="LEFT"/>test_mixed_requires_grad()<br ALIGN="LEFT"/>test_multiple_backward()<br ALIGN="LEFT"/>test_multiple_backward_with_errors()<br ALIGN="LEFT"/>test_nested_backward_accumulate_grads()<br ALIGN="LEFT"/>test_nested_context()<br ALIGN="LEFT"/>test_no_grad_copy()<br ALIGN="LEFT"/>test_no_grad_copy_sparse()<br ALIGN="LEFT"/>test_no_graph_with_tensors_not_require_grad()<br ALIGN="LEFT"/>test_no_graph_with_tensors_not_require_grad_remote()<br ALIGN="LEFT"/>test_post_hooks()<br ALIGN="LEFT"/>test_remote_complex_args()<br ALIGN="LEFT"/>test_rpc_complex_args()<br ALIGN="LEFT"/>test_thread_local_context_id()<br ALIGN="LEFT"/>test_trainer_ps()<br ALIGN="LEFT"/>test_trainer_ps_torchscript_functions()<br ALIGN="LEFT"/>test_worker_ids_recorded()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest" [color="black", fontcolor="black", label=<{DistOptimizerTest|<br ALIGN="LEFT"/>|test_dist_optim()<br ALIGN="LEFT"/>test_dist_optim_exception()<br ALIGN="LEFT"/>test_dist_optim_exception_on_constructor()<br ALIGN="LEFT"/>test_dist_optim_none_grads()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.DistTestCases" [color="black", fontcolor="black", label=<{DistTestCases|backend_feature : dict<br ALIGN="LEFT"/>skip_collective : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parallel.distributed.DistributedDataParallel" [color="black", fontcolor="black", label=<{DistributedDataParallel|broadcast_bucket_size : int<br ALIGN="LEFT"/>broadcast_buffers : bool<br ALIGN="LEFT"/>bucket_bytes_cap : int<br ALIGN="LEFT"/>bucket_bytes_cap_default : bool<br ALIGN="LEFT"/>buffer_hook<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>device_ids : NoneType<br ALIGN="LEFT"/>device_mesh<br ALIGN="LEFT"/>device_type<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>find_unused_parameters : bool<br ALIGN="LEFT"/>gradient_as_bucket_view : bool<br ALIGN="LEFT"/>is_multi_device_module<br ALIGN="LEFT"/>join_device<br ALIGN="LEFT"/>join_process_group<br ALIGN="LEFT"/>logger : Optional[dist.Logger]<br ALIGN="LEFT"/>mixed_precision : Optional[_MixedPrecision]<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>modules_buffers<br ALIGN="LEFT"/>named_module_buffers<br ALIGN="LEFT"/>output_device : NoneType, int<br ALIGN="LEFT"/>parameters_to_ignore : set<br ALIGN="LEFT"/>process_group : NoneType<br ALIGN="LEFT"/>reducer<br ALIGN="LEFT"/>require_backward_grad_sync : bool<br ALIGN="LEFT"/>require_forward_param_sync : bool<br ALIGN="LEFT"/>static_graph : bool<br ALIGN="LEFT"/>use_side_stream_for_tensor_copies<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>gather(outputs, output_device)<br ALIGN="LEFT"/>join(divide_by_initial_world_size: bool, enable: bool, throw_on_early_termination: bool)<br ALIGN="LEFT"/>join_hook()<br ALIGN="LEFT"/>no_sync()<br ALIGN="LEFT"/>register_comm_hook(state: object, hook: Callable)<br ALIGN="LEFT"/>scatter(inputs, kwargs, device_ids)<br ALIGN="LEFT"/>to_kwargs(inputs, kwargs, device_id)<br ALIGN="LEFT"/>train(mode)<br ALIGN="LEFT"/>will_sync_module_buffers()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel.DistributedDataParallelCPU" [color="black", fontcolor="black", label=<{DistributedDataParallelCPU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.optim.optimizer.DistributedOptimizer" [color="black", fontcolor="black", label=<{DistributedOptimizer|is_functional_optim<br ALIGN="LEFT"/>remote_optimizers : list<br ALIGN="LEFT"/>|step(context_id)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.distributed.DistributedSampler" [color="black", fontcolor="black", label=<{DistributedSampler|dataset<br ALIGN="LEFT"/>drop_last : bool<br ALIGN="LEFT"/>epoch : int<br ALIGN="LEFT"/>num_replicas : Optional[int]<br ALIGN="LEFT"/>num_samples<br ALIGN="LEFT"/>rank : Optional[int]<br ALIGN="LEFT"/>seed : int<br ALIGN="LEFT"/>shuffle : bool<br ALIGN="LEFT"/>total_size<br ALIGN="LEFT"/>|set_epoch(epoch: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.DistributedState" [color="black", fontcolor="black", label=<{DistributedState|all_states : Optional[List[LocalState]]<br ALIGN="LEFT"/>compile_pg : Any<br ALIGN="LEFT"/>local_state<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest" [color="black", fontcolor="black", label=<{DistributedTest|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.DistributedTestBase" [color="black", fontcolor="black", label=<{DistributedTestBase|<br ALIGN="LEFT"/>|backend(device): str<br ALIGN="LEFT"/>create_pg(device)<br ALIGN="LEFT"/>rank_to_device(device)<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.DistributedVariable" [color="black", fontcolor="black", label=<{DistributedVariable|value<br ALIGN="LEFT"/>|is_available()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.distribution.Distribution" [color="black", fontcolor="black", label=<{Distribution|arg_constraints<br ALIGN="LEFT"/>batch_shape<br ALIGN="LEFT"/>event_shape<br ALIGN="LEFT"/>has_enumerate_support : bool<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|<I>cdf</I>(value: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/><I>entropy</I>(): torch.Tensor<br ALIGN="LEFT"/><I>enumerate_support</I>(expand: bool): torch.Tensor<br ALIGN="LEFT"/><I>expand</I>(batch_shape: _size, _instance)<br ALIGN="LEFT"/><I>icdf</I>(value: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/><I>log_prob</I>(value: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>perplexity(): torch.Tensor<br ALIGN="LEFT"/><I>rsample</I>(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample_n(n: int): torch.Tensor<br ALIGN="LEFT"/>set_default_validate_args(value: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.DivElementwiseTypePromotionRule" [color="black", fontcolor="black", label=<{DivElementwiseTypePromotionRule|promotion_kind : DEFAULT, INT_TO_FLOAT<br ALIGN="LEFT"/>|preview_type_promotion(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.DivideByKey" [color="black", fontcolor="black", label=<{DivideByKey|divisor : int<br ALIGN="LEFT"/>|get(o: int): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.DonatedBuffer" [color="black", fontcolor="black", label=<{DonatedBuffer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.DoubleLinear" [color="black", fontcolor="black", label=<{DoubleLinear|lin1<br ALIGN="LEFT"/>lin2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>use_second_linear : bool<br ALIGN="LEFT"/>|forward(x: torch.Tensor): Union[Tuple[torch.Tensor, torch.Tensor], torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.DoubleStorage" [color="black", fontcolor="black", label=<{DoubleStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.DoubleStorage" [color="black", fontcolor="black", label=<{DoubleStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._draft_export.DraftExportReport" [color="black", fontcolor="black", label=<{DraftExportReport|failures : List[FailureReport]<br ALIGN="LEFT"/>str_to_filename : Dict[str, str]<br ALIGN="LEFT"/>|<I>apply_suggested_fixes</I>(): None<br ALIGN="LEFT"/>successful(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.dropout.Dropout" [color="black", fontcolor="black", label=<{Dropout|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.Dropout" [color="black", fontcolor="black", label=<{Dropout|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.Dropout1d" [color="black", fontcolor="black", label=<{Dropout1d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.Dropout2d" [color="black", fontcolor="black", label=<{Dropout2d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.Dropout3d" [color="black", fontcolor="black", label=<{Dropout3d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.optimization.remove_dropout.DropoutRemover" [color="black", fontcolor="black", label=<{DropoutRemover|<br ALIGN="LEFT"/>|call_module(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dtype_propagation.DtypePropagationOpsHandler" [color="black", fontcolor="black", label=<{DtypePropagationOpsHandler|<br ALIGN="LEFT"/>|bucketize(values: DTypeArg, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: DTypeArg, indexing_dtype: torch.dtype, right: bool): torch.dtype<br ALIGN="LEFT"/>ceil_to_int(x: DTypeArg, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>constant(value: torch.types.Number, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>div(a: DTypeArg, b: DTypeArg): torch.dtype<br ALIGN="LEFT"/>floor(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>floor_to_int(x: DTypeArg, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>floordiv(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>fmod(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>frexp(x: DTypeArg): Tuple[torch.dtype, torch.dtype]<br ALIGN="LEFT"/>gelu(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>getitem(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>halide_clamp(value, size, check)<br ALIGN="LEFT"/>identity(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>index_expr(expr: sympy.Expr, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>indirect_indexing(x: DTypeArg, size: int, check: bool, wrap_neg: bool): torch.dtype<br ALIGN="LEFT"/>inline_asm_elementwise()<br ALIGN="LEFT"/>int_truediv(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>invert(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>libdevice_abs(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>load(name: str, index): torch.dtype<br ALIGN="LEFT"/>load_seed(name: str, offset: int): torch.dtype<br ALIGN="LEFT"/>lshift(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>masked(mask: DTypeArg, body: 'LoopBodyBlock', other: DTypeArg): torch.dtype<br ALIGN="LEFT"/>matmul(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>mod(a: DTypeArg, b: DTypeArg): torch.dtype<br ALIGN="LEFT"/>mul(a: DTypeArg, b: DTypeArg): torch.dtype<br ALIGN="LEFT"/>op_dtype_rule(): torch.dtype<br ALIGN="LEFT"/>pow(a: DTypeArg, b: DTypeArg): torch.dtype<br ALIGN="LEFT"/>rand(seed: int, offset: int): torch.dtype<br ALIGN="LEFT"/>randint64(seed: int, offset: int, low: int, high: int): torch.dtype<br ALIGN="LEFT"/>randn(seed: int, offset: int): torch.dtype<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: str, value: DTypeArg): torch.dtype<br ALIGN="LEFT"/>return_dtype(): torch.dtype<br ALIGN="LEFT"/>round(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>round_decimal(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>round_to_int(x: DTypeArg, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>rshift(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>scan(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[T, ...], Tuple[T, ...]], Tuple[T, ...]], values: Tuple[T, ...]): Tuple[torch.dtype, ...]<br ALIGN="LEFT"/>sort(dtypes: Tuple[torch.dtype, ...], values: Tuple[T, ...], stable: bool, descending: bool): Tuple[torch.dtype, ...]<br ALIGN="LEFT"/>store(name: str, index, value: DTypeArg, mode: Optional[str]): None<br ALIGN="LEFT"/>store_reduction(name: str, index, value: DTypeArg): None<br ALIGN="LEFT"/>to_dtype(x: DTypeArg, dtype: torch.dtype, src_dtype: Optional[torch.dtype], use_compute_types): torch.dtype<br ALIGN="LEFT"/>to_dtype_bitcast(x: DTypeArg, dtype: torch.dtype, src_dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>truediv(a: DTypeArg, b: DTypeArg): torch.dtype<br ALIGN="LEFT"/>trunc(x: DTypeArg): torch.dtype<br ALIGN="LEFT"/>trunc_to_int(x: DTypeArg, dtype: torch.dtype): torch.dtype<br ALIGN="LEFT"/>truncdiv(x: DTypeArg, y: DTypeArg): torch.dtype<br ALIGN="LEFT"/>where(a: DTypeArg, b: DTypeArg, c: DTypeArg): torch.dtype<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.DtypeView" [color="black", fontcolor="black", label=<{DtypeView|dtype<br ALIGN="LEFT"/>target_dtype<br ALIGN="LEFT"/>|create(x, new_dtype)<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.DualLevelContextManager" [color="black", fontcolor="black", label=<{DualLevelContextManager|new_level<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.DummyDDP" [color="black", fontcolor="black", label=<{DummyDDP|module<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.DummyEnv" [color="black", fontcolor="black", label=<{DummyEnv|iter : int<br ALIGN="LEFT"/>num_iters : int<br ALIGN="LEFT"/>reward_threshold : float<br ALIGN="LEFT"/>state_dim : int<br ALIGN="LEFT"/>|reset()<br ALIGN="LEFT"/>seed(manual_seed)<br ALIGN="LEFT"/>step(action)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.replay_record.DummyModule" [color="black", fontcolor="black", label=<{DummyModule|is_torch : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR._direct_serialization_deserialize.DummyModule" [color="black", fontcolor="black", label=<{DummyModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.get_code.patched_compile_to_module.DummyModule" [color="black", fontcolor="black", label=<{DummyModule|<br ALIGN="LEFT"/>|<I>call</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.DummyObserver" [color="black", fontcolor="black", label=<{DummyObserver|<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.DummyProcessGroup" [color="black", fontcolor="black", label=<{DummyProcessGroup|<br ALIGN="LEFT"/>|allreduce()<br ALIGN="LEFT"/>rank(): int<br ALIGN="LEFT"/>size(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_forward_backward_hook.DummyTestModel" [color="black", fontcolor="black", label=<{DummyTestModel|fc<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.show_pickle.DumpUnpickler" [color="black", fontcolor="black", label=<{DumpUnpickler|catch_invalid_utf8 : bool<br ALIGN="LEFT"/>dispatch : dict<br ALIGN="LEFT"/>|dump(in_stream, out_stream)<br ALIGN="LEFT"/>find_class(module, name)<br ALIGN="LEFT"/>load_binunicode()<br ALIGN="LEFT"/>persistent_load(pid)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e.duplicate_dq_pass.DuplicateDQPass" [color="black", fontcolor="black", label=<{DuplicateDQPass|<br ALIGN="LEFT"/>|call(graph_module: torch.fx.GraphModule): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.DuplicateInputs" [color="black", fontcolor="black", label=<{DuplicateInputs|input_source_a<br ALIGN="LEFT"/>input_source_b<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.DuplicateWarningChecker" [color="black", fontcolor="black", label=<{DuplicateWarningChecker|maxsize : int<br ALIGN="LEFT"/>set : OrderedDict<br ALIGN="LEFT"/>|add(key: Union[str, Tuple[object, object]]): bool<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.DynamicDimConstraintPrinter" [color="black", fontcolor="black", label=<{DynamicDimConstraintPrinter|source_name_to_debug_name : Mapping[str, str]<br ALIGN="LEFT"/>symbol_to_source : Dict[sympy.Symbol, List[Source]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner" [color="black", fontcolor="black", label=<{DynamicMetaLoadPlanner|metadata<br ALIGN="LEFT"/>|set_up_planner(state_dict: STATE_DICT_TYPE, metadata: Optional[Metadata], is_coordinator: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.DynamicOutputShapeException" [color="black", fontcolor="red", label=<{DynamicOutputShapeException|func<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [color="black", fontcolor="black", label=<{DynamicRendezvousHandler|settings<br ALIGN="LEFT"/>use_agent_store<br ALIGN="LEFT"/>|from_backend(run_id: str, store: Store, backend: RendezvousBackend, min_nodes: int, max_nodes: int, local_addr: Optional[str], timeout: Optional[RendezvousTimeout])<br ALIGN="LEFT"/>get_backend(): str<br ALIGN="LEFT"/>get_run_id(): str<br ALIGN="LEFT"/>is_closed(): bool<br ALIGN="LEFT"/>next_rendezvous(): RendezvousInfo<br ALIGN="LEFT"/>num_nodes_waiting(): int<br ALIGN="LEFT"/>set_closed(): None<br ALIGN="LEFT"/>shutdown(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.DynamicScalar" [color="black", fontcolor="black", label=<{DynamicScalar|keypath<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>sym<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_assert.DynamicShapeAssert" [color="black", fontcolor="black", label=<{DynamicShapeAssert|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_constructor.DynamicShapeConstructor" [color="black", fontcolor="black", label=<{DynamicShapeConstructor|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_if_guard.DynamicShapeIfGuard" [color="black", fontcolor="black", label=<{DynamicShapeIfGuard|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_map.DynamicShapeMap" [color="black", fontcolor="black", label=<{DynamicShapeMap|<br ALIGN="LEFT"/>|forward(xs, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_round.DynamicShapeRound" [color="black", fontcolor="black", label=<{DynamicShapeRound|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_slicing.DynamicShapeSlicing" [color="black", fontcolor="black", label=<{DynamicShapeSlicing|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.dynamic_shape_view.DynamicShapeView" [color="black", fontcolor="black", label=<{DynamicShapeView|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.dynamic_shapes.DynamicShapesSpec" [color="black", fontcolor="black", label=<{DynamicShapesSpec|dims : Dict[str, RootDim]<br ALIGN="LEFT"/>dynamic_shapes : Union[Dict[str, Any], Tuple[Any], List[Any], None]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.DynamicStaticDetector" [color="black", fontcolor="black", label=<{DynamicStaticDetector|DEFAULT_DYNAMIC_REC_KEY : str<br ALIGN="LEFT"/>DEFAULT_DYNAMIC_STATIC_CHECK_SUPPORTED : set<br ALIGN="LEFT"/>DEFAULT_DYNAMIC_STATIC_FUTURE_SUPPORTED : set<br ALIGN="LEFT"/>DEFAULT_POST_OBSERVER_NAME : str<br ALIGN="LEFT"/>DEFAULT_PRE_OBSERVER_NAME : str<br ALIGN="LEFT"/>INPUT_ACTIVATION_PREFIX : str<br ALIGN="LEFT"/>IS_CURRENTLY_SUPPORTED_KEY : str<br ALIGN="LEFT"/>NON_STATIONARY_STR : str<br ALIGN="LEFT"/>OUTPUT_ACTIVATION_PREFIX : str<br ALIGN="LEFT"/>POST_OBS_COMP_STAT_KEY : str<br ALIGN="LEFT"/>POST_OBS_DATA_DIST_KEY : str<br ALIGN="LEFT"/>PRE_OBS_COMP_STAT_KEY : str<br ALIGN="LEFT"/>PRE_OBS_DATA_DIST_KEY : str<br ALIGN="LEFT"/>STATIONARY_STR : str<br ALIGN="LEFT"/>TOLERANCE_KEY : str<br ALIGN="LEFT"/>tolerance : float<br ALIGN="LEFT"/>useful_observer_fqns : Set[str]<br ALIGN="LEFT"/>|determine_observer_insert_points(prepared_fx_model: GraphModule): Dict[str, Dict[str, Any]]<br ALIGN="LEFT"/>generate_detector_report(model: GraphModule): Tuple[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_detector_name(): str<br ALIGN="LEFT"/>get_qconfig_info(model): Dict[str, DetectorQConfigInfo]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.types.DynamoCallbackFn" [color="black", fontcolor="black", label=<{DynamoCallbackFn|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.DynamoDistributedMultiProcTestCase" [color="black", fontcolor="black", label=<{DynamoDistributedMultiProcTestCase|file_name : str<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.DynamoDistributedSingleProcTestCase" [color="black", fontcolor="black", label=<{DynamoDistributedSingleProcTestCase|<br ALIGN="LEFT"/>|setUpClass()<br ALIGN="LEFT"/>tearDownClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.dynamo_graph_extractor.DynamoExport" [color="black", fontcolor="black", label=<{DynamoExport|aten_graph : bool<br ALIGN="LEFT"/>|generate_fx(options: _exporter_legacy.ResolvedExportOptions, model: torch.nn.Module \| Callable, model_args: Sequence[Any], model_kwargs: Mapping[str, Any]): torch.fx.GraphModule<br ALIGN="LEFT"/>pre_export_passes(options: _exporter_legacy.ResolvedExportOptions, original_model: torch.nn.Module \| Callable, fx_module: torch.fx.GraphModule, fx_module_args: Sequence[Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.dynamo_graph_extractor.DynamoFlattenOutputStep" [color="black", fontcolor="black", label=<{DynamoFlattenOutputStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Sequence[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.types.DynamoGuardHook" [color="black", fontcolor="black", label=<{DynamoGuardHook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.DynamoStance" [color="black", fontcolor="black", label=<{DynamoStance|backend : Optional[Union[str, Callable[..., Any], None]]<br ALIGN="LEFT"/>skip_guard_eval_unsafe : bool<br ALIGN="LEFT"/>stance : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.DynamoTLS" [color="black", fontcolor="black", label=<{DynamoTLS|traced_frame_infos : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.DynamoTritonHOPifier" [color="black", fontcolor="black", label=<{DynamoTritonHOPifier|<br ALIGN="LEFT"/>|call_HOP(variable, grids, combined_args_raw, tx): ConstantVariable<br ALIGN="LEFT"/>call_grid(grid, meta, tx)<br ALIGN="LEFT"/>check_grid(grid): Tuple[torch.fx.proxy.Proxy, ...]<br ALIGN="LEFT"/>get_value(val: Any): Any<br ALIGN="LEFT"/>is_callable(maybe_callable: Any): bool<br ALIGN="LEFT"/>raise_unsupported(msg: str): Never<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims.ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND" [color="black", fontcolor="black", label=<{ELEMENTWISE_PRIM_TYPE_PROMOTION_KIND|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims_common.ELEMENTWISE_TYPE_PROMOTION_KIND" [color="black", fontcolor="black", label=<{ELEMENTWISE_TYPE_PROMOTION_KIND|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.ELU" [color="black", fontcolor="black", label=<{ELU|scale<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.ELU" [color="black", fontcolor="black", label=<{ELU|alpha : float<br ALIGN="LEFT"/>inplace : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.testing.EagerAndRecordGraphs" [color="black", fontcolor="black", label=<{EagerAndRecordGraphs|graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._edge.Edge" [color="black", fontcolor="black", label=<{Edge|id : str<br ALIGN="LEFT"/>label : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>source_node_id : str<br ALIGN="LEFT"/>target_node_id : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._edge_traversal.EdgeTraversal" [color="black", fontcolor="black", label=<{EdgeTraversal|edge_id : str<br ALIGN="LEFT"/>final_state : Optional[Any]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>step_over_edge_count : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize._canonicalize_graph.sort_nodes.Edges" [color="black", fontcolor="black", label=<{Edges|ins : int<br ALIGN="LEFT"/>outs : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.EffectTokensWrapper" [color="black", fontcolor="black", label=<{EffectTokensWrapper|<br ALIGN="LEFT"/>|post_compile(compiled_fn, _aot_config)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.EffectfulKernel" [color="black", fontcolor="black", label=<{EffectfulKernel|effect_type : NoneType, ORDERED<br ALIGN="LEFT"/>prev_effect_buffer<br ALIGN="LEFT"/>|get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._einsum_strategy.EinsumDims" [color="black", fontcolor="black", label=<{EinsumDims|batch_dims : List[str]<br ALIGN="LEFT"/>contracting_dims : List[str]<br ALIGN="LEFT"/>lhs_out_only_dims : List[str]<br ALIGN="LEFT"/>rhs_out_only_dims : List[str]<br ALIGN="LEFT"/>|parse_dims(input_dims: List[str], output_dim: str): 'EinsumDims'<br ALIGN="LEFT"/>parse_equation(equation: str): Tuple[List[str], str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.ElasticAgent" [color="black", fontcolor="black", label=<{ElasticAgent|<br ALIGN="LEFT"/>|<I>get_worker_group</I>(role: str): WorkerGroup<br ALIGN="LEFT"/><I>run</I>(role: str): RunResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.utils.data.elastic_distributed_sampler.ElasticDistributedSampler" [color="black", fontcolor="black", label=<{ElasticDistributedSampler|num_samples : int<br ALIGN="LEFT"/>start_index : int<br ALIGN="LEFT"/>total_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.refs.ElementwiseBinaryPythonRefInfo" [color="black", fontcolor="black", label=<{ElementwiseBinaryPythonRefInfo|torch_opinfo<br ALIGN="LEFT"/>torch_opinfo_name<br ALIGN="LEFT"/>torch_opinfo_variant_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.ElementwiseTypePromotionRule" [color="black", fontcolor="black", label=<{ElementwiseTypePromotionRule|promote_args_positions : Sequence[int]<br ALIGN="LEFT"/>promote_kwargs_names : Sequence[str]<br ALIGN="LEFT"/>promotion_kind : ELEMENTWISE_TYPE_PROMOTION_KIND<br ALIGN="LEFT"/>|preview_type_promotion(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.ElementwiseTypePromotionRuleSetGenerator" [color="black", fontcolor="black", label=<{ElementwiseTypePromotionRuleSetGenerator|<br ALIGN="LEFT"/>|generate_from_torch_refs(): set[ElementwiseTypePromotionRule]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.refs.ElementwiseUnaryPythonRefInfo" [color="black", fontcolor="black", label=<{ElementwiseUnaryPythonRefInfo|torch_opinfo<br ALIGN="LEFT"/>torch_opinfo_name<br ALIGN="LEFT"/>torch_opinfo_variant_name : str<br ALIGN="LEFT"/>validate_view_consistency : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.EmbBagWrapper" [color="black", fontcolor="black", label=<{EmbBagWrapper|emb_bag<br ALIGN="LEFT"/>|forward(indices, offsets)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.sparse.Embedding" [color="black", fontcolor="black", label=<{Embedding|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>from_float(mod, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.embedding_ops.Embedding" [color="black", fontcolor="black", label=<{Embedding|dtype<br ALIGN="LEFT"/>embedding_dim : int<br ALIGN="LEFT"/>num_embeddings : int<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(indices: Tensor): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_embedding)<br ALIGN="LEFT"/>set_weight(w: torch.Tensor): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.embedding_ops.Embedding" [color="black", fontcolor="black", label=<{Embedding|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.sparse.Embedding" [color="black", fontcolor="black", label=<{Embedding|embedding_dim : int<br ALIGN="LEFT"/>freeze : bool<br ALIGN="LEFT"/>max_norm : Optional[float]<br ALIGN="LEFT"/>norm_type : float<br ALIGN="LEFT"/>num_embeddings : int<br ALIGN="LEFT"/>padding_idx : Optional[int]<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>scale_grad_by_freq : bool<br ALIGN="LEFT"/>sparse : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>from_pretrained(embeddings, freeze, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.sparse.EmbeddingBag" [color="black", fontcolor="black", label=<{EmbeddingBag|<br ALIGN="LEFT"/>|forward(input: Tensor, offsets: Optional[Tensor], per_sample_weights: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, weight_qparams, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag" [color="black", fontcolor="black", label=<{EmbeddingBag|dtype<br ALIGN="LEFT"/>include_last_offset : bool<br ALIGN="LEFT"/>mode : str<br ALIGN="LEFT"/>pruned_weights : bool<br ALIGN="LEFT"/>|forward(indices: Tensor, offsets: Optional[Tensor], per_sample_weights: Optional[Tensor], compressed_indices_mapping: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_embedding_bag)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.embedding_ops.EmbeddingBag" [color="black", fontcolor="black", label=<{EmbeddingBag|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input, offsets, per_sample_weights): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" [color="black", fontcolor="black", label=<{EmbeddingBag|embedding_dim : int<br ALIGN="LEFT"/>include_last_offset : bool<br ALIGN="LEFT"/>max_norm : Optional[float]<br ALIGN="LEFT"/>mode : str<br ALIGN="LEFT"/>norm_type : float<br ALIGN="LEFT"/>num_embeddings : int<br ALIGN="LEFT"/>padding_idx : Optional[int]<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>scale_grad_by_freq : bool<br ALIGN="LEFT"/>sparse : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor, offsets: Optional[Tensor], per_sample_weights: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_pretrained(embeddings: Tensor, freeze: bool, max_norm: Optional[float], norm_type: float, scale_grad_by_freq: bool, mode: str, sparse: bool, include_last_offset: bool, padding_idx: Optional[int]): 'EmbeddingBag'<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.EmbeddingBagModule" [color="black", fontcolor="black", label=<{EmbeddingBagModule|emb<br ALIGN="LEFT"/>|forward(indices, offsets, per_sample_weights)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.EmbeddingConvLinearModule" [color="black", fontcolor="black", label=<{EmbeddingConvLinearModule|conv<br ALIGN="LEFT"/>emb<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>|forward(indices)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.EmbeddingModule" [color="black", fontcolor="black", label=<{EmbeddingModule|emb<br ALIGN="LEFT"/>|forward(indices)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.EmbeddingModule" [color="black", fontcolor="black", label=<{EmbeddingModule|emb<br ALIGN="LEFT"/>|forward(indices)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" [color="black", fontcolor="black", label=<{EmbeddingNetDifferentParams|embedding<br ALIGN="LEFT"/>lin<br ALIGN="LEFT"/>lin2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams" [color="black", fontcolor="black", label=<{EmbeddingPackedParams|dtype<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>set_weight(weight: torch.Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.embedding_expanded_weights.EmbeddingPerSampleGrad" [color="black", fontcolor="black", label=<{EmbeddingPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, kwarg_names, _)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.EmbeddingQuantizeHandler" [color="black", fontcolor="black", label=<{EmbeddingQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.embedding_quantizer.EmbeddingQuantizer" [color="black", fontcolor="black", label=<{EmbeddingQuantizer|<br ALIGN="LEFT"/>|annotate(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/>get_supported_operator_for_quantization_config(quantization_config: QuantizationConfig): List[OperatorPatternType]<br ALIGN="LEFT"/>get_supported_operators(): List[OperatorConfig]<br ALIGN="LEFT"/>get_supported_quantization_configs(): List[QuantizationConfig]<br ALIGN="LEFT"/><I>validate</I>(model: torch.fx.GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [color="black", fontcolor="black", label=<{EmbeddingWithStaticLinear|dequant<br ALIGN="LEFT"/>emb<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(indices, offsets, linear_in)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cutlass_lib_extensions.gemm_operation_extensions.EmitGemmUniversal3xInstanceWithEVT" [color="black", fontcolor="black", label=<{EmitGemmUniversal3xInstanceWithEVT|builtin_epilogue_functor_template : str<br ALIGN="LEFT"/>gemm_template : str<br ALIGN="LEFT"/>includes : list<br ALIGN="LEFT"/>operation_suffix : str<br ALIGN="LEFT"/>|emit(operation)<br ALIGN="LEFT"/>instance_template()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.Empty" [color="black", fontcolor="black", label=<{Empty|size_hint : int<br ALIGN="LEFT"/>|get_live_ranges()<br ALIGN="LEFT"/>get_size_hint()<br ALIGN="LEFT"/>get_symbolic_size()<br ALIGN="LEFT"/>is_empty()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.package_exporter.EmptyMatchError" [color="black", fontcolor="red", label=<{EmptyMatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd_kernel_features.EnableReduction" [color="black", fontcolor="black", label=<{EnableReduction|<br ALIGN="LEFT"/>|filter(node_schedule: List[NodeScheduleEntry]): Iterable[SchedulerNode]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._state.EnabledProxy" [color="black", fontcolor="black", label=<{EnabledProxy|enabled : bool<br ALIGN="LEFT"/>|parse_env(name, default, true_message, false_message)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler.EnforceUnique" [color="black", fontcolor="black", label=<{EnforceUnique|seen : set<br ALIGN="LEFT"/>|see()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.EnterDeviceContextManagerLine" [color="black", fontcolor="black", label=<{EnterDeviceContextManagerLine|device_idx : int<br ALIGN="LEFT"/>last_seen_device_guard_index : Optional[int]<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.EnterSubgraphLine" [color="black", fontcolor="black", label=<{EnterSubgraphLine|graph<br ALIGN="LEFT"/>wrapper<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._pytree.EnumEncoder" [color="black", fontcolor="black", label=<{EnumEncoder|<br ALIGN="LEFT"/>|default(obj: object): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.serialize.EnumEncoder" [color="black", fontcolor="black", label=<{EnumEncoder|<br ALIGN="LEFT"/>|default(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.constant.EnumVariable" [color="black", fontcolor="black", label=<{EnumVariable|value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>create(cls_type, value_vt, options)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_spec.api.EnumerableShardingSpec" [color="black", fontcolor="black", label=<{EnumerableShardingSpec|shards : List[ShardMetadata]<br ALIGN="LEFT"/>|build_metadata(tensor_sizes: torch.Size, tensor_properties: sharded_tensor_meta.TensorProperties): sharded_tensor_meta.ShardedTensorMetadata<br ALIGN="LEFT"/><I>shard</I>(tensor: torch.Tensor, src_rank: int, process_group): 'ShardedTensor'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.EphemeralSource" [color="black", fontcolor="black", label=<{EphemeralSource|desc : Optional[str]<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>is_ephemeral()<br ALIGN="LEFT"/><I>make_guard</I>(fn)<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.refinement_types.Equality" [color="black", fontcolor="black", label=<{Equality|lhs<br ALIGN="LEFT"/>rhs<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.EqualityConstraint" [color="black", fontcolor="black", label=<{EqualityConstraint|derived_equalities : List[Tuple[Source, Union[Source, sympy.Symbol], Callable[[sympy.Expr], sympy.Expr]]]<br ALIGN="LEFT"/>phantom_symbols : List[sympy.Symbol]<br ALIGN="LEFT"/>relaxed_sources : Set[Source]<br ALIGN="LEFT"/>source_pairs : List[Tuple[Source, Source]]<br ALIGN="LEFT"/>|is_derived(src: Source, symbol_src: Source, fn: Callable[[sympy.Expr], sympy.Expr]): bool<br ALIGN="LEFT"/>is_equal(source1: Source, source2: Source): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._equalize.EqualizationQConfig" [color="black", fontcolor="black", label=<{EqualizationQConfig|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.freezing.ErasedTensor" [color="black", fontcolor="black", label=<{ErasedTensor|erased_name : Optional[str]<br ALIGN="LEFT"/>owning_mod_ref<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.ErrorFromChoice" [color="black", fontcolor="red", label=<{ErrorFromChoice|choice<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.errors.error_handler.ErrorHandler" [color="black", fontcolor="black", label=<{ErrorHandler|<br ALIGN="LEFT"/>|dump_error_file(rootcause_error_file: str, error_code: int)<br ALIGN="LEFT"/>initialize(): None<br ALIGN="LEFT"/>override_error_code_in_rootcause_data(rootcause_error_file: str, rootcause_error: Dict[str, Any], error_code: int)<br ALIGN="LEFT"/>record_exception(e: BaseException): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.ErrorInput" [color="black", fontcolor="black", label=<{ErrorInput|error_regex<br ALIGN="LEFT"/>error_type : RuntimeError<br ALIGN="LEFT"/>sample_input<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._comparison.ErrorMeta" [color="black", fontcolor="red", label=<{ErrorMeta|id : tuple<br ALIGN="LEFT"/>msg : str<br ALIGN="LEFT"/>type : Type[Exception]<br ALIGN="LEFT"/>|to_error(msg: Optional[Union[str, Callable[[str], str]]]): Exception<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.ErrorModuleInput" [color="black", fontcolor="black", label=<{ErrorModuleInput|error_on : CONSTRUCTION_ERROR<br ALIGN="LEFT"/>error_regex<br ALIGN="LEFT"/>error_type : RuntimeError<br ALIGN="LEFT"/>module_error_input<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.ErrorOptimizerInput" [color="black", fontcolor="black", label=<{ErrorOptimizerInput|error_on : CONSTRUCTION_ERROR<br ALIGN="LEFT"/>error_regex : str<br ALIGN="LEFT"/>error_type : RuntimeError<br ALIGN="LEFT"/>optimizer_error_input<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvous" [color="black", fontcolor="black", label=<{EtcdRendezvous|client<br ALIGN="LEFT"/>|announce_self_waiting(expected_version)<br ALIGN="LEFT"/>confirm_membership(expected_version, this_rank)<br ALIGN="LEFT"/>confirm_phase(expected_version, this_rank)<br ALIGN="LEFT"/>create_path_if_not_exists(full_path, ttl)<br ALIGN="LEFT"/>get_path(path)<br ALIGN="LEFT"/>get_rdzv_state()<br ALIGN="LEFT"/>handle_existing_rendezvous(expected_version)<br ALIGN="LEFT"/>handle_join_last_call(expected_version, deadline)<br ALIGN="LEFT"/>init_phase()<br ALIGN="LEFT"/>join_phase(expected_version)<br ALIGN="LEFT"/>join_rendezvous(expected_version)<br ALIGN="LEFT"/>load_extra_data(rdzv_version, key, timeout)<br ALIGN="LEFT"/>rendezvous_barrier()<br ALIGN="LEFT"/>set_closed()<br ALIGN="LEFT"/>setup_kv_store(rdzv_version)<br ALIGN="LEFT"/>setup_lease_renewal(full_path, ttl)<br ALIGN="LEFT"/>store_extra_data(rdzv_version, key, value)<br ALIGN="LEFT"/>try_create_rendezvous()<br ALIGN="LEFT"/>try_wait_for_state_change(etcd_index, timeout)<br ALIGN="LEFT"/>wait_for_final(expected_version)<br ALIGN="LEFT"/>wait_for_peers(expected_version)<br ALIGN="LEFT"/>wait_for_rendezvous_to_free(expected_version)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend" [color="black", fontcolor="black", label=<{EtcdRendezvousBackend|name<br ALIGN="LEFT"/>|get_state(): Optional[Tuple[bytes, Token]]<br ALIGN="LEFT"/>set_state(state: bytes, token: Optional[Token]): Optional[Tuple[bytes, Token, bool]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler" [color="black", fontcolor="black", label=<{EtcdRendezvousHandler|<br ALIGN="LEFT"/>|get_backend(): str<br ALIGN="LEFT"/>get_run_id(): str<br ALIGN="LEFT"/>is_closed()<br ALIGN="LEFT"/>next_rendezvous()<br ALIGN="LEFT"/>num_nodes_waiting()<br ALIGN="LEFT"/>set_closed()<br ALIGN="LEFT"/>shutdown(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousRetryImmediately" [color="black", fontcolor="red", label=<{EtcdRendezvousRetryImmediately|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousRetryableFailure" [color="black", fontcolor="red", label=<{EtcdRendezvousRetryableFailure|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_server.EtcdServer" [color="black", fontcolor="black", label=<{EtcdServer|<br ALIGN="LEFT"/>|get_client()<br ALIGN="LEFT"/>get_endpoint(): str<br ALIGN="LEFT"/>get_host(): str<br ALIGN="LEFT"/>get_port(): int<br ALIGN="LEFT"/>start(timeout: int, num_retries: int, stderr: Union[int, TextIO, None]): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.etcd_store.EtcdStore" [color="black", fontcolor="black", label=<{EtcdStore|client<br ALIGN="LEFT"/>prefix<br ALIGN="LEFT"/>|add(key, num: int): int<br ALIGN="LEFT"/>check(keys): bool<br ALIGN="LEFT"/>get(key): bytes<br ALIGN="LEFT"/>set(key, value)<br ALIGN="LEFT"/>wait(keys, override_timeout: Optional[datetime.timedelta])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.annotations.EvalEnv" [color="black", fontcolor="black", label=<{EvalEnv|env : dict<br ALIGN="LEFT"/>rcb<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.xpu.streams.Event" [color="black", fontcolor="black", label=<{Event|<br ALIGN="LEFT"/>|elapsed_time(end_event)<br ALIGN="LEFT"/>query(): bool<br ALIGN="LEFT"/>record(stream): None<br ALIGN="LEFT"/>synchronize(): None<br ALIGN="LEFT"/>wait(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceInterface.Event" [color="black", fontcolor="black", label=<{Event|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CpuInterface.Event" [color="black", fontcolor="black", label=<{Event|time : float<br ALIGN="LEFT"/>|elapsed_time(end_event): float<br ALIGN="LEFT"/>record(stream)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.mps.event.Event" [color="black", fontcolor="black", label=<{Event|<br ALIGN="LEFT"/>|elapsed_time(end_event)<br ALIGN="LEFT"/>query()<br ALIGN="LEFT"/>record()<br ALIGN="LEFT"/>synchronize()<br ALIGN="LEFT"/>wait()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cpu.Event" [color="black", fontcolor="black", label=<{Event|<br ALIGN="LEFT"/>|query(): bool<br ALIGN="LEFT"/><I>record</I>(stream): None<br ALIGN="LEFT"/><I>synchronize</I>(): None<br ALIGN="LEFT"/><I>wait</I>(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.events.api.Event" [color="black", fontcolor="black", label=<{Event|metadata : Dict[str, EventMetadataValue]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>timestamp : int<br ALIGN="LEFT"/>|deserialize(data: Union[str, 'Event']): 'Event'<br ALIGN="LEFT"/>serialize(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.streams.Event" [color="black", fontcolor="black", label=<{Event|<br ALIGN="LEFT"/>|elapsed_time(end_event)<br ALIGN="LEFT"/>from_ipc_handle(device, handle)<br ALIGN="LEFT"/>ipc_handle()<br ALIGN="LEFT"/>query()<br ALIGN="LEFT"/>record(stream)<br ALIGN="LEFT"/>synchronize(): None<br ALIGN="LEFT"/>wait(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.MultiProcessTestCase.Event" [color="black", fontcolor="black", label=<{Event|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.EventHandler" [color="black", fontcolor="black", label=<{EventHandler|seq_num : int<br ALIGN="LEFT"/>syncs<br ALIGN="LEFT"/>tensors_accessed<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._utils.EventKey" [color="black", fontcolor="black", label=<{EventKey|event<br ALIGN="LEFT"/>|intervals_overlap(intervals: List[Interval])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler_util.EventList" [color="black", fontcolor="black", label=<{EventList|self_cpu_time_total<br ALIGN="LEFT"/>|export_chrome_trace(path)<br ALIGN="LEFT"/>export_stacks(path: str, metric: str)<br ALIGN="LEFT"/>key_averages(group_by_input_shapes, group_by_stack_n)<br ALIGN="LEFT"/>supported_export_stacks_metrics()<br ALIGN="LEFT"/>table(sort_by, row_limit, max_src_column_width, max_name_column_width, max_shapes_column_width, header, top_level_events_only)<br ALIGN="LEFT"/>total_average()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._utils.EventMetrics" [color="black", fontcolor="black", label=<{EventMetrics|duration_time_ns : int<br ALIGN="LEFT"/>fraction_idle_time<br ALIGN="LEFT"/>idle_time_ns : int<br ALIGN="LEFT"/>queue_depth : int<br ALIGN="LEFT"/>self_time_ns : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.events.api.EventSource" [color="black", fontcolor="black", label=<{EventSource|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.EventVariable" [color="black", fontcolor="black", label=<{EventVariable|proxy<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.repro.after_aot.repro_analyze.ExactReaderInterp" [color="black", fontcolor="black", label=<{ExactReaderInterp|<br ALIGN="LEFT"/>|run_node(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" [color="black", fontcolor="black", label=<{ExactWeakKeyDictionary|refs : dict<br ALIGN="LEFT"/>values : dict<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>get(key, default)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.ExampleAggregateAsDataFrames" [color="black", fontcolor="black", label=<{ExampleAggregateAsDataFrames|columns : NoneType<br ALIGN="LEFT"/>dataframe_size : int<br ALIGN="LEFT"/>source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._exception.Exception" [color="black", fontcolor="red", label=<{Exception|inner_exceptions : Optional[List[_exception.Exception]]<br ALIGN="LEFT"/>kind : Optional[str]<br ALIGN="LEFT"/>message : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>stack : Optional[_stack.Stack]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_input_exception.ExceptionModule" [color="black", fontcolor="black", label=<{ExceptionModule|param<br ALIGN="LEFT"/>|forward(_)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.bytecode_transformation.ExceptionTableEntry" [color="black", fontcolor="black", label=<{ExceptionTableEntry|depth : int<br ALIGN="LEFT"/>end : int<br ALIGN="LEFT"/>lasti : bool<br ALIGN="LEFT"/>start : int<br ALIGN="LEFT"/>target : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.ExceptionVariable" [color="black", fontcolor="black", label=<{ExceptionVariable|args<br ALIGN="LEFT"/>exc_type<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._utils.ExceptionWrapper" [color="black", fontcolor="black", label=<{ExceptionWrapper|exc_msg : str<br ALIGN="LEFT"/>exc_type<br ALIGN="LEFT"/>where : str<br ALIGN="LEFT"/>|reraise()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.ExclusiveKeywordArg" [color="black", fontcolor="black", label=<{ExclusiveKeywordArg|name : str<br ALIGN="LEFT"/>|pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.ExecMode" [color="black", fontcolor="black", label=<{ExecMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.replay_record.ExecutionRecord" [color="black", fontcolor="black", label=<{ExecutionRecord|builtins : Dict[str, Any]<br ALIGN="LEFT"/>closure : Tuple[CellType]<br ALIGN="LEFT"/>code<br ALIGN="LEFT"/>code_options : Dict[str, Any]<br ALIGN="LEFT"/>globals : Dict[str, Any]<br ALIGN="LEFT"/>locals : Dict[str, Any]<br ALIGN="LEFT"/>|dump(f: IO[str]): None<br ALIGN="LEFT"/>load(f: BinaryIO): Self<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.replay_record.ExecutionRecorder" [color="black", fontcolor="black", label=<{ExecutionRecorder|LOCAL_MOD_PREFIX : str<br ALIGN="LEFT"/>builtins : Dict[str, Any]<br ALIGN="LEFT"/>closure : Tuple[CellType]<br ALIGN="LEFT"/>code<br ALIGN="LEFT"/>code_options : Dict[str, Any]<br ALIGN="LEFT"/>globals : Dict[str, Any]<br ALIGN="LEFT"/>locals : Dict[str, Any]<br ALIGN="LEFT"/>name_to_modrec : Dict[str, ModuleRecord]<br ALIGN="LEFT"/>|add_global_var(name: str, var: Any): None<br ALIGN="LEFT"/>add_local_mod(name: str, mod: ModuleType): None<br ALIGN="LEFT"/>add_local_var(name: str, var: Any): None<br ALIGN="LEFT"/>get_record(): ExecutionRecord<br ALIGN="LEFT"/>record_module_access(mod: ModuleType, name: str, val: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.ExecutionState" [color="black", fontcolor="black", label=<{ExecutionState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.throughput_benchmark.ExecutionStats" [color="black", fontcolor="black", label=<{ExecutionStats|benchmark_config<br ALIGN="LEFT"/>iters_per_second<br ALIGN="LEFT"/>latency_avg_ms<br ALIGN="LEFT"/>num_iters<br ALIGN="LEFT"/>total_time_seconds<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler.profiler.ExecutionTraceObserver" [color="black", fontcolor="black", label=<{ExecutionTraceObserver|is_registered<br ALIGN="LEFT"/>|cleanup()<br ALIGN="LEFT"/>get_output_file_path(): str<br ALIGN="LEFT"/>is_running()<br ALIGN="LEFT"/>register_callback(output_file_path: str): Self<br ALIGN="LEFT"/>start()<br ALIGN="LEFT"/>stop()<br ALIGN="LEFT"/>unregister_callback()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.executorch_call_delegate.ExecutorchCallDelegate" [color="black", fontcolor="black", label=<{ExecutorchCallDelegate|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.ExecutorchCallDelegateHigherOrderVariable" [color="black", fontcolor="black", label=<{ExecutorchCallDelegateHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.ExitDeviceContextManagerLine" [color="black", fontcolor="black", label=<{ExitDeviceContextManagerLine|<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.ExitSubgraphLine" [color="black", fontcolor="black", label=<{ExitSubgraphLine|wrapper<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.relaxed_categorical.ExpRelaxedCategorical" [color="black", fontcolor="black", label=<{ExpRelaxedCategorical|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>temperature<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.ExpTransform" [color="black", fontcolor="black", label=<{ExpTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>sign : int<br ALIGN="LEFT"/>|log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ExpandView" [color="black", fontcolor="black", label=<{ExpandView|size : List[Expr]<br ALIGN="LEFT"/>|create(x, new_size)<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>make_reindexer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.expanded_weights_impl.ExpandedWeight" [color="black", fontcolor="black", label=<{ExpandedWeight|allow_smaller_batches : bool<br ALIGN="LEFT"/>batch_first : bool<br ALIGN="LEFT"/>batch_size<br ALIGN="LEFT"/>data<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>handled_functions : dict<br ALIGN="LEFT"/>is_cuda<br ALIGN="LEFT"/>loss_reduction<br ALIGN="LEFT"/>orig_weight<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|data_ptr()<br ALIGN="LEFT"/>get_device()<br ALIGN="LEFT"/>set_allow_smaller_batches(is_allow_smaller_batches)<br ALIGN="LEFT"/>set_batch_first(is_batch_first)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.debugging.ExplainOutput" [color="black", fontcolor="black", label=<{ExplainOutput|break_reasons : List[Any]<br ALIGN="LEFT"/>compile_times : Optional[str]<br ALIGN="LEFT"/>graph_break_count : int<br ALIGN="LEFT"/>graph_count : int<br ALIGN="LEFT"/>graphs : List[torch.fx.GraphModule]<br ALIGN="LEFT"/>op_count : int<br ALIGN="LEFT"/>ops_per_graph : Optional[List[torch.fx.Node]]<br ALIGN="LEFT"/>out_guards : Optional[List[_guards.Guard]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.converter.ExplainTS2FXGraphConverter" [color="black", fontcolor="black", label=<{ExplainTS2FXGraphConverter|name_to_node<br ALIGN="LEFT"/>unsupported_node_list : List[torch._C.Node]<br ALIGN="LEFT"/>|convert_node(node)<br ALIGN="LEFT"/>explain()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.debugging.ExplainWithBackend" [color="black", fontcolor="black", label=<{ExplainWithBackend|backend<br ALIGN="LEFT"/>break_reasons : list<br ALIGN="LEFT"/>graphs : list<br ALIGN="LEFT"/>op_count : int<br ALIGN="LEFT"/>|output(): ExplainOutput<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.exponential.Exponential" [color="black", fontcolor="black", label=<{Exponential|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>rate<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.exp_family.ExponentialFamily" [color="black", fontcolor="black", label=<{ExponentialFamily|<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.ExponentialLR" [color="black", fontcolor="black", label=<{ExponentialLR|gamma : float<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._trace.ExportArtifact" [color="black", fontcolor="black", label=<{ExportArtifact|aten<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>module_call_specs : Dict[str, Dict[str, pytree.TreeSpec]]<br ALIGN="LEFT"/>out_spec<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.ExportBackwardSignature" [color="black", fontcolor="black", label=<{ExportBackwardSignature|gradients_to_parameters : Dict[str, str]<br ALIGN="LEFT"/>gradients_to_user_inputs : Dict[str, str]<br ALIGN="LEFT"/>loss_output : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.case.ExportCase" [color="black", fontcolor="black", label=<{ExportCase|description : str<br ALIGN="LEFT"/>dynamic_shapes : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>example_args : Tuple<br ALIGN="LEFT"/>example_kwargs : Dict[str, Any]<br ALIGN="LEFT"/>extra_args : Optional[ArgsType]<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>support_level<br ALIGN="LEFT"/>tags : Set[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._diagnostic.ExportDiagnosticEngine" [color="black", fontcolor="black", label=<{ExportDiagnosticEngine|background_context<br ALIGN="LEFT"/>contexts : list[infra.DiagnosticContext]<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>create_diagnostic_context(name: str, version: str, options: infra.DiagnosticOptions \| None): infra.DiagnosticContext<br ALIGN="LEFT"/>dump(file_path: str, compress: bool): None<br ALIGN="LEFT"/>sarif_log()<br ALIGN="LEFT"/>to_json(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.ExportDynamoConfig" [color="black", fontcolor="black", label=<{ExportDynamoConfig|allow_rnn : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._trace.ExportDynamoConfig" [color="black", fontcolor="black", label=<{ExportDynamoConfig|allow_rnn : bool<br ALIGN="LEFT"/>do_not_emit_runtime_asserts : bool<br ALIGN="LEFT"/>reorderable_logging_functions : Set[Callable]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.error.ExportError" [color="black", fontcolor="red", label=<{ExportError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.error.ExportErrorType" [color="black", fontcolor="black", label=<{ExportErrorType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" [color="black", fontcolor="black", label=<{ExportGraphSignature|assertion_dep_token<br ALIGN="LEFT"/>backward_signature<br ALIGN="LEFT"/>buffers<br ALIGN="LEFT"/>buffers_to_mutate<br ALIGN="LEFT"/>input_specs : List[InputSpec]<br ALIGN="LEFT"/>input_tokens<br ALIGN="LEFT"/>inputs_to_buffers<br ALIGN="LEFT"/>inputs_to_lifted_custom_objs<br ALIGN="LEFT"/>inputs_to_lifted_tensor_constants<br ALIGN="LEFT"/>inputs_to_parameters<br ALIGN="LEFT"/>lifted_custom_objs<br ALIGN="LEFT"/>lifted_tensor_constants<br ALIGN="LEFT"/>non_persistent_buffers<br ALIGN="LEFT"/>output_specs : List[OutputSpec]<br ALIGN="LEFT"/>output_tokens<br ALIGN="LEFT"/>parameters<br ALIGN="LEFT"/>user_inputs<br ALIGN="LEFT"/>user_inputs_to_mutate<br ALIGN="LEFT"/>user_outputs<br ALIGN="LEFT"/>|get_replace_hook(replace_inputs)<br ALIGN="LEFT"/>replace_all_uses(old: str, new: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportInterpreter" [color="black", fontcolor="black", label=<{ExportInterpreter|callback : str<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>|call_function(target: torch.fx.node.Target, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): ProxyValue<br ALIGN="LEFT"/>call_method(target: str, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): None<br ALIGN="LEFT"/>call_module(target: torch.fx.node.Target, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): None<br ALIGN="LEFT"/>get_attr(target: str, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): Argument<br ALIGN="LEFT"/>output(target: torch.fx.node.Target, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): ProxyValue<br ALIGN="LEFT"/>placeholder(target: str, args: Tuple[Argument, ...], kwargs: Dict[str, Argument]): ProxyValue<br ALIGN="LEFT"/>run_node(n: torch.fx.Node): Argument<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._experimental.ExportOptions" [color="black", fontcolor="black", label=<{ExportOptions|custom_opsets : Optional[Mapping[str, int]]<br ALIGN="LEFT"/>do_constant_folding : bool<br ALIGN="LEFT"/>dynamic_axes : Optional[Mapping[str, Union[Mapping[int, str], Sequence[int]]]]<br ALIGN="LEFT"/>export_modules_as_functions : Union[bool, Set[Type[torch.nn.Module]]]<br ALIGN="LEFT"/>export_params : bool<br ALIGN="LEFT"/>input_names : Optional[Sequence[str]]<br ALIGN="LEFT"/>keep_initializers_as_inputs : Optional[bool]<br ALIGN="LEFT"/>operator_export_type<br ALIGN="LEFT"/>opset_version : Optional[int]<br ALIGN="LEFT"/>output_names : Optional[Sequence[str]]<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>verbose : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.ExportOptions" [color="black", fontcolor="black", label=<{ExportOptions|diagnostic_options<br ALIGN="LEFT"/>dynamic_shapes : bool \| None<br ALIGN="LEFT"/>fake_context : ONNXFakeContext \| None<br ALIGN="LEFT"/>onnx_registry : OnnxRegistry \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.pass_base.ExportPassBaseError" [color="black", fontcolor="red", label=<{ExportPassBaseError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.ExportResult" [color="black", fontcolor="black", label=<{ExportResult|graph_module<br ALIGN="LEFT"/>guards<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._reporting.ExportStatus" [color="black", fontcolor="black", label=<{ExportStatus|decomposition : bool \| None<br ALIGN="LEFT"/>onnx_checker : bool \| None<br ALIGN="LEFT"/>onnx_runtime : bool \| None<br ALIGN="LEFT"/>onnx_translation : bool \| None<br ALIGN="LEFT"/>output_accuracy : bool \| None<br ALIGN="LEFT"/>torch_export : bool \| None<br ALIGN="LEFT"/>torch_export_non_strict : bool \| None<br ALIGN="LEFT"/>torch_jit : bool \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.wrappers.ExportTracepoint" [color="black", fontcolor="black", label=<{ExportTracepoint|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.ExportTracepointHigherOrderVariable" [color="black", fontcolor="black", label=<{ExportTracepointHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" [color="black", fontcolor="black", label=<{ExportTracer|callback : str<br ALIGN="LEFT"/>fake_tensor_mode : NoneType, Optional[FakeTensorMode]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>submodules : Dict[torch.nn.Module, str]<br ALIGN="LEFT"/>tensor_attrs : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>|create_arg(a: Argument): torch.fx.Node<br ALIGN="LEFT"/>set_metadata(node: torch.fx.Node, value: Argument): None<br ALIGN="LEFT"/>trace(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._exporter_states.ExportTypes" [color="black", fontcolor="black", label=<{ExportTypes|COMPRESSED_ZIP_ARCHIVE : str<br ALIGN="LEFT"/>DIRECTORY : str<br ALIGN="LEFT"/>PROTOBUF_FILE : str<br ALIGN="LEFT"/>ZIP_ARCHIVE : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.ExportedProgram" [color="black", fontcolor="black", label=<{ExportedProgram|graph_module : Annotated[GraphModule, 10]<br ALIGN="LEFT"/>opset_version : Annotated[Dict[str, int], 20]<br ALIGN="LEFT"/>range_constraints : Annotated[Dict[str, RangeConstraint], 30]<br ALIGN="LEFT"/>schema_version : Annotated[SchemaVersion, 60]<br ALIGN="LEFT"/>torch_version : Annotated[str, 80]<br ALIGN="LEFT"/>verifiers : Annotated[List[str], 70]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.exported_program.ExportedProgram" [color="black", fontcolor="black", label=<{ExportedProgram|call_spec<br ALIGN="LEFT"/>constants<br ALIGN="LEFT"/>dialect<br ALIGN="LEFT"/>example_inputs<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>graph_module<br ALIGN="LEFT"/>graph_signature<br ALIGN="LEFT"/>module_call_graph<br ALIGN="LEFT"/>range_constraints<br ALIGN="LEFT"/>state_dict<br ALIGN="LEFT"/>tensor_constants<br ALIGN="LEFT"/>verifier<br ALIGN="LEFT"/>verifiers<br ALIGN="LEFT"/>|buffers(): Iterator[torch.Tensor]<br ALIGN="LEFT"/>module(): torch.nn.Module<br ALIGN="LEFT"/>named_buffers(): Iterator[Tuple[str, torch.Tensor]]<br ALIGN="LEFT"/>named_parameters(): Iterator[Tuple[str, torch.nn.Parameter]]<br ALIGN="LEFT"/>parameters(): Iterator[torch.nn.Parameter]<br ALIGN="LEFT"/>run_decompositions(decomp_table: Optional[Dict[torch._ops.OperatorBase, Callable]]): 'ExportedProgram'<br ALIGN="LEFT"/>validate()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.serialize.ExportedProgramDeserializer" [color="black", fontcolor="black", label=<{ExportedProgramDeserializer|expected_opset_version : Dict[str, int]<br ALIGN="LEFT"/>|deserialize(exported_program: ExportedProgram, state_dict: Union[Dict[str, torch.Tensor], bytes], constants: Union[Dict[str, torch.Tensor], bytes], example_inputs: Optional[Union[Tuple[Tuple[torch.Tensor, ...], Dict[str, Any]], bytes]]): ep.ExportedProgram<br ALIGN="LEFT"/>deserialize_range_constraints(symbol_name_to_range: Dict[str, symbolic_shapes.ValueRanges], symbol_name_to_symbol: Dict[str, sympy.Symbol]): Dict[sympy.Symbol, ValueRanges]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.serialize.ExportedProgramSerializer" [color="black", fontcolor="black", label=<{ExportedProgramSerializer|opset_version : Dict[str, int]<br ALIGN="LEFT"/>|serialize(exported_program: ep.ExportedProgram): _SerializedProgram<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.Exporter" [color="black", fontcolor="black", label=<{Exporter|model : torch.nn.Module \| Callable<br ALIGN="LEFT"/>model_args : Sequence[Any]<br ALIGN="LEFT"/>model_kwargs : Mapping[str, Any]<br ALIGN="LEFT"/>options<br ALIGN="LEFT"/>|export(): _onnx_program.ONNXProgram<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.frontend.ExprBuilder" [color="black", fontcolor="black", label=<{ExprBuilder|binop_map : dict<br ALIGN="LEFT"/>boolop_map : dict<br ALIGN="LEFT"/>cmpop_map : dict<br ALIGN="LEFT"/>unop_map : dict<br ALIGN="LEFT"/>|build_Attribute(ctx, expr)<br ALIGN="LEFT"/>build_BinOp(ctx, expr)<br ALIGN="LEFT"/>build_BoolOp(ctx, expr)<br ALIGN="LEFT"/>build_Call(ctx, expr)<br ALIGN="LEFT"/>build_Compare(ctx, expr)<br ALIGN="LEFT"/>build_Constant(ctx, expr)<br ALIGN="LEFT"/>build_Dict(ctx, expr)<br ALIGN="LEFT"/>build_DictComp(ctx, stmt)<br ALIGN="LEFT"/>build_Ellipsis(ctx, expr)<br ALIGN="LEFT"/>build_GeneratorExp(ctx, stmt)<br ALIGN="LEFT"/>build_IfExp(ctx, expr)<br ALIGN="LEFT"/>build_JoinedStr(ctx, expr)<br ALIGN="LEFT"/>build_List(ctx, expr)<br ALIGN="LEFT"/>build_ListComp(ctx, stmt)<br ALIGN="LEFT"/>build_Name(ctx, expr)<br ALIGN="LEFT"/>build_NameConstant(ctx, expr)<br ALIGN="LEFT"/>build_Num(ctx, expr)<br ALIGN="LEFT"/>build_Starred(ctx, expr)<br ALIGN="LEFT"/>build_Str(ctx, expr)<br ALIGN="LEFT"/>build_Subscript(ctx, expr)<br ALIGN="LEFT"/>build_Tuple(ctx, expr)<br ALIGN="LEFT"/>build_UnaryOp(ctx, expr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.ExprCounter" [color="black", fontcolor="black", label=<{ExprCounter|<br ALIGN="LEFT"/>|visit(node: ast.AST): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.printers.ExprPrinter" [color="black", fontcolor="black", label=<{ExprPrinter|printmethod : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.ExtensionHandler" [color="black", fontcolor="black", label=<{ExtensionHandler|<br ALIGN="LEFT"/>|<I>from_op_name</I>(name: str)<br ALIGN="LEFT"/><I>namespace</I>(): str<br ALIGN="LEFT"/><I>op_schema</I>(op): torch.FunctionSchema<br ALIGN="LEFT"/><I>to_op_name</I>(op): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._cpp_extension_versioner.ExtensionVersioner" [color="black", fontcolor="black", label=<{ExtensionVersioner|entries : dict<br ALIGN="LEFT"/>|bump_version_if_changed(name, source_files, build_arguments, build_directory, with_cuda, is_python_module, is_standalone)<br ALIGN="LEFT"/>get_version(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.ExtensionsData" [color="black", fontcolor="black", label=<{ExtensionsData|all_gather_input_sizes : Sequence[torch.Size]<br ALIGN="LEFT"/>all_gather_metadata : Optional[Any]<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ExternKernel" [color="black", fontcolor="black", label=<{ExternKernel|allarg_properties<br ALIGN="LEFT"/>arg_properties : Optional[List[Dict[str, Any]]]<br ALIGN="LEFT"/>constant_args : Tuple[Any, ...]<br ALIGN="LEFT"/>cpp_kernel_name : Optional[str]<br ALIGN="LEFT"/>fx_node<br ALIGN="LEFT"/>kwarg_properties : Optional[Dict[str, Dict[str, Any]]]<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>mutation_outputs : List[MutationOutput]<br ALIGN="LEFT"/>op_overload : Optional[Union[torch._ops.OpOverload, torch._ops.HigherOrderOperator]]<br ALIGN="LEFT"/>ordered_kwargs_for_cpp_kernel : Iterable[str]<br ALIGN="LEFT"/>output_view : Optional[ReinterpretView]<br ALIGN="LEFT"/>python_kernel_name : Optional[str]<br ALIGN="LEFT"/>schema_kwargs<br ALIGN="LEFT"/>unbacked_bindings : Dict[sympy.Symbol, pytree.KeyPath]<br ALIGN="LEFT"/>|<I>apply_constraint</I>(): None<br ALIGN="LEFT"/>canonicalize()<br ALIGN="LEFT"/><I>codegen</I>(wrapper)<br ALIGN="LEFT"/>codegen_args()<br ALIGN="LEFT"/>codegen_comment(wrapper): None<br ALIGN="LEFT"/>codegen_const_args(names: Optional[List[str]])<br ALIGN="LEFT"/>codegen_kwargs(skip_out)<br ALIGN="LEFT"/>codegen_size_asserts(wrapper): None<br ALIGN="LEFT"/>collect_arg_kwarg_properties()<br ALIGN="LEFT"/>convert_to_reinterpret_view(x)<br ALIGN="LEFT"/>copy_input(x)<br ALIGN="LEFT"/>decide_layout()<br ALIGN="LEFT"/>fill_non_provided_args(args, kwargs)<br ALIGN="LEFT"/>get_group_stride()<br ALIGN="LEFT"/>get_kernel_name()<br ALIGN="LEFT"/>get_kwargs_value(arg_name)<br ALIGN="LEFT"/>get_outputs(): List[Buffer]<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>process_kernel(kernel): Tuple[Any, List[Any], List[Any], Callable[[Any, Any], Any], Optional[Dict[sympy.Symbol, pytree.KeyPath]]]<br ALIGN="LEFT"/>realize_input(x)<br ALIGN="LEFT"/>require_channels_last(x)<br ALIGN="LEFT"/>require_channels_last_3d(x)<br ALIGN="LEFT"/>require_contiguous(x)<br ALIGN="LEFT"/>require_exact_strides(x, exact_strides, allow_padding)<br ALIGN="LEFT"/>require_stride1(x)<br ALIGN="LEFT"/>require_stride_order(x, order, allow_padding)<br ALIGN="LEFT"/>require_strides(x, order: Optional[Sequence[int]], exact_strides: Optional[Sequence[_IntLike]], allow_padding)<br ALIGN="LEFT"/>set_cpp_kernel_name(cpp_kernel_name: Optional[str]): None<br ALIGN="LEFT"/>set_python_kernel_name(python_kernel_name: Optional[str]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ExternKernelAlloc" [color="black", fontcolor="black", label=<{ExternKernelAlloc|name<br ALIGN="LEFT"/>outputs : Sequence[Any]<br ALIGN="LEFT"/>|<I>apply_constraint</I>()<br ALIGN="LEFT"/>codegen(wrapper): None<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.ExternKernelCaller" [color="black", fontcolor="black", label=<{ExternKernelCaller|choice<br ALIGN="LEFT"/>has_out_variant : bool<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|autoheuristic_id()<br ALIGN="LEFT"/>benchmark()<br ALIGN="LEFT"/>hash_key()<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]<br ALIGN="LEFT"/>output_node()<br ALIGN="LEFT"/>to_callable()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.ExternKernelChoice" [color="black", fontcolor="black", label=<{ExternKernelChoice|cpp_kernel_name : NoneType<br ALIGN="LEFT"/>has_out_variant : bool<br ALIGN="LEFT"/>kernel_creator : NoneType<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>op_overload : NoneType<br ALIGN="LEFT"/>ordered_kwargs_for_cpp_kernel : tuple<br ALIGN="LEFT"/>use_fallback_kernel : bool<br ALIGN="LEFT"/>|bind(input_nodes, layout, ordered_kwargs_for_cpp_kernel)<br ALIGN="LEFT"/>call_name()<br ALIGN="LEFT"/>hash_key()<br ALIGN="LEFT"/>to_callable()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ExternKernelNode" [color="black", fontcolor="black", label=<{ExternKernelNode|name : str<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.aoti_schema.ExternKernelNode" [color="black", fontcolor="black", label=<{ExternKernelNode|name : str<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.aoti_schema.ExternKernelNodes" [color="black", fontcolor="black", label=<{ExternKernelNodes|nodes : List[ExternKernelNode]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.ExternKernelOut" [color="black", fontcolor="black", label=<{ExternKernelOut|name<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.ExternKernelSchedulerNode" [color="black", fontcolor="black", label=<{ExternKernelSchedulerNode|last_usage<br ALIGN="LEFT"/>max_order<br ALIGN="LEFT"/>min_order<br ALIGN="LEFT"/>|debug_str_extra(): str<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._external_properties.ExternalProperties" [color="black", fontcolor="black", label=<{ExternalProperties|addresses : Optional[List[_address.Address]]<br ALIGN="LEFT"/>artifacts : Optional[List[_artifact.Artifact]]<br ALIGN="LEFT"/>conversion : Optional[_conversion.Conversion]<br ALIGN="LEFT"/>driver : Optional[_tool_component.ToolComponent]<br ALIGN="LEFT"/>extensions : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>externalized_properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>graphs : Optional[List[_graph.Graph]]<br ALIGN="LEFT"/>guid : Optional[str]<br ALIGN="LEFT"/>invocations : Optional[List[_invocation.Invocation]]<br ALIGN="LEFT"/>logical_locations : Optional[List[_logical_location.LogicalLocation]]<br ALIGN="LEFT"/>policies : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>results : Optional[List[_result.Result]]<br ALIGN="LEFT"/>run_guid : Optional[str]<br ALIGN="LEFT"/>schema : Optional[str]<br ALIGN="LEFT"/>taxonomies : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>thread_flow_locations : Optional[List[_thread_flow_location.ThreadFlowLocation]]<br ALIGN="LEFT"/>translations : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>version : Optional[Literal['2.1.0']]<br ALIGN="LEFT"/>web_requests : Optional[List[_web_request.WebRequest]]<br ALIGN="LEFT"/>web_responses : Optional[List[_web_response.WebResponse]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._external_property_file_reference.ExternalPropertyFileReference" [color="black", fontcolor="black", label=<{ExternalPropertyFileReference|guid : Optional[str]<br ALIGN="LEFT"/>item_count : int<br ALIGN="LEFT"/>location : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._external_property_file_references.ExternalPropertyFileReferences" [color="black", fontcolor="black", label=<{ExternalPropertyFileReferences|addresses : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>artifacts : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>conversion : Optional[_external_property_file_reference.ExternalPropertyFileReference]<br ALIGN="LEFT"/>driver : Optional[_external_property_file_reference.ExternalPropertyFileReference]<br ALIGN="LEFT"/>extensions : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>externalized_properties : Optional[_external_property_file_reference.ExternalPropertyFileReference]<br ALIGN="LEFT"/>graphs : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>invocations : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>logical_locations : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>policies : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>results : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>taxonomies : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>thread_flow_locations : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>translations : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>web_requests : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>web_responses : Optional[List[_external_property_file_reference.ExternalPropertyFileReference]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.streams.ExternalStream" [color="black", fontcolor="black", label=<{ExternalStream|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.ExtraCUDACopyPattern" [color="black", fontcolor="black", label=<{ExtraCUDACopyPattern|description : str<br ALIGN="LEFT"/>init_ops : set<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>skip<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|benchmark(events: List[_ProfilerEvent])<br ALIGN="LEFT"/>match(event)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.definitions.nested.ExtraOpData" [color="black", fontcolor="black", label=<{ExtraOpData|dim_args : Optional[List[List[str]]]<br ALIGN="LEFT"/>is_view : bool<br ALIGN="LEFT"/>|get_dim_argnames(): Tuple[Optional[str], Optional[str]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.ExtractConstantsHandler" [color="black", fontcolor="black", label=<{ExtractConstantsHandler|device<br ALIGN="LEFT"/>|constant(value: Any, dtype: torch.dtype): 'torch._inductor.ir.Constant'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.F" [color="black", fontcolor="black", label=<{F|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.FP32MatMulPattern" [color="black", fontcolor="black", label=<{FP32MatMulPattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>skip<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|benchmark(events: List[_ProfilerEvent])<br ALIGN="LEFT"/>match(event: _ProfilerEvent)<br ALIGN="LEFT"/>report(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.FPGM_pruner.FPGMPruner" [color="black", fontcolor="black", label=<{FPGMPruner|dist_fn : NoneType, int<br ALIGN="LEFT"/>|update_mask(module, tensor_name, sparsity_level)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPCommContext" [color="black", fontcolor="black", label=<{FSDPCommContext|all_gather_copy_in_stream<br ALIGN="LEFT"/>all_gather_state : NoneType, Optional[AllGatherState]<br ALIGN="LEFT"/>all_gather_stream<br ALIGN="LEFT"/>all_reduce_stream<br ALIGN="LEFT"/>device_handle<br ALIGN="LEFT"/>post_forward_order : List[FSDPParamGroup]<br ALIGN="LEFT"/>reduce_scatter_state : NoneType, Optional[ReduceScatterState]<br ALIGN="LEFT"/>reduce_scatter_stream<br ALIGN="LEFT"/>|get_all_gather_streams(async_op: bool, training_state: TrainingState): Tuple[torch.Stream, torch.Stream]<br ALIGN="LEFT"/>lazy_init(device: torch.device)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fsdp_extensions.FSDPExtensions" [color="black", fontcolor="black", label=<{FSDPExtensions|<br ALIGN="LEFT"/>|<I>all_gather_dtensor</I>(tensor: DTensor, parent_mesh: Optional[DeviceMesh]): torch.Tensor<br ALIGN="LEFT"/><I>chunk_dtensor</I>(tensor: torch.Tensor, rank: int, device_mesh: DeviceMesh): torch.Tensor<br ALIGN="LEFT"/><I>chunk_tensor</I>(tensor: torch.Tensor, rank: int, world_size: int, num_devices_per_node: int, pg: dist.ProcessGroup, device: Optional[torch.device]): torch.Tensor<br ALIGN="LEFT"/><I>post_unflatten_transform</I>(tensor: torch.Tensor, param_extension: Any): torch.Tensor<br ALIGN="LEFT"/><I>pre_flatten_transform</I>(tensor: torch.Tensor): Tuple[torch.Tensor, Optional[Any]]<br ALIGN="LEFT"/><I>pre_load_state_dict_transform</I>(tensor: torch.Tensor): Tuple[torch.Tensor, List[Shard]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.FSDPInitMode" [color="black", fontcolor="black", label=<{FSDPInitMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.nn_module.FSDPManagedNNModuleVariable" [color="black", fontcolor="black", label=<{FSDPManagedNNModuleVariable|source<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker.FSDPMemTracker" [color="black", fontcolor="black", label=<{FSDPMemTracker|<br ALIGN="LEFT"/>|<I>track_external</I>(): None<br ALIGN="LEFT"/>track_inputs(inputs: Tuple[Any, ...]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.FSDPMeshInfo" [color="black", fontcolor="black", label=<{FSDPMeshInfo|shard_mesh_rank : int<br ALIGN="LEFT"/>shard_mesh_size : int<br ALIGN="LEFT"/>shard_process_group<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fully_shard.FSDPModule" [color="black", fontcolor="black", label=<{FSDPModule|<br ALIGN="LEFT"/>|reshard(): None<br ALIGN="LEFT"/>set_is_last_backward(is_last_backward: bool): None<br ALIGN="LEFT"/>set_modules_to_backward_prefetch(modules: List['FSDPModule']): None<br ALIGN="LEFT"/>set_modules_to_forward_prefetch(modules: List['FSDPModule']): None<br ALIGN="LEFT"/>set_post_optim_event(event: torch.Event): None<br ALIGN="LEFT"/>set_reduce_scatter_divide_factor(factor: float): None<br ALIGN="LEFT"/>set_requires_all_reduce(requires_all_reduce: bool): None<br ALIGN="LEFT"/>set_requires_gradient_sync(requires_gradient_sync: bool): None<br ALIGN="LEFT"/>set_reshard_after_backward(reshard_after_backward: bool): None<br ALIGN="LEFT"/>set_unshard_in_backward(unshard_in_backward: bool): None<br ALIGN="LEFT"/>unshard(async_op: bool): Optional['UnshardHandle']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.FSDPNNModuleSource" [color="black", fontcolor="black", label=<{FSDPNNModuleSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [color="black", fontcolor="black", label=<{FSDPParam|all_gather_inputs<br ALIGN="LEFT"/>all_gather_outputs : List[torch.Tensor]<br ALIGN="LEFT"/>contiguous_sharded_post_forward_stride : Tuple[int, ...]<br ALIGN="LEFT"/>contiguous_sharded_stride : Tuple[int, ...]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>fsdp_placement : NoneType<br ALIGN="LEFT"/>grad_offload_event : Optional[torch.Event]<br ALIGN="LEFT"/>is_dtensor<br ALIGN="LEFT"/>mesh_info<br ALIGN="LEFT"/>mp_policy<br ALIGN="LEFT"/>offload_to_cpu : bool<br ALIGN="LEFT"/>orig_dtype<br ALIGN="LEFT"/>padded_sharded_param_size<br ALIGN="LEFT"/>param_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>pin_memory<br ALIGN="LEFT"/>post_forward_mesh_info : Optional[FSDPMeshInfo]<br ALIGN="LEFT"/>reduce_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>shard_mesh<br ALIGN="LEFT"/>sharded_param<br ALIGN="LEFT"/>sharded_post_forward_size<br ALIGN="LEFT"/>sharded_size<br ALIGN="LEFT"/>sharded_state : SHARDED_POST_FORWARD, UNSHARDED<br ALIGN="LEFT"/>unsharded_accumulated_grad : Optional[torch.Tensor]<br ALIGN="LEFT"/>unsharded_accumulated_grad_data<br ALIGN="LEFT"/>unsharded_grad_data<br ALIGN="LEFT"/>unsharded_param<br ALIGN="LEFT"/>|accumulate_unsharded_grad_if_needed(): None<br ALIGN="LEFT"/>alloc_all_gather_outputs(): None<br ALIGN="LEFT"/>free_unsharded_param(): None<br ALIGN="LEFT"/>init_all_gather_outputs(all_gather_input_numels: List[int], all_gather_input_dtypes: List[torch.dtype], world_size: int, device: torch.device, force_recreate: bool)<br ALIGN="LEFT"/>init_dtype_attrs(mp_policy: MixedPrecisionPolicy)<br ALIGN="LEFT"/>init_unsharded_param()<br ALIGN="LEFT"/>reset_sharded_param()<br ALIGN="LEFT"/>to_accumulated_grad_if_needed(): None<br ALIGN="LEFT"/>to_sharded(): None<br ALIGN="LEFT"/>to_sharded_dtensor(tensor: torch.Tensor): DTensor<br ALIGN="LEFT"/>to_sharded_post_forward(): None<br ALIGN="LEFT"/>to_sharded_post_forward_dtensor(tensor: torch.Tensor): DTensor<br ALIGN="LEFT"/>to_unsharded(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [color="black", fontcolor="black", label=<{FSDPParamGroup|all_reduce_grads : bool<br ALIGN="LEFT"/>comm_ctx<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>device_handle<br ALIGN="LEFT"/>fsdp_params<br ALIGN="LEFT"/>is_sharded<br ALIGN="LEFT"/>is_sharded_post_forward<br ALIGN="LEFT"/>is_unsharded<br ALIGN="LEFT"/>mesh_info<br ALIGN="LEFT"/>modules : Tuple[nn.Module, ...]<br ALIGN="LEFT"/>mp_policy<br ALIGN="LEFT"/>offload_policy<br ALIGN="LEFT"/>post_forward_mesh_info : Optional[FSDPMeshInfo]<br ALIGN="LEFT"/>reduce_grads : bool<br ALIGN="LEFT"/>reduce_scatter_reduce_op : Optional[dist.ReduceOp]<br ALIGN="LEFT"/>reshard_after_backward : bool<br ALIGN="LEFT"/>unshard_async_op : bool<br ALIGN="LEFT"/>unshard_in_backward : bool<br ALIGN="LEFT"/>|finalize_backward()<br ALIGN="LEFT"/>lazy_init()<br ALIGN="LEFT"/>post_backward()<br ALIGN="LEFT"/>post_forward(module: nn.Module, input: Any, output: Any)<br ALIGN="LEFT"/>pre_backward(default_prefetch: bool)<br ALIGN="LEFT"/>pre_forward(module: nn.Module, args: Tuple[Any, ...], kwargs: Dict[str, Any]): Tuple[Tuple[Any, ...], Dict[str, Any]]<br ALIGN="LEFT"/>reshard()<br ALIGN="LEFT"/>unshard(async_op: bool)<br ALIGN="LEFT"/>use_training_state(training_state: TrainingState)<br ALIGN="LEFT"/>wait_for_unshard()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.FSDPParamGroupUseTrainingStateVariable" [color="black", fontcolor="black", label=<{FSDPParamGroupUseTrainingStateVariable|param_group_var<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]')<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', param_group_var, target_value)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._optim_utils.FSDPParamInfo" [color="black", fontcolor="black", label=<{FSDPParamInfo|handle<br ALIGN="LEFT"/>param_indices : Dict[str, int]<br ALIGN="LEFT"/>param_requires_grad : List[bool]<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [color="black", fontcolor="black", label=<{FSDPState|<br ALIGN="LEFT"/>|init(modules: Tuple[nn.Module, ...], device: torch.device, mp_policy: MixedPrecisionPolicy): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_state.FSDPStateContext" [color="black", fontcolor="black", label=<{FSDPStateContext|all_states : List[FSDPState]<br ALIGN="LEFT"/>is_last_backward : bool<br ALIGN="LEFT"/>iter_forward_root : NoneType, Optional[FSDPState]<br ALIGN="LEFT"/>post_backward_final_callback_queued : bool<br ALIGN="LEFT"/>post_optim_event : NoneType, Optional[torch.Event]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.FSDPTest" [color="black", fontcolor="black", label=<{FSDPTest|destroy_pg_upon_exit<br ALIGN="LEFT"/>file_name<br ALIGN="LEFT"/>init_method<br ALIGN="LEFT"/>process_group<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|run_subtests()<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.FSDPTestModel" [color="black", fontcolor="black", label=<{FSDPTestModel|<br ALIGN="LEFT"/>|<I>get_input</I>(device): Tuple[torch.Tensor, ...]<br ALIGN="LEFT"/><I>get_loss</I>(input, output): torch.Tensor<br ALIGN="LEFT"/><I>init</I>(): nn.Module<br ALIGN="LEFT"/><I>run_backward</I>(loss): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.FSDPTestMultiThread" [color="black", fontcolor="black", label=<{FSDPTestMultiThread|world_size<br ALIGN="LEFT"/>|perThreadSetUp()<br ALIGN="LEFT"/>perThreadTearDown()<br ALIGN="LEFT"/>run_subtests()<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional" [color="black", fontcolor="black", label=<{FXFloatFunctional|<br ALIGN="LEFT"/>|add(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_relu(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>cat(x: List[Tensor], dim: int): Tensor<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>matmul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.FXGraphCacheLoadable" [color="black", fontcolor="black", label=<{FXGraphCacheLoadable|fx_graph_cache_key : str<br ALIGN="LEFT"/>|is_backward()<br ALIGN="LEFT"/>load(example_inputs, fx_config: _CompileFxKwargs): CompiledFxGraph<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.FXGraphCacheMiss" [color="black", fontcolor="red", label=<{FXGraphCacheMiss|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.FXGraphExtractor" [color="black", fontcolor="black", label=<{FXGraphExtractor|input_adapter<br ALIGN="LEFT"/>output_adapter<br ALIGN="LEFT"/>|<I>generate_fx</I>(options: ResolvedExportOptions, model: torch.nn.Module \| Callable, model_args: Sequence[Any], model_kwargs: Mapping[str, Any]): torch.fx.GraphModule<br ALIGN="LEFT"/><I>pre_export_passes</I>(options: ResolvedExportOptions, original_model: torch.nn.Module \| Callable, fx_module: torch.fx.GraphModule, fx_module_args: Sequence[Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.fx_symbolic_graph_extractor.FXSymbolicTracer" [color="black", fontcolor="black", label=<{FXSymbolicTracer|concrete_args : dict[str, Any] \| None<br ALIGN="LEFT"/>|generate_fx(options: _exporter_legacy.ResolvedExportOptions, model: torch.nn.Module \| Callable, model_args: Sequence[Any], model_kwargs: Mapping[str, Any]): torch.fx.GraphModule<br ALIGN="LEFT"/>pre_export_passes(options: _exporter_legacy.ResolvedExportOptions, original_model: torch.nn.Module \| Callable, fx_module: torch.fx.GraphModule, fx_module_args: Sequence[Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.FailOnRecompileLimitHit" [color="black", fontcolor="red", label=<{FailOnRecompileLimitHit|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.FailedMatch" [color="black", fontcolor="red", label=<{FailedMatch|args : tuple<br ALIGN="LEFT"/>format_string : str<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.FailingOptimizer" [color="black", fontcolor="black", label=<{FailingOptimizer|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._draft_export.FailureReport" [color="black", fontcolor="black", label=<{FailureReport|data : Dict[str, Any]<br ALIGN="LEFT"/>failure_type<br ALIGN="LEFT"/>xfail : bool<br ALIGN="LEFT"/>|print(str_to_filename: Dict[str, str]): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._draft_export.FailureType" [color="black", fontcolor="black", label=<{FailureType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.optests.generate_tests.FailuresDict" [color="black", fontcolor="black", label=<{FailuresDict|data : Dict<br ALIGN="LEFT"/>path : str<br ALIGN="LEFT"/>|get_status(qualname: str, test_name: str): str<br ALIGN="LEFT"/>load(path): 'FailuresDict'<br ALIGN="LEFT"/>save(): None<br ALIGN="LEFT"/>set_status(qualname: str, test_name: str, status: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.external_utils.FakeBackwardCFunction" [color="black", fontcolor="black", label=<{FakeBackwardCFunction|real<br ALIGN="LEFT"/>saved_tensors : List[torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.show_pickle.FakeClass" [color="black", fontcolor="black", label=<{FakeClass|module<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|fake_new()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.fake_class_registry.FakeClassRegistry" [color="black", fontcolor="black", label=<{FakeClassRegistry|<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>deregister(full_qualname: str): Any<br ALIGN="LEFT"/>get_impl(full_qualname: str): Any<br ALIGN="LEFT"/>has_impl(full_qualname: str): bool<br ALIGN="LEFT"/>register(full_qualname: str, fake_class): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.external_utils.FakeCompiledAutogradEngine" [color="black", fontcolor="black", label=<{FakeCompiledAutogradEngine|<br ALIGN="LEFT"/>|exec_final_callbacks(final_callbacks: List[Callable[[], None]]): None<br ALIGN="LEFT"/>queue_callback(final_callbacks: List[Callable[[], None]], cb: Callable[[], None]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.torchbind_impls.register_fake_classes.FakeContainsTensor" [color="black", fontcolor="black", label=<{FakeContainsTensor|t<br ALIGN="LEFT"/>|get()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.FakeCopyMode" [color="black", fontcolor="black", label=<{FakeCopyMode|fake_mode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.torchbind_impls.register_fake_classes.FakeFoo" [color="black", fontcolor="black", label=<{FakeFoo|x : int<br ALIGN="LEFT"/>y : int<br ALIGN="LEFT"/>|add_tensor(z)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.fake_impl.FakeImplCtx" [color="black", fontcolor="black", label=<{FakeImplCtx|<br ALIGN="LEFT"/>|create_unbacked_symint(): torch.SymInt<br ALIGN="LEFT"/>new_dynamic_size(): torch.SymInt<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.fake_impl.FakeImplHolder" [color="black", fontcolor="black", label=<{FakeImplHolder|kernel : NoneType, Optional[Kernel]<br ALIGN="LEFT"/>lib : NoneType, Optional[torch.library.Library]<br ALIGN="LEFT"/>qualname : str<br ALIGN="LEFT"/>|register(func: Callable, source: str): RegistrationHandle<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.FakeIndentedBuffer" [color="black", fontcolor="black", label=<{FakeIndentedBuffer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.FakeItemVariable" [color="black", fontcolor="black", label=<{FakeItemVariable|need_unwrap<br ALIGN="LEFT"/>|from_tensor_variable(tensor_variable)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.show_pickle.FakeObject" [color="black", fontcolor="black", label=<{FakeObject|args<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>state : NoneType<br ALIGN="LEFT"/>|pp_format(printer, obj, stream, indent, allowance, context, level)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._decomposed.FakeQuantPerChannel" [color="black", fontcolor="black", label=<{FakeQuantPerChannel|<br ALIGN="LEFT"/>|backward(ctx, gy)<br ALIGN="LEFT"/>forward(ctx, input, scales, zero_points, axis, quant_min, quant_max)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fake_quantize.FakeQuantize" [color="black", fontcolor="black", label=<{FakeQuantize|activation_post_process<br ALIGN="LEFT"/>ch_axis : int<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>is_dynamic : bool<br ALIGN="LEFT"/>is_per_channel<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>quant_max : int<br ALIGN="LEFT"/>quant_min : int<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(X)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fake_quantize.FakeQuantizeBase" [color="black", fontcolor="black", label=<{FakeQuantizeBase|fake_quant_enabled<br ALIGN="LEFT"/>observer_enabled<br ALIGN="LEFT"/>|<I>calculate_qparams</I>()<br ALIGN="LEFT"/>disable_fake_quant()<br ALIGN="LEFT"/>disable_observer()<br ALIGN="LEFT"/>enable_fake_quant(enabled: bool): None<br ALIGN="LEFT"/>enable_observer(enabled: bool): None<br ALIGN="LEFT"/><I>forward</I>(x)<br ALIGN="LEFT"/>with_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.FakeRootModule" [color="black", fontcolor="black", label=<{FakeRootModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.fake_class_registry.FakeScriptMethod" [color="black", fontcolor="black", label=<{FakeScriptMethod|method_name : str<br ALIGN="LEFT"/>schema : Optional[torch.FunctionSchema]<br ALIGN="LEFT"/>self_fake_obj<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.fake_class_registry.FakeScriptObject" [color="black", fontcolor="black", label=<{FakeScriptObject|real_obj<br ALIGN="LEFT"/>script_class_name : str<br ALIGN="LEFT"/>wrapped_obj : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.FakeSequential" [color="black", fontcolor="black", label=<{FakeSequential|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.sparsifier.utils.FakeSparsity" [color="black", fontcolor="black", label=<{FakeSparsity|mask<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.fake_pg.FakeStore" [color="black", fontcolor="black", label=<{FakeStore|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.parametrization.FakeStructuredSparsity" [color="black", fontcolor="black", label=<{FakeStructuredSparsity|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.FakeTensor" [color="black", fontcolor="black", label=<{FakeTensor|constant : Optional[Tensor]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>fake_device<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>item_memo<br ALIGN="LEFT"/>names<br ALIGN="LEFT"/>nested_int_memo<br ALIGN="LEFT"/>nonzero_memo<br ALIGN="LEFT"/>real_tensor : Optional[Tensor]<br ALIGN="LEFT"/>unique_memo<br ALIGN="LEFT"/>|from_tensor(t: Tensor, fake_mode: FakeTensorMode): FakeTensor<br ALIGN="LEFT"/>get_nested_int(): torch.SymInt<br ALIGN="LEFT"/>tolist(): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorConfig" [color="black", fontcolor="black", label=<{FakeTensorConfig|debug<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorConverter" [color="black", fontcolor="black", label=<{FakeTensorConverter|constant_storage_mapping : Dict[StorageWeakRef, List[ReferenceType]]<br ALIGN="LEFT"/>export : bool<br ALIGN="LEFT"/>meta_converter<br ALIGN="LEFT"/>tensor_memo<br ALIGN="LEFT"/>|add_constant_storage_mapping(fake_tensor: FakeTensor): None<br ALIGN="LEFT"/>from_meta_and_device(fake_mode: FakeTensorMode, t: Tensor, device: torch.device): FakeTensor<br ALIGN="LEFT"/>from_real_tensor(fake_mode: FakeTensorMode, t: Tensor, make_constant: bool, shape_env: Optional[ShapeEnv]): FakeTensor<br ALIGN="LEFT"/>invalidate_constant_aliases(tensor: Tensor): None<br ALIGN="LEFT"/>set_tensor_memo(t: Tensor, v: FakeTensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.recording.FakeTensorMeta" [color="black", fontcolor="black", label=<{FakeTensorMeta|is_nested : bool<br ALIGN="LEFT"/>tensor_size : Tuple[Union[int, torch.SymInt], ...]<br ALIGN="LEFT"/>tensor_storage_offset : Union[int, torch.SymInt]<br ALIGN="LEFT"/>tensor_stride : Tuple[Union[int, torch.SymInt], ...]<br ALIGN="LEFT"/>|dim(): int<br ALIGN="LEFT"/>from_fake(fake): 'FakeTensorMeta'<br ALIGN="LEFT"/>size(): Tuple[Union[int, torch.SymInt], ...]<br ALIGN="LEFT"/>storage_offset(): Union[int, torch.SymInt]<br ALIGN="LEFT"/>stride(): Tuple[Union[int, torch.SymInt], ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" [color="black", fontcolor="black", label=<{FakeTensorMode|allow_fallback_kernels : bool<br ALIGN="LEFT"/>allow_meta : bool<br ALIGN="LEFT"/>allow_non_fake_inputs : bool<br ALIGN="LEFT"/>allow_scalar_outputs : bool<br ALIGN="LEFT"/>avoid_device_init<br ALIGN="LEFT"/>cache : Dict[_DispatchCacheKey, _DispatchCacheEntry]<br ALIGN="LEFT"/>cache_bypasses : Dict[str, int]<br ALIGN="LEFT"/>cache_crosscheck_enabled<br ALIGN="LEFT"/>cache_enabled<br ALIGN="LEFT"/>cache_hits : int<br ALIGN="LEFT"/>cache_misses : int<br ALIGN="LEFT"/>enter_stack : List[Tuple[bool, Optional[TorchDispatchMode], Optional[bool]]]<br ALIGN="LEFT"/>epoch : int<br ALIGN="LEFT"/>fake_tensor_converter<br ALIGN="LEFT"/>in_kernel_invocation : bool<br ALIGN="LEFT"/>lift_fns : dict<br ALIGN="LEFT"/>nt_tensor_id_counter : int<br ALIGN="LEFT"/>nt_tensor_id_initial_count : int<br ALIGN="LEFT"/>propagate_real_tensors : bool<br ALIGN="LEFT"/>shape_env : Optional[ShapeEnv]<br ALIGN="LEFT"/>stack<br ALIGN="LEFT"/>static_shapes : bool<br ALIGN="LEFT"/>|cache_clear(): None<br ALIGN="LEFT"/>cache_info(): DispatchCacheInfo<br ALIGN="LEFT"/>can_run_unsafe_fallback(func: OpOverload): bool<br ALIGN="LEFT"/>cpp_meta_supports_symint(func: OpOverload): bool<br ALIGN="LEFT"/>create_symbolic_nested_int(): torch.SymInt<br ALIGN="LEFT"/>dispatch(func: OpOverload, types: Sequence[Type], args: Sequence[object], kwargs: Mapping[str, object]): object<br ALIGN="LEFT"/>from_tensor(tensor: Tensor): FakeTensor<br ALIGN="LEFT"/>invalidate_written_to_constants(func: OpOverload, flat_arg_fake_tensors: Sequence[FakeTensor], args: Sequence[object], kwargs: Mapping[str, object]): None<br ALIGN="LEFT"/>is_infra_mode(): bool<br ALIGN="LEFT"/>is_our_fake(t: object): TypeGuard[FakeTensor]<br ALIGN="LEFT"/>may_turn_const(t: Tensor): bool<br ALIGN="LEFT"/>reset_nt_tensor_id_counter(): None<br ALIGN="LEFT"/>validate_and_convert_non_fake_tensors(func: OpOverload, converter: FakeTensorConverter, flat_args: Sequence[object], args_spec: TreeSpec): Tuple[List[object], List[FakeTensor]]<br ALIGN="LEFT"/>wrap_meta_outputs_with_default_device_logic(r: object, func: OpOverload, flat_args: Sequence[object], device: torch.device): PyTree<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.fake_tensor_prop.FakeTensorProp" [color="black", fontcolor="black", label=<{FakeTensorProp|<br ALIGN="LEFT"/>|propagate()<br ALIGN="LEFT"/>propagate_dont_convert_inputs()<br ALIGN="LEFT"/>run_node(n: Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_utils.FakeTensorUpdater" [color="black", fontcolor="black", label=<{FakeTensorUpdater|graph<br ALIGN="LEFT"/>processed_hashes<br ALIGN="LEFT"/>|hash_node(node: torch.fx.Node)<br ALIGN="LEFT"/>incremental_update()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker.FSDPMemTracker._instrument_and_maybe_bypass_collectives.FakeWork" [color="black", fontcolor="black", label=<{FakeWork|<br ALIGN="LEFT"/>|get_future(): Future<br ALIGN="LEFT"/>wait(timeout: Optional[timedelta]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.distributed.SubmodCompiler.run_node.FakeifyFirstAOTInvocationGuard" [color="black", fontcolor="black", label=<{FakeifyFirstAOTInvocationGuard|tc<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.FakifiedOutWrapper" [color="black", fontcolor="black", label=<{FakifiedOutWrapper|fwd_output_strides : Optional[List[List[int]]]<br ALIGN="LEFT"/>needs_post_compile : bool<br ALIGN="LEFT"/>out_metas : List[torch.Tensor]<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>pre_compile(fw_module, flat_args, aot_config): Tuple[Callable, List[Tensor], ViewAndMutationMeta]<br ALIGN="LEFT"/>set_fwd_output_strides(fwd_output_strides)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.FallbackKernel" [color="black", fontcolor="black", label=<{FallbackKernel|alias_names : List[str]<br ALIGN="LEFT"/>kwargs : NoneType, dict<br ALIGN="LEFT"/>mutation_names : List[str]<br ALIGN="LEFT"/>op_overload<br ALIGN="LEFT"/>outputs : NoneType, list<br ALIGN="LEFT"/>unbacked_bindings : NoneType<br ALIGN="LEFT"/>unflatten_args<br ALIGN="LEFT"/>use_runtime_dispatch : bool<br ALIGN="LEFT"/>|apply_constraint()<br ALIGN="LEFT"/>codegen(wrapper): None<br ALIGN="LEFT"/>codegen_args()<br ALIGN="LEFT"/>codegen_unbacked_symbol_defs(wrapper): None<br ALIGN="LEFT"/>create(kernel)<br ALIGN="LEFT"/>export_extern_kernel_node()<br ALIGN="LEFT"/>find_device(tensor_args, example_output)<br ALIGN="LEFT"/>get_inputs_that_alias_output()<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>has_side_effects()<br ALIGN="LEFT"/>tensor_to_layout(output: torch.Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest" [color="black", fontcolor="black", label=<{FaultyAgentDistAutogradTest|<br ALIGN="LEFT"/>|context_cleanup_test_helper(rpc_args, func)<br ALIGN="LEFT"/>test_context_cleanup_tensor_with_grad()<br ALIGN="LEFT"/>test_verify_backend_options()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.faulty_agent_rpc_test.FaultyAgentRpcTest" [color="black", fontcolor="black", label=<{FaultyAgentRpcTest|<br ALIGN="LEFT"/>|test_builtin_remote_message_dropped_timeout()<br ALIGN="LEFT"/>test_builtin_remote_message_dropped_timeout_to_self()<br ALIGN="LEFT"/>test_check_failed_messages()<br ALIGN="LEFT"/>test_custom_faulty_messages()<br ALIGN="LEFT"/>test_custom_messages_to_delay()<br ALIGN="LEFT"/>test_no_faulty_messages()<br ALIGN="LEFT"/>test_remote_message_builtin_delay_timeout()<br ALIGN="LEFT"/>test_remote_message_builtin_delay_timeout_to_self()<br ALIGN="LEFT"/>test_remote_message_dropped_pickle()<br ALIGN="LEFT"/>test_remote_message_dropped_pickle_to_self()<br ALIGN="LEFT"/>test_remote_message_script_delay_timeout()<br ALIGN="LEFT"/>test_remote_message_script_delay_timeout_to_self()<br ALIGN="LEFT"/>test_rpc_builtin_timeout()<br ALIGN="LEFT"/>test_rpc_script_timeout()<br ALIGN="LEFT"/>test_rref_to_here_timeout()<br ALIGN="LEFT"/>test_udf_remote_message_delay_timeout()<br ALIGN="LEFT"/>test_udf_remote_message_delay_timeout_to_self()<br ALIGN="LEFT"/>test_udf_remote_message_dropped_timeout()<br ALIGN="LEFT"/>test_udf_remote_message_dropped_timeout_to_self()<br ALIGN="LEFT"/>test_verify_backend_options()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture" [color="black", fontcolor="black", label=<{FaultyRpcAgentTestFixture|messages_to_delay : dict<br ALIGN="LEFT"/>messages_to_fail : list<br ALIGN="LEFT"/>rpc_backend<br ALIGN="LEFT"/>rpc_backend_options<br ALIGN="LEFT"/>|get_shutdown_error_regex()<br ALIGN="LEFT"/>get_timeout_error_regex()<br ALIGN="LEFT"/>setup_fault_injection(faulty_messages, messages_to_delay)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.examples.compare.FauxTorch" [color="black", fontcolor="black", label=<{FauxTorch|<br ALIGN="LEFT"/>|add()<br ALIGN="LEFT"/>cat()<br ALIGN="LEFT"/>extra_overhead(result)<br ALIGN="LEFT"/>matmul()<br ALIGN="LEFT"/>mul()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout.FeatureAlphaDropout" [color="black", fontcolor="black", label=<{FeatureAlphaDropout|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.FeatureSet" [color="black", fontcolor="black", label=<{FeatureSet|dense_features<br ALIGN="LEFT"/>sparse_features<br ALIGN="LEFT"/>values<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" [color="black", fontcolor="black", label=<{FeedForward|gelu<br ALIGN="LEFT"/>resid_dropout<br ALIGN="LEFT"/>w1<br ALIGN="LEFT"/>w2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.file_baton.FileBaton" [color="black", fontcolor="black", label=<{FileBaton|fd : NoneType<br ALIGN="LEFT"/>lock_file_path<br ALIGN="LEFT"/>wait_seconds : float<br ALIGN="LEFT"/>|release()<br ALIGN="LEFT"/>try_acquire()<br ALIGN="LEFT"/>wait()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.filelister.FileListerIterDataPipe" [color="black", fontcolor="black", label=<{FileListerIterDataPipe|abspath : bool<br ALIGN="LEFT"/>datapipe<br ALIGN="LEFT"/>length : int<br ALIGN="LEFT"/>masks : Union[str, List[str]]<br ALIGN="LEFT"/>non_deterministic : bool<br ALIGN="LEFT"/>recursive : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._filelock.FileLock" [color="black", fontcolor="black", label=<{FileLock|region_counter<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.fileopener.FileOpenerIterDataPipe" [color="black", fontcolor="black", label=<{FileOpenerIterDataPipe|datapipe : Iterable<br ALIGN="LEFT"/>encoding : Optional[str]<br ALIGN="LEFT"/>length : int<br ALIGN="LEFT"/>mode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint._fsspec_filesystem.FileSystem" [color="black", fontcolor="black", label=<{FileSystem|fs : Optional[AbstractFileSystem]<br ALIGN="LEFT"/>|concat_path(path: Union[str, os.PathLike], suffix: str): Union[str, os.PathLike]<br ALIGN="LEFT"/>create_stream(path: Union[str, os.PathLike], mode: str): Generator[io.IOBase, None, None]<br ALIGN="LEFT"/>exists(path: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>init_path(path: Union[str, os.PathLike]): Union[str, os.PathLike]<br ALIGN="LEFT"/>mkdir(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>rename(path: Union[str, os.PathLike], new_path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>rm_file(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystem" [color="black", fontcolor="black", label=<{FileSystem|<br ALIGN="LEFT"/>|concat_path(path: Union[str, os.PathLike], suffix: str): Union[str, os.PathLike]<br ALIGN="LEFT"/>create_stream(path: Union[str, os.PathLike], mode: str): Generator[io.IOBase, None, None]<br ALIGN="LEFT"/>exists(path: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>init_path(path: Union[str, os.PathLike]): Union[str, os.PathLike]<br ALIGN="LEFT"/>mkdir(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>rename(path: Union[str, os.PathLike], new_path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>rm_file(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/>validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystemBase" [color="black", fontcolor="black", label=<{FileSystemBase|<br ALIGN="LEFT"/>|<I>concat_path</I>(path: Union[str, os.PathLike], suffix: str): Union[str, os.PathLike]<br ALIGN="LEFT"/><I>create_stream</I>(path: Union[str, os.PathLike], mode: str): Generator[io.IOBase, None, None]<br ALIGN="LEFT"/><I>exists</I>(path: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/><I>init_path</I>(path: Union[str, os.PathLike]): Union[str, os.PathLike]<br ALIGN="LEFT"/><I>mkdir</I>(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/><I>rename</I>(path: Union[str, os.PathLike], new_path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/><I>rm_file</I>(path: Union[str, os.PathLike]): None<br ALIGN="LEFT"/><I>validate_checkpoint_id</I>(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystemReader" [color="black", fontcolor="black", label=<{FileSystemReader|checkpoint_id<br ALIGN="LEFT"/>fs<br ALIGN="LEFT"/>load_id : str<br ALIGN="LEFT"/>path : NoneType, Path<br ALIGN="LEFT"/>storage_data : Dict[MetadataIndex, _StorageInfo], dict<br ALIGN="LEFT"/>|prepare_global_plan(plans: List[LoadPlan]): List[LoadPlan]<br ALIGN="LEFT"/>prepare_local_plan(plan: LoadPlan): LoadPlan<br ALIGN="LEFT"/>read_data(plan: LoadPlan, planner: LoadPlanner): Future[None]<br ALIGN="LEFT"/>read_metadata(): Metadata<br ALIGN="LEFT"/>reset(checkpoint_id: Union[str, os.PathLike, None]): None<br ALIGN="LEFT"/>set_up_storage_reader(metadata: Metadata, is_coordinator: bool): None<br ALIGN="LEFT"/>validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystemWriter" [color="black", fontcolor="black", label=<{FileSystemWriter|per_thread_copy_ahead : int<br ALIGN="LEFT"/>|stage(state_dict: STATE_DICT_TYPE): STATE_DICT_TYPE<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerClient" [color="black", fontcolor="black", label=<{FileTimerClient|signal<br ALIGN="LEFT"/>|acquire(scope_id: str, expiration_time: float): None<br ALIGN="LEFT"/>release(scope_id: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerRequest" [color="black", fontcolor="black", label=<{FileTimerRequest|expiration_time : float<br ALIGN="LEFT"/>scope_id : str<br ALIGN="LEFT"/>signal : int<br ALIGN="LEFT"/>version : int<br ALIGN="LEFT"/>worker_pid : int<br ALIGN="LEFT"/>|to_json(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerServer" [color="black", fontcolor="black", label=<{FileTimerServer|<br ALIGN="LEFT"/>|clear_timers(worker_pids: Set[int]): None<br ALIGN="LEFT"/>get_expired_timers(deadline: float): Dict[int, List[FileTimerRequest]]<br ALIGN="LEFT"/>get_last_progress_time(): int<br ALIGN="LEFT"/>is_process_running(pid: int)<br ALIGN="LEFT"/>register_timers(timer_requests: List[FileTimerRequest]): None<br ALIGN="LEFT"/>run_once(): None<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.tensorboard.writer.FileWriter" [color="black", fontcolor="black", label=<{FileWriter|event_writer<br ALIGN="LEFT"/>|add_event(event, step, walltime)<br ALIGN="LEFT"/>add_graph(graph_profile, walltime)<br ALIGN="LEFT"/>add_onnx_graph(graph, walltime)<br ALIGN="LEFT"/>add_summary(summary, global_step, walltime)<br ALIGN="LEFT"/>close()<br ALIGN="LEFT"/>flush()<br ALIGN="LEFT"/>get_logdir()<br ALIGN="LEFT"/>reopen()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.FilterDataFramesPipe" [color="black", fontcolor="black", label=<{FilterDataFramesPipe|filter_fn<br ALIGN="LEFT"/>source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.selecting.FilterIterDataPipe" [color="black", fontcolor="black", label=<{FilterIterDataPipe|datapipe : IterDataPipe[_T_co]<br ALIGN="LEFT"/>filter_fn : Callable<br ALIGN="LEFT"/>input_col : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.FilterVariable" [color="black", fontcolor="black", label=<{FilterVariable|fn<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>iterable : Union[List[VariableTracker], VariableTracker]<br ALIGN="LEFT"/>|has_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>reconstruct_items(codegen)<br ALIGN="LEFT"/>unpack_var_sequence(tx): List['VariableTracker']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.serialize.Final" [color="black", fontcolor="black", label=<{Final|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.fishersnedecor.FisherSnedecor" [color="black", fontcolor="black", label=<{FisherSnedecor|arg_constraints : dict<br ALIGN="LEFT"/>df1<br ALIGN="LEFT"/>df2<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._fix.Fix" [color="black", fontcolor="black", label=<{Fix|artifact_changes : List[_artifact_change.ArtifactChange]<br ALIGN="LEFT"/>description : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.FixedLayout" [color="black", fontcolor="black", label=<{FixedLayout|dtype<br ALIGN="LEFT"/>|make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.bytecode_analysis.FixedPointBox" [color="black", fontcolor="black", label=<{FixedPointBox|value : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize" [color="black", fontcolor="black", label=<{FixedQParamsFakeQuantize|scale<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.FixedQParamsObserver" [color="black", fontcolor="black", label=<{FixedQParamsObserver|dtype<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>quant_max : int<br ALIGN="LEFT"/>quant_min : int<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(X)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.FixedQParamsOpQuantizeHandler" [color="black", fontcolor="black", label=<{FixedQParamsOpQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.FixedQParamsQuantizationSpec" [color="black", fontcolor="black", label=<{FixedQParamsQuantizationSpec|dtype<br ALIGN="LEFT"/>is_dynamic : bool<br ALIGN="LEFT"/>qscheme : Optional[torch.qscheme]<br ALIGN="LEFT"/>quant_max : Optional[int]<br ALIGN="LEFT"/>quant_min : Optional[int]<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.FixedTritonConfig" [color="black", fontcolor="black", label=<{FixedTritonConfig|config : Dict[str, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._ndarray.Flags" [color="black", fontcolor="black", label=<{Flags|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.unflatten.FlatArgsAdapter" [color="black", fontcolor="black", label=<{FlatArgsAdapter|<br ALIGN="LEFT"/>|<I>adapt</I>(target_spec: pytree.TreeSpec, input_spec: pytree.TreeSpec, input_args: List[Any]): List[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.FlatParamHandle" [color="black", fontcolor="black", label=<{FlatParamHandle|device<br ALIGN="LEFT"/>flat_param<br ALIGN="LEFT"/>process_group<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>sharded_grad<br ALIGN="LEFT"/>uses_sharded_strategy<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|flat_param_to()<br ALIGN="LEFT"/>flatten_tensors(tensors: List[Tensor], aligned_numel: int): Tensor<br ALIGN="LEFT"/>flatten_tensors_into_flat_param(tensors: List[Tensor], aligned_numel: int, requires_grad: bool): FlatParameter<br ALIGN="LEFT"/>init_flat_param_attributes(): None<br ALIGN="LEFT"/>is_sharded(tensor: Tensor): bool<br ALIGN="LEFT"/>needs_unshard(): bool<br ALIGN="LEFT"/>param_module_names(): Iterator[Tuple[str, str]]<br ALIGN="LEFT"/>post_reshard()<br ALIGN="LEFT"/>post_unshard()<br ALIGN="LEFT"/>pre_unshard(): bool<br ALIGN="LEFT"/>prepare_gradient_for_backward()<br ALIGN="LEFT"/>prepare_gradient_for_optim()<br ALIGN="LEFT"/>reshard(free_unsharded_flat_param: bool)<br ALIGN="LEFT"/>reshard_grad()<br ALIGN="LEFT"/>shard()<br ALIGN="LEFT"/>shard_metadata(): FlatParamShardMetadata<br ALIGN="LEFT"/>shared_param_module_names(): Iterator[Tuple[str, str]]<br ALIGN="LEFT"/>to_cpu()<br ALIGN="LEFT"/>unflatten_as_params(): Generator<br ALIGN="LEFT"/>unshard()<br ALIGN="LEFT"/>unshard_grad()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.FlatParamShardMetadata" [color="black", fontcolor="black", label=<{FlatParamShardMetadata|param_contiguities : Tuple[bool, ...]<br ALIGN="LEFT"/>param_names : Tuple[str, ...]<br ALIGN="LEFT"/>param_numels : Tuple[int, ...]<br ALIGN="LEFT"/>param_offsets : Tuple[Tuple[int, int], ...]<br ALIGN="LEFT"/>param_shapes : Tuple[torch.Size, ...]<br ALIGN="LEFT"/>param_strides : Tuple[Tuple[int, ...], ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.FlatParameter" [color="black", fontcolor="black", label=<{FlatParameter|data<br ALIGN="LEFT"/>grad : NoneType<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.Flatten" [color="black", fontcolor="black", label=<{Flatten|input_dims : Sequence[DimSpec]<br ALIGN="LEFT"/>|inputs(): Iterable[DimSpec]<br ALIGN="LEFT"/>new(dims: Sequence[DimSpec]): DimSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.flatten.Flatten" [color="black", fontcolor="black", label=<{Flatten|end_dim : int<br ALIGN="LEFT"/>start_dim : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.FlattenInputOutputSignature" [color="black", fontcolor="black", label=<{FlattenInputOutputSignature|current_node<br ALIGN="LEFT"/>flat_results : List[Any]<br ALIGN="LEFT"/>matched_output_elements_positions : List[int]<br ALIGN="LEFT"/>new_args : list<br ALIGN="LEFT"/>old_args_gen<br ALIGN="LEFT"/>|output(target, args, kwargs)<br ALIGN="LEFT"/>placeholder(target, args, kwargs)<br ALIGN="LEFT"/>run_node(n)<br ALIGN="LEFT"/>transform()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.FlattenInputWithTreeSpecValidationInputStep" [color="black", fontcolor="black", label=<{FlattenInputWithTreeSpecValidationInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.FlattenOutputStep" [color="black", fontcolor="black", label=<{FlattenOutputStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Sequence[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.FlattenOutputWithTreeSpecValidationOutputStep" [color="black", fontcolor="black", label=<{FlattenOutputWithTreeSpecValidationOutputStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Sequence[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.FlattenScriptObjectSource" [color="black", fontcolor="black", label=<{FlattenScriptObjectSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.flex_attention.FlexAttentionAutogradOp" [color="black", fontcolor="black", label=<{FlexAttentionAutogradOp|<br ALIGN="LEFT"/>|backward(ctx: Any, grad_out: Tensor, grad_logsumexp: Tensor): Tuple[Optional[Tensor], ...]<br ALIGN="LEFT"/>forward(ctx: Any, query: Tensor, key: Tensor, value: Tensor, fw_graph: Callable, joint_graph: Callable, block_mask: Tuple[Any, ...], scale: float, kernel_options: Dict[str, Any], mask_mod_other_buffers: Tuple[Any, ...]): Tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.flex_attention.FlexAttentionBackwardHOP" [color="black", fontcolor="black", label=<{FlexAttentionBackwardHOP|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.flex_attention.FlexAttentionHOP" [color="black", fontcolor="black", label=<{FlexAttentionHOP|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.FlexAttentionHigherOrderVariable" [color="black", fontcolor="black", label=<{FlexAttentionHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create_wrapped_node(tx: 'InstructionTranslator', query: 'VariableTracker', fn: 'VariableTracker', fn_name: str)<br ALIGN="LEFT"/>normalize_to_args(args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.FlexibleLayout" [color="black", fontcolor="black", label=<{FlexibleLayout|allow_indexing : bool<br ALIGN="LEFT"/>|as_exact_strides(exact_strides, allow_padding)<br ALIGN="LEFT"/>as_fill_order(order)<br ALIGN="LEFT"/>as_same_order(stride)<br ALIGN="LEFT"/>as_stride_order(order, allow_padding)<br ALIGN="LEFT"/>contiguous_strides(sizes)<br ALIGN="LEFT"/>fill_ordered(sizes, order)<br ALIGN="LEFT"/>same_ordered(sizes, stride)<br ALIGN="LEFT"/>stride_ordered(sizes, order)<br ALIGN="LEFT"/>stride_ordered_for_memory_format(sizes, memory_format)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" [color="black", fontcolor="black", label=<{FloatFunctional|activation_post_process<br ALIGN="LEFT"/>|add(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_relu(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>cat(x: List[Tensor], dim: int): Tensor<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>matmul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.FloatPow" [color="black", fontcolor="black", label=<{FloatPow|is_real : bool<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base, exp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.FloatStorage" [color="black", fontcolor="black", label=<{FloatStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.FloatStorage" [color="black", fontcolor="black", label=<{FloatStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.FloatTensorSource" [color="black", fontcolor="black", label=<{FloatTensorSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.FloatTrueDiv" [color="black", fontcolor="black", label=<{FloatTrueDiv|is_real : bool<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base, divisor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.FloorDiv" [color="black", fontcolor="black", label=<{FloorDiv|base<br ALIGN="LEFT"/>divisor<br ALIGN="LEFT"/>is_integer : bool<br ALIGN="LEFT"/>nargs : Tuple[int, ...]<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base: sympy.Integer, divisor: sympy.Integer): Union[sympy.Basic, None]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.FloorToInt" [color="black", fontcolor="black", label=<{FloorToInt|is_integer : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.flop_counter.FlopCounterMode" [color="black", fontcolor="black", label=<{FlopCounterMode|depth : int<br ALIGN="LEFT"/>display : bool<br ALIGN="LEFT"/>flop_counts : Dict[str, Dict[Any, int]]<br ALIGN="LEFT"/>flop_registry<br ALIGN="LEFT"/>mod_tracker<br ALIGN="LEFT"/>mode : NoneType, Optional[_FlopCounterMode]<br ALIGN="LEFT"/>|get_flop_counts(): Dict[str, Dict[Any, int]]<br ALIGN="LEFT"/>get_table(depth)<br ALIGN="LEFT"/>get_total_flops(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.fn_with_kwargs.FnWithKwargs" [color="black", fontcolor="black", label=<{FnWithKwargs|<br ALIGN="LEFT"/>|forward(pos0, tuple0)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.fold.Fold" [color="black", fontcolor="black", label=<{Fold|dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>output_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.const_fold.FoldedGraphModule" [color="black", fontcolor="black", label=<{FoldedGraphModule|const_subgraph_module : NoneType<br ALIGN="LEFT"/>device_for_folded_attrs : str<br ALIGN="LEFT"/>fx_const_folded_attrs_name : Optional[str]<br ALIGN="LEFT"/>has_folding_been_run : bool<br ALIGN="LEFT"/>|run_folding()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.Foo" [color="black", fontcolor="black", label=<{Foo|bar : int<br ALIGN="LEFT"/>x<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.FooBackendOptions" [color="black", fontcolor="black", label=<{FooBackendOptions|init_method<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.ForLoopIndexingPattern" [color="black", fontcolor="black", label=<{ForLoopIndexingPattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>visited : Set[int]<br ALIGN="LEFT"/>|eventTreeTraversal()<br ALIGN="LEFT"/>match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.ForeachFuncInfo" [color="black", fontcolor="black", label=<{ForeachFuncInfo|backward_requires_result : bool<br ALIGN="LEFT"/>dtypes<br ALIGN="LEFT"/>has_no_in_place<br ALIGN="LEFT"/>inplace_variant<br ALIGN="LEFT"/>method_variant<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>ref<br ALIGN="LEFT"/>ref_inplace<br ALIGN="LEFT"/>supports_alpha_param : bool<br ALIGN="LEFT"/>supports_scalar_self_arg : bool<br ALIGN="LEFT"/>|sample_zero_size_inputs(device, dtype, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.ForeachKernelSchedulerNode" [color="black", fontcolor="black", label=<{ForeachKernelSchedulerNode|ancestors<br ALIGN="LEFT"/>enable_autotune : bool<br ALIGN="LEFT"/>group : tuple<br ALIGN="LEFT"/>group_algorithm_for_combo_kernels : Callable[[Scheduler], List[List[BaseSchedulerNode]]]<br ALIGN="LEFT"/>max_order<br ALIGN="LEFT"/>min_order<br ALIGN="LEFT"/>name_to_node : dict<br ALIGN="LEFT"/>node : NoneType<br ALIGN="LEFT"/>origins<br ALIGN="LEFT"/>read_to_node : dict<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>snodes<br ALIGN="LEFT"/>unmet_dependencies<br ALIGN="LEFT"/>use_custom_partition_algo : bool<br ALIGN="LEFT"/>users : List[NodeUser]<br ALIGN="LEFT"/>|can_fuse(producer: BaseSchedulerNode, consumer: BaseSchedulerNode): bool<br ALIGN="LEFT"/><I>codegen</I>(): None<br ALIGN="LEFT"/>combinable_nodes(nodes: List[BaseSchedulerNode]): List[BaseSchedulerNode]<br ALIGN="LEFT"/>fuse(producer: BaseSchedulerNode, consumer: BaseSchedulerNode): ForeachKernelSchedulerNode<br ALIGN="LEFT"/>get_consumer_subnode_for(producer: BaseSchedulerNode): Optional[BaseSchedulerNode]<br ALIGN="LEFT"/>get_first_name(): str<br ALIGN="LEFT"/>get_nodes(): Sequence[BaseSchedulerNode]<br ALIGN="LEFT"/>get_producer_subnode_for(consumer: BaseSchedulerNode): Optional[BaseSchedulerNode]<br ALIGN="LEFT"/>get_subkernel_nodes(): List[BaseSchedulerNode]<br ALIGN="LEFT"/>group_nodes_for_combo_kernels(scheduler: Scheduler): List[List[BaseSchedulerNode]]<br ALIGN="LEFT"/>is_foreach(): bool<br ALIGN="LEFT"/><I>mark_run</I>(): None<br ALIGN="LEFT"/>prune_redundant_deps(name_to_fused_node: Dict[str, BaseSchedulerNode]): None<br ALIGN="LEFT"/>set_group_algorithm_for_combo_kernels(custom_group_algorithm: Callable[[Scheduler], List[List[BaseSchedulerNode]]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.foreach_map.ForeachMap" [color="black", fontcolor="black", label=<{ForeachMap|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.ForeachRightmostArgType" [color="black", fontcolor="black", label=<{ForeachRightmostArgType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.ForeachSampleInput" [color="black", fontcolor="black", label=<{ForeachSampleInput|disable_fastpath : bool<br ALIGN="LEFT"/>ref_args : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining.ForkerIterDataPipe" [color="black", fontcolor="black", label=<{ForkerIterDataPipe|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.format_utils.FormatMode" [color="black", fontcolor="black", label=<{FormatMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler_util.FormattedTimesMixin" [color="black", fontcolor="black", label=<{FormattedTimesMixin|cpu_time<br ALIGN="LEFT"/>cpu_time_str<br ALIGN="LEFT"/>cpu_time_total_str<br ALIGN="LEFT"/>cuda_time<br ALIGN="LEFT"/>device_time<br ALIGN="LEFT"/>device_time_str<br ALIGN="LEFT"/>device_time_total_str<br ALIGN="LEFT"/>self_cpu_time_total_str<br ALIGN="LEFT"/>self_device_time_total_str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.ForwardHasDefaultArgs" [color="black", fontcolor="black", label=<{ForwardHasDefaultArgs|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, idx)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x, idx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.FractionalMaxPool2d" [color="black", fontcolor="black", label=<{FractionalMaxPool2d|kernel_size : Union<br ALIGN="LEFT"/>output_ratio : Union<br ALIGN="LEFT"/>output_size : Union<br ALIGN="LEFT"/>return_indices : bool<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.FractionalMaxPool3d" [color="black", fontcolor="black", label=<{FractionalMaxPool3d|kernel_size : Union<br ALIGN="LEFT"/>output_ratio : Union<br ALIGN="LEFT"/>output_size : Union<br ALIGN="LEFT"/>return_indices : bool<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.FrameStateSizeEntry" [color="black", fontcolor="black", label=<{FrameStateSizeEntry|scalar : Union[int, AutoDynamic, AutoUnset]<br ALIGN="LEFT"/>size : Union[AutoDynamic, AutoUnset, Tuple[Union[int, AutoDynamic], ...]]<br ALIGN="LEFT"/>stride : Union[AutoDynamic, AutoUnset, Tuple[Union[int, AutoDynamic, InferStride], ...]]<br ALIGN="LEFT"/>|is_size_dynamic(dim: int): bool<br ALIGN="LEFT"/>is_stride_dynamic(dim: int): bool<br ALIGN="LEFT"/>make_scalar(x: int): FrameStateSizeEntry<br ALIGN="LEFT"/>make_size(size: Tuple[int, ...]): FrameStateSizeEntry<br ALIGN="LEFT"/>make_tensor(size: Tuple[int, ...], stride: Tuple[int, ...]): FrameStateSizeEntry<br ALIGN="LEFT"/>render(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.FreeIfNotReusedLine" [color="black", fontcolor="black", label=<{FreeIfNotReusedLine|is_reused : bool<br ALIGN="LEFT"/>node : Union<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>plan(state: MemoryPlanningState): MemoryPlanningLine<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies.FreeUnbackedSymbolsOpsHandler" [color="black", fontcolor="black", label=<{FreeUnbackedSymbolsOpsHandler|symbols : OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>|frexp(x)<br ALIGN="LEFT"/>indirect_indexing(index_var, size, check, wrap_neg): sympy.Symbol<br ALIGN="LEFT"/>masked(mask, body, other): None<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[None, Tuple[None, ...]]): Union[None, Tuple[None, ...]]<br ALIGN="LEFT"/>scan(dtypes, combine_fn, values)<br ALIGN="LEFT"/>sort(dtypes, values, stable, descending)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.memory.FreeableInputBuffer" [color="black", fontcolor="black", label=<{FreeableInputBuffer|mpi_buffer<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._freeze.Freezer" [color="black", fontcolor="black", label=<{Freezer|frozen_modules : List[FrozenModule]<br ALIGN="LEFT"/>indent : int<br ALIGN="LEFT"/>verbose : bool<br ALIGN="LEFT"/>|compile_file(path: Path, top_package_path: Path)<br ALIGN="LEFT"/>compile_package(path: Path, top_package_path: Path)<br ALIGN="LEFT"/>compile_path(path: Path, top_package_path: Path)<br ALIGN="LEFT"/>compile_string(file_content: str): types.CodeType<br ALIGN="LEFT"/>get_module_qualname(file_path: Path, top_package_path: Path): List[str]<br ALIGN="LEFT"/>msg(path: Path, code: str)<br ALIGN="LEFT"/>write_bytecode(install_root)<br ALIGN="LEFT"/>write_frozen(m: FrozenModule, outfp)<br ALIGN="LEFT"/>write_main(install_root, oss, symbol_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.frontend.FrontendError" [color="black", fontcolor="red", label=<{FrontendError|error_report<br ALIGN="LEFT"/>msg<br ALIGN="LEFT"/>source_range<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.frontend.FrontendTypeError" [color="black", fontcolor="red", label=<{FrontendTypeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.FrozenDataClassVariable" [color="black", fontcolor="black", label=<{FrozenDataClassVariable|fields : NoneType, dict<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>create(tx, value, source)<br ALIGN="LEFT"/>method_setattr_standard(tx: 'InstructionTranslator', name, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._freeze.FrozenModule" [color="black", fontcolor="black", label=<{FrozenModule|bytecode : bytes<br ALIGN="LEFT"/>c_name : str<br ALIGN="LEFT"/>module_name : str<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" [color="black", fontcolor="black", label=<{FrozensetVariable|set_items<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint._fsspec_filesystem.FsspecReader" [color="black", fontcolor="black", label=<{FsspecReader|fs<br ALIGN="LEFT"/>path : Path<br ALIGN="LEFT"/>|validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint._fsspec_filesystem.FsspecWriter" [color="black", fontcolor="black", label=<{FsspecWriter|fs<br ALIGN="LEFT"/>path : Path<br ALIGN="LEFT"/>|validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.FullOptimStateDictConfig" [color="black", fontcolor="black", label=<{FullOptimStateDictConfig|rank0_only : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.FullStateDictConfig" [color="black", fontcolor="black", label=<{FullStateDictConfig|rank0_only : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.test_compiled_fsdp.FullyShardMode" [color="black", fontcolor="black", label=<{FullyShardMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel" [color="black", fontcolor="black", label=<{FullyShardedDataParallel|module<br ALIGN="LEFT"/>training_state : IDLE<br ALIGN="LEFT"/>|apply(fn: Callable[[nn.Module], None]): 'FullyShardedDataParallel'<br ALIGN="LEFT"/>check_is_root(): bool<br ALIGN="LEFT"/>clip_grad_norm_(max_norm: Union[float, int], norm_type: Union[float, int]): torch.Tensor<br ALIGN="LEFT"/>flatten_sharded_optim_state_dict(sharded_optim_state_dict: Dict[str, Any], model: torch.nn.Module, optim: torch.optim.Optimizer): Dict[str, Any]<br ALIGN="LEFT"/>forward(): Any<br ALIGN="LEFT"/>fsdp_modules(module: nn.Module, root_only: bool): List['FullyShardedDataParallel']<br ALIGN="LEFT"/>full_optim_state_dict(model: torch.nn.Module, optim: torch.optim.Optimizer, optim_input: Optional[Union[List[Dict[str, Any]], Iterable[torch.nn.Parameter]]], rank0_only: bool, group: Optional[dist.ProcessGroup]): Dict[str, Any]<br ALIGN="LEFT"/>get_state_dict_type(module: nn.Module): StateDictSettings<br ALIGN="LEFT"/>named_buffers(): Iterator[Tuple[str, torch.Tensor]]<br ALIGN="LEFT"/>named_parameters(): Iterator[Tuple[str, torch.nn.Parameter]]<br ALIGN="LEFT"/>no_sync(): Generator<br ALIGN="LEFT"/>optim_state_dict(model: torch.nn.Module, optim: torch.optim.Optimizer, optim_state_dict: Optional[Dict[str, Any]], group: Optional[dist.ProcessGroup]): Dict[str, Any]<br ALIGN="LEFT"/>optim_state_dict_to_load(model: torch.nn.Module, optim: torch.optim.Optimizer, optim_state_dict: Dict[str, Any], is_named_optimizer: bool, load_directly: bool, group: Optional[dist.ProcessGroup]): Dict[str, Any]<br ALIGN="LEFT"/>register_comm_hook(state: object, hook: callable)<br ALIGN="LEFT"/>rekey_optim_state_dict(optim_state_dict: Dict[str, Any], optim_state_key_type: OptimStateKeyType, model: torch.nn.Module, optim_input: Optional[Union[List[Dict[str, Any]], Iterable[torch.nn.Parameter]]], optim: Optional[torch.optim.Optimizer]): Dict[str, Any]<br ALIGN="LEFT"/>scatter_full_optim_state_dict(full_optim_state_dict: Optional[Dict[str, Any]], model: torch.nn.Module, optim_input: Optional[Union[List[Dict[str, Any]], Iterable[torch.nn.Parameter]]], optim: Optional[torch.optim.Optimizer], group: Optional[Any]): Dict[str, Any]<br ALIGN="LEFT"/>set_state_dict_type(module: nn.Module, state_dict_type: StateDictType, state_dict_config: Optional[StateDictConfig], optim_state_dict_config: Optional[OptimStateDictConfig]): StateDictSettings<br ALIGN="LEFT"/>shard_full_optim_state_dict(full_optim_state_dict: Dict[str, Any], model: torch.nn.Module, optim_input: Optional[Union[List[Dict[str, Any]], Iterable[torch.nn.Parameter]]], optim: Optional[torch.optim.Optimizer]): Dict[str, Any]<br ALIGN="LEFT"/>sharded_optim_state_dict(model: torch.nn.Module, optim: torch.optim.Optimizer, group: Optional[dist.ProcessGroup]): Dict[str, Any]<br ALIGN="LEFT"/>state_dict_type(module: nn.Module, state_dict_type: StateDictType, state_dict_config: Optional[StateDictConfig], optim_state_dict_config: Optional[OptimStateDictConfig]): Generator<br ALIGN="LEFT"/>summon_full_params(module: nn.Module, recurse: bool, writeback: bool, rank0_only: bool, offload_to_cpu: bool, with_grads: bool): Generator<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._custom_op.impl.FuncAndLocation" [color="black", fontcolor="black", label=<{FuncAndLocation|func : Callable<br ALIGN="LEFT"/>location : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.pyfunctorch.FuncTorchInterpreter" [color="black", fontcolor="black", label=<{FuncTorchInterpreter|<br ALIGN="LEFT"/>|check_state(state)<br ALIGN="LEFT"/><I>get_state</I>()<br ALIGN="LEFT"/>key()<br ALIGN="LEFT"/>level()<br ALIGN="LEFT"/>lower()<br ALIGN="LEFT"/><I>process</I>(op, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function.Function" [color="black", fontcolor="black", label=<{Function|generate_vmap_rule : bool<br ALIGN="LEFT"/>|apply()<br ALIGN="LEFT"/><I>vmap</I>(info, in_dims)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCount" [color="black", fontcolor="black", label=<{FunctionCount|count : int<br ALIGN="LEFT"/>function : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts" [color="black", fontcolor="black", label=<{FunctionCounts|inclusive : bool<br ALIGN="LEFT"/>truncate_rows : bool<br ALIGN="LEFT"/>|denoise(): 'FunctionCounts'<br ALIGN="LEFT"/>filter(filter_fn: Callable[[str], bool]): 'FunctionCounts'<br ALIGN="LEFT"/>sum(): int<br ALIGN="LEFT"/>transform(map_fn: Callable[[str], str]): 'FunctionCounts'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function.FunctionCtx" [color="black", fontcolor="black", label=<{FunctionCtx|dirty_tensors : tuple<br ALIGN="LEFT"/>materialize_grads : bool<br ALIGN="LEFT"/>non_differentiable : tuple<br ALIGN="LEFT"/>saved_for_forward : tuple<br ALIGN="LEFT"/>to_save : tuple<br ALIGN="LEFT"/>|mark_dirty()<br ALIGN="LEFT"/>mark_non_differentiable()<br ALIGN="LEFT"/><I>mark_shared_storage</I>()<br ALIGN="LEFT"/>save_for_backward()<br ALIGN="LEFT"/>save_for_forward()<br ALIGN="LEFT"/>set_materialize_grads(value: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler_util.FunctionEvent" [color="black", fontcolor="black", label=<{FunctionEvent|concrete_inputs : Optional[List[Any]]<br ALIGN="LEFT"/>count : int<br ALIGN="LEFT"/>cpu_children : List[FunctionEvent]<br ALIGN="LEFT"/>cpu_memory_usage : int<br ALIGN="LEFT"/>cpu_parent : Optional[FunctionEvent]<br ALIGN="LEFT"/>cpu_time_total<br ALIGN="LEFT"/>cuda_time_total<br ALIGN="LEFT"/>device_index : int<br ALIGN="LEFT"/>device_memory_usage : int<br ALIGN="LEFT"/>device_resource_id : int<br ALIGN="LEFT"/>device_time_total<br ALIGN="LEFT"/>device_type<br ALIGN="LEFT"/>flops : Optional[int]<br ALIGN="LEFT"/>fwd_thread : Optional[int]<br ALIGN="LEFT"/>id : int<br ALIGN="LEFT"/>input_shapes : Optional[Tuple[int, ...]]<br ALIGN="LEFT"/>is_async : bool<br ALIGN="LEFT"/>is_legacy : bool<br ALIGN="LEFT"/>is_remote : bool<br ALIGN="LEFT"/>is_user_annotation : Optional[bool]<br ALIGN="LEFT"/>kernels : List[Kernel]<br ALIGN="LEFT"/>key<br ALIGN="LEFT"/>kwinputs : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>node_id : int<br ALIGN="LEFT"/>scope : int<br ALIGN="LEFT"/>self_cpu_memory_usage<br ALIGN="LEFT"/>self_cpu_percent : int<br ALIGN="LEFT"/>self_cpu_time_total<br ALIGN="LEFT"/>self_cuda_memory_usage<br ALIGN="LEFT"/>self_cuda_time_total<br ALIGN="LEFT"/>self_device_memory_usage<br ALIGN="LEFT"/>self_device_time_total<br ALIGN="LEFT"/>sequence_nr : int<br ALIGN="LEFT"/>stack : Optional[List]<br ALIGN="LEFT"/>thread : int<br ALIGN="LEFT"/>time_range<br ALIGN="LEFT"/>total_cpu_percent : int<br ALIGN="LEFT"/>total_device_percent : int<br ALIGN="LEFT"/>trace_name : Optional[str]<br ALIGN="LEFT"/>use_device : Optional[str]<br ALIGN="LEFT"/>|append_cpu_child(child)<br ALIGN="LEFT"/>append_kernel(name, device, duration)<br ALIGN="LEFT"/>set_cpu_parent(parent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler_util.FunctionEventAvg" [color="black", fontcolor="black", label=<{FunctionEventAvg|count : int<br ALIGN="LEFT"/>cpu_children : Optional[List[FunctionEvent]]<br ALIGN="LEFT"/>cpu_memory_usage : int<br ALIGN="LEFT"/>cpu_parent : Optional[FunctionEvent]<br ALIGN="LEFT"/>cpu_time_total : int<br ALIGN="LEFT"/>device_memory_usage : int<br ALIGN="LEFT"/>device_time_total : int<br ALIGN="LEFT"/>device_type<br ALIGN="LEFT"/>flops : int<br ALIGN="LEFT"/>input_shapes : Optional[List[List[int]]]<br ALIGN="LEFT"/>is_async : bool<br ALIGN="LEFT"/>is_legacy : bool<br ALIGN="LEFT"/>is_remote : bool<br ALIGN="LEFT"/>is_user_annotation<br ALIGN="LEFT"/>key : Optional[str]<br ALIGN="LEFT"/>node_id : int<br ALIGN="LEFT"/>scope : Optional[int]<br ALIGN="LEFT"/>self_cpu_memory_usage : int<br ALIGN="LEFT"/>self_cpu_time_total : int<br ALIGN="LEFT"/>self_device_memory_usage : int<br ALIGN="LEFT"/>self_device_time_total : int<br ALIGN="LEFT"/>stack : Optional[List]<br ALIGN="LEFT"/>use_device : Optional[str]<br ALIGN="LEFT"/>|add(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.FunctionID" [color="black", fontcolor="black", label=<{FunctionID|id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.trace_rules.FunctionIdSet" [color="black", fontcolor="black", label=<{FunctionIdSet|function_ids : Optional[Set[int]]<br ALIGN="LEFT"/>function_names : Optional[Dict[int, str]]<br ALIGN="LEFT"/>lazy_initializer : Callable[[], Union[Dict[int, str], Set[int]]]<br ALIGN="LEFT"/>|add(idx: int)<br ALIGN="LEFT"/>get_name(idx: int, default: str)<br ALIGN="LEFT"/>remove(idx: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.trace_rules.FunctionInfo" [color="black", fontcolor="black", label=<{FunctionInfo|code : Optional[types.CodeType]<br ALIGN="LEFT"/>filename : str<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>py_obj : Optional[object]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.FunctionInput" [color="black", fontcolor="black", label=<{FunctionInput|args : tuple<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.function.FunctionMeta" [color="black", fontcolor="black", label=<{FunctionMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._jit_internal.FunctionModifiers" [color="black", fontcolor="black", label=<{FunctionModifiers|COPY_TO_SCRIPT_WRAPPER : str<br ALIGN="LEFT"/>DEFAULT : str<br ALIGN="LEFT"/>EXPORT : str<br ALIGN="LEFT"/>IGNORE : str<br ALIGN="LEFT"/>UNUSED : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.prim_hop_base.FunctionWithNoFreeVars" [color="black", fontcolor="black", label=<{FunctionWithNoFreeVars|fn<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.FunctionalCallVariable" [color="black", fontcolor="black", label=<{FunctionalCallVariable|<br ALIGN="LEFT"/>|call_function(tx, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" [color="black", fontcolor="black", label=<{FunctionalConv2d|bias<br ALIGN="LEFT"/>dilation : tuple<br ALIGN="LEFT"/>groups : int<br ALIGN="LEFT"/>padding : tuple<br ALIGN="LEFT"/>stride : tuple<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConvReluConvModel" [color="black", fontcolor="black", label=<{FunctionalConvReluConvModel|conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConvReluModel" [color="black", fontcolor="black", label=<{FunctionalConvReluModel|conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" [color="black", fontcolor="black", label=<{FunctionalLinear|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinearAddModel" [color="black", fontcolor="black", label=<{FunctionalLinearAddModel|linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinearReluLinearModel" [color="black", fontcolor="black", label=<{FunctionalLinearReluLinearModel|linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinearReluModel" [color="black", fontcolor="black", label=<{FunctionalLinearReluModel|linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.wrap_functional.FunctionalModule" [color="black", fontcolor="black", label=<{FunctionalModule|<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.make_functional.FunctionalModule" [color="black", fontcolor="black", label=<{FunctionalModule|names_map : Dict[str, List[str]]<br ALIGN="LEFT"/>param_names : Tuple[str, ...]<br ALIGN="LEFT"/>stateless_model<br ALIGN="LEFT"/>|forward(params: Iterable[Tensor]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.make_functional.FunctionalModuleWithBuffers" [color="black", fontcolor="black", label=<{FunctionalModuleWithBuffers|all_names_map : dict<br ALIGN="LEFT"/>buffer_names : Tuple[str, ...]<br ALIGN="LEFT"/>param_names : Tuple[str, ...]<br ALIGN="LEFT"/>stateless_model<br ALIGN="LEFT"/>|forward(params: Iterable[Tensor], buffers: Iterable[Tensor]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.operator_support.create_op_support.FunctionalOperatorSupport" [color="black", fontcolor="black", label=<{FunctionalOperatorSupport|<br ALIGN="LEFT"/>|is_node_supported(submodules: t.Mapping[str, torch.nn.Module], node: torch.fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.FunctionalTensor" [color="black", fontcolor="black", label=<{FunctionalTensor|bfloat16<br ALIGN="LEFT"/>bool<br ALIGN="LEFT"/>byte<br ALIGN="LEFT"/>char<br ALIGN="LEFT"/>cpu<br ALIGN="LEFT"/>double<br ALIGN="LEFT"/>elem<br ALIGN="LEFT"/>float<br ALIGN="LEFT"/>half<br ALIGN="LEFT"/>int<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>long<br ALIGN="LEFT"/>metadata_fns : list<br ALIGN="LEFT"/>|commit_update(): None<br ALIGN="LEFT"/>cuda(device)<br ALIGN="LEFT"/>from_functional()<br ALIGN="LEFT"/>is_base_tensor(): bool<br ALIGN="LEFT"/>mark_mutation_hidden_from_autograd(): None<br ALIGN="LEFT"/>replace_(output): None<br ALIGN="LEFT"/>sync(): None<br ALIGN="LEFT"/>to()<br ALIGN="LEFT"/>to_dense()<br ALIGN="LEFT"/>to_functional(x)<br ALIGN="LEFT"/>tolist(): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq" [color="black", fontcolor="black", label=<{FunctionalTensorMetadataEq|tensor<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.FunctionalTensorMode" [color="black", fontcolor="black", label=<{FunctionalTensorMode|enter_stack : list<br ALIGN="LEFT"/>export : bool<br ALIGN="LEFT"/>is_on_stack : bool<br ALIGN="LEFT"/>pre_dispatch : bool<br ALIGN="LEFT"/>|is_infra_mode(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.functionalization.Functionalize" [color="black", fontcolor="black", label=<{Functionalize|allow_fake_constant : bool \| None<br ALIGN="LEFT"/>enable_dynamic_axes : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.pyfunctorch.FunctionalizeInterpreter" [color="black", fontcolor="black", label=<{FunctionalizeInterpreter|<br ALIGN="LEFT"/>|functionalize_add_back_views()<br ALIGN="LEFT"/>get_state()<br ALIGN="LEFT"/>process(op, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.FunctionalizedRngRuntimeWrapper" [color="black", fontcolor="black", label=<{FunctionalizedRngRuntimeWrapper|return_new_outs : bool<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>pre_compile(flat_fn, flat_args, aot_config): Tuple[Callable, List[Tensor], ViewAndMutationMeta]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.FunctoolsPartialVariable" [color="black", fontcolor="black", label=<{FunctoolsPartialVariable|args<br ALIGN="LEFT"/>func<br ALIGN="LEFT"/>keywords<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>get_function()<br ALIGN="LEFT"/>guard_as_python_constant()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.FunctorchFunctionalizeAPI" [color="black", fontcolor="black", label=<{FunctorchFunctionalizeAPI|interpreter<br ALIGN="LEFT"/>|commit_update(tensor): None<br ALIGN="LEFT"/>functionalize(inner_f: Callable): Callable<br ALIGN="LEFT"/>mark_mutation_hidden_from_autograd(tensor): None<br ALIGN="LEFT"/>redispatch_to_next(): ContextManager<br ALIGN="LEFT"/>replace(input_tensor, output_tensor): None<br ALIGN="LEFT"/>sync(tensor): None<br ALIGN="LEFT"/>unwrap_tensors(args: Union[torch.Tensor, Tuple[torch.Tensor, ...]]): Union[torch.Tensor, Tuple[torch.Tensor, ...]]<br ALIGN="LEFT"/>wrap_tensors(args: Tuple[Any]): Tuple[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.FunctorchHigherOrderVariable" [color="black", fontcolor="black", label=<{FunctorchHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.custom_config.FuseCustomConfig" [color="black", fontcolor="black", label=<{FuseCustomConfig|preserved_attributes : List[str]<br ALIGN="LEFT"/>|from_dict(fuse_custom_config_dict: Dict[str, Any]): FuseCustomConfig<br ALIGN="LEFT"/>set_preserved_attributes(attributes: List[str]): FuseCustomConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.fuse_handler.FuseHandler" [color="black", fontcolor="black", label=<{FuseHandler|<br ALIGN="LEFT"/>|<I>fuse</I>(load_arg: Callable, named_modules: Dict[str, torch.nn.Module], fused_graph: Graph, root_node: Node, extra_inputs: List[Any], matched_node_pattern: NodePattern, fuse_custom_config: FuseCustomConfig, fuser_method_mapping: Dict[Pattern, Union[torch.nn.Sequential, Callable]], is_qat: bool): Node<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.graph_module.FusedGraphModule" [color="black", fontcolor="black", label=<{FusedGraphModule|preserved_attr_names : Set[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize" [color="black", fontcolor="black", label=<{FusedMovingAvgObsFakeQuantize|is_symmetric_quant<br ALIGN="LEFT"/>|calculate_qparams(): Tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>forward(X: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.FusedSchedulerNode" [color="black", fontcolor="black", label=<{FusedSchedulerNode|group<br ALIGN="LEFT"/>snodes : List[BaseSchedulerNode]<br ALIGN="LEFT"/>users : List[NodeUser]<br ALIGN="LEFT"/>|<I>add_fake_dep</I>(name: Dep): None<br ALIGN="LEFT"/><I>can_inplace</I>(read_dep: dependencies.Dep): bool<br ALIGN="LEFT"/>debug_str(): str<br ALIGN="LEFT"/>debug_str_extra(): str<br ALIGN="LEFT"/>debug_str_short(): str<br ALIGN="LEFT"/>fuse(node1: BaseSchedulerNode, node2: BaseSchedulerNode): FusedSchedulerNode<br ALIGN="LEFT"/>get_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_device(): torch.device<br ALIGN="LEFT"/>get_first_name(): str<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_nodes(): Sequence[BaseSchedulerNode]<br ALIGN="LEFT"/>get_outputs(): List[SchedulerBuffer]<br ALIGN="LEFT"/>get_template_node(): Optional[ir.TemplateBuffer]<br ALIGN="LEFT"/>has_aliasing_or_mutation(): bool<br ALIGN="LEFT"/>is_reduction(): bool<br ALIGN="LEFT"/>is_split_scan(): bool<br ALIGN="LEFT"/>is_template(): bool<br ALIGN="LEFT"/>reorder_loops_by_dep_pair(self_dep: MemoryDep, other_dep: MemoryDep): None<br ALIGN="LEFT"/>set_last_usage(future_used_buffers: OrderedSet[str], mutation_real_name: Dict[str, str]): None<br ALIGN="LEFT"/><I>update_mutated_names</I>(renames: Dict[str, str]): None<br ALIGN="LEFT"/>used_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>used_or_aliased_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.tools_common.FxNetAccFusionsFinder.FusionGroup" [color="black", fontcolor="black", label=<{FusionGroup|inputs : Set<br ALIGN="LEFT"/>nodes : Set<br ALIGN="LEFT"/>nodes_need_process : Set<br ALIGN="LEFT"/>top_node_idx : int<br ALIGN="LEFT"/>|add_node(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.futures.Future" [color="black", fontcolor="black", label=<{Future|<br ALIGN="LEFT"/>|add_done_callback(callback: Callable[[Future[T]], None]): None<br ALIGN="LEFT"/>done(): bool<br ALIGN="LEFT"/>set_exception(result: T): None<br ALIGN="LEFT"/>set_result(result: T): None<br ALIGN="LEFT"/>then(callback: Callable[[Future[T]], S]): Future[S]<br ALIGN="LEFT"/>value(): T<br ALIGN="LEFT"/>wait(): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.FutureTypingTest" [color="black", fontcolor="black", label=<{FutureTypingTest|<br ALIGN="LEFT"/>|test_future_passed_between_python_and_jit()<br ALIGN="LEFT"/>test_future_python_annotation()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.fuzzer.FuzzedParameter" [color="black", fontcolor="black", label=<{FuzzedParameter|name<br ALIGN="LEFT"/>strict : bool<br ALIGN="LEFT"/>|sample(state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.sparse_fuzzer.FuzzedSparseTensor" [color="black", fontcolor="black", label=<{FuzzedSparseTensor|<br ALIGN="LEFT"/>|sparse_tensor_constructor(size, dtype, sparse_dim, nnz, is_coalesced)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.fuzzer.FuzzedTensor" [color="black", fontcolor="black", label=<{FuzzedTensor|name<br ALIGN="LEFT"/>|default_tensor_constructor(size, dtype)<br ALIGN="LEFT"/>satisfies_constraints(params)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.fuzzer.Fuzzer" [color="black", fontcolor="black", label=<{Fuzzer|rejection_rate<br ALIGN="LEFT"/>|take(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compile_fx.FxCompile" [color="black", fontcolor="black", label=<{FxCompile|<br ALIGN="LEFT"/>|<I>codegen_and_compile</I>(gm: GraphModule, example_inputs: Sequence[InputType], inputs_to_check: Sequence[int], graph_kwargs: _CompileFxKwargs): OutputCode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.FxGraphCache" [color="black", fontcolor="black", label=<{FxGraphCache|<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>get_remote_cache(): Optional[RemoteCache[JsonDataTy]]<br ALIGN="LEFT"/>load_with_key(key: str, debug_lines: List[str], example_inputs: Sequence[InputType], local: bool, remote_cache: Optional[RemoteCache[JsonDataTy]], is_backward: bool, constants: CompiledFxGraphConstants): Tuple[Optional[CompiledFxGraph], Dict[str, Any]]<br ALIGN="LEFT"/>prepare_key(gm: torch.fx.GraphModule, example_inputs: Sequence[InputType], fx_kwargs: _CompileFxKwargs, inputs_to_check: Sequence[int], remote: bool): Tuple[Optional[Tuple[str, List[str]]], Dict[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.FxGraphCachePickler" [color="black", fontcolor="black", label=<{FxGraphCachePickler|dispatch_table : dict<br ALIGN="LEFT"/>fast : bool<br ALIGN="LEFT"/>include_non_inlined : bool<br ALIGN="LEFT"/>|debug_lines(inp: FxGraphHashDetails): List[str]<br ALIGN="LEFT"/>dumps(obj: Any): bytes<br ALIGN="LEFT"/>get_hash(obj: Any): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.graph_drawer.FxGraphDrawer" [color="black", fontcolor="black", label=<{FxGraphDrawer|dot_graph_shape : NoneType, str<br ALIGN="LEFT"/>normalize_args : bool<br ALIGN="LEFT"/>|get_all_dot_graphs(): Dict[str, pydot.Dot]<br ALIGN="LEFT"/>get_dot_graph(submod_name): pydot.Dot<br ALIGN="LEFT"/>get_main_dot_graph(): pydot.Dot<br ALIGN="LEFT"/>get_submod_dot_graph(submod_name): pydot.Dot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.FxGraphHashDetails" [color="black", fontcolor="black", label=<{FxGraphHashDetails|EXCLUDED_KWARGS : list<br ALIGN="LEFT"/>cache_key_tag : str<br ALIGN="LEFT"/>cuda_matmul_settings : tuple<br ALIGN="LEFT"/>deterministic_algorithms_settings : tuple<br ALIGN="LEFT"/>example_inputs : Sequence[InputType]<br ALIGN="LEFT"/>fx_kwargs : Dict[str, object]<br ALIGN="LEFT"/>gm<br ALIGN="LEFT"/>inductor_config<br ALIGN="LEFT"/>inputs_to_check : Sequence[int]<br ALIGN="LEFT"/>post_grad_custom_post_pass : NoneType<br ALIGN="LEFT"/>post_grad_custom_pre_pass : NoneType<br ALIGN="LEFT"/>system_info : dict<br ALIGN="LEFT"/>torch_version : bytes<br ALIGN="LEFT"/>user_defined_triton_source : List[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.tools_common.FxNetAccFusionsFinder" [color="black", fontcolor="black", label=<{FxNetAccFusionsFinder|acc_nodes : Set<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>nodes : list<br ALIGN="LEFT"/>|recursive_add_node(fusion_group: 'FxNetAccFusionsFinder.FusionGroup', inputs: Union[NodeSet, NodeList], visited: Optional[NodeSet])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base.FxNetAccNodesFinder" [color="black", fontcolor="black", label=<{FxNetAccNodesFinder|acc_nodes : Set<br ALIGN="LEFT"/>allow_non_tensor : bool<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>operator_support<br ALIGN="LEFT"/>|reduce_acc_nodes_non_tensor_input()<br ALIGN="LEFT"/>reduce_acc_nodes_non_tensor_input_helper(cpu_worklist: NodeList)<br ALIGN="LEFT"/>reduce_acc_nodes_non_tensor_output()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.net_min_base.FxNetMinimizerBadModuleError" [color="black", fontcolor="red", label=<{FxNetMinimizerBadModuleError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.net_min_base.FxNetMinimizerResultMismatchError" [color="black", fontcolor="red", label=<{FxNetMinimizerResultMismatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.net_min_base.FxNetMinimizerRunFuncError" [color="black", fontcolor="red", label=<{FxNetMinimizerRunFuncError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base.FxNetSplitterInternalError" [color="black", fontcolor="red", label=<{FxNetSplitterInternalError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter" [color="black", fontcolor="black", label=<{FxOnnxInterpreter|diagnostic_context<br ALIGN="LEFT"/>|call_function(node: torch.fx.Node, onnxscript_tracer: onnxscript_graph_building.TorchScriptTracingEvaluator, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]], onnxfunction_dispatcher: onnxfunction_dispatcher.OnnxFunctionDispatcher, fx_graph_module: torch.fx.GraphModule)<br ALIGN="LEFT"/>call_method(node: torch.fx.Node)<br ALIGN="LEFT"/>call_module(node: torch.fx.Node, parent_onnxscript_graph: onnxscript_graph_building.TorchScriptGraph, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]], tracer: onnxscript_graph_building.TorchScriptTracingEvaluator, root_fx_graph_module: torch.fx.GraphModule, onnxfunction_dispatcher: onnxfunction_dispatcher.OnnxFunctionDispatcher): None<br ALIGN="LEFT"/>get_attr(node: torch.fx.Node, onnxscript_graph: onnxscript_graph_building.TorchScriptGraph, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]], fx_graph_module: torch.fx.GraphModule)<br ALIGN="LEFT"/>output(node: torch.fx.Node, onnxscript_graph: onnxscript_graph_building.TorchScriptGraph, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]])<br ALIGN="LEFT"/>placeholder(node: torch.fx.Node, onnxscript_graph: onnxscript_graph_building.TorchScriptGraph, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]])<br ALIGN="LEFT"/>run(fx_graph_module: torch.fx.GraphModule, onnxfunction_dispatcher: onnxfunction_dispatcher.OnnxFunctionDispatcher, parent_onnxscript_graph: onnxscript_graph_building.TorchScriptGraph \| None): onnxscript_graph_building.TorchScriptGraph<br ALIGN="LEFT"/>run_node(node, fx_graph_module: torch.fx.GraphModule, onnxfunction_dispatcher: onnxfunction_dispatcher.OnnxFunctionDispatcher, onnxscript_graph: onnxscript_graph_building.TorchScriptGraph, onnxscript_tracer: onnxscript_graph_building.TorchScriptTracingEvaluator, fx_name_to_onnxscript_value: dict[str, onnxscript_graph_building.TorchScriptTensor \| tuple[onnxscript_graph_building.TorchScriptTensor, ...]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.GELU" [color="black", fontcolor="black", label=<{GELU|approximate : str<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.GLU" [color="black", fontcolor="black", label=<{GLU|dim : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.GPUDeviceBenchmarkMixin" [color="black", fontcolor="black", label=<{GPUDeviceBenchmarkMixin|<br ALIGN="LEFT"/>|do_bench(fn): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.GRU" [color="black", fontcolor="black", label=<{GRU|<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]): None<br ALIGN="LEFT"/>forward(input, hx)<br ALIGN="LEFT"/>forward_impl(input: Tensor, hx: Optional[Tensor], batch_sizes: Optional[Tensor], max_batch_size: int, sorted_indices: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>forward_packed(input: PackedSequence, hx: Optional[Tensor]): Tuple[PackedSequence, Tensor]<br ALIGN="LEFT"/>forward_tensor(input: Tensor, hx: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_mod)<br ALIGN="LEFT"/>permute_hidden(hx: Tensor, permutation: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.GRU" [color="black", fontcolor="black", label=<{GRU|<br ALIGN="LEFT"/>|forward(input, hx)<br ALIGN="LEFT"/>from_float(mod, weight_qparams_dict)<br ALIGN="LEFT"/>get_flat_weights()<br ALIGN="LEFT"/>get_quantized_weight_bias_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.GRU" [color="black", fontcolor="black", label=<{GRU|<br ALIGN="LEFT"/>|<I>forward</I>(input: Tensor, hx: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.GRUCell" [color="black", fontcolor="black", label=<{GRUCell|<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.GRUCell" [color="black", fontcolor="black", label=<{GRUCell|bias_hh<br ALIGN="LEFT"/>bias_ih<br ALIGN="LEFT"/>weight_hh<br ALIGN="LEFT"/>weight_ih<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, weight_qparams_dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.GRUCell" [color="black", fontcolor="black", label=<{GRUCell|<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.gamma.Gamma" [color="black", fontcolor="black", label=<{Gamma|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>rate<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.Gather" [color="black", fontcolor="black", label=<{Gather|dst<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel._functions.Gather" [color="black", fontcolor="black", label=<{Gather|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, target_device, dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.logging_tensor.GatherTraceback" [color="black", fontcolor="black", label=<{GatherTraceback|cpp : bool<br ALIGN="LEFT"/>python : bool<br ALIGN="LEFT"/>script : bool<br ALIGN="LEFT"/>|filter(record)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.GaussianNLLLoss" [color="black", fontcolor="black", label=<{GaussianNLLLoss|eps : float<br ALIGN="LEFT"/>full : bool<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor, var: Union[Tensor, float]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.GeneralTensorShapeOpQuantizeHandler" [color="black", fontcolor="black", label=<{GeneralTensorShapeOpQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.GeneratedFileCleaner" [color="black", fontcolor="black", label=<{GeneratedFileCleaner|dirs_to_clean : list<br ALIGN="LEFT"/>files_to_clean : set<br ALIGN="LEFT"/>keep_intermediates : bool<br ALIGN="LEFT"/>|makedirs(dn, exist_ok)<br ALIGN="LEFT"/>open(fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.mutation_guard.GenerationTracker" [color="black", fontcolor="black", label=<{GenerationTracker|dynamic_classes<br ALIGN="LEFT"/>generation : int<br ALIGN="LEFT"/>generation_values<br ALIGN="LEFT"/>|check(obj: Any): bool<br ALIGN="LEFT"/>clear(): None<br ALIGN="LEFT"/>get_generation_value(obj: Any): int<br ALIGN="LEFT"/>mark_class_dynamic(cls: Type[torch.nn.Module]): None<br ALIGN="LEFT"/>tag(obj: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.GenericContextWrappingVariable" [color="black", fontcolor="black", label=<{GenericContextWrappingVariable|cm_obj<br ALIGN="LEFT"/>|enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>exit_on_graph_break()<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>supports_graph_breaks()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing.GenericMeta" [color="black", fontcolor="black", label=<{GenericMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.simple_registry.GenericTorchDispatchRuleHolder" [color="black", fontcolor="black", label=<{GenericTorchDispatchRuleHolder|qualname<br ALIGN="LEFT"/>|find(torch_dispatch_class)<br ALIGN="LEFT"/>register(torch_dispatch_class: type, func: Callable): RegistrationHandle<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.GenericView" [color="black", fontcolor="black", label=<{GenericView|reindex : Callable[..., Any]<br ALIGN="LEFT"/>size : List[Expr]<br ALIGN="LEFT"/>|create(x, new_size, reindex)<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>make_reindexer()<br ALIGN="LEFT"/>reindex_str(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.geometric.Geometric" [color="black", fontcolor="black", label=<{Geometric|arg_constraints : dict<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._pytree.GetAttrKey" [color="black", fontcolor="black", label=<{GetAttrKey|name : str<br ALIGN="LEFT"/>|get(obj: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.GetAttrVariable" [color="black", fontcolor="black", label=<{GetAttrVariable|name<br ALIGN="LEFT"/>obj<br ALIGN="LEFT"/>py_type : NoneType<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>const_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>create_getattr_proxy(base_proxy: torch.fx.Proxy, attr)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor.core.MaskedTensor.get_data.GetData" [color="black", fontcolor="black", label=<{GetData|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, self)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.GetItem" [color="black", fontcolor="black", label=<{GetItem|index<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>res<br ALIGN="LEFT"/>tensor_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.split_cat.GetItem" [color="black", fontcolor="black", label=<{GetItem|<br ALIGN="LEFT"/>|find_anchor_nodes(ctx: MatchContext, searched: OrderedSet[torch.fx.Node])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.GetItemSource" [color="black", fontcolor="black", label=<{GetItemSource|index : Any<br ALIGN="LEFT"/>index_is_slice : bool<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>unpack_slice()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.GetItemTensor" [color="black", fontcolor="black", label=<{GetItemTensor|index_tuple<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>res<br ALIGN="LEFT"/>tensor_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.populate_builtin_to_tensor_fn_map.GetMethodMode" [color="black", fontcolor="black", label=<{GetMethodMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.GetSetDescriptorVariable" [color="black", fontcolor="black", label=<{GetSetDescriptorVariable|desc<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.glob_group.GlobGroup" [color="black", fontcolor="black", label=<{GlobGroup|exclude : list<br ALIGN="LEFT"/>include : list<br ALIGN="LEFT"/>separator : str<br ALIGN="LEFT"/>|matches(candidate: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.GlobalContext" [color="black", fontcolor="black", label=<{GlobalContext|global_state : Dict[str, Tuple[Callable, ...]], dict<br ALIGN="LEFT"/>|copy_graphstate()<br ALIGN="LEFT"/>restore_graphstate(state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.GlobalContextCheckpointState" [color="black", fontcolor="black", label=<{GlobalContextCheckpointState|global_state : Dict[str, Tuple[Callable, ...]]<br ALIGN="LEFT"/>|diff(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.GlobalSource" [color="black", fontcolor="black", label=<{GlobalSource|global_name : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.GlobalStateSource" [color="black", fontcolor="black", label=<{GlobalStateSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.GlobalWeakRefSource" [color="black", fontcolor="black", label=<{GlobalWeakRefSource|global_name : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.GlobalsBridge" [color="black", fontcolor="black", label=<{GlobalsBridge|<br ALIGN="LEFT"/>|construct(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.GmWrapper" [color="black", fontcolor="black", label=<{GmWrapper|gm<br ALIGN="LEFT"/>unflatten_fn<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.GradIncrementNestingCtxManagerVariable" [color="black", fontcolor="black", label=<{GradIncrementNestingCtxManagerVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.GradInplaceRequiresGradCtxManagerVariable" [color="black", fontcolor="black", label=<{GradInplaceRequiresGradCtxManagerVariable|prev_state<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_values)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.pyfunctorch.GradInterpreter" [color="black", fontcolor="black", label=<{GradInterpreter|<br ALIGN="LEFT"/>|get_state()<br ALIGN="LEFT"/>lift(args, kwargs)<br ALIGN="LEFT"/>lower()<br ALIGN="LEFT"/>prev_grad_mode()<br ALIGN="LEFT"/>process(op, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.GradModeVariable" [color="black", fontcolor="black", label=<{GradModeVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]')<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', target_value, initialized)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.GradNotSetToNonePattern" [color="black", fontcolor="black", label=<{GradNotSetToNonePattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cpu.amp.grad_scaler.GradScaler" [color="black", fontcolor="black", label=<{GradScaler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.amp.grad_scaler.GradScaler" [color="black", fontcolor="black", label=<{GradScaler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.amp.grad_scaler.GradScaler" [color="black", fontcolor="black", label=<{GradScaler|<br ALIGN="LEFT"/>|get_backoff_factor(): float<br ALIGN="LEFT"/>get_growth_factor(): float<br ALIGN="LEFT"/>get_growth_interval(): int<br ALIGN="LEFT"/>get_scale(): float<br ALIGN="LEFT"/>is_enabled(): bool<br ALIGN="LEFT"/>load_state_dict(state_dict: Dict[str, Any]): None<br ALIGN="LEFT"/>scale(outputs: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>set_backoff_factor(new_factor: float): None<br ALIGN="LEFT"/>set_growth_factor(new_factor: float): None<br ALIGN="LEFT"/>set_growth_interval(new_interval: int): None<br ALIGN="LEFT"/>state_dict(): Dict[str, Any]<br ALIGN="LEFT"/>step(optimizer: torch.optim.Optimizer): Optional[float]<br ALIGN="LEFT"/>unscale_(optimizer: torch.optim.Optimizer): None<br ALIGN="LEFT"/>update(new_scale: Optional[Union[float, torch.Tensor]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.GradSource" [color="black", fontcolor="black", label=<{GradSource|member : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.gradcheck.GradcheckError" [color="black", fontcolor="red", label=<{GradcheckError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.GradientEdge" [color="black", fontcolor="black", label=<{GradientEdge|node<br ALIGN="LEFT"/>output_nr : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.GradientToParameterSpec" [color="black", fontcolor="black", label=<{GradientToParameterSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>parameter_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.GradientToUserInputSpec" [color="black", fontcolor="black", label=<{GradientToUserInputSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>user_input_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph.Graph" [color="black", fontcolor="black", label=<{Graph|nodes<br ALIGN="LEFT"/>old_modules : dict<br ALIGN="LEFT"/>owning_module<br ALIGN="LEFT"/>|call_function(the_function: Callable[..., Any], args: Optional[Tuple['Argument', ...]], kwargs: Optional[Dict[str, 'Argument']], type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>call_method(method_name: str, args: Optional[Tuple['Argument', ...]], kwargs: Optional[Dict[str, 'Argument']], type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>call_module(module_name: str, args: Optional[Tuple['Argument', ...]], kwargs: Optional[Dict[str, 'Argument']], type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>create_node(op: str, target: 'Target', args: Optional[Tuple['Argument', ...]], kwargs: Optional[Dict[str, 'Argument']], name: Optional[str], type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>eliminate_dead_code(is_impure_node: Optional[Callable[[Node], bool]]): bool<br ALIGN="LEFT"/>erase_node(to_erase: Node): None<br ALIGN="LEFT"/>find_nodes()<br ALIGN="LEFT"/>get_attr(qualified_name: str, type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>graph_copy(g: 'Graph', val_map: Dict[Node, Node], return_output_node): 'Optional[Argument]'<br ALIGN="LEFT"/>inserting_after(n: Optional[Node])<br ALIGN="LEFT"/>inserting_before(n: Optional[Node])<br ALIGN="LEFT"/>lint()<br ALIGN="LEFT"/>node_copy(node: Node, arg_transform: Callable[[Node], 'Argument']): Node<br ALIGN="LEFT"/>on_generate_code(make_transformer: Callable[[Optional[TransformCodeFunc]], TransformCodeFunc])<br ALIGN="LEFT"/>output(result: 'Argument', type_expr: Optional[Any])<br ALIGN="LEFT"/>output_node(): Node<br ALIGN="LEFT"/>placeholder(name: str, type_expr: Optional[Any], default_value: Any): Node<br ALIGN="LEFT"/>print_tabular()<br ALIGN="LEFT"/>process_inputs()<br ALIGN="LEFT"/>process_outputs(out)<br ALIGN="LEFT"/>python_code(root_module: str): PythonCode<br ALIGN="LEFT"/>set_codegen(codegen: CodeGen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Graph" [color="black", fontcolor="black", label=<{Graph|description : str \| None<br ALIGN="LEFT"/>graph : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|sarif(): sarif.Graph<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._graph.Graph" [color="black", fontcolor="black", label=<{Graph|description : Optional[_message.Message]<br ALIGN="LEFT"/>edges : Optional[List[_edge.Edge]]<br ALIGN="LEFT"/>nodes : Optional[List[_node.Node]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.Graph" [color="black", fontcolor="black", label=<{Graph|ad_matrix : ndarray<br ALIGN="LEFT"/>fw_post_order : List[str]<br ALIGN="LEFT"/>name2node : Dict[str, Node]<br ALIGN="LEFT"/>nodes : List[Node]<br ALIGN="LEFT"/>|add_node(node: Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.Graph" [color="black", fontcolor="black", label=<{Graph|custom_obj_values : Annotated[Dict[str, CustomObjArgument], 80]<br ALIGN="LEFT"/>inputs : Annotated[List[Argument], 10]<br ALIGN="LEFT"/>is_single_tensor_return : Annotated[bool, 70]<br ALIGN="LEFT"/>nodes : Annotated[List[Node], 30]<br ALIGN="LEFT"/>outputs : Annotated[List[Argument], 20]<br ALIGN="LEFT"/>sym_bool_values : Annotated[Dict[str, SymBool], 60]<br ALIGN="LEFT"/>sym_float_values : Annotated[Dict[str, SymFloat], 90]<br ALIGN="LEFT"/>sym_int_values : Annotated[Dict[str, SymInt], 50]<br ALIGN="LEFT"/>tensor_values : Annotated[Dict[str, TensorMeta], 40]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.proxy.GraphAppendingTracer" [color="black", fontcolor="black", label=<{GraphAppendingTracer|graph<br ALIGN="LEFT"/>module_stack : OrderedDict<br ALIGN="LEFT"/>node_name_to_scope : dict<br ALIGN="LEFT"/>scope<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.GraphArg" [color="black", fontcolor="black", label=<{GraphArg|example<br ALIGN="LEFT"/>example_strong_ref : Optional[torch.Tensor]<br ALIGN="LEFT"/>fake_tensor : Optional[torch._subclasses.fake_tensor.FakeTensor]<br ALIGN="LEFT"/>is_tensor : bool<br ALIGN="LEFT"/>pass_arg_as_tensor : bool<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>|erase()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.GraphArgument" [color="black", fontcolor="black", label=<{GraphArgument|graph : Annotated['Graph', 20]<br ALIGN="LEFT"/>name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.output_graph.GraphCompileReason" [color="black", fontcolor="black", label=<{GraphCompileReason|graph_break : bool<br ALIGN="LEFT"/>reason : str<br ALIGN="LEFT"/>user_stack : List[traceback.FrameSummary]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._errors.GraphConstructionError" [color="black", fontcolor="red", label=<{GraphConstructionError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.jit_utils.GraphContext" [color="black", fontcolor="black", label=<{GraphContext|at<br ALIGN="LEFT"/>block<br ALIGN="LEFT"/>env : dict[_C.Value, _C.Value]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>new_nodes : list[_C.Node]<br ALIGN="LEFT"/>opset : int<br ALIGN="LEFT"/>original_node<br ALIGN="LEFT"/>params_dict : dict[str, _C.IValue]<br ALIGN="LEFT"/>values_in_env : set[_C.Value]<br ALIGN="LEFT"/>|aten_op(operator: str)<br ALIGN="LEFT"/>onnxscript_op(onnx_fn)<br ALIGN="LEFT"/>op(opname: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.GraphID" [color="black", fontcolor="black", label=<{GraphID|id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.verification.GraphInfo" [color="black", fontcolor="black", label=<{GraphInfo|export_options<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>id : str<br ALIGN="LEFT"/>input_args : tuple[Any, ...]<br ALIGN="LEFT"/>lower_graph_info : GraphInfo \| None<br ALIGN="LEFT"/>mismatch_error : AssertionError \| None<br ALIGN="LEFT"/>params_dict : dict[str, Any]<br ALIGN="LEFT"/>pt_outs : Sequence[_NumericType] \| None<br ALIGN="LEFT"/>upper_graph_info : GraphInfo \| None<br ALIGN="LEFT"/>|all_mismatch_leaf_graph_info(): list[GraphInfo]<br ALIGN="LEFT"/>clear()<br ALIGN="LEFT"/>essential_node_count(): int<br ALIGN="LEFT"/>essential_node_kinds(): set[str]<br ALIGN="LEFT"/>export_repro(repro_dir: str \| None, name: str \| None): str<br ALIGN="LEFT"/>find_mismatch(options: VerificationOptions \| None)<br ALIGN="LEFT"/>find_partition(id: str): GraphInfo \| None<br ALIGN="LEFT"/>has_mismatch(): bool<br ALIGN="LEFT"/>pretty_print_mismatch(graph: bool)<br ALIGN="LEFT"/>pretty_print_tree()<br ALIGN="LEFT"/>verify_export(options: VerificationOptions): tuple[AssertionError \| None, torch.Graph, _OutputsType, _OutputsType]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx.verification.GraphInfoPrettyPrinter" [color="black", fontcolor="black", label=<{GraphInfoPrettyPrinter|children_str_lambdas : Mapping[int, str]<br ALIGN="LEFT"/>connector_str_lambdas : Mapping[int, str]<br ALIGN="LEFT"/>graph_info : GraphInfo \| None<br ALIGN="LEFT"/>graph_str_lambdas : Mapping[int, str]<br ALIGN="LEFT"/>lower_printer : GraphInfoPrettyPrinter \| None<br ALIGN="LEFT"/>upper_printer : GraphInfoPrettyPrinter \| None<br ALIGN="LEFT"/>|pretty_print()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._lazy.extract_compiled_graph.GraphInputMatcher" [color="black", fontcolor="black", label=<{GraphInputMatcher|graph_input_ivalues : List[Any]<br ALIGN="LEFT"/>graph_input_tensor_ids : List[int]<br ALIGN="LEFT"/>tensor_id_to_arg_idx : Dict[int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.graph.GraphLowering" [color="black", fontcolor="black", label=<{GraphLowering|aligned_inputs<br ALIGN="LEFT"/>all_codegen_kernel_names<br ALIGN="LEFT"/>allocated_constant_name : Dict[str, str]<br ALIGN="LEFT"/>aot_mode : bool<br ALIGN="LEFT"/>bound_unbacked_symbols<br ALIGN="LEFT"/>buffers : List[ir.Buffer]<br ALIGN="LEFT"/>bw_donated_idxs : NoneType<br ALIGN="LEFT"/>cache_key : str<br ALIGN="LEFT"/>cache_linemap : List[Tuple[int, str]]<br ALIGN="LEFT"/>cache_path : str<br ALIGN="LEFT"/>const_code : Optional[str]<br ALIGN="LEFT"/>const_module : Optional['GraphLowering']<br ALIGN="LEFT"/>const_output_index : Dict[str, int]<br ALIGN="LEFT"/>constant_reprs : Dict[str, str]<br ALIGN="LEFT"/>constants : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>cpp_wrapper : bool<br ALIGN="LEFT"/>creation_time<br ALIGN="LEFT"/>current_device : NoneType, Optional[torch.device]<br ALIGN="LEFT"/>current_node : NoneType<br ALIGN="LEFT"/>device_idxs : OrderedSet[int]<br ALIGN="LEFT"/>device_node_mapping : Dict[torch.device, torch.fx.Node]<br ALIGN="LEFT"/>device_ops : Optional[DeviceOpOverrides]<br ALIGN="LEFT"/>device_type : str<br ALIGN="LEFT"/>device_types : OrderedSet[str]<br ALIGN="LEFT"/>disable_cudagraphs_reason : Optional[str]<br ALIGN="LEFT"/>dynamo_flat_name_to_original_fqn<br ALIGN="LEFT"/>effectful_ops : Dict[_EffectType, ir.Buffer]<br ALIGN="LEFT"/>example_inputs : Optional[Sequence[object]]<br ALIGN="LEFT"/>extern_kernel_nodes : List[ir.ExternKernelNode]<br ALIGN="LEFT"/>extern_node_serializer : Callable[[List[ir.ExternKernelNode]], Any]<br ALIGN="LEFT"/>extra_traceback : bool<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>folded_constants : OrderedSet[str]<br ALIGN="LEFT"/>get_backend_features<br ALIGN="LEFT"/>graph_id : Optional[int]<br ALIGN="LEFT"/>graph_input_names : List[str]<br ALIGN="LEFT"/>graph_inputs : Dict[str, TensorBox]<br ALIGN="LEFT"/>graph_inputs_original : Dict[str, InputBuffer]<br ALIGN="LEFT"/>graph_outputs : List[ir.IRNode]<br ALIGN="LEFT"/>inplaced_to_remove<br ALIGN="LEFT"/>inputs_to_check : Optional[Sequence[int]]<br ALIGN="LEFT"/>is_backward : bool<br ALIGN="LEFT"/>is_const_graph : bool<br ALIGN="LEFT"/>is_inference : bool<br ALIGN="LEFT"/>layout_opt : NoneType, bool<br ALIGN="LEFT"/>lists : Dict[str, List[str]]<br ALIGN="LEFT"/>multi_kernel_to_choice : Dict[str, str]<br ALIGN="LEFT"/>mutated_buffers<br ALIGN="LEFT"/>mutated_input_idxs : List[int]<br ALIGN="LEFT"/>mutated_inputs<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>name_to_buffer : Dict[str, ir.Buffer]<br ALIGN="LEFT"/>name_to_op : Dict[str, ir.Operation]<br ALIGN="LEFT"/>name_to_users : DefaultDict[str, List[ir.IRNode]]<br ALIGN="LEFT"/>never_reuse_buffers<br ALIGN="LEFT"/>no_fuse_buffer_names<br ALIGN="LEFT"/>nodes_prefer_channels_last<br ALIGN="LEFT"/>num_channels_last_conv : int<br ALIGN="LEFT"/>operations : List[ir.Operation]<br ALIGN="LEFT"/>orig_gm<br ALIGN="LEFT"/>placeholder_idx : int<br ALIGN="LEFT"/>post_grad_graph_id<br ALIGN="LEFT"/>ras_by_symbol : Dict[Optional[sympy.Symbol], List[RuntimeAssert]]<br ALIGN="LEFT"/>record_multi_kernel_choice : bool<br ALIGN="LEFT"/>removed_buffers<br ALIGN="LEFT"/>removed_inplace_buffers<br ALIGN="LEFT"/>removed_operations<br ALIGN="LEFT"/>reuse_shape_env : bool<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>seen_subgraphs : Dict[str, ir.Subgraph]<br ALIGN="LEFT"/>sizevars<br ALIGN="LEFT"/>torchbind_constants : Dict[str, torch._C.ScriptObject]<br ALIGN="LEFT"/>user_visible_output_strides : dict<br ALIGN="LEFT"/>workspace_id : count<br ALIGN="LEFT"/>wrapper_code : Optional[PythonWrapperCodegen]<br ALIGN="LEFT"/>zero_dim_cpu_tensor_list<br ALIGN="LEFT"/>|add_device_info(device: torch.device): None<br ALIGN="LEFT"/>add_symbol_graph_input(symbol: sympy.Expr): None<br ALIGN="LEFT"/>add_tensor_constant(data: Tensor, name: Optional[str]): TensorBox<br ALIGN="LEFT"/>allocate_non_dup_const_name(name: Optional[str], data: Union[Tensor]): str<br ALIGN="LEFT"/>call_function(target: Callable, args: Any, kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>call_method(target: Any, args: Any, kwargs: Any): NoReturn<br ALIGN="LEFT"/>call_module(target: Any, args: Any, kwargs: Any): NoReturn<br ALIGN="LEFT"/>can_inline_constant(t: torch.Tensor): bool<br ALIGN="LEFT"/>codegen(): Tuple[str, List[Tuple[int, Node]]]<br ALIGN="LEFT"/>codegen_subgraph(parent_graph: 'GraphLowering'): None<br ALIGN="LEFT"/>codegen_with_cpp_wrapper(): Tuple[str, List[Tuple[int, Node]]]<br ALIGN="LEFT"/>compile_to_module(): ModuleType<br ALIGN="LEFT"/>constant_name(name: str, device_override: Optional[torch.device]): str<br ALIGN="LEFT"/>count_bytes(): Tuple[int, List[Tuple[BaseSchedulerNode, int]], List[Tuple[BaseSchedulerNode, float]]]<br ALIGN="LEFT"/>decide_layout_opt(gm: GraphModule): bool<br ALIGN="LEFT"/>finalize(): None<br ALIGN="LEFT"/>find_nodes_prefer_channels_last(): OrderedSet[Node]<br ALIGN="LEFT"/>get_attr(target: str, args: Tuple[()], kwargs: Dict[str, object]): Union[Constant, TensorBox, ir.Subgraph, TorchBindObject]<br ALIGN="LEFT"/>get_buffer(buffer_name: str): Union[ir.TensorBox, ir.Buffer]<br ALIGN="LEFT"/>get_current_device_or_throw(): torch.device<br ALIGN="LEFT"/>get_dtype(buffer_name: str): torch.dtype<br ALIGN="LEFT"/>get_numel(buffer_name: str): Union[int, Expr]<br ALIGN="LEFT"/>get_original_value_of_constant(name: str): torch.Tensor<br ALIGN="LEFT"/>get_output_names(): List[str]<br ALIGN="LEFT"/>get_training_phase(): str<br ALIGN="LEFT"/>has_feature(device: Union[torch._inductor.ir.IRNode, device, None], feature: BackendFeature): bool<br ALIGN="LEFT"/>init_wrapper_code(is_subgraph: bool, subgraph_name: Optional[str], parent_wrapper_code: Optional[PythonWrapperCodegen]): None<br ALIGN="LEFT"/>is_unspec_arg(name: str): bool<br ALIGN="LEFT"/>make_subgraph(gm: torch.fx.GraphModule, example_inputs: List[torch.Tensor], subgraph_name: str): 'SubgraphLowering'<br ALIGN="LEFT"/>mark_buffer_mutated(name: str): None<br ALIGN="LEFT"/>output(target: str, args: Tuple[object], kwargs: Dict[str, object]): None<br ALIGN="LEFT"/>placeholder(target: str, args: Tuple[object], kwargs: Dict[str, object]): Union[Expr, TensorBox, None]<br ALIGN="LEFT"/>propagate_mutation(fx_node: torch.fx.Node, old_args: Tuple[Any], old_kwargs: Dict[str, Any], new_args: Tuple[Any], new_kwargs: Dict[str, Any]): None<br ALIGN="LEFT"/>qualify_name(name: str): str<br ALIGN="LEFT"/>register_buffer(buffer: ir.Buffer): str<br ALIGN="LEFT"/>register_operation(op: ir.Operation): str<br ALIGN="LEFT"/>register_operation_list(operation_names: List[str]): str<br ALIGN="LEFT"/>register_users_of(node_output: Union[Iterable[ir.IRNode], ir.IRNode]): None<br ALIGN="LEFT"/>run(): Any<br ALIGN="LEFT"/>run_node(n: torch.fx.Node): object<br ALIGN="LEFT"/><I>save_output_code</I>(code: str): None<br ALIGN="LEFT"/>set_current_device(device: torch.device): Iterator[None]<br ALIGN="LEFT"/>set_current_node(node: torch.fx.Node)<br ALIGN="LEFT"/>static_sizes_strides(ex: torch.Tensor): Tuple[List[sympy.Expr], List[sympy.Expr]]<br ALIGN="LEFT"/>symbolic_sizes_strides(ex: torch.Tensor): Tuple[Sequence[Union[int, Expr]], Sequence[Union[int, Expr]]]<br ALIGN="LEFT"/>try_get_buffer(buffer_name: str): Optional[Union[ir.TensorBox, ir.Buffer]]<br ALIGN="LEFT"/>try_match_insignificant_strides(tensor: Union[ir.TensorBox, ir.BaseView], meta_strides_inp: Tuple[Union[int, torch.SymInt], ...]): Union[ir.TensorBox, ir.BaseView]<br ALIGN="LEFT"/>validate_can_generate_cpp_wrapper(): None<br ALIGN="LEFT"/>warn_fallback(name: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.graph_matcher.GraphMatchingException" [color="black", fontcolor="red", label=<{GraphMatchingException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph_module.GraphModule" [color="black", fontcolor="black", label=<{GraphModule|code<br ALIGN="LEFT"/>compile_subgraph_reason : NoneType<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>meta : Dict[str, Any], dict<br ALIGN="LEFT"/>shape_env : NoneType<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>|add_submodule(target: str, m: torch.nn.Module): bool<br ALIGN="LEFT"/>delete_all_unused_submodules(): None<br ALIGN="LEFT"/>delete_submodule(target: str): bool<br ALIGN="LEFT"/>print_readable(print_output, include_stride, include_device, colored)<br ALIGN="LEFT"/>recompile(): PythonCode<br ALIGN="LEFT"/>to_folder(folder: Union[str, os.PathLike], module_name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.GraphModule" [color="black", fontcolor="black", label=<{GraphModule|graph : Annotated[Graph, 10]<br ALIGN="LEFT"/>metadata : Annotated[Dict[str, str], 40]<br ALIGN="LEFT"/>module_call_graph : Annotated[List[ModuleCallEntry], 60]<br ALIGN="LEFT"/>signature : Annotated[GraphSignature, 50]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.GraphModuleDeserializer" [color="black", fontcolor="black", label=<{GraphModuleDeserializer|constants : dict<br ALIGN="LEFT"/>example_inputs : NoneType, dict<br ALIGN="LEFT"/>fake_tensor_mode<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>serialized_name_to_meta : Dict[str, MetaType], dict<br ALIGN="LEFT"/>serialized_name_to_node : Dict[str, torch.fx.Node], dict<br ALIGN="LEFT"/>shape_env<br ALIGN="LEFT"/>signature<br ALIGN="LEFT"/>symbol_name_to_range : dict<br ALIGN="LEFT"/>symbol_name_to_symbol : Dict[str, sympy.Symbol]<br ALIGN="LEFT"/>sympy_functions : dict<br ALIGN="LEFT"/>|deserialize(serialized_graph_module: GraphModule, serialized_state_dict: Union[Dict[str, torch.Tensor], bytes], constants: Union[Dict[str, Any], bytes], example_inputs: Optional[Union[Tuple[Tuple[torch.Tensor, ...], Dict[str, Any]], bytes]], symbol_name_to_range: Optional[Dict[str, symbolic_shapes.ValueRanges]]): Result<br ALIGN="LEFT"/>deserialize_argument_spec(x: Argument): ep.ArgumentSpec<br ALIGN="LEFT"/>deserialize_constant_input(inp: ConstantValue): Any<br ALIGN="LEFT"/>deserialize_extension_operator(serialized_target: str)<br ALIGN="LEFT"/>deserialize_graph(serialized_graph: Graph): torch.fx.Graph<br ALIGN="LEFT"/>deserialize_graph_output(output): Optional[Union[torch.fx.Node, int]]<br ALIGN="LEFT"/>deserialize_hoo_inputs(inputs: List[NamedArgument])<br ALIGN="LEFT"/>deserialize_input(inp: Argument): Any<br ALIGN="LEFT"/>deserialize_input_spec(i: InputSpec): ep.InputSpec<br ALIGN="LEFT"/>deserialize_inputs(target, serialized_node: Node)<br ALIGN="LEFT"/>deserialize_metadata(metadata: Dict[str, str]): Dict[str, Any]<br ALIGN="LEFT"/>deserialize_module_call_graph(module_call_graph: List[ModuleCallEntry]): List[ep.ModuleCallEntry]<br ALIGN="LEFT"/>deserialize_module_call_signature(module_call_signature: ModuleCallSignature): ep.ModuleCallSignature<br ALIGN="LEFT"/>deserialize_multiple_outputs(serialized_node: Node, fx_node: torch.fx.Node): None<br ALIGN="LEFT"/>deserialize_node(serialized_node: Node, target: Callable): None<br ALIGN="LEFT"/>deserialize_operator(serialized_target: str)<br ALIGN="LEFT"/>deserialize_output_spec(o: OutputSpec): ep.OutputSpec<br ALIGN="LEFT"/>deserialize_outputs(serialized_node: Node, fx_node: torch.fx.Node)<br ALIGN="LEFT"/>deserialize_script_obj_meta(script_obj_meta: CustomObjArgument): ep.CustomObjArgument<br ALIGN="LEFT"/>deserialize_signature(sig: GraphSignature): ep.ExportGraphSignature<br ALIGN="LEFT"/>deserialize_sym_argument(sym_arg)<br ALIGN="LEFT"/>deserialize_sym_bool(s: SymBool): Union[bool, torch.SymBool]<br ALIGN="LEFT"/>deserialize_sym_float(s: SymFloat): Union[float, torch.SymFloat]<br ALIGN="LEFT"/>deserialize_sym_int(s: SymInt): Union[int, torch.SymInt]<br ALIGN="LEFT"/>deserialize_sym_op_inputs(inputs)<br ALIGN="LEFT"/>deserialize_sym_op_outputs(serialized_node: Node, fx_node: torch.fx.Node)<br ALIGN="LEFT"/>deserialize_tensor_meta(tensor_meta: TensorMeta): FakeTensor<br ALIGN="LEFT"/>save_graph_module(): Iterator[None]<br ALIGN="LEFT"/>sync_fx_node(name: str, fx_node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph_module.GraphModule.__new__.GraphModuleImpl" [color="black", fontcolor="black", label=<{GraphModuleImpl|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx._pass.GraphModuleOnnxMeta" [color="black", fontcolor="black", label=<{GraphModuleOnnxMeta|package_info<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.GraphModuleSerializer" [color="black", fontcolor="black", label=<{GraphModuleSerializer|custom_objs : Dict[str, torch._C.ScriptObject]<br ALIGN="LEFT"/>duplicate_getitem_nodes : Dict[str, str]<br ALIGN="LEFT"/>graph_signature<br ALIGN="LEFT"/>graph_state<br ALIGN="LEFT"/>module_call_graph : List[ep.ModuleCallEntry]<br ALIGN="LEFT"/>|handle_call_function(node: torch.fx.Node)<br ALIGN="LEFT"/><I>handle_get_attr</I>(node)<br ALIGN="LEFT"/>handle_output(node: torch.fx.Node)<br ALIGN="LEFT"/>handle_placeholder(node: torch.fx.Node)<br ALIGN="LEFT"/>is_sym_bool_arg(arg): bool<br ALIGN="LEFT"/>is_sym_float_arg(arg): bool<br ALIGN="LEFT"/>is_sym_int_arg(arg): bool<br ALIGN="LEFT"/>save_graph_state()<br ALIGN="LEFT"/>serialize(graph_module: torch.fx.GraphModule): GraphModule<br ALIGN="LEFT"/>serialize_argument_spec(x: ep.ArgumentSpec): Argument<br ALIGN="LEFT"/>serialize_graph(graph_module: torch.fx.GraphModule): Graph<br ALIGN="LEFT"/>serialize_graph_module_metadata(meta: Dict[str, Any])<br ALIGN="LEFT"/>serialize_hoo_inputs(args, kwargs): List[NamedArgument]<br ALIGN="LEFT"/>serialize_hoo_outputs(node: torch.fx.Node): List[Argument]<br ALIGN="LEFT"/>serialize_input(arg, arg_type: Optional[torch._C.Argument]): Argument<br ALIGN="LEFT"/>serialize_input_spec(spec: ep.InputSpec): InputSpec<br ALIGN="LEFT"/>serialize_inputs(target: Any, args, kwargs): List[NamedArgument]<br ALIGN="LEFT"/>serialize_metadata(node: torch.fx.Node): Dict[str, str]<br ALIGN="LEFT"/>serialize_module_call_graph(module_call_graph: List[ep.ModuleCallEntry]): List[ModuleCallEntry]<br ALIGN="LEFT"/>serialize_module_call_signature(module_call_signature: ep.ModuleCallSignature): ModuleCallSignature<br ALIGN="LEFT"/>serialize_operator(target): str<br ALIGN="LEFT"/>serialize_output(name: str, meta_val: Any): Argument<br ALIGN="LEFT"/>serialize_output_spec(spec: ep.OutputSpec): OutputSpec<br ALIGN="LEFT"/>serialize_outputs(node: torch.fx.Node): List[Argument]<br ALIGN="LEFT"/>serialize_script_obj_meta(script_obj_meta: ep.CustomObjArgument): CustomObjArgument<br ALIGN="LEFT"/>serialize_signature(sig: ep.ExportGraphSignature): GraphSignature<br ALIGN="LEFT"/>serialize_sym_bool_output(name, meta_val): SymIntArgument<br ALIGN="LEFT"/>serialize_sym_float_output(name, meta_val): SymFloatArgument<br ALIGN="LEFT"/>serialize_sym_int_output(name, meta_val): SymIntArgument<br ALIGN="LEFT"/>serialize_sym_op_inputs(op, args): List[NamedArgument]<br ALIGN="LEFT"/>serialize_tensor_output(name, meta_val): TensorArgument<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.codegen.GraphOutputEntry" [color="black", fontcolor="black", label=<{GraphOutputEntry|index : int<br ALIGN="LEFT"/>variable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.GraphPatternEntry" [color="black", fontcolor="black", label=<{GraphPatternEntry|handler : Callable[..., Any]<br ALIGN="LEFT"/>|apply(match: Match, graph: torch.fx.Graph, node: torch.fx.Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.tensorboard._pytorch_graph.GraphPy" [color="black", fontcolor="black", label=<{GraphPy|nodes_io : OrderedDict<br ALIGN="LEFT"/>nodes_op : list<br ALIGN="LEFT"/>scope_name_appeared : list<br ALIGN="LEFT"/>shallowest_scope_name : str<br ALIGN="LEFT"/>unique_name_to_scoped_name : dict<br ALIGN="LEFT"/>|append(x)<br ALIGN="LEFT"/>find_common_root()<br ALIGN="LEFT"/>populate_namespace_from_OP_to_IO()<br ALIGN="LEFT"/>printall()<br ALIGN="LEFT"/>to_proto()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.graph_region_tracker.GraphRegionTracker" [color="black", fontcolor="black", label=<{GraphRegionTracker|hash_to_duplicates : Dict[str, IdenticalNodes]<br ALIGN="LEFT"/>input_pickler<br ALIGN="LEFT"/>node_to_duplicates : Dict[Node, IdenticalNodes]<br ALIGN="LEFT"/>|get_identical_regions(graph: torch.fx.Graph): List[List[Region]]<br ALIGN="LEFT"/>track_node(tx: 'InstructionTranslatorBase', node: Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.GraphSignature" [color="black", fontcolor="black", label=<{GraphSignature|input_specs : Annotated[List[InputSpec], 10]<br ALIGN="LEFT"/>output_specs : Annotated[List[OutputSpec], 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.GraphSignature" [color="black", fontcolor="black", label=<{GraphSignature|backward_signature : Optional[BackwardSignature]<br ALIGN="LEFT"/>buffers : List[FQN]<br ALIGN="LEFT"/>buffers_to_mutate : Dict[GraphOutputName, FQN]<br ALIGN="LEFT"/>in_spec<br ALIGN="LEFT"/>input_tokens : List[GraphInputName]<br ALIGN="LEFT"/>inputs_to_buffers : Dict[GraphInputName, FQN]<br ALIGN="LEFT"/>inputs_to_parameters : Dict[GraphInputName, FQN]<br ALIGN="LEFT"/>out_spec<br ALIGN="LEFT"/>output_tokens : List[GraphOutputName]<br ALIGN="LEFT"/>parameters : List[FQN]<br ALIGN="LEFT"/>user_inputs : List[GraphInputName]<br ALIGN="LEFT"/>user_inputs_to_mutate : Dict[GraphOutputName, GraphInputName]<br ALIGN="LEFT"/>user_outputs : List[GraphOutputName]<br ALIGN="LEFT"/>|from_tracing_metadata(): 'GraphSignature'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.serialize.GraphState" [color="black", fontcolor="black", label=<{GraphState|custom_obj_values : Dict[str, CustomObjArgument]<br ALIGN="LEFT"/>inputs : List[Argument]<br ALIGN="LEFT"/>is_single_tensor_return : bool<br ALIGN="LEFT"/>nodes : List[Node]<br ALIGN="LEFT"/>outputs : List[Argument]<br ALIGN="LEFT"/>sym_bool_values : Dict[str, SymBool]<br ALIGN="LEFT"/>sym_float_values : Dict[str, SymFloat]<br ALIGN="LEFT"/>sym_int_values : Dict[str, SymInt]<br ALIGN="LEFT"/>tensor_values : Dict[str, TensorMeta]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.graph_transform_observer.GraphTransformObserver" [color="black", fontcolor="black", label=<{GraphTransformObserver|created_nodes : set<br ALIGN="LEFT"/>erased_nodes : set<br ALIGN="LEFT"/>gm<br ALIGN="LEFT"/>input_dot_graph<br ALIGN="LEFT"/>log_url : Optional[str]<br ALIGN="LEFT"/>passname : str<br ALIGN="LEFT"/>subsystem : Optional[str]<br ALIGN="LEFT"/>|apply_gm_pass(pass_fn: Callable[[GraphModule], T]): Optional[T]<br ALIGN="LEFT"/>apply_graph_pass(pass_fn: Callable[[Graph], T]): Optional[T]<br ALIGN="LEFT"/>get_current_pass_count()<br ALIGN="LEFT"/>on_node_creation(node)<br ALIGN="LEFT"/>on_node_erase(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._graph_traversal.GraphTraversal" [color="black", fontcolor="black", label=<{GraphTraversal|description : Optional[_message.Message]<br ALIGN="LEFT"/>edge_traversals : Optional[List[_edge_traversal.EdgeTraversal]]<br ALIGN="LEFT"/>immutable_state : Optional[Any]<br ALIGN="LEFT"/>initial_state : Optional[Any]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>result_graph_index : int<br ALIGN="LEFT"/>run_graph_index : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.graph_gradual_typechecker.GraphTypeChecker" [color="black", fontcolor="black", label=<{GraphTypeChecker|env<br ALIGN="LEFT"/>traced<br ALIGN="LEFT"/>|type_check()<br ALIGN="LEFT"/>type_check_node(n: Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.graphs.make_graphed_callables.make_graphed_autograd_function.Graphed" [color="black", fontcolor="black", label=<{Graphed|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._meta_registrations.GridSamplerInterpolation" [color="black", fontcolor="black", label=<{GridSamplerInterpolation|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.GroupBatchFusionBase" [color="black", fontcolor="black", label=<{GroupBatchFusionBase|graph_search_options<br ALIGN="LEFT"/>|<I>fuse</I>(graph, subset)<br ALIGN="LEFT"/><I>match</I>(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.GroupFusion" [color="black", fontcolor="black", label=<{GroupFusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.GroupLinearFusion" [color="black", fontcolor="black", label=<{GroupLinearFusion|<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node): Optional[Tuple[str, bool]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d.GroupMember" [color="black", fontcolor="black", label=<{GroupMember|NON_GROUP_MEMBER : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.normalization.GroupNorm" [color="black", fontcolor="black", label=<{GroupNorm|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.normalization.GroupNorm" [color="black", fontcolor="black", label=<{GroupNorm|affine : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>num_channels : int<br ALIGN="LEFT"/>num_groups : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.group_norm_expanded_weights.GroupNormPerSampleGrad" [color="black", fontcolor="black", label=<{GroupNormPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, kwarg_names, _)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.GroupedSchedulerNode" [color="black", fontcolor="black", label=<{GroupedSchedulerNode|snodes : List[BaseSchedulerNode]<br ALIGN="LEFT"/>|add_fake_dep(fake_dep: Dep): None<br ALIGN="LEFT"/>can_fuse(producer: BaseSchedulerNode, consumer: BaseSchedulerNode): bool<br ALIGN="LEFT"/>create(snodes: List[BaseSchedulerNode]): GroupedSchedulerNode<br ALIGN="LEFT"/>get_buffer_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_first_name(): str<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_nodes(): Sequence[BaseSchedulerNode]<br ALIGN="LEFT"/>get_outputs(): List[SchedulerBuffer]<br ALIGN="LEFT"/>unpack(): List[BaseSchedulerNode]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.grouping.GrouperIterDataPipe" [color="black", fontcolor="black", label=<{GrouperIterDataPipe|buffer_elements : DefaultDict[Any, List], defaultdict<br ALIGN="LEFT"/>curr_buffer_size : int<br ALIGN="LEFT"/>datapipe : IterDataPipe[_T_co]<br ALIGN="LEFT"/>drop_remaining : bool<br ALIGN="LEFT"/>group_key_fn : Callable[[_T_co], Any]<br ALIGN="LEFT"/>group_size : NoneType<br ALIGN="LEFT"/>guaranteed_group_size : NoneType<br ALIGN="LEFT"/>keep_key : bool<br ALIGN="LEFT"/>max_buffer_size : int<br ALIGN="LEFT"/>wrapper_class<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.GroupwiseConv2d" [color="black", fontcolor="black", label=<{GroupwiseConv2d|conv<br ALIGN="LEFT"/>|example_inputs()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.Guard" [color="black", fontcolor="black", label=<{Guard|code_list : Optional[List[str]]<br ALIGN="LEFT"/>create_fn : Callable[[GuardBuilderBase, Guard], None]<br ALIGN="LEFT"/>guard_types : Optional[List[str]]<br ALIGN="LEFT"/>guarded_class_weakref : Optional[type]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>obj_weakref : Optional[object]<br ALIGN="LEFT"/>originating_source<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>stack : Optional[CapturedTraceback]<br ALIGN="LEFT"/>user_stack : Optional[traceback.StackSummary]<br ALIGN="LEFT"/>|create(builder: GuardBuilderBase)<br ALIGN="LEFT"/>inner_create_fn()<br ALIGN="LEFT"/>is_fsdp_module()<br ALIGN="LEFT"/>is_local()<br ALIGN="LEFT"/>is_specialized_nn_module()<br ALIGN="LEFT"/>set_export_info(guard_type, guarded_class, code_list, obj_weakref)<br ALIGN="LEFT"/>sort_key()<br ALIGN="LEFT"/>weakref_to_str(obj_weakref)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.GuardBuilder" [color="black", fontcolor="black", label=<{GuardBuilder|argnames : List[str]<br ALIGN="LEFT"/>check_fn_manager<br ALIGN="LEFT"/>code : List[GuardCodeList]<br ALIGN="LEFT"/>guard_manager<br ALIGN="LEFT"/>id_matched_objs : Dict[str, ReferenceType[object]]<br ALIGN="LEFT"/>id_ref : Callable[[Any, str], str]<br ALIGN="LEFT"/>key_order_guarded_dict_ids : set<br ALIGN="LEFT"/>lookup_weakrefs : Callable[[object], ReferenceType[object]]<br ALIGN="LEFT"/>no_tensor_aliasing_guard_managers : List[GuardManagerWrapper]<br ALIGN="LEFT"/>no_tensor_aliasing_names : List[str]<br ALIGN="LEFT"/>scope : Dict[str, Dict[str, object]]<br ALIGN="LEFT"/>shape_env_code : List[GuardCodeList]<br ALIGN="LEFT"/>source_ref : Callable[[Source], str]<br ALIGN="LEFT"/>|BUILTIN_MATCH(guard: Guard)<br ALIGN="LEFT"/>CLOSURE_MATCH(guard: Guard)<br ALIGN="LEFT"/>CONSTANT_MATCH(guard: Guard)<br ALIGN="LEFT"/>DATA_PTR_MATCH(guard: Guard)<br ALIGN="LEFT"/>DEFAULT_DEVICE(guard: Guard)<br ALIGN="LEFT"/><I>DETERMINISTIC_ALGORITHMS</I>(guard: Guard)<br ALIGN="LEFT"/>DICT_CONST_KEYS(guard)<br ALIGN="LEFT"/>DICT_CONTAINS(guard: Guard, key: str, invert: bool)<br ALIGN="LEFT"/>DICT_KEYS(guard)<br ALIGN="LEFT"/>DICT_VERSION(guard: Guard)<br ALIGN="LEFT"/>DUAL_LEVEL(guard: Guard)<br ALIGN="LEFT"/>DUPLICATE_INPUT(guard, source_b)<br ALIGN="LEFT"/>EMPTY_NN_MODULE_HOOKS_DICT(guard)<br ALIGN="LEFT"/>EQUALS_MATCH(guard: Guard)<br ALIGN="LEFT"/><I>FSDP_TRAINING_STATE</I>(guard: Guard)<br ALIGN="LEFT"/>FUNCTION_MATCH(guard: Guard)<br ALIGN="LEFT"/>FUNCTORCH_STACK_MATCH(guard: Guard)<br ALIGN="LEFT"/><I>GRAD_MODE</I>(guard: Guard)<br ALIGN="LEFT"/>HASATTR(guard: Guard)<br ALIGN="LEFT"/>ID_MATCH(guard: Guard)<br ALIGN="LEFT"/>NAME_MATCH(guard: Guard)<br ALIGN="LEFT"/>NN_MODULE(guard: Guard)<br ALIGN="LEFT"/>NOT_NONE_MATCH(guard: Guard, value)<br ALIGN="LEFT"/>NOT_PRESENT_IN_GENERIC_DICT(guard: Guard, attr): None<br ALIGN="LEFT"/>OBJECT_MUTATION(guard: Guard)<br ALIGN="LEFT"/>PYMODULE_MATCH(guard: Guard)<br ALIGN="LEFT"/>RANGE_ITERATOR_MATCH(guard)<br ALIGN="LEFT"/>SEQUENCE_LENGTH(guard)<br ALIGN="LEFT"/>SHAPE_ENV(guard: Guard)<br ALIGN="LEFT"/>TENSOR_MATCH(guard: Guard, value)<br ALIGN="LEFT"/>TENSOR_SUBCLASS_METADATA_MATCH(guard: Guard)<br ALIGN="LEFT"/><I>TORCH_FUNCTION_STATE</I>(guard: Guard)<br ALIGN="LEFT"/>TUPLE_ITERATOR_LEN(guard)<br ALIGN="LEFT"/>TYPE_MATCH(guard: Guard): None<br ALIGN="LEFT"/>WEAKREF_ALIVE(guard)<br ALIGN="LEFT"/>add_python_lambda_leaf_guard_to_root(code_parts, verbose_code_parts, closure_vars, is_epilogue)<br ALIGN="LEFT"/>arg_ref(guard: Union[str, Guard]): str<br ALIGN="LEFT"/>get(name: str): Any<br ALIGN="LEFT"/>get_global_guard_manager()<br ALIGN="LEFT"/>get_guard_manager(guard: Guard)<br ALIGN="LEFT"/>get_guard_manager_from_source(source)<br ALIGN="LEFT"/>get_guard_manager_type(source, example_value)<br ALIGN="LEFT"/>getattr_on_nn_module(source, base_guard_manager, base_example_value, example_value, base_source_name, source_name, guard_manager_enum)<br ALIGN="LEFT"/>guard_on_dict_keys_and_ignore_order(example_value, guard)<br ALIGN="LEFT"/>guard_on_dict_keys_and_order(value, guard)<br ALIGN="LEFT"/>manager_guards_on_keys(mgr_enum)<br ALIGN="LEFT"/>requires_key_order_guarding(source)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.GuardBuilderBase" [color="black", fontcolor="black", label=<{GuardBuilderBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.guards.GuardCodeList" [color="black", fontcolor="black", label=<{GuardCodeList|code_list : List[str]<br ALIGN="LEFT"/>guard<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.GuardEnvExpr" [color="black", fontcolor="black", label=<{GuardEnvExpr|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.types.GuardFail" [color="black", fontcolor="black", label=<{GuardFail|orig_code<br ALIGN="LEFT"/>reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.types.GuardFn" [color="black", fontcolor="black", label=<{GuardFn|args : List[str]<br ALIGN="LEFT"/>cache_entry : Optional[CacheEntry]<br ALIGN="LEFT"/>closure_vars : Dict[str, object]<br ALIGN="LEFT"/>code_parts : List[str]<br ALIGN="LEFT"/>extra_state : Optional[ExtraState]<br ALIGN="LEFT"/>global_scope : Dict[str, object]<br ALIGN="LEFT"/>guard_fail_fn : Optional[Callable[[GuardFail], None]]<br ALIGN="LEFT"/>verbose_code_parts : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.optimizer.GuardInstallException" [color="black", fontcolor="red", label=<{GuardInstallException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.guards.GuardManagerType" [color="black", fontcolor="black", label=<{GuardManagerType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.guards.GuardManagerWrapper" [color="black", fontcolor="black", label=<{GuardManagerWrapper|args : NoneType<br ALIGN="LEFT"/>cache_entry : NoneType<br ALIGN="LEFT"/>closure_vars : NoneType<br ALIGN="LEFT"/>code_parts : list<br ALIGN="LEFT"/>diff_guard_root : NoneType<br ALIGN="LEFT"/>diff_guard_sources : OrderedSet[str], set<br ALIGN="LEFT"/>extra_state : NoneType<br ALIGN="LEFT"/>global_scope : NoneType, dict<br ALIGN="LEFT"/>guard_fail_fn : NoneType<br ALIGN="LEFT"/>id_matched_objs : dict<br ALIGN="LEFT"/>no_tensor_aliasing_sources : list<br ALIGN="LEFT"/>print_no_tensor_aliasing_guard : bool<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>verbose_code_parts : NoneType, list<br ALIGN="LEFT"/>|check(x)<br ALIGN="LEFT"/>check_verbose(x)<br ALIGN="LEFT"/>clone_with_chosen_sources(chosen_sources)<br ALIGN="LEFT"/>collect_diff_guard_sources()<br ALIGN="LEFT"/>construct_dict_manager_string(mgr, body)<br ALIGN="LEFT"/>construct_manager_string(mgr, body)<br ALIGN="LEFT"/>finalize()<br ALIGN="LEFT"/>get_guard_lines(guard)<br ALIGN="LEFT"/>get_manager_line(guard_manager, accessor_str)<br ALIGN="LEFT"/>populate_code_parts_for_debugging()<br ALIGN="LEFT"/>populate_diff_guard_manager()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.GuardOnDataDependentSymNode" [color="black", fontcolor="red", label=<{GuardOnDataDependentSymNode|cond : Basic<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.GuardSource" [color="black", fontcolor="black", label=<{GuardSource|name<br ALIGN="LEFT"/>|is_fsdp_module(): bool<br ALIGN="LEFT"/>is_local()<br ALIGN="LEFT"/>is_specialized_nn_module(): bool<br ALIGN="LEFT"/>is_unspecialized_builtin_nn_module(): bool<br ALIGN="LEFT"/>is_unspecialized_nn_module(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.types.GuardedCode" [color="black", fontcolor="black", label=<{GuardedCode|code<br ALIGN="LEFT"/>compile_id : CompileId<br ALIGN="LEFT"/>guard_manager<br ALIGN="LEFT"/>trace_annotation : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.GuardsCheckpointState" [color="black", fontcolor="black", label=<{GuardsCheckpointState|dynamo_guards : Set[Guard]<br ALIGN="LEFT"/>|diff(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.GuardsContext" [color="black", fontcolor="black", label=<{GuardsContext|aotautograd_guards : List[GuardEnvExpr]<br ALIGN="LEFT"/>dynamo_guards<br ALIGN="LEFT"/>|copy_graphstate()<br ALIGN="LEFT"/>restore_graphstate(state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.GuardsSet" [color="black", fontcolor="black", label=<{GuardsSet|inner : NoneType, set<br ALIGN="LEFT"/>|add(guard: Guard)<br ALIGN="LEFT"/>remove_guards_with_source(source)<br ALIGN="LEFT"/>update()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.gumbel.Gumbel" [color="black", fontcolor="black", label=<{Gumbel|arg_constraints : dict<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.HFPretrainedConfigVariable" [color="black", fontcolor="black", label=<{HFPretrainedConfigVariable|obj<br ALIGN="LEFT"/>|call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>is_matching_cls(cls)<br ALIGN="LEFT"/>is_matching_object(obj)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.HPUTestBase" [color="black", fontcolor="black", label=<{HPUTestBase|device_type : str<br ALIGN="LEFT"/>primary_device : ClassVar[str]<br ALIGN="LEFT"/>|get_primary_device()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.HSDPMeshInfo" [color="black", fontcolor="black", label=<{HSDPMeshInfo|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.half_cauchy.HalfCauchy" [color="black", fontcolor="black", label=<{HalfCauchy|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(prob)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.half_normal.HalfNormal" [color="black", fontcolor="black", label=<{HalfNormal|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(prob)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.HalfStorage" [color="black", fontcolor="black", label=<{HalfStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.HalfStorage" [color="black", fontcolor="black", label=<{HalfStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.HalideCSEVariable" [color="black", fontcolor="black", label=<{HalideCSEVariable|undefined_re<br ALIGN="LEFT"/>used_dims : Optional[List[sympy.Symbol]]<br ALIGN="LEFT"/>|index_str(dims)<br ALIGN="LEFT"/>subs_str(replacements)<br ALIGN="LEFT"/>update_on_args(name, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.HalideCodeCache" [color="black", fontcolor="black", label=<{HalideCodeCache|cache : Dict[str, Callable[[], Union[ModuleType, CDLL]]]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>glue_template_cpp<br ALIGN="LEFT"/>glue_template_cuda<br ALIGN="LEFT"/>prefix<br ALIGN="LEFT"/>standalone_runtime_cuda_init<br ALIGN="LEFT"/>|build_standalone_runtime(): str<br ALIGN="LEFT"/>config_hash(): str<br ALIGN="LEFT"/>find_header(name: str): str<br ALIGN="LEFT"/>find_libautoschedule(name: str): str<br ALIGN="LEFT"/>generate_halide(): Callable[[], Any]<br ALIGN="LEFT"/>generate_halide_async(meta: HalideMeta, source_code: str, submit_fn: Any): Callable[[], Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.HalideInputSpec" [color="black", fontcolor="black", label=<{HalideInputSpec|alias_of : Optional[str]<br ALIGN="LEFT"/>ctype : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>offset : Optional[str]<br ALIGN="LEFT"/>shape : Optional[List[str]]<br ALIGN="LEFT"/>stride : Optional[List[str]]<br ALIGN="LEFT"/>|bindings_type(): str<br ALIGN="LEFT"/>halide_type(): str<br ALIGN="LEFT"/>is_buffer(): bool<br ALIGN="LEFT"/>is_scalar(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.HalideKernel" [color="black", fontcolor="black", label=<{HalideKernel|buffer_aliases : Dict[str, List[str]]<br ALIGN="LEFT"/>buffer_dimensions : Dict[str, List[DimensionInfo]]<br ALIGN="LEFT"/>buffer_offsets : Dict[str, sympy.Expr]<br ALIGN="LEFT"/>compute<br ALIGN="LEFT"/>dom_renames : Dict[str, Dict[sympy.Symbol, sympy.Symbol]]<br ALIGN="LEFT"/>halide_vars : Dict[sympy.Symbol, sympy.Expr]<br ALIGN="LEFT"/>has_indirect_indexing : bool<br ALIGN="LEFT"/>has_reduction : bool<br ALIGN="LEFT"/>index_replacements : Dict[sympy.Expr, sympy.Expr]<br ALIGN="LEFT"/>indexing_code_dom<br ALIGN="LEFT"/>kexpr : Callable[[sympy.Expr], str]<br ALIGN="LEFT"/>loads<br ALIGN="LEFT"/>needs_dom_indexing : bool<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>reduction_renames : Dict[sympy.Symbol, sympy.Symbol]<br ALIGN="LEFT"/>stores<br ALIGN="LEFT"/>|apply_offset_to_dimension(dims, offset)<br ALIGN="LEFT"/>call_kernel(name: str, node)<br ALIGN="LEFT"/><I>check_bounds</I>(expr: sympy.Expr, size: sympy.Expr, lower: bool, upper: bool)<br ALIGN="LEFT"/>codegen_kernel(name)<br ALIGN="LEFT"/>codegen_rdom(name, vars)<br ALIGN="LEFT"/>create_cse_var(name, bounds, dtype)<br ALIGN="LEFT"/>dtype_to_str(dtype: torch.dtype): str<br ALIGN="LEFT"/>finalize_indexing(indices: Sequence[sympy.Expr])<br ALIGN="LEFT"/>generate_assert(check)<br ALIGN="LEFT"/>genfunc(line, used_dims): HalideCSEVariable<br ALIGN="LEFT"/>halide_argdefs()<br ALIGN="LEFT"/>halide_buffer_numel(name: str)<br ALIGN="LEFT"/>halide_kernel_meta(): HalideMeta<br ALIGN="LEFT"/>indexing_to_dimensions(var: str, index: sympy.Expr, is_store: bool)<br ALIGN="LEFT"/>install_dims(var, dims, offset, is_store)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>lookup_cse_var(name: str)<br ALIGN="LEFT"/>make_index_str(dims, replacements, zero_vars)<br ALIGN="LEFT"/>newfunc(used_dims): HalideCSEVariable<br ALIGN="LEFT"/>prepare_indexing(index: sympy.Expr)<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[CSEVariable, Tuple[CSEVariable, ...]]): Union[CSEVariable, Tuple[CSEVariable, ...]]<br ALIGN="LEFT"/>scan(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[CSEVariable, ...], Tuple[CSEVariable, ...]], Tuple[CSEVariable, ...]], values_orig: Tuple[CSEVariable, ...]): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>setup_dom_indexing()<br ALIGN="LEFT"/>sort_used_dims(used_dims)<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: CSEVariable, mode: StoreMode): None<br ALIGN="LEFT"/>sym_size(sym)<br ALIGN="LEFT"/>used_dims_from_index(index: sympy.Expr)<br ALIGN="LEFT"/>welford_combine_impl(mean, m2, weight)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.HalideMeta" [color="black", fontcolor="black", label=<{HalideMeta|argtypes : List[HalideInputSpec]<br ALIGN="LEFT"/>cuda_device : Optional[int]<br ALIGN="LEFT"/>scheduler : Optional[str]<br ALIGN="LEFT"/>scheduler_flags : Optional[Dict[str, Union[int, str]]]<br ALIGN="LEFT"/>target : str<br ALIGN="LEFT"/>|args(): List[str]<br ALIGN="LEFT"/>is_cuda(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.HalideOverrides" [color="black", fontcolor="black", label=<{HalideOverrides|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>acosh(x)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>asinh(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>atan2(x, y)<br ALIGN="LEFT"/>atanh(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_left_shift(a, b)<br ALIGN="LEFT"/>bitwise_not(a)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>bitwise_right_shift(a, b)<br ALIGN="LEFT"/>bitwise_xor(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>constant(value, dtype)<br ALIGN="LEFT"/>copysign(x, y)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>erf(x)<br ALIGN="LEFT"/>erfinv(x)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>fmod(a, b)<br ALIGN="LEFT"/>halide_clamp(value, size, check)<br ALIGN="LEFT"/>hypot(x, y)<br ALIGN="LEFT"/>index_expr(expr, dtype)<br ALIGN="LEFT"/>indirect_indexing(index_var, size, check, wrap_neg)<br ALIGN="LEFT"/>int_truediv(a, b)<br ALIGN="LEFT"/>isinf(x)<br ALIGN="LEFT"/>isnan(x)<br ALIGN="LEFT"/>lgamma(x)<br ALIGN="LEFT"/>libdevice_exp(x)<br ALIGN="LEFT"/>load_seed(name, offset)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>logical_and(a, b)<br ALIGN="LEFT"/>logical_not(a)<br ALIGN="LEFT"/>logical_or(a, b)<br ALIGN="LEFT"/>logical_xor(a, b)<br ALIGN="LEFT"/>masked(mask, body, other)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>nextafter(x, y)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>rand(seed, offset)<br ALIGN="LEFT"/>randint64(seed, offset, low, high)<br ALIGN="LEFT"/>randn(seed, offset)<br ALIGN="LEFT"/>relu(x)<br ALIGN="LEFT"/>round(x)<br ALIGN="LEFT"/>rsqrt(x)<br ALIGN="LEFT"/>sign(x)<br ALIGN="LEFT"/>signbit(x)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>tan(x)<br ALIGN="LEFT"/>tanh(x)<br ALIGN="LEFT"/>to_dtype(x, dtype: torch.dtype, src_dtype: Optional[torch.dtype], use_compute_types)<br ALIGN="LEFT"/>to_dtype_bitcast(x, dtype: torch.dtype, src_dtype: torch.dtype)<br ALIGN="LEFT"/>trunc(x)<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>where(a, b, c)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.HalidePrinter" [color="black", fontcolor="black", label=<{HalidePrinter|<br ALIGN="LEFT"/>|cast_float(expr)<br ALIGN="LEFT"/>cast_index(expr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.HalideScheduling" [color="black", fontcolor="black", label=<{HalideScheduling|kernel_type<br ALIGN="LEFT"/>|define_kernel(src_code, node_schedule, kernel)<br ALIGN="LEFT"/>get_backend_features(device: torch.device)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.HandleShardingStrategy" [color="black", fontcolor="black", label=<{HandleShardingStrategy|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._common_utils.HandleTrainingState" [color="black", fontcolor="black", label=<{HandleTrainingState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.activation.Hardshrink" [color="black", fontcolor="black", label=<{Hardshrink|lambd : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Hardsigmoid" [color="black", fontcolor="black", label=<{Hardsigmoid|inplace : bool<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.Hardswish" [color="black", fontcolor="black", label=<{Hardswish|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Hardswish" [color="black", fontcolor="black", label=<{Hardswish|inplace : bool<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Hardtanh" [color="black", fontcolor="black", label=<{Hardtanh|inplace : bool<br ALIGN="LEFT"/>max_val : float<br ALIGN="LEFT"/>min_val : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.fake_class_registry.HasStaticMethodFromReal" [color="black", fontcolor="black", label=<{HasStaticMethodFromReal|<br ALIGN="LEFT"/>|<I>from_real</I>(real_obj: torch.ScriptObject)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer" [color="black", fontcolor="black", label=<{HealthCheckServer|<br ALIGN="LEFT"/>|start(): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.HelperFunctions" [color="black", fontcolor="black", label=<{HelperFunctions|finalized_helpers : List[str]<br ALIGN="LEFT"/>|add(template_code: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.HeuristicType" [color="black", fontcolor="black", label=<{HeuristicType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms.model_averaging.hierarchical_model_averager.HierarchicalModelAverager" [color="black", fontcolor="black", label=<{HierarchicalModelAverager|period_process_group_dict : OrderedDict<br ALIGN="LEFT"/>step<br ALIGN="LEFT"/>warmup_steps : int<br ALIGN="LEFT"/>|average_parameters(params: Union[Iterable[torch.nn.Parameter], Iterable[Dict[str, torch.nn.Parameter]]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops.HigherOrderOperator" [color="black", fontcolor="black", label=<{HigherOrderOperator|namespace<br ALIGN="LEFT"/>non_fallthrough_keys<br ALIGN="LEFT"/>|cacheable()<br ALIGN="LEFT"/>dispatch()<br ALIGN="LEFT"/>fallthrough(dispatch_key)<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>py_impl(k: Any): Callable[[_F], _F]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.HingeEmbeddingLoss" [color="black", fontcolor="black", label=<{HingeEmbeddingLoss|margin : float<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.hints_wrap.HintsWrapper" [color="black", fontcolor="black", label=<{HintsWrapper|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.HintsWrapperHigherOrderVariable" [color="black", fontcolor="black", label=<{HintsWrapperHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.HipifyResult" [color="black", fontcolor="black", label=<{HipifyResult|current_state<br ALIGN="LEFT"/>hipified_path<br ALIGN="LEFT"/>status : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.observer.HistogramObserver" [color="black", fontcolor="black", label=<{HistogramObserver|bins : int<br ALIGN="LEFT"/>dst_nbins<br ALIGN="LEFT"/>histogram<br ALIGN="LEFT"/>max_val<br ALIGN="LEFT"/>min_val<br ALIGN="LEFT"/>upsample_rate : int<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x_orig: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>reset_histogram(x: torch.Tensor, min_val: torch.Tensor, max_val: torch.Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.utils.common.HolderModule" [color="black", fontcolor="black", label=<{HolderModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.hooks.Hooks" [color="black", fontcolor="black", label=<{Hooks|guard_export_fn : Optional[Callable[[GuardsSet], None]]<br ALIGN="LEFT"/>guard_fail_fn : Optional[Callable[[GuardFail], None]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.HopDispatchSetCache" [color="black", fontcolor="black", label=<{HopDispatchSetCache|hop_cache_map : dict<br ALIGN="LEFT"/>|get_cache(op: torch._ops.HigherOrderOperator): Optional[HopSubgraphCache]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.HopSubgraphCache" [color="black", fontcolor="black", label=<{HopSubgraphCache|<br ALIGN="LEFT"/>|<I>add_autograd_key_entry</I>(identifier: str, key: Callable)<br ALIGN="LEFT"/><I>add_dynamo_identifier</I>(cache_key: str, identifier: str)<br ALIGN="LEFT"/><I>add_proxy_dispatch_entry</I>(identifier: str, key: Callable)<br ALIGN="LEFT"/><I>get_autograd_key_entry</I>(identifier: str)<br ALIGN="LEFT"/><I>get_dynamo_identifier</I>(cache_key: str): Optional[str]<br ALIGN="LEFT"/><I>get_proxy_dispatch_entry</I>(identifier: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.HuberLoss" [color="black", fontcolor="black", label=<{HuberLoss|delta : float<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [color="black", fontcolor="black", label=<{HybridModel|ddp_params : tuple<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>non_ddp_params : tuple<br ALIGN="LEFT"/>remote_em_rref : RRef<br ALIGN="LEFT"/>remote_net_rref : RRef<br ALIGN="LEFT"/>|forward(input: FeatureSet)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.IRNode" [color="black", fontcolor="black", label=<{IRNode|dtype<br ALIGN="LEFT"/>origin_node : Optional[torch.fx.Node]<br ALIGN="LEFT"/>origins : OrderedSet[Any]<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>traceback : Optional[List[str]]<br ALIGN="LEFT"/>|<I>codegen_reference</I>(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/>common_repr(shorten: bool): Sequence[str]<br ALIGN="LEFT"/><I>constant_to_device</I>(device: torch.device): IRNode<br ALIGN="LEFT"/>current_origins(origins: OrderedSet[Node]): Generator[None, None, None]<br ALIGN="LEFT"/><I>freeze_layout</I>(): None<br ALIGN="LEFT"/><I>freeze_layout_with_exact_strides</I>(exact_strides: List[_IntLike], allow_padding: bool): None<br ALIGN="LEFT"/><I>freeze_layout_with_fill_order</I>(order: List[int]): None<br ALIGN="LEFT"/><I>freeze_layout_with_same_order</I>(stride: List[_IntLike]): None<br ALIGN="LEFT"/><I>freeze_layout_with_stride_order</I>(order: List[int], allow_padding: bool): None<br ALIGN="LEFT"/>get_defining_op(): Optional[Operation]<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_device_or_error(): torch.device<br ALIGN="LEFT"/>get_dtype(): torch.dtype<br ALIGN="LEFT"/><I>get_inputs_that_alias_output</I>(): Sequence[str]<br ALIGN="LEFT"/><I>get_layout</I>(): Layout<br ALIGN="LEFT"/><I>get_mutation_names</I>(): Sequence[str]<br ALIGN="LEFT"/><I>get_name</I>(): str<br ALIGN="LEFT"/>get_numel(): Expr<br ALIGN="LEFT"/><I>get_operation_name</I>(): str<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_output_spec(): OutputSpec<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/><I>get_read_writes</I>(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/><I>get_reduction_size</I>(): Sequence[sympy.Expr]<br ALIGN="LEFT"/><I>get_reduction_type</I>(): Optional[str]<br ALIGN="LEFT"/><I>get_size</I>(): Sequence[Expr]<br ALIGN="LEFT"/><I>get_storage_numel</I>(): _IntLike<br ALIGN="LEFT"/><I>get_stride</I>(): Sequence[_IntLike]<br ALIGN="LEFT"/>get_traceback(): Optional[List[str]]<br ALIGN="LEFT"/><I>get_unbacked_symbol_uses</I>(): OrderedSet[Symbol]<br ALIGN="LEFT"/>has_exceeded_max_reads(): bool<br ALIGN="LEFT"/>has_large_inner_fn(threshold: Optional[int]): bool<br ALIGN="LEFT"/>has_tensor_output(): bool<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>is_no_op(): bool<br ALIGN="LEFT"/>is_zero_elements(): bool<br ALIGN="LEFT"/><I>make_indexer</I>(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/><I>make_loader</I>(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/><I>mark_reuse</I>(users: int): None<br ALIGN="LEFT"/>maybe_get_dtype(): Optional[torch.dtype]<br ALIGN="LEFT"/>maybe_get_layout(): Optional[Layout]<br ALIGN="LEFT"/>maybe_get_name(): Optional[str]<br ALIGN="LEFT"/>maybe_get_output_spec(): Optional[OutputSpec]<br ALIGN="LEFT"/>maybe_get_size(): Optional[Sequence[_IntLike]]<br ALIGN="LEFT"/>maybe_get_stride(): Optional[Sequence[_IntLike]]<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/><I>realize</I>(): Optional[str]<br ALIGN="LEFT"/><I>realize_hint</I>(): None<br ALIGN="LEFT"/>str_helper(lines: Sequence[object], shorten: bool, multiline: bool): str<br ALIGN="LEFT"/><I>unwrap_view</I>(): IRNode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.Identity" [color="black", fontcolor="black", label=<{Identity|precedence : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.prune.Identity" [color="black", fontcolor="black", label=<{Identity|PRUNING_TYPE : str<br ALIGN="LEFT"/>|apply(module, name)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.linear.Identity" [color="black", fontcolor="black", label=<{Identity|training<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.pre_grad.remove_identity.IdentityRemover" [color="black", fontcolor="black", label=<{IdentityRemover|<br ALIGN="LEFT"/>|call_module(target, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy.testing.utils.IgnoreException" [color="black", fontcolor="red", label=<{IgnoreException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.Ignored" [color="black", fontcolor="black", label=<{Ignored|<br ALIGN="LEFT"/>|pretty_print(pp: PatternPrettyPrinter): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.utils.decoder.ImageHandler" [color="black", fontcolor="black", label=<{ImageHandler|imagespec<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.ImplementedSparsifier" [color="black", fontcolor="black", label=<{ImplementedSparsifier|<br ALIGN="LEFT"/>|update_mask(module: nn.Module, tensor_name: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.importer.Importer" [color="black", fontcolor="black", label=<{Importer|modules : Dict[str, ModuleType]<br ALIGN="LEFT"/>|get_name(obj: Any, name: Optional[str]): Tuple[str, str]<br ALIGN="LEFT"/><I>import_module</I>(module_name: str): ModuleType<br ALIGN="LEFT"/>whichmodule(obj: Any, name: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic.InconsistentMetadata" [color="black", fontcolor="red", label=<{InconsistentMetadata|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.IncorrectUsage" [color="black", fontcolor="red", label=<{IncorrectUsage|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.IncrementRecursionCount" [color="black", fontcolor="black", label=<{IncrementRecursionCount|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.IndentedBuffer" [color="black", fontcolor="black", label=<{IndentedBuffer|tabwidth : int<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>do_indent(offset)<br ALIGN="LEFT"/>do_unindent(offset)<br ALIGN="LEFT"/>getrawvalue(): str<br ALIGN="LEFT"/>getvalue(): str<br ALIGN="LEFT"/>getvaluewithlinemap(): tuple[str, list[tuple[int, LineContext]]]<br ALIGN="LEFT"/>indent(offset)<br ALIGN="LEFT"/>map(func: Callable[[Any], Any]): IndentedBuffer<br ALIGN="LEFT"/>newline()<br ALIGN="LEFT"/>prefix()<br ALIGN="LEFT"/>splice(other_code, strip)<br ALIGN="LEFT"/>writeline(line)<br ALIGN="LEFT"/>writelines(lines)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.GuardManagerWrapper.__str__.IndentedBufferWithPrefix" [color="black", fontcolor="black", label=<{IndentedBufferWithPrefix|tabwidth : int<br ALIGN="LEFT"/>|prefix()<br ALIGN="LEFT"/>writeline(line, skip_prefix)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.independent.Independent" [color="black", fontcolor="black", label=<{Independent|arg_constraints : Dict[str, constraints.Constraint]<br ALIGN="LEFT"/>base_dist<br ALIGN="LEFT"/>has_enumerate_support<br ALIGN="LEFT"/>has_rsample<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>reinterpreted_batch_ndims<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>enumerate_support(expand)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.IndependentTransform" [color="black", fontcolor="black", label=<{IndependentTransform|base_transform<br ALIGN="LEFT"/>bijective<br ALIGN="LEFT"/>reinterpreted_batch_ndims<br ALIGN="LEFT"/>sign<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies.IndexExprDep" [color="black", fontcolor="black", label=<{IndexExprDep|index : Expr<br ALIGN="LEFT"/>size : Tuple[sympy.Expr, ...]<br ALIGN="LEFT"/>var_names : Tuple[sympy.Symbol, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._funcs.IndexExpression" [color="black", fontcolor="black", label=<{IndexExpression|maketuple<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.index_propagation.IndexPropVar" [color="black", fontcolor="black", label=<{IndexPropVar|is_symbolic : bool<br ALIGN="LEFT"/>value : Any<br ALIGN="LEFT"/>|new_symbolic(expr: TypedExpr): 'IndexPropVar'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.index_propagation.IndexPropagation" [color="black", fontcolor="black", label=<{IndexPropagation|axioms<br ALIGN="LEFT"/>indirect_var_ranges : Dict[sympy.Symbol, sympy.Expr]<br ALIGN="LEFT"/>shape_env<br ALIGN="LEFT"/>var_to_range : tuple<br ALIGN="LEFT"/>|fallback(name: Literal['indirect_indexing'], args: Tuple[Any, ...], kwargs: Dict[str, Any]): IndexPropVar<br ALIGN="LEFT"/>indirect_indexing(index: Union[Any, IndexPropVar], size: Any, check: bool, wrap_neg): Any<br ALIGN="LEFT"/>materialize_expr(expr: sympy.Expr, dtype: torch.dtype): Any<br ALIGN="LEFT"/>propagate_sympy(name: str, args: Tuple[Any, ...], kwargs: Dict[str, Any]): IndexPropResult<br ALIGN="LEFT"/>statically_true(e)<br ALIGN="LEFT"/>unwrap(a: Union[Any, IndexPropVar]): Any<br ALIGN="LEFT"/>wrap(a): IndexPropResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.IndexPutFallback" [color="black", fontcolor="black", label=<{IndexPutFallback|indices<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.IndexSelect" [color="black", fontcolor="black", label=<{IndexSelect|dim_replace<br ALIGN="LEFT"/>index<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>tensor_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.IndexingConstant" [color="black", fontcolor="black", label=<{IndexingConstant|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>index : Any<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.IndexingOptions" [color="black", fontcolor="black", label=<{IndexingOptions|expand_str : Optional[str]<br ALIGN="LEFT"/>index : Expr<br ALIGN="LEFT"/>index_str : str<br ALIGN="LEFT"/>mask_str : str<br ALIGN="LEFT"/>mask_vars : OrderedSet[str]<br ALIGN="LEFT"/>|has_indirect()<br ALIGN="LEFT"/>has_mask()<br ALIGN="LEFT"/>has_rindex()<br ALIGN="LEFT"/>has_rmask()<br ALIGN="LEFT"/>has_tmpmask()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.choices.InductorChoices" [color="black", fontcolor="black", label=<{InductorChoices|<br ALIGN="LEFT"/>|can_fuse(scheduler: Scheduler, node1: BaseSchedulerNode, node2: BaseSchedulerNode, shared_data_score: int): bool<br ALIGN="LEFT"/>can_fuse_horizontal(scheduler: Scheduler, node1: BaseSchedulerNode, node2: BaseSchedulerNode, shared_data_score: int): bool<br ALIGN="LEFT"/>can_fuse_vertical(scheduler: Scheduler, node1: BaseSchedulerNode, node2: BaseSchedulerNode, shared_data_score: int): bool<br ALIGN="LEFT"/>reduction_split_factor(device: torch.device, reduction_numel_hint: int, numel_hint: int, inner_reduction: bool): int<br ALIGN="LEFT"/>score_fusion(scheduler: Scheduler, node1: BaseSchedulerNode, node2: BaseSchedulerNode): Sortable<br ALIGN="LEFT"/>should_use_cooperative_reduction(features: SIMDKernelFeatures): bool<br ALIGN="LEFT"/>should_use_persistent_reduction(features: SIMDKernelFeatures, cooperative_reduction: bool): bool<br ALIGN="LEFT"/>triton_kernel_kwargs(kernel_cls: Type[TritonKernel], features: SIMDKernelFeatures, groups: List[sympy.Expr], kernel_kwargs: Dict[str, Any]): Dict[str, Any]<br ALIGN="LEFT"/>want_no_x_dim(features: SIMDKernelFeatures): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.InferStride" [color="black", fontcolor="black", label=<{InferStride|dim : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.InferenceModeVariable" [color="black", fontcolor="black", label=<{InferenceModeVariable|target_values<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_value)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._vendor.packaging._structures.InfinityType" [color="black", fontcolor="black", label=<{InfinityType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.bundled_inputs.InflatableArg" [color="black", fontcolor="black", label=<{InflatableArg|fmt : str<br ALIGN="LEFT"/>fmt_fn : str<br ALIGN="LEFT"/>value : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.autograd.Info" [color="black", fontcolor="black", label=<{Info|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.autograd.InfoProtocol" [color="black", fontcolor="black", label=<{InfoProtocol|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.InliningGeneratorInstructionTranslator" [color="black", fontcolor="black", label=<{InliningGeneratorInstructionTranslator|generated_items : List[VariableTracker]<br ALIGN="LEFT"/>instruction_pointer<br ALIGN="LEFT"/>|GET_YIELD_FROM_ITER(inst)<br ALIGN="LEFT"/>SEND(inst)<br ALIGN="LEFT"/>YIELD_FROM(inst)<br ALIGN="LEFT"/>YIELD_VALUE(inst: Instruction)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.InliningInstructionTranslator" [color="black", fontcolor="black", label=<{InliningInstructionTranslator|fake_mode<br ALIGN="LEFT"/>instruction_pointer : NoneType<br ALIGN="LEFT"/>nn_module_stack<br ALIGN="LEFT"/>num_calls<br ALIGN="LEFT"/>one_graph<br ALIGN="LEFT"/>parent<br ALIGN="LEFT"/>symbolic_result : Optional[TensorVariable]<br ALIGN="LEFT"/>|RETURN_CONST(inst)<br ALIGN="LEFT"/>RETURN_VALUE(inst)<br ALIGN="LEFT"/>STORE_GLOBAL(inst)<br ALIGN="LEFT"/>check_inlineable(func)<br ALIGN="LEFT"/>create_call_resume_at(offset)<br ALIGN="LEFT"/>get_globals_source_and_value(name)<br ALIGN="LEFT"/>inline_call(parent, func, args, kwargs)<br ALIGN="LEFT"/>inline_call_(parent, func: VariableTracker, args: List[VariableTracker], kwargs)<br ALIGN="LEFT"/>run_ctx_mgr()<br ALIGN="LEFT"/>should_compile_partial_graph()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.InnerModule" [color="black", fontcolor="black", label=<{InnerModule|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>relu2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>fuse_modules()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.InnerTensorKey" [color="black", fontcolor="black", label=<{InnerTensorKey|inner_name : str<br ALIGN="LEFT"/>|get(o: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.InplaceBernoulliFallback" [color="black", fontcolor="black", label=<{InplaceBernoulliFallback|name<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.InplaceCopyFallback" [color="black", fontcolor="black", label=<{InplaceCopyFallback|name<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(dst, src, non_blocking: bool)<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function.InplaceFunction" [color="black", fontcolor="black", label=<{InplaceFunction|inplace : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.reinplace.InplaceableOp" [color="black", fontcolor="black", label=<{InplaceableOp|extra_check : Callable[[torch.fx.Node], bool]<br ALIGN="LEFT"/>inplace_op : Callable[..., Any]<br ALIGN="LEFT"/>mutated_arg : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.InplacedBuffer" [color="black", fontcolor="black", label=<{InplacedBuffer|inner_name : str<br ALIGN="LEFT"/>other_names : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.InputAdaptStep" [color="black", fontcolor="black", label=<{InputAdaptStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.InputAdapter" [color="black", fontcolor="black", label=<{InputAdapter|<br ALIGN="LEFT"/>|append_step(step: InputAdaptStep): None<br ALIGN="LEFT"/>apply(): Sequence[int \| float \| bool \| str \| torch.Tensor \| torch.dtype \| None]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.InputAliasInfo" [color="black", fontcolor="black", label=<{InputAliasInfo|is_leaf : bool<br ALIGN="LEFT"/>keep_input_mutations : bool<br ALIGN="LEFT"/>mutates_data : bool<br ALIGN="LEFT"/>mutates_metadata : bool<br ALIGN="LEFT"/>mutates_storage_metadata : bool<br ALIGN="LEFT"/>mutation_inductor_storage_resize : bool<br ALIGN="LEFT"/>mutation_type<br ALIGN="LEFT"/>mutations_hidden_from_autograd : bool<br ALIGN="LEFT"/>mutations_under_no_grad_or_inference_mode : bool<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.InputBuffer" [color="black", fontcolor="black", label=<{InputBuffer|<br ALIGN="LEFT"/>|num_reads(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.subgraph_lowering.InputDescriptor" [color="black", fontcolor="black", label=<{InputDescriptor|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.InputDim" [color="black", fontcolor="black", label=<{InputDim|input_dim : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.passes.add_runtime_assertions_for_constraints_pass.InputDim" [color="black", fontcolor="black", label=<{InputDim|dim : int<br ALIGN="LEFT"/>input_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.InputError" [color="black", fontcolor="red", label=<{InputError|message<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.InputKind" [color="black", fontcolor="black", label=<{InputKind|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.graph_region_tracker.InputPickler" [color="black", fontcolor="black", label=<{InputPickler|dispatch_table : dict<br ALIGN="LEFT"/>fast : bool<br ALIGN="LEFT"/>|dumps(obj: Any): bytes<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.InputReader" [color="black", fontcolor="black", label=<{InputReader|args : list<br ALIGN="LEFT"/>pbar : NoneType<br ALIGN="LEFT"/>store : NoneType<br ALIGN="LEFT"/>|storage(storage_hash, nbytes)<br ALIGN="LEFT"/>symint(val)<br ALIGN="LEFT"/>tensor(storage, shape, stride)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.InputSpec" [color="black", fontcolor="black", label=<{InputSpec|buffer : Annotated[InputToBufferSpec, 30]<br ALIGN="LEFT"/>constant_input : Annotated[InputToConstantInputSpec, 60]<br ALIGN="LEFT"/>custom_obj : Annotated[InputToCustomObjSpec, 50]<br ALIGN="LEFT"/>parameter : Annotated[InputToParameterSpec, 20]<br ALIGN="LEFT"/>tensor_constant : Annotated[InputToTensorConstantSpec, 40]<br ALIGN="LEFT"/>token : Annotated[InputTokenSpec, 70]<br ALIGN="LEFT"/>user_input : Annotated[UserInputSpec, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.InputSpec" [color="black", fontcolor="black", label=<{InputSpec|arg : Union<br ALIGN="LEFT"/>kind<br ALIGN="LEFT"/>persistent : Optional[bool]<br ALIGN="LEFT"/>target : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputToBufferSpec" [color="black", fontcolor="black", label=<{InputToBufferSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>buffer_name : Annotated[str, 20]<br ALIGN="LEFT"/>persistent : Annotated[bool, 30]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputToConstantInputSpec" [color="black", fontcolor="black", label=<{InputToConstantInputSpec|name : Annotated[str, 10]<br ALIGN="LEFT"/>value : Annotated[ConstantValue, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputToCustomObjSpec" [color="black", fontcolor="black", label=<{InputToCustomObjSpec|arg : Annotated[CustomObjArgument, 10]<br ALIGN="LEFT"/>custom_obj_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputToParameterSpec" [color="black", fontcolor="black", label=<{InputToParameterSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>parameter_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputToTensorConstantSpec" [color="black", fontcolor="black", label=<{InputToTensorConstantSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>tensor_constant_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.InputTokenSpec" [color="black", fontcolor="black", label=<{InputTokenSpec|arg : Annotated[TokenArgument, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.InputVariableMixin" [color="black", fontcolor="black", label=<{InputVariableMixin|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.InputWeightEqualizationDetector" [color="black", fontcolor="black", label=<{InputWeightEqualizationDetector|ACTIVATION_PREFIX : str<br ALIGN="LEFT"/>CHANNEL_KEY : str<br ALIGN="LEFT"/>COMP_METRIC_KEY : str<br ALIGN="LEFT"/>DEFAULT_PRE_OBSERVER_NAME : str<br ALIGN="LEFT"/>DEFAULT_RECOMMEND_INPUT_WEIGHT_CHANNEL_RATIO : float<br ALIGN="LEFT"/>GLOBAL_MAX_KEY : str<br ALIGN="LEFT"/>GLOBAL_MIN_KEY : str<br ALIGN="LEFT"/>INPUT_STR : str<br ALIGN="LEFT"/>PER_CHANNEL_MAX_KEY : str<br ALIGN="LEFT"/>PER_CHANNEL_MIN_KEY : str<br ALIGN="LEFT"/>RECOMMENDED_KEY : str<br ALIGN="LEFT"/>SUPPORTED_MODULES : Set[Callable]<br ALIGN="LEFT"/>THRESHOLD_KEY : str<br ALIGN="LEFT"/>WEIGHT_PREFIX : str<br ALIGN="LEFT"/>WEIGHT_STR : str<br ALIGN="LEFT"/>ch_axis : int<br ALIGN="LEFT"/>ratio_threshold : float<br ALIGN="LEFT"/>|determine_observer_insert_points(prepared_fx_model: GraphModule): Dict[str, Dict[str, Any]]<br ALIGN="LEFT"/>generate_detector_report(model: GraphModule): Tuple[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_detector_name(): str<br ALIGN="LEFT"/>get_qconfig_info(model): Dict[str, DetectorQConfigInfo]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.InputWriter" [color="black", fontcolor="black", label=<{InputWriter|save_dir<br ALIGN="LEFT"/>seen_storages : dict<br ALIGN="LEFT"/>storage_counter : count<br ALIGN="LEFT"/>store : NoneType<br ALIGN="LEFT"/>|const(name): None<br ALIGN="LEFT"/>lines()<br ALIGN="LEFT"/>storage(untyped_storage): str<br ALIGN="LEFT"/>symint(name, val): None<br ALIGN="LEFT"/>tensor(name, t): None<br ALIGN="LEFT"/>unsupported(name, arg)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.InputsKernel" [color="black", fontcolor="black", label=<{InputsKernel|inputs : List[Buffer]<br ALIGN="LEFT"/>|get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/>unwrap_storage(inputs)<br ALIGN="LEFT"/>unwrap_storage_for_input(x: IRNode): IRNode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.InsertTypePromotion" [color="black", fontcolor="black", label=<{InsertTypePromotion|interpreter<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.InspectBoundArgumentsVariable" [color="black", fontcolor="black", label=<{InspectBoundArgumentsVariable|bound_arguments : BoundArguments<br ALIGN="LEFT"/>bound_arguments_var<br ALIGN="LEFT"/>defaults : Dict[str, VariableTracker]<br ALIGN="LEFT"/>packed_vars : set<br ALIGN="LEFT"/>signature<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.InspectParameterVariable" [color="black", fontcolor="black", label=<{InspectParameterVariable|value<br ALIGN="LEFT"/>|var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.InspectSignatureVariable" [color="black", fontcolor="black", label=<{InspectSignatureVariable|fn<br ALIGN="LEFT"/>inspected<br ALIGN="LEFT"/>parameters : list<br ALIGN="LEFT"/>signature<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create(callable)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm1d" [color="black", fontcolor="black", label=<{InstanceNorm1d|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm1d" [color="black", fontcolor="black", label=<{InstanceNorm1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm2d" [color="black", fontcolor="black", label=<{InstanceNorm2d|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm2d" [color="black", fontcolor="black", label=<{InstanceNorm2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm3d" [color="black", fontcolor="black", label=<{InstanceNorm3d|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm3d" [color="black", fontcolor="black", label=<{InstanceNorm3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.decomposition_skip.InstanceNormDecompSkip" [color="black", fontcolor="black", label=<{InstanceNormDecompSkip|new_op_name : str<br ALIGN="LEFT"/>new_op_schema : str<br ALIGN="LEFT"/>onnxscript_function<br ALIGN="LEFT"/>op_callable<br ALIGN="LEFT"/>|abstract(input, weight, bias, running_mean, running_var, use_input_stats: bool, momentum: float, eps: float, cudnn_enabled: bool)<br ALIGN="LEFT"/>register(export_options: torch.onnx.ExportOptions)<br ALIGN="LEFT"/>unregister()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.instance_norm_expanded_weights.InstanceNormPerSampleGrad" [color="black", fontcolor="black", label=<{InstanceNormPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, kwarg_names, _)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.bytecode_transformation.Instruction" [color="black", fontcolor="black", label=<{Instruction|arg : Optional[int]<br ALIGN="LEFT"/>argval : Any<br ALIGN="LEFT"/>exn_tab_entry : Optional[InstructionExnTabEntry]<br ALIGN="LEFT"/>is_jump_target : bool<br ALIGN="LEFT"/>offset : Optional[int]<br ALIGN="LEFT"/>opcode : int<br ALIGN="LEFT"/>opname : str<br ALIGN="LEFT"/>positions : Optional['dis.Positions']<br ALIGN="LEFT"/>starts_line : Optional[int]<br ALIGN="LEFT"/>target : Optional['Instruction']<br ALIGN="LEFT"/>|short_inst_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.bytecode_transformation.InstructionExnTabEntry" [color="black", fontcolor="black", label=<{InstructionExnTabEntry|depth : int<br ALIGN="LEFT"/>end : str<br ALIGN="LEFT"/>lasti : bool<br ALIGN="LEFT"/>start : str<br ALIGN="LEFT"/>target : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.InstructionTranslator" [color="black", fontcolor="black", label=<{InstructionTranslator|debug_locals : List[Tuple[VariableTracker, List[VariableTracker]]]<br ALIGN="LEFT"/>export<br ALIGN="LEFT"/>instruction_pointer : NoneType<br ALIGN="LEFT"/>one_graph : bool<br ALIGN="LEFT"/>symbolic_locals : dict, tuple<br ALIGN="LEFT"/>symbolic_torch_function_state<br ALIGN="LEFT"/>|RETURN_CONST(inst)<br ALIGN="LEFT"/>RETURN_VALUE(inst)<br ALIGN="LEFT"/>create_call_resume_at(inst)<br ALIGN="LEFT"/>current_tx(): 'InstructionTranslator'<br ALIGN="LEFT"/>get_example_value(source: Source)<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>set_current_tx()<br ALIGN="LEFT"/>should_compile_partial_graph()<br ALIGN="LEFT"/>symbolic_locals_contain_module_class()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.InstructionTranslatorBase" [color="black", fontcolor="black", label=<{InstructionTranslatorBase|BINARY_ADD<br ALIGN="LEFT"/>BINARY_AND<br ALIGN="LEFT"/>BINARY_FLOOR_DIVIDE<br ALIGN="LEFT"/>BINARY_LSHIFT<br ALIGN="LEFT"/>BINARY_MATRIX_MULTIPLY<br ALIGN="LEFT"/>BINARY_MODULO<br ALIGN="LEFT"/>BINARY_MULTIPLY<br ALIGN="LEFT"/>BINARY_OR<br ALIGN="LEFT"/>BINARY_POWER<br ALIGN="LEFT"/>BINARY_REMAINDER<br ALIGN="LEFT"/>BINARY_RSHIFT<br ALIGN="LEFT"/>BINARY_SUBSCR<br ALIGN="LEFT"/>BINARY_SUBTRACT<br ALIGN="LEFT"/>BINARY_TRUE_DIVIDE<br ALIGN="LEFT"/>BINARY_XOR<br ALIGN="LEFT"/>BUILD_MAP_UNPACK_WITH_CALL<br ALIGN="LEFT"/>BUILD_TUPLE_UNPACK_WITH_CALL<br ALIGN="LEFT"/>DICT_UPDATE<br ALIGN="LEFT"/>INPLACE_ADD<br ALIGN="LEFT"/>INPLACE_AND<br ALIGN="LEFT"/>INPLACE_FLOOR_DIVIDE<br ALIGN="LEFT"/>INPLACE_LSHIFT<br ALIGN="LEFT"/>INPLACE_MATRIX_MULTIPLY<br ALIGN="LEFT"/>INPLACE_MODULO<br ALIGN="LEFT"/>INPLACE_MULTIPLY<br ALIGN="LEFT"/>INPLACE_OR<br ALIGN="LEFT"/>INPLACE_POWER<br ALIGN="LEFT"/>INPLACE_REMAINDER<br ALIGN="LEFT"/>INPLACE_RSHIFT<br ALIGN="LEFT"/>INPLACE_SUBTRACT<br ALIGN="LEFT"/>INPLACE_TRUE_DIVIDE<br ALIGN="LEFT"/>INPLACE_XOR<br ALIGN="LEFT"/>JUMP_ABSOLUTE<br ALIGN="LEFT"/>JUMP_BACKWARD<br ALIGN="LEFT"/>JUMP_BACKWARD_NO_INTERRUPT<br ALIGN="LEFT"/>JUMP_FORWARD<br ALIGN="LEFT"/>JUMP_IF_FALSE_OR_POP<br ALIGN="LEFT"/>JUMP_IF_TRUE_OR_POP<br ALIGN="LEFT"/>LOAD_CLOSURE<br ALIGN="LEFT"/>POP_JUMP_BACKWARD_IF_FALSE<br ALIGN="LEFT"/>POP_JUMP_BACKWARD_IF_TRUE<br ALIGN="LEFT"/>POP_JUMP_FORWARD_IF_FALSE<br ALIGN="LEFT"/>POP_JUMP_FORWARD_IF_TRUE<br ALIGN="LEFT"/>POP_JUMP_IF_FALSE<br ALIGN="LEFT"/>POP_JUMP_IF_TRUE<br ALIGN="LEFT"/>UNARY_INVERT<br ALIGN="LEFT"/>UNARY_NEGATIVE<br ALIGN="LEFT"/>UNARY_NOT<br ALIGN="LEFT"/>UNARY_POSITIVE<br ALIGN="LEFT"/>accept_prefix_inst : bool<br ALIGN="LEFT"/>block_stack : List[BlockStackEntry]<br ALIGN="LEFT"/>code_options : Dict[str, Any]<br ALIGN="LEFT"/>current_instruction<br ALIGN="LEFT"/>current_speculation : Optional[SpeculationEntry]<br ALIGN="LEFT"/>dispatch_table : List[Any]<br ALIGN="LEFT"/>distributed_state : Optional[DistributedState]<br ALIGN="LEFT"/>exec_recorder : Optional[ExecutionRecorder]<br ALIGN="LEFT"/>exn_vt_stack : List[VariableTracker]<br ALIGN="LEFT"/>export : bool<br ALIGN="LEFT"/>f_builtins : Dict[str, Any]<br ALIGN="LEFT"/>f_code<br ALIGN="LEFT"/>f_globals : Dict[str, Any]<br ALIGN="LEFT"/>f_locals : Dict[str, Any]<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>generic_context_manager_depth : int<br ALIGN="LEFT"/>inconsistent_side_effects : bool<br ALIGN="LEFT"/>indexof : Dict[Instruction, int]<br ALIGN="LEFT"/>inline_depth : int<br ALIGN="LEFT"/>instruction_pointer : Optional[int]<br ALIGN="LEFT"/>instructions : List[Instruction]<br ALIGN="LEFT"/>is_non_empty_graph<br ALIGN="LEFT"/>kw_names : Optional[ConstantVariable]<br ALIGN="LEFT"/>lineno : int<br ALIGN="LEFT"/>next_instruction<br ALIGN="LEFT"/>nn_module_stack : Dict[str, Tuple[str, Type[Any]]]<br ALIGN="LEFT"/>nn_modules_globals_vt<br ALIGN="LEFT"/>num_calls : Dict[str, int]<br ALIGN="LEFT"/>one_graph : bool<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>prefix_insts : List[Instruction]<br ALIGN="LEFT"/>speculation_log<br ALIGN="LEFT"/>stack : List[VariableTracker]<br ALIGN="LEFT"/>strict_checks_fn : Optional[Callable[[VariableTracker], bool]]<br ALIGN="LEFT"/>symbolic_globals : Dict[str, VariableTracker]<br ALIGN="LEFT"/>symbolic_locals : Dict[str, VariableTracker]<br ALIGN="LEFT"/>symbolic_torch_function_state<br ALIGN="LEFT"/>|BEFORE_WITH(inst)<br ALIGN="LEFT"/>BEGIN_FINALLY(inst)<br ALIGN="LEFT"/>BINARY_OP(inst)<br ALIGN="LEFT"/>BUILD_CONST_KEY_MAP(inst)<br ALIGN="LEFT"/>BUILD_LIST(inst)<br ALIGN="LEFT"/>BUILD_LIST_UNPACK(inst, cls)<br ALIGN="LEFT"/>BUILD_MAP(inst)<br ALIGN="LEFT"/>BUILD_MAP_UNPACK(inst)<br ALIGN="LEFT"/>BUILD_SET(inst)<br ALIGN="LEFT"/>BUILD_SLICE(inst)<br ALIGN="LEFT"/>BUILD_STRING(inst)<br ALIGN="LEFT"/>BUILD_TUPLE(inst)<br ALIGN="LEFT"/>BUILD_TUPLE_UNPACK(inst)<br ALIGN="LEFT"/><I>CACHE</I>(inst)<br ALIGN="LEFT"/>CALL(inst)<br ALIGN="LEFT"/>CALL_FINALLY(inst)<br ALIGN="LEFT"/>CALL_FUNCTION(inst)<br ALIGN="LEFT"/>CALL_FUNCTION_EX(inst)<br ALIGN="LEFT"/>CALL_FUNCTION_KW(inst)<br ALIGN="LEFT"/>CALL_INTRINSIC_1(inst)<br ALIGN="LEFT"/>CALL_KW(inst)<br ALIGN="LEFT"/>CALL_METHOD(inst)<br ALIGN="LEFT"/>CHECK_EXC_MATCH(inst)<br ALIGN="LEFT"/>COMPARE_OP(inst)<br ALIGN="LEFT"/>CONTAINS_OP(inst)<br ALIGN="LEFT"/>CONVERT_VALUE(inst)<br ALIGN="LEFT"/>COPY(inst)<br ALIGN="LEFT"/>COPY_FREE_VARS(inst)<br ALIGN="LEFT"/>DELETE_ATTR(inst)<br ALIGN="LEFT"/>DELETE_FAST(inst)<br ALIGN="LEFT"/>DELETE_SUBSCR(inst)<br ALIGN="LEFT"/>DICT_MERGE(inst)<br ALIGN="LEFT"/>DUP_TOP(inst)<br ALIGN="LEFT"/>DUP_TOP_TWO(inst)<br ALIGN="LEFT"/>END_FINALLY(inst)<br ALIGN="LEFT"/>END_FOR(inst)<br ALIGN="LEFT"/>END_SEND(inst)<br ALIGN="LEFT"/>FORMAT_SIMPLE(inst)<br ALIGN="LEFT"/>FORMAT_VALUE(inst)<br ALIGN="LEFT"/>FORMAT_WITH_SPEC(inst)<br ALIGN="LEFT"/>FOR_ITER(inst)<br ALIGN="LEFT"/>GEN_START(inst)<br ALIGN="LEFT"/>GET_ITER(inst)<br ALIGN="LEFT"/>GET_LEN(inst)<br ALIGN="LEFT"/>IMPORT_FROM(inst)<br ALIGN="LEFT"/>IMPORT_NAME(inst)<br ALIGN="LEFT"/>IS_OP(inst)<br ALIGN="LEFT"/>JUMP_IF_NOT_EXC_MATCH(inst)<br ALIGN="LEFT"/>KW_NAMES(inst)<br ALIGN="LEFT"/>LIST_APPEND(inst)<br ALIGN="LEFT"/>LIST_EXTEND(inst)<br ALIGN="LEFT"/>LIST_TO_TUPLE(inst)<br ALIGN="LEFT"/>LOAD_ASSERTION_ERROR(inst)<br ALIGN="LEFT"/>LOAD_ATTR(inst)<br ALIGN="LEFT"/>LOAD_ATTR_SUPER(inst)<br ALIGN="LEFT"/>LOAD_CONST(inst)<br ALIGN="LEFT"/>LOAD_DEREF(inst)<br ALIGN="LEFT"/>LOAD_FAST(inst)<br ALIGN="LEFT"/>LOAD_FAST_AND_CLEAR(inst)<br ALIGN="LEFT"/>LOAD_FAST_CHECK(inst)<br ALIGN="LEFT"/>LOAD_GLOBAL(inst)<br ALIGN="LEFT"/>LOAD_METHOD(inst)<br ALIGN="LEFT"/>LOAD_METHOD_SUPER(inst)<br ALIGN="LEFT"/>LOAD_SUPER_ATTR(inst)<br ALIGN="LEFT"/>MAKE_CELL(inst)<br ALIGN="LEFT"/>MAKE_FUNCTION(inst)<br ALIGN="LEFT"/>MAP_ADD(inst)<br ALIGN="LEFT"/>MATCH_KEYS(inst)<br ALIGN="LEFT"/>MATCH_MAPPING(inst)<br ALIGN="LEFT"/>MATCH_SEQUENCE(inst)<br ALIGN="LEFT"/><I>NOP</I>(inst)<br ALIGN="LEFT"/>POP_BLOCK(inst)<br ALIGN="LEFT"/>POP_EXCEPT(inst)<br ALIGN="LEFT"/>POP_FINALLY(inst)<br ALIGN="LEFT"/>POP_TOP(inst)<br ALIGN="LEFT"/><I>PRECALL</I>(inst)<br ALIGN="LEFT"/>PUSH_EXC_INFO(inst)<br ALIGN="LEFT"/>PUSH_NULL(inst)<br ALIGN="LEFT"/>RAISE_VARARGS(inst)<br ALIGN="LEFT"/>RERAISE(inst)<br ALIGN="LEFT"/>RESUME(inst)<br ALIGN="LEFT"/>RETURN_GENERATOR(inst)<br ALIGN="LEFT"/>ROT_FOUR(inst)<br ALIGN="LEFT"/>ROT_THREE(inst)<br ALIGN="LEFT"/>ROT_TWO(inst)<br ALIGN="LEFT"/>SETUP_EXCEPT(inst)<br ALIGN="LEFT"/>SETUP_FINALLY(inst)<br ALIGN="LEFT"/>SETUP_LOOP(inst)<br ALIGN="LEFT"/>SETUP_WITH(inst)<br ALIGN="LEFT"/>SET_ADD(inst)<br ALIGN="LEFT"/>SET_FUNCTION_ATTRIBUTE(inst)<br ALIGN="LEFT"/>SET_UPDATE(inst)<br ALIGN="LEFT"/>STORE_ATTR(inst)<br ALIGN="LEFT"/>STORE_DEREF(inst)<br ALIGN="LEFT"/>STORE_FAST(inst)<br ALIGN="LEFT"/>STORE_GLOBAL(inst)<br ALIGN="LEFT"/>STORE_SUBSCR(inst)<br ALIGN="LEFT"/>SWAP(inst)<br ALIGN="LEFT"/>TO_BOOL(inst)<br ALIGN="LEFT"/>UNPACK_EX(inst)<br ALIGN="LEFT"/>UNPACK_SEQUENCE(inst)<br ALIGN="LEFT"/>WITH_CLEANUP_FINISH(inst)<br ALIGN="LEFT"/>WITH_CLEANUP_START(inst)<br ALIGN="LEFT"/>append_prefix_inst(inst)<br ALIGN="LEFT"/>calc_package()<br ALIGN="LEFT"/>call_function(fn: VariableTracker, args: List[VariableTracker], kwargs: Dict[str, VariableTracker])<br ALIGN="LEFT"/>cell_and_freevars()<br ALIGN="LEFT"/>cellvars()<br ALIGN="LEFT"/>check_if_exc_matches()<br ALIGN="LEFT"/>create_call_resume_at(offset)<br ALIGN="LEFT"/>exception_handler(raised_exception)<br ALIGN="LEFT"/>format_frame_summary(additional_stack_frames)<br ALIGN="LEFT"/>frame_summary()<br ALIGN="LEFT"/>freevars()<br ALIGN="LEFT"/>get_line_of_code_header(lineno)<br ALIGN="LEFT"/>get_log_starts_line_log_str()<br ALIGN="LEFT"/>import_source(module_name)<br ALIGN="LEFT"/>inline_user_function_return(fn, args, kwargs)<br ALIGN="LEFT"/>is_co_filename_from_nn_modules()<br ALIGN="LEFT"/>is_non_empty_graph()<br ALIGN="LEFT"/>jump(inst)<br ALIGN="LEFT"/>load_builtin(inst)<br ALIGN="LEFT"/>load_builtin_from_argval(argval)<br ALIGN="LEFT"/>mark_inconsistent_side_effects()<br ALIGN="LEFT"/>maybe_has_backedge()<br ALIGN="LEFT"/>pop(): VariableTracker<br ALIGN="LEFT"/>popn(n: int): List[VariableTracker]<br ALIGN="LEFT"/>prune_dead_locals()<br ALIGN="LEFT"/>push(val: Optional[VariableTracker])<br ALIGN="LEFT"/>push_many(vals: List[VariableTracker])<br ALIGN="LEFT"/>resolve_name(name, package, level)<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>run_ctx_mgr()<br ALIGN="LEFT"/>setup_or_before_with(inst)<br ALIGN="LEFT"/>should_compile_partial_graph(): bool<br ALIGN="LEFT"/>speculate(): SpeculationEntry<br ALIGN="LEFT"/>starts_line(lineno)<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>step_graph_break(continue_inst)<br ALIGN="LEFT"/>store_attr_graph_break(inst)<br ALIGN="LEFT"/>store_global_weakref_by_id(prefix, value)<br ALIGN="LEFT"/>strict_translation_mode(check_fn: Callable[[VariableTracker], bool])<br ALIGN="LEFT"/>update_block_stack(inst)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.numbers.IntInfinity" [color="black", fontcolor="black", label=<{IntInfinity|is_commutative : bool<br ALIGN="LEFT"/>is_comparable : bool<br ALIGN="LEFT"/>is_extended_positive : bool<br ALIGN="LEFT"/>is_extended_real : bool<br ALIGN="LEFT"/>is_integer : bool<br ALIGN="LEFT"/>is_number : bool<br ALIGN="LEFT"/>is_prime : bool<br ALIGN="LEFT"/>|ceiling()<br ALIGN="LEFT"/>floor()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.IntStorage" [color="black", fontcolor="black", label=<{IntStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.IntStorage" [color="black", fontcolor="black", label=<{IntStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.IntTrueDiv" [color="black", fontcolor="black", label=<{IntTrueDiv|is_real : bool<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base, divisor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing.Integer" [color="black", fontcolor="black", label=<{Integer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.Intermediate" [color="black", fontcolor="black", label=<{Intermediate|idx : int<br ALIGN="LEFT"/>|fake(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.debug_utils.IntermediateValueDebuggingLevel" [color="black", fontcolor="black", label=<{IntermediateValueDebuggingLevel|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.error.InternalError" [color="black", fontcolor="red", label=<{InternalError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.utils.matcher_utils.InternalMatch" [color="black", fontcolor="black", label=<{InternalMatch|anchors : List[Node]<br ALIGN="LEFT"/>name_node_map : Dict[str, Node]<br ALIGN="LEFT"/>nodes_map : Dict[Node, Node]<br ALIGN="LEFT"/>placeholder_nodes : List[Node]<br ALIGN="LEFT"/>returning_nodes : List[Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.InternalTorchDynamoError" [color="black", fontcolor="red", label=<{InternalTorchDynamoError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.interpreter.Interpreter" [color="black", fontcolor="black", label=<{Interpreter|args_iter : Iterator[Any]<br ALIGN="LEFT"/>env : Dict[Node, Any], NoneType, dict<br ALIGN="LEFT"/>extra_traceback : bool<br ALIGN="LEFT"/>garbage_collect_values : bool<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>submodules : dict<br ALIGN="LEFT"/>user_to_last_uses : Dict[Node, List[Node]]<br ALIGN="LEFT"/>|boxed_run(args_list)<br ALIGN="LEFT"/>call_function(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>call_method(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>call_module(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>fetch_args_kwargs_from_env(n: Node): Tuple[Tuple, Dict]<br ALIGN="LEFT"/>fetch_attr(target: str)<br ALIGN="LEFT"/>get_attr(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>map_nodes_to_values(args: Argument, n: Node): Argument<br ALIGN="LEFT"/>output(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>placeholder(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>run(): Any<br ALIGN="LEFT"/>run_node(n: Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.unflatten.InterpreterModule" [color="black", fontcolor="black", label=<{InterpreterModule|arg_names : list<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>graph_module : Optional[torch.fx.GraphModule]<br ALIGN="LEFT"/>|finalize()<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>print_readable(print_output, include_stride, include_device, colored)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.unflatten.InterpreterModuleDispatcher" [color="black", fontcolor="black", label=<{InterpreterModuleDispatcher|<br ALIGN="LEFT"/>|call_modules()<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>print_readable(print_output, include_stride, include_device, colored)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.InterpreterShim" [color="black", fontcolor="black", label=<{InterpreterShim|current_node : NoneType<br ALIGN="LEFT"/>extra_traceback : bool<br ALIGN="LEFT"/>fetch_attr<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>submodules<br ALIGN="LEFT"/>|run()<br ALIGN="LEFT"/>run_node(n: torch.fx.Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler_util.Interval" [color="black", fontcolor="black", label=<{Interval|end<br ALIGN="LEFT"/>start<br ALIGN="LEFT"/>|elapsed_us()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._utils.Interval" [color="black", fontcolor="black", label=<{Interval|end : int<br ALIGN="LEFT"/>queue_depth : int<br ALIGN="LEFT"/>start : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.invalid_removeable_handle.Invalid" [color="black", fontcolor="black", label=<{Invalid|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.InvalidBackend" [color="black", fontcolor="red", label=<{InvalidBackend|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.exc.InvalidCxxCompiler" [color="black", fontcolor="red", label=<{InvalidCxxCompiler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.InvalidExportOptionsError" [color="black", fontcolor="red", label=<{InvalidExportOptionsError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.partitioners.InvalidNodeBase" [color="black", fontcolor="black", label=<{InvalidNodeBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.InvalidVecISA" [color="black", fontcolor="black", label=<{InvalidVecISA|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._vendor.packaging.version.InvalidVersion" [color="black", fontcolor="red", label=<{InvalidVersion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.inverse_gamma.InverseGamma" [color="black", fontcolor="black", label=<{InverseGamma|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>rate<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Invocation" [color="black", fontcolor="black", label=<{Invocation|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._invocation.Invocation" [color="black", fontcolor="black", label=<{Invocation|account : Optional[str]<br ALIGN="LEFT"/>arguments : Optional[List[str]]<br ALIGN="LEFT"/>command_line : Optional[str]<br ALIGN="LEFT"/>end_time_utc : Optional[str]<br ALIGN="LEFT"/>environment_variables : Optional[Any]<br ALIGN="LEFT"/>executable_location : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>execution_successful : bool<br ALIGN="LEFT"/>exit_code : Optional[int]<br ALIGN="LEFT"/>exit_code_description : Optional[str]<br ALIGN="LEFT"/>exit_signal_name : Optional[str]<br ALIGN="LEFT"/>exit_signal_number : Optional[int]<br ALIGN="LEFT"/>machine : Optional[str]<br ALIGN="LEFT"/>notification_configuration_overrides : Optional[List[_configuration_override.ConfigurationOverride]]<br ALIGN="LEFT"/>process_id : Optional[int]<br ALIGN="LEFT"/>process_start_failure_message : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>response_files : Optional[List[_artifact_location.ArtifactLocation]]<br ALIGN="LEFT"/>rule_configuration_overrides : Optional[List[_configuration_override.ConfigurationOverride]]<br ALIGN="LEFT"/>start_time_utc : Optional[str]<br ALIGN="LEFT"/>stderr : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>stdin : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>stdout : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>stdout_stderr : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>tool_configuration_notifications : Optional[List[_notification.Notification]]<br ALIGN="LEFT"/>tool_execution_notifications : Optional[List[_notification.Notification]]<br ALIGN="LEFT"/>working_directory : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.InvokeSubgraph" [color="black", fontcolor="black", label=<{InvokeSubgraph|name<br ALIGN="LEFT"/>operands : Optional[List[TensorBox]]<br ALIGN="LEFT"/>outputs : Optional[List[MultiOutput]]<br ALIGN="LEFT"/>subgraph : Optional[Subgraph]<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(subgraph: Subgraph, operands)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.invoke_subgraph.InvokeSubgraphAutogradOp" [color="black", fontcolor="black", label=<{InvokeSubgraphAutogradOp|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, fw_graph, bw_graph, identifier, num_fw_outs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.InvokeSubgraphCache" [color="black", fontcolor="black", label=<{InvokeSubgraphCache|autograd_cache : Dict[str, Callable]<br ALIGN="LEFT"/>dynamo_identifiers : Dict[str, str]<br ALIGN="LEFT"/>proxy_dispatch_cache : Dict[str, Callable]<br ALIGN="LEFT"/>|add_autograd_key_entry(identifier: str, key: Callable)<br ALIGN="LEFT"/>add_dynamo_identifier(cache_key: str, identifier: str)<br ALIGN="LEFT"/>add_proxy_dispatch_entry(identifier: str, key: Callable)<br ALIGN="LEFT"/>get_autograd_key_entry(identifier: str)<br ALIGN="LEFT"/>get_dynamo_identifier(cache_key: str): Optional[str]<br ALIGN="LEFT"/>get_proxy_dispatch_entry(identifier: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.invoke_subgraph.InvokeSubgraphHOP" [color="black", fontcolor="black", label=<{InvokeSubgraphHOP|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.InvokeSubgraphHigherOrderVariable" [color="black", fontcolor="black", label=<{InvokeSubgraphHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>install_subgraph_in_output_graph(tx, fn_vt, fn_args_vt, kwargs, body_gmod, attr_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.IsInputHandler" [color="black", fontcolor="black", label=<{IsInputHandler|base_idx<br ALIGN="LEFT"/>unwrap_out<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.IsNonOverlappingAndDenseIndicator" [color="black", fontcolor="black", label=<{IsNonOverlappingAndDenseIndicator|is_integer : bool<br ALIGN="LEFT"/>|eval()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" [color="black", fontcolor="black", label=<{IterDataPipe|functions : Dict[str, Callable]<br ALIGN="LEFT"/>getstate_hook : Optional[Callable]<br ALIGN="LEFT"/>reduce_ex_hook : Optional[Callable]<br ALIGN="LEFT"/>repr_hook : Optional[Callable]<br ALIGN="LEFT"/>str_hook : Optional[Callable]<br ALIGN="LEFT"/>|register_datapipe_as_function(function_name, cls_to_register, enable_df_api_tracing)<br ALIGN="LEFT"/>register_function(function_name, function)<br ALIGN="LEFT"/><I>reset</I>(): None<br ALIGN="LEFT"/>set_getstate_hook(hook_fn)<br ALIGN="LEFT"/>set_reduce_ex_hook(hook_fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataset.IterableDataset" [color="black", fontcolor="black", label=<{IterableDataset|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.utils.IterableWrapperIterDataPipe" [color="black", fontcolor="black", label=<{IterableWrapperIterDataPipe|deepcopy : bool<br ALIGN="LEFT"/>iterable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.IterationRanges" [color="black", fontcolor="black", label=<{IterationRanges|divisor<br ALIGN="LEFT"/>is_reduction<br ALIGN="LEFT"/>kernel<br ALIGN="LEFT"/>length<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>numel : Expr<br ALIGN="LEFT"/>prefix : str<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>symt<br ALIGN="LEFT"/>var_list : List[sympy.Symbol]<br ALIGN="LEFT"/>var_ranges : Dict[sympy.Symbol, sympy.Expr]<br ALIGN="LEFT"/>|symbol()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.IterationRangesEntry" [color="black", fontcolor="black", label=<{IterationRangesEntry|codegen<br ALIGN="LEFT"/>expr : Expr<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>parent<br ALIGN="LEFT"/>|cache_clear()<br ALIGN="LEFT"/>precomputed_args()<br ALIGN="LEFT"/>set_name(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.IterationRangesRoot" [color="black", fontcolor="black", label=<{IterationRangesRoot|grid_dim<br ALIGN="LEFT"/>has_zdim<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>is_loop<br ALIGN="LEFT"/>nodes : Dict[sympy.Expr, IterationRangesEntry]<br ALIGN="LEFT"/>pid_cache : Optional[Dict[str, str]]<br ALIGN="LEFT"/>tensor_dim<br ALIGN="LEFT"/>|cache_clear()<br ALIGN="LEFT"/>construct(lengths: List[sympy.Expr])<br ALIGN="LEFT"/>construct_entries(lengths: List[sympy.Expr])<br ALIGN="LEFT"/>index_sym()<br ALIGN="LEFT"/>lookup(divisor, length)<br ALIGN="LEFT"/>vars_and_sizes(index: sympy.Expr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._hook_iterator.hook_iterator.IteratorDecorator" [color="black", fontcolor="black", label=<{IteratorDecorator|datapipe<br ALIGN="LEFT"/>iterator<br ALIGN="LEFT"/>iterator_id<br ALIGN="LEFT"/>self_and_has_next_method<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.IteratorVariable" [color="black", fontcolor="black", label=<{IteratorVariable|<br ALIGN="LEFT"/>|force_unpack_var_sequence(tx): List[VariableTracker]<br ALIGN="LEFT"/>has_force_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.ItertoolsVariable" [color="black", fontcolor="black", label=<{ItertoolsVariable|value<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_jit.JitCommonTestCase" [color="black", fontcolor="black", label=<{JitCommonTestCase|<br ALIGN="LEFT"/>|assertAutodiffNode(graph, should_autodiff_node, nonfusible_nodes, fusible_nodes)<br ALIGN="LEFT"/>assertExportImport(trace, inputs)<br ALIGN="LEFT"/>assertExportImportModule(m, inputs)<br ALIGN="LEFT"/>autoDiffErrorMessage(should_autodiff_node, nodes_not_in_diff_graph, fusion_nodes_not_found, non_fusible_nodes_being_fused, fusion_nodes_found, nodes_in_diff_graph)<br ALIGN="LEFT"/>checkShapeAnalysis(out_sizes: Union[List[int], List[List[int]]], traced_graph, assert_propagation, constant_prop)<br ALIGN="LEFT"/>createFunctionFromGraph(trace)<br ALIGN="LEFT"/>getExportImportCopy(m, also_test_file, map_location)<br ALIGN="LEFT"/>runAndSaveRNG(func, inputs, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest" [color="black", fontcolor="black", label=<{JitDistAutogradTest|<br ALIGN="LEFT"/>|test_dist_backward()<br ALIGN="LEFT"/>test_get_gradients()<br ALIGN="LEFT"/>test_jit_fork_within_context()<br ALIGN="LEFT"/>test_restore_context_after_swtich_to_jit_thread()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest" [color="black", fontcolor="black", label=<{JitFaultyAgentRpcTest|<br ALIGN="LEFT"/>|test_remote_timeout_to_here_in_jit()<br ALIGN="LEFT"/>test_rref_timeout_pickle_in_jit()<br ALIGN="LEFT"/>test_rref_timeout_pickle_script_func()<br ALIGN="LEFT"/>test_rref_to_here_timeout_in_jit()<br ALIGN="LEFT"/>test_timeout_in_python()<br ALIGN="LEFT"/>test_timeout_in_torchscript_function()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest" [color="black", fontcolor="black", label=<{JitRpcOpTest|<br ALIGN="LEFT"/>|test_all_kwargs_are_populated_by_defaults()<br ALIGN="LEFT"/>test_args_and_kwargs_contain_different_types()<br ALIGN="LEFT"/>test_args_kwargs_are_neither_passed()<br ALIGN="LEFT"/>test_call_python_function_remotely_from_script_not_supported()<br ALIGN="LEFT"/>test_call_script_function_that_not_exists_remotely_from_script()<br ALIGN="LEFT"/>test_call_script_function_that_raises_remotely_from_script()<br ALIGN="LEFT"/>test_kwargs_not_passed()<br ALIGN="LEFT"/>test_less_than_needed_args_are_specified()<br ALIGN="LEFT"/>test_more_than_needed_args_are_specified()<br ALIGN="LEFT"/>test_no_kwargs_are_populated_by_defaults()<br ALIGN="LEFT"/>test_some_kwargs_are_populated_by_defaults()<br ALIGN="LEFT"/>test_unexepected_kwarg_is_specified()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" [color="black", fontcolor="black", label=<{JitRpcTest|<br ALIGN="LEFT"/>|test_add_done_callback()<br ALIGN="LEFT"/>test_async_function_remote()<br ALIGN="LEFT"/>test_async_function_remote_multi()<br ALIGN="LEFT"/>test_async_function_simple()<br ALIGN="LEFT"/>test_async_function_wrong_decorator_order()<br ALIGN="LEFT"/>test_async_function_wrong_return_type()<br ALIGN="LEFT"/>test_async_function_wrong_return_type_remote()<br ALIGN="LEFT"/>test_async_script_throw()<br ALIGN="LEFT"/>test_async_script_udf()<br ALIGN="LEFT"/>test_call_fork_in_jit_with_profiling()<br ALIGN="LEFT"/>test_call_rpc_with_profiling()<br ALIGN="LEFT"/>test_callback_chain()<br ALIGN="LEFT"/>test_callback_simple()<br ALIGN="LEFT"/>test_callback_with_exception()<br ALIGN="LEFT"/>test_create_script_module_on_remote()<br ALIGN="LEFT"/>test_load_script_module_with_pickled_rref()<br ALIGN="LEFT"/>test_record_function_jit_end_callbacks_with_fork()<br ALIGN="LEFT"/>test_record_function_on_caller_rpc_async()<br ALIGN="LEFT"/>test_remote_script_module()<br ALIGN="LEFT"/>test_remote_script_throw()<br ALIGN="LEFT"/>test_remote_script_udf()<br ALIGN="LEFT"/>test_rpc_async_jit_profiled()<br ALIGN="LEFT"/>test_rpc_torchscript_record_function()<br ALIGN="LEFT"/>test_rref_jit_pickle_not_supported()<br ALIGN="LEFT"/>test_torchscript_function()<br ALIGN="LEFT"/>test_torchscript_function_exception()<br ALIGN="LEFT"/>test_torchscript_functions_not_supported()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._type_utils.JitScalarType" [color="black", fontcolor="black", label=<{JitScalarType|name<br ALIGN="LEFT"/>|dtype(): torch.dtype<br ALIGN="LEFT"/>from_dtype(dtype: torch.dtype \| None): JitScalarType<br ALIGN="LEFT"/>from_onnx_type(onnx_type: int \| _C_onnx.TensorProtoDataType \| None): JitScalarType<br ALIGN="LEFT"/>from_value(value: None \| torch._C.Value \| torch.Tensor, default): JitScalarType<br ALIGN="LEFT"/>onnx_compatible(): bool<br ALIGN="LEFT"/>onnx_type(): _C_onnx.TensorProtoDataType<br ALIGN="LEFT"/>scalar_name(): ScalarName<br ALIGN="LEFT"/>torch_name(): TorchName<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils.JitTestCase" [color="black", fontcolor="black", label=<{JitTestCase|<br ALIGN="LEFT"/>|assertAllFused(graph, except_for)<br ALIGN="LEFT"/>assertExpectedGraph(trace)<br ALIGN="LEFT"/>assertExpectedONNXGraph(g)<br ALIGN="LEFT"/>assertGraphContains(graph, kind, consider_subgraphs)<br ALIGN="LEFT"/>assertGraphContainsExactly(graph, kind, num_kind_nodes, consider_subgraphs)<br ALIGN="LEFT"/>assertRaisesRegexWithHighlight(exception, regex, highlight)<br ALIGN="LEFT"/>checkBailouts(model, inputs, expected)<br ALIGN="LEFT"/>checkModule(nn_module, args)<br ALIGN="LEFT"/>checkScript(script, inputs, name, optimize, inputs_requires_grad, capture_output, frames_up, profiling, atol, rtol)<br ALIGN="LEFT"/>checkScriptRaisesRegex(script, inputs, exception, regex, name, outputs, capture_output, frames_up, profiling)<br ALIGN="LEFT"/>checkTrace(func, reference_tensors, input_tensors, drop, allow_unused, verbose, inputs_require_grads, check_tolerance, export_import, _force_outplace, grad_atol, grad_rtol)<br ALIGN="LEFT"/>clearHooks()<br ALIGN="LEFT"/>emitFunctionHook(func)<br ALIGN="LEFT"/>emitModuleHook(module)<br ALIGN="LEFT"/>getExportImportCopyWithPacking(m, also_test_file, map_location)<br ALIGN="LEFT"/>get_frame_vars(frames_up)<br ALIGN="LEFT"/>run_pass(name, trace)<br ALIGN="LEFT"/>setHooks()<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.JitTraceConvertStrategy" [color="black", fontcolor="black", label=<{JitTraceConvertStrategy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._monkeytype_config.JitTypeTraceConfig" [color="black", fontcolor="black", label=<{JitTypeTraceConfig|s<br ALIGN="LEFT"/>|code_filter(): Optional[CodeFilter]<br ALIGN="LEFT"/>trace_logger(): JitTypeTraceStoreLogger<br ALIGN="LEFT"/>trace_store(): CallTraceStore<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._monkeytype_config.JitTypeTraceStore" [color="black", fontcolor="black", label=<{JitTypeTraceStore|trace_records : Dict[str, list]<br ALIGN="LEFT"/>|add(traces: Iterable[CallTrace])<br ALIGN="LEFT"/>analyze(qualified_name: str): Dict<br ALIGN="LEFT"/>consolidate_types(qualified_name: str): Dict<br ALIGN="LEFT"/>filter(qualified_name: str, qualname_prefix: Optional[str], limit: int): List[CallTraceThunk]<br ALIGN="LEFT"/>get_args_types(qualified_name: str): Dict<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._monkeytype_config.JitTypeTraceStoreLogger" [color="black", fontcolor="black", label=<{JitTypeTraceStoreLogger|<br ALIGN="LEFT"/>|log(trace: CallTrace): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.join.Join" [color="black", fontcolor="black", label=<{Join|<br ALIGN="LEFT"/>|notify_join_context(joinable: Joinable)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.join.JoinHook" [color="black", fontcolor="black", label=<{JoinHook|<br ALIGN="LEFT"/>|<I>main_hook</I>(): None<br ALIGN="LEFT"/><I>post_hook</I>(is_last_joiner: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.join.Joinable" [color="black", fontcolor="black", label=<{Joinable|join_device<br ALIGN="LEFT"/>join_process_group<br ALIGN="LEFT"/>|<I>join_hook</I>(): JoinHook<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.kernel.flex_attention.JointOutputResult" [color="black", fontcolor="black", label=<{JointOutputResult|captured_grads : List[Optional[TensorBox]]<br ALIGN="LEFT"/>captured_grads_compute : List[ComputedBuffer]<br ALIGN="LEFT"/>grad_input<br ALIGN="LEFT"/>mutated_grads : List[TensorBox]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.JvpIncrementNestingCtxManagerVariable" [color="black", fontcolor="black", label=<{JvpIncrementNestingCtxManagerVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.pyfunctorch.JvpInterpreter" [color="black", fontcolor="black", label=<{JvpInterpreter|<br ALIGN="LEFT"/>|get_state()<br ALIGN="LEFT"/>lift(args, kwargs)<br ALIGN="LEFT"/>lower()<br ALIGN="LEFT"/>prev_fwd_grad_mode()<br ALIGN="LEFT"/>process(op, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims_common.is_non_overlapping_and_dense.K" [color="black", fontcolor="black", label=<{K|size : int<br ALIGN="LEFT"/>stride : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.loss.KLDivLoss" [color="black", fontcolor="black", label=<{KLDivLoss|log_target : bool<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph_module._deserialize_graph_module.KeepModules" [color="black", fontcolor="black", label=<{KeepModules|<br ALIGN="LEFT"/>|is_leaf_module(_: torch.nn.Module, __: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.Kernel" [color="black", fontcolor="black", label=<{Kernel|args<br ALIGN="LEFT"/>assert_function<br ALIGN="LEFT"/>compute : NoneType<br ALIGN="LEFT"/>cse<br ALIGN="LEFT"/>current_node : NoneType<br ALIGN="LEFT"/>inplace_update_buffers : dict<br ALIGN="LEFT"/>inplaced_to_remove<br ALIGN="LEFT"/>kernel_name : NoneType<br ALIGN="LEFT"/>load_format : NoneType<br ALIGN="LEFT"/>loads : NoneType<br ALIGN="LEFT"/>min_elem_per_thread : int<br ALIGN="LEFT"/>must_keep_buffers<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>newvar_prefix : str<br ALIGN="LEFT"/>node_to_bounds : Optional[Dict[torch.fx.Node, ValueRanges[Any]]]<br ALIGN="LEFT"/>num_load : int<br ALIGN="LEFT"/>num_reduction : int<br ALIGN="LEFT"/>overrides : Optional[Callable[[OpsHandler[Any]], OpsHandler[Any]]]<br ALIGN="LEFT"/>removed_buffers<br ALIGN="LEFT"/>store_buffer_names<br ALIGN="LEFT"/>store_format : NoneType<br ALIGN="LEFT"/>stores : NoneType<br ALIGN="LEFT"/>suffix : str<br ALIGN="LEFT"/>|<I>bucketize</I>(values: CSEVariable, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: CSEVariable, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[CSEVariable]): CSEVariable<br ALIGN="LEFT"/><I>check_bounds</I>(expr: sympy.Expr, size: sympy.Expr, lower: bool, upper: bool)<br ALIGN="LEFT"/>create_cse_var()<br ALIGN="LEFT"/><I>index_to_str</I>(index: sympy.Expr): str<br ALIGN="LEFT"/>indirect_assert(var: Union[CSEVariable, str], lower: Optional[str], upper: Optional[str], mask: Optional[Union[CSEVariable, str]]): str<br ALIGN="LEFT"/>indirect_load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/><I>load</I>(name: str, index: sympy.Expr): CSEVariable<br ALIGN="LEFT"/><I>reduction</I>(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[CSEVariable, Tuple[CSEVariable, ...]]): Union[CSEVariable, Tuple[CSEVariable, ...]]<br ALIGN="LEFT"/>remove_buffer(name: str): None<br ALIGN="LEFT"/>remove_inplace_buffer(name: str): None<br ALIGN="LEFT"/>remove_kernel_local_buffers(): None<br ALIGN="LEFT"/>rename_indexing(index): sympy.Expr<br ALIGN="LEFT"/><I>scan</I>(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[CSEVariable, ...], Tuple[CSEVariable, ...]], Tuple[CSEVariable, ...]], values: Tuple[CSEVariable, ...]): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>set_current_node(node)<br ALIGN="LEFT"/><I>sort</I>(dtypes: Tuple[torch.dtype, ...], values: Tuple[CSEVariable, ...], stable: bool, descending: bool): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/><I>store</I>(name: str, index: sympy.Expr, value: CSEVariable, mode: StoreMode): None<br ALIGN="LEFT"/><I>store_reduction</I>(name: str, index: sympy.Expr, value: CSEVariable)<br ALIGN="LEFT"/>swap_buffers(lb, cb, sb)<br ALIGN="LEFT"/><I>var_ranges</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.utils.Kernel" [color="black", fontcolor="black", label=<{Kernel|func : Callable<br ALIGN="LEFT"/>source : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.KernelArgs" [color="black", fontcolor="black", label=<{KernelArgs|inplace_buffers : dict<br ALIGN="LEFT"/>input_buffers : dict<br ALIGN="LEFT"/>output_buffers : dict<br ALIGN="LEFT"/>sizevars : dict<br ALIGN="LEFT"/>workspace_args : list<br ALIGN="LEFT"/>|aliases()<br ALIGN="LEFT"/>call_names()<br ALIGN="LEFT"/>cpp_argdefs()<br ALIGN="LEFT"/>input(name)<br ALIGN="LEFT"/>is_removed(name)<br ALIGN="LEFT"/>live_output_buffers()<br ALIGN="LEFT"/>make_inplace(input_name, output_name)<br ALIGN="LEFT"/>output(name)<br ALIGN="LEFT"/>python_argdefs()<br ALIGN="LEFT"/>seed_offset(name, value)<br ALIGN="LEFT"/>semaphores(min_size: sympy.Expr)<br ALIGN="LEFT"/>size(name)<br ALIGN="LEFT"/>workspace(nbytes: sympy.Expr, zero_fill: bool)<br ALIGN="LEFT"/>wrap_ptr_arg(buf, dtype)<br ALIGN="LEFT"/>wrap_size_arg(size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.KernelFormatterHandler" [color="black", fontcolor="black", label=<{KernelFormatterHandler|output<br ALIGN="LEFT"/>parent_handler<br ALIGN="LEFT"/>var_counter : count<br ALIGN="LEFT"/>|getvalue(result)<br ALIGN="LEFT"/>ir_to_string(ir_fn, index, rindex): str<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[str, Tuple[str, ...]]): Union[str, Tuple[str, ...]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.KernelGroup" [color="black", fontcolor="black", label=<{KernelGroup|args<br ALIGN="LEFT"/>loops_code<br ALIGN="LEFT"/>scheduled_nodes : list<br ALIGN="LEFT"/>stack : ExitStack<br ALIGN="LEFT"/>ws<br ALIGN="LEFT"/>|call_kernel(wrapper, kernel_name)<br ALIGN="LEFT"/>codegen_group(name): str<br ALIGN="LEFT"/>finalize_kernel(new_kernel, nodes)<br ALIGN="LEFT"/>get_num_args()<br ALIGN="LEFT"/>new_kernel(cls)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.KernelNamespace" [color="black", fontcolor="black", label=<{KernelNamespace|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.KernelSideTable" [color="black", fontcolor="black", label=<{KernelSideTable|constant_args : Dict[int, Dict[str, Any]]<br ALIGN="LEFT"/>id_to_kernel : Dict[int, 'TritonKernelType']<br ALIGN="LEFT"/>kernel_to_id : Dict['TritonKernelType', int]<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>|add_constant_args(args: Dict[str, Any]): int<br ALIGN="LEFT"/>add_kernel(kernel: 'TritonKernelType'): int<br ALIGN="LEFT"/>get_constant_args(idx: int): Dict[str, Any]<br ALIGN="LEFT"/>get_kernel(idx: int): 'TritonKernelType'<br ALIGN="LEFT"/>reset_table(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.KernelTemplate" [color="black", fontcolor="black", label=<{KernelTemplate|name : str<br ALIGN="LEFT"/>|<I>generate</I>(): torch._inductor.ir.ChoiceCaller<br ALIGN="LEFT"/>indent_except_first(source: str, num_indents: int, indents_spacing)<br ALIGN="LEFT"/>maybe_append_choice(choices)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.Key" [color="black", fontcolor="black", label=<{Key|device<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree.KeyEntry" [color="black", fontcolor="black", label=<{KeyEntry|<br ALIGN="LEFT"/>|get(parent: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._utils.KeyErrorMessage" [color="black", fontcolor="black", label=<{KeyErrorMessage|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.KeyErrorMsg" [color="black", fontcolor="black", label=<{KeyErrorMsg|value<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.KeyedJaggedTensorVariable" [color="black", fontcolor="black", label=<{KeyedJaggedTensorVariable|<br ALIGN="LEFT"/>|is_matching_object(obj)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.KeywordArg" [color="black", fontcolor="black", label=<{KeywordArg|name : str<br ALIGN="LEFT"/>|pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler.KinetoStepTracker" [color="black", fontcolor="black", label=<{KinetoStepTracker|<br ALIGN="LEFT"/>|current_step(): int<br ALIGN="LEFT"/>erase_step_count(requester: str): bool<br ALIGN="LEFT"/>increment_step(requester: str): int<br ALIGN="LEFT"/>init_step_count(requester: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.kumaraswamy.Kumaraswamy" [color="black", fontcolor="black", label=<{Kumaraswamy|arg_constraints : dict<br ALIGN="LEFT"/>concentration0<br ALIGN="LEFT"/>concentration1<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.L1Loss" [color="black", fontcolor="black", label=<{L1Loss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.prune.L1Unstructured" [color="black", fontcolor="black", label=<{L1Unstructured|PRUNING_TYPE : str<br ALIGN="LEFT"/>amount<br ALIGN="LEFT"/>|apply(module, name, amount, importance_scores)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lbfgs.LBFGS" [color="black", fontcolor="black", label=<{LBFGS|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.lkj_cholesky.LKJCholesky" [color="black", fontcolor="black", label=<{LKJCholesky|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>dim<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._lobpcg.LOBPCG" [color="black", fontcolor="black", label=<{LOBPCG|A : Optional[Tensor]<br ALIGN="LEFT"/>B : Optional[Tensor]<br ALIGN="LEFT"/>E<br ALIGN="LEFT"/>R<br ALIGN="LEFT"/>S<br ALIGN="LEFT"/>X<br ALIGN="LEFT"/>bparams : Dict[str, bool]<br ALIGN="LEFT"/>bvars : Dict[str, bool]<br ALIGN="LEFT"/>fparams : Dict[str, float]<br ALIGN="LEFT"/>fvars : Dict[str, float]<br ALIGN="LEFT"/>iK : Optional[Tensor]<br ALIGN="LEFT"/>iparams : Dict[str, int]<br ALIGN="LEFT"/>ivars : Dict[str, int]<br ALIGN="LEFT"/>method : str<br ALIGN="LEFT"/>tracker : NoneType<br ALIGN="LEFT"/>tvars : Dict[str, Tensor]<br ALIGN="LEFT"/>|<I>call_tracker</I>()<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>stop_iteration()<br ALIGN="LEFT"/>update()<br ALIGN="LEFT"/>update_converged_count()<br ALIGN="LEFT"/>update_residual()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._lobpcg.LOBPCGAutogradFunction" [color="black", fontcolor="black", label=<{LOBPCGAutogradFunction|<br ALIGN="LEFT"/>|backward(ctx, D_grad, U_grad)<br ALIGN="LEFT"/>forward(ctx, A: Tensor, k: Optional[int], B: Optional[Tensor], X: Optional[Tensor], n: Optional[int], iK: Optional[Tensor], niter: Optional[int], tol: Optional[float], largest: Optional[bool], method: Optional[str], tracker: None, ortho_iparams: Optional[Dict[str, int]], ortho_fparams: Optional[Dict[str, float]], ortho_bparams: Optional[Dict[str, bool]]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.LPPool1d" [color="black", fontcolor="black", label=<{LPPool1d|kernel_size : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.LPPool2d" [color="black", fontcolor="black", label=<{LPPool2d|kernel_size : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.LPPool3d" [color="black", fontcolor="black", label=<{LPPool3d|kernel_size : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.LRScheduler" [color="black", fontcolor="black", label=<{LRScheduler|base_lrs : List[float]<br ALIGN="LEFT"/>last_epoch : int<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>verbose : bool, str<br ALIGN="LEFT"/>|get_last_lr(): List[float]<br ALIGN="LEFT"/><I>get_lr</I>(): List[float]<br ALIGN="LEFT"/>load_state_dict(state_dict: Dict[str, Any])<br ALIGN="LEFT"/>print_lr(is_verbose: bool, group: Dict[str, Any], lr: float, epoch: Optional[int])<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step(epoch: Optional[int])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.LSTM" [color="black", fontcolor="black", label=<{LSTM|<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tuple[Tensor, Tensor], batch_sizes: Optional[Tensor]): None<br ALIGN="LEFT"/>forward(input, hx)<br ALIGN="LEFT"/>forward_impl(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]], batch_sizes: Optional[Tensor], max_batch_size: int, sorted_indices: Optional[Tensor]): Tuple[Tensor, Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>forward_packed(input: PackedSequence, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[PackedSequence, Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>forward_tensor(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_mod)<br ALIGN="LEFT"/>permute_hidden(hx: Tuple[Tensor, Tensor], permutation: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.LSTM" [color="black", fontcolor="black", label=<{LSTM|<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tuple[Tensor, Tensor], batch_sizes: Optional[Tensor])<br ALIGN="LEFT"/>forward(input, hx)<br ALIGN="LEFT"/>from_float(mod, weight_qparams_dict)<br ALIGN="LEFT"/>get_expected_cell_size(input: Tensor, batch_sizes: Optional[Tensor]): Tuple[int, int, int]<br ALIGN="LEFT"/>get_flat_weights()<br ALIGN="LEFT"/>get_quantized_weight_bias_dict()<br ALIGN="LEFT"/>permute_hidden(hx: Tuple[Tensor, Tensor], permutation: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.rnn.LSTM" [color="black", fontcolor="black", label=<{LSTM|<br ALIGN="LEFT"/>|<I>from_float</I>()<br ALIGN="LEFT"/>from_observed(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantizable.modules.rnn.LSTM" [color="black", fontcolor="black", label=<{LSTM|batch_first : bool<br ALIGN="LEFT"/>bias : bool<br ALIGN="LEFT"/>bidirectional : bool<br ALIGN="LEFT"/>dropout : float<br ALIGN="LEFT"/>hidden_size : int<br ALIGN="LEFT"/>input_size : int<br ALIGN="LEFT"/>layers<br ALIGN="LEFT"/>num_layers : int<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>|forward(x: Tensor, hidden: Optional[Tuple[Tensor, Tensor]])<br ALIGN="LEFT"/>from_float(other, qconfig, split_gates)<br ALIGN="LEFT"/><I>from_observed</I>(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.LSTM" [color="black", fontcolor="black", label=<{LSTM|<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tuple[Tensor, Tensor], batch_sizes: Optional[Tensor])<br ALIGN="LEFT"/><I>forward</I>(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>get_expected_cell_size(input: Tensor, batch_sizes: Optional[Tensor]): Tuple[int, int, int]<br ALIGN="LEFT"/>permute_hidden(hx: Tuple[Tensor, Tensor], permutation: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.LSTMCell" [color="black", fontcolor="black", label=<{LSTMCell|<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.LSTMCell" [color="black", fontcolor="black", label=<{LSTMCell|bias_hh<br ALIGN="LEFT"/>bias_ih<br ALIGN="LEFT"/>weight_hh<br ALIGN="LEFT"/>weight_ih<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>from_float(mod, weight_qparams_dict, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantizable.modules.rnn.LSTMCell" [color="black", fontcolor="black", label=<{LSTMCell|bias : bool<br ALIGN="LEFT"/>cell_gate<br ALIGN="LEFT"/>cell_state_dtype<br ALIGN="LEFT"/>fgate_cx<br ALIGN="LEFT"/>fgate_cx_igate_cgate<br ALIGN="LEFT"/>forget_gate<br ALIGN="LEFT"/>gates<br ALIGN="LEFT"/>hgates<br ALIGN="LEFT"/>hidden_size : int<br ALIGN="LEFT"/>hidden_state_dtype<br ALIGN="LEFT"/>igate_cgate<br ALIGN="LEFT"/>igates<br ALIGN="LEFT"/>initial_cell_state_qparams : Tuple[float, int]<br ALIGN="LEFT"/>initial_hidden_state_qparams : Tuple[float, int]<br ALIGN="LEFT"/>input_gate<br ALIGN="LEFT"/>input_size : int<br ALIGN="LEFT"/>ogate_cy<br ALIGN="LEFT"/>output_gate<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>split_gates : bool<br ALIGN="LEFT"/>|forward(x: Tensor, hidden: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>from_float(other, use_precomputed_fake_quant, split_gates)<br ALIGN="LEFT"/>from_params(wi, wh, bi, bh, split_gates)<br ALIGN="LEFT"/>initialize_hidden(batch_size: int, is_quantized: bool): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.LSTMCell" [color="black", fontcolor="black", label=<{LSTMCell|<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tuple[Tensor, Tensor]]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.LSTMLayerNormLinearModel" [color="black", fontcolor="black", label=<{LSTMLayerNormLinearModel|linear<br ALIGN="LEFT"/>lstm<br ALIGN="LEFT"/>norm<br ALIGN="LEFT"/>|forward(x: torch.Tensor): Tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.LSTMLinearModel" [color="black", fontcolor="black", label=<{LSTMLinearModel|linear<br ALIGN="LEFT"/>lstm<br ALIGN="LEFT"/>|forward(input: torch.Tensor): Tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.lstm_saliency_pruner.LSTMSaliencyPruner" [color="black", fontcolor="black", label=<{LSTMSaliencyPruner|<br ALIGN="LEFT"/>|update_mask(module, tensor_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel" [color="black", fontcolor="black", label=<{LSTMwithHiddenDynamicModel|lstm<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x, hid)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.LShift" [color="black", fontcolor="black", label=<{LShift|is_integer : bool<br ALIGN="LEFT"/>|eval(base, shift)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.LambdaFuture" [color="black", fontcolor="black", label=<{LambdaFuture|result_fn : Callable[..., Any]<br ALIGN="LEFT"/>|result(): Callable[..., Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.LambdaLR" [color="black", fontcolor="black", label=<{LambdaLR|lr_lambdas : List[Callable[[int], float]], list<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.scheduler.lambda_scheduler.LambdaSL" [color="black", fontcolor="black", label=<{LambdaSL|sl_lambdas : list<br ALIGN="LEFT"/>sparsifier<br ALIGN="LEFT"/>|get_sl()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.LambdaVariable" [color="black", fontcolor="black", label=<{LambdaVariable|fn<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.timer.Language" [color="black", fontcolor="black", label=<{Language|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.laplace.Laplace" [color="black", fontcolor="black", label=<{Laplace|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.LargeNet" [color="black", fontcolor="black", label=<{LargeNet|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.launcher.api.LaunchConfig" [color="black", fontcolor="black", label=<{LaunchConfig|local_addr : Optional[str]<br ALIGN="LEFT"/>log_line_prefix_template : Optional[str]<br ALIGN="LEFT"/>logs_specs : Optional[LogsSpecs]<br ALIGN="LEFT"/>max_nodes : int<br ALIGN="LEFT"/>max_restarts : int<br ALIGN="LEFT"/>metrics_cfg : Dict[str, str]<br ALIGN="LEFT"/>min_nodes : int<br ALIGN="LEFT"/>monitor_interval : float<br ALIGN="LEFT"/>nproc_per_node : int<br ALIGN="LEFT"/>rdzv_backend : str<br ALIGN="LEFT"/>rdzv_configs : Dict[str, Any]<br ALIGN="LEFT"/>rdzv_endpoint : str<br ALIGN="LEFT"/>rdzv_timeout : int<br ALIGN="LEFT"/>role : str<br ALIGN="LEFT"/>run_id : str<br ALIGN="LEFT"/>start_method : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_nn._create_basic_net.Layer" [color="black", fontcolor="black", label=<{Layer|layer_dummy_buf<br ALIGN="LEFT"/>layer_dummy_param<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.normalization.LayerNorm" [color="black", fontcolor="black", label=<{LayerNorm|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.normalization.LayerNorm" [color="black", fontcolor="black", label=<{LayerNorm|bias<br ALIGN="LEFT"/>elementwise_affine : bool<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>normalized_shape : Tuple[int, ...]<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.layer_norm_expanded_weights.LayerNormPerSampleGrad" [color="black", fontcolor="black", label=<{LayerNormPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, kwarg_names, _)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.Layout" [color="black", fontcolor="black", label=<{Layout|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>offset : Expr<br ALIGN="LEFT"/>size : List[Expr]<br ALIGN="LEFT"/>stride : NoneType, Optional[List[Expr]], list<br ALIGN="LEFT"/>|as_fixed()<br ALIGN="LEFT"/>get_device(): torch.device<br ALIGN="LEFT"/>is_channels_last_contiguous(shape: Sequence[_IntLike], strides: Sequence[_IntLike]): bool<br ALIGN="LEFT"/>is_channels_last_stride_ordered()<br ALIGN="LEFT"/>is_contiguous(): bool<br ALIGN="LEFT"/>is_stride_ordered(order): bool<br ALIGN="LEFT"/>is_transposed(): bool<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>pad_strides()<br ALIGN="LEFT"/>should_pad_strides()<br ALIGN="LEFT"/>storage_size(): sympy.Expr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.Layout" [color="black", fontcolor="black", label=<{Layout|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cuda.cuda_kernel.LayoutArg" [color="black", fontcolor="black", label=<{LayoutArg|attr : Literal<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>symbol : Literal<br ALIGN="LEFT"/>|matches(node, attr, dim): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_micro_gemm.LayoutType" [color="black", fontcolor="black", label=<{LayoutType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.LazyBatchNorm1d" [color="black", fontcolor="black", label=<{LazyBatchNorm1d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.LazyBatchNorm2d" [color="black", fontcolor="black", label=<{LazyBatchNorm2d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.LazyBatchNorm3d" [color="black", fontcolor="black", label=<{LazyBatchNorm3d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lazy.LazyCache" [color="black", fontcolor="black", label=<{LazyCache|source : Any<br ALIGN="LEFT"/>value : Any<br ALIGN="LEFT"/>vt : Optional[VariableTracker]<br ALIGN="LEFT"/>|realize(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConv1d" [color="black", fontcolor="black", label=<{LazyConv1d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConv2d" [color="black", fontcolor="black", label=<{LazyConv2d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConv3d" [color="black", fontcolor="black", label=<{LazyConv3d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConvTranspose1d" [color="black", fontcolor="black", label=<{LazyConvTranspose1d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConvTranspose2d" [color="black", fontcolor="black", label=<{LazyConvTranspose2d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.conv.LazyConvTranspose3d" [color="black", fontcolor="black", label=<{LazyConvTranspose3d|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.LazyInstanceNorm1d" [color="black", fontcolor="black", label=<{LazyInstanceNorm1d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.LazyInstanceNorm2d" [color="black", fontcolor="black", label=<{LazyInstanceNorm2d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm.LazyInstanceNorm3d" [color="black", fontcolor="black", label=<{LazyInstanceNorm3d|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.linear.LazyLinear" [color="black", fontcolor="black", label=<{LazyLinear|bias<br ALIGN="LEFT"/>cls_to_become<br ALIGN="LEFT"/>in_features<br ALIGN="LEFT"/>out_features : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|initialize_parameters(input): None<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.lazy.LazyModuleMixin" [color="black", fontcolor="black", label=<{LazyModuleMixin|cls_to_become : Optional[Type[Any]]<br ALIGN="LEFT"/>|has_uninitialized_params()<br ALIGN="LEFT"/><I>initialize_parameters</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.LazyProxy" [color="black", fontcolor="black", label=<{LazyProxy|args : tuple<br ALIGN="LEFT"/>fn<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._logging._internal.LazyString" [color="black", fontcolor="black", label=<{LazyString|args : tuple<br ALIGN="LEFT"/>func<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lazy.LazySymNodeFormatString" [color="black", fontcolor="black", label=<{LazySymNodeFormatString|fmt_var<br ALIGN="LEFT"/>sym_node_var<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.LazyTestBase" [color="black", fontcolor="black", label=<{LazyTestBase|device_type : str<br ALIGN="LEFT"/>|setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._logging._internal.LazyTraceHandler" [color="black", fontcolor="black", label=<{LazyTraceHandler|root_dir : Optional[str]<br ALIGN="LEFT"/>stream : NoneType, _TemporaryFileWrapper<br ALIGN="LEFT"/>|close()<br ALIGN="LEFT"/>emit(record)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.LazyVal" [color="black", fontcolor="black", label=<{LazyVal|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lazy.LazyVariableTracker" [color="black", fontcolor="black", label=<{LazyVariableTracker|visit<br ALIGN="LEFT"/>|clone(): VariableTracker<br ALIGN="LEFT"/>create(value: Any, source: Any): 'LazyVariableTracker'<br ALIGN="LEFT"/>is_realized(): bool<br ALIGN="LEFT"/>peek_type(): type[Any]<br ALIGN="LEFT"/>peek_value(): Any<br ALIGN="LEFT"/>realize(): VariableTracker<br ALIGN="LEFT"/>realize_all(value: Any, cache: Optional[Dict[int, Tuple[Any, Any]]]): Any<br ALIGN="LEFT"/>unwrap(): Union[VariableTracker, Self]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._cxx_pytree.LeafSpec" [color="black", fontcolor="black", label=<{LeafSpec|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree.LeafSpec" [color="black", fontcolor="black", label=<{LeafSpec|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._cxx_pytree.LeafSpecMeta" [color="black", fontcolor="black", label=<{LeafSpecMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.LeakyReLU" [color="black", fontcolor="black", label=<{LeakyReLU|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.LeakyReLU" [color="black", fontcolor="black", label=<{LeakyReLU|inplace : bool<br ALIGN="LEFT"/>negative_slope : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristic" [color="black", fontcolor="black", label=<{LearnedHeuristic|<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_decision(context: AHContext, choices: List[Choice]): Optional[Choice]<br ALIGN="LEFT"/>get_decisions_ranked(context: AHContext): Optional[List[str]]<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.learned_heuristic_controller.LearnedHeuristicController" [color="black", fontcolor="black", label=<{LearnedHeuristicController|context<br ALIGN="LEFT"/>existing_heuristics : Dict[str, List[LearnedHeuristic]]<br ALIGN="LEFT"/>heuristics_initialized : bool<br ALIGN="LEFT"/>metadata<br ALIGN="LEFT"/>|get_decision(): Optional[Choice]<br ALIGN="LEFT"/>get_decisions_ranked(top_k: int): Optional[List[Choice]]<br ALIGN="LEFT"/>get_heuristics(name: str): List[LearnedHeuristic]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" [color="black", fontcolor="black", label=<{LearnedHeuristicDecision|<br ALIGN="LEFT"/>|get_best_choices(context: AHContext): Optional[List[Tuple[float, int]]]<br ALIGN="LEFT"/>get_choice(idx: int): Optional[str]<br ALIGN="LEFT"/>get_decision(context: AHContext, choices: List[Choice]): Optional[Choice]<br ALIGN="LEFT"/>get_decisions_ranked(context: AHContext): Optional[List[str]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicRegression" [color="black", fontcolor="black", label=<{LearnedHeuristicRegression|<br ALIGN="LEFT"/>|get_decision(context: AHContext, choices: List[Choice]): Optional[Choice]<br ALIGN="LEFT"/>get_feedback(context: AHContext, choice: Choice): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.LegacyDynamoStrategy" [color="black", fontcolor="black", label=<{LegacyDynamoStrategy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Level" [color="black", fontcolor="black", label=<{Level|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.library.Library" [color="black", fontcolor="black", label=<{Library|dispatch_key : str<br ALIGN="LEFT"/>kind<br ALIGN="LEFT"/>m : NoneType, Optional[Any]<br ALIGN="LEFT"/>ns<br ALIGN="LEFT"/>|define(schema, alias_analysis)<br ALIGN="LEFT"/>fallback(fn, dispatch_key)<br ALIGN="LEFT"/>impl(op_name, fn, dispatch_key)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.LiftParametersAndBuffersIntoArgsInputStep" [color="black", fontcolor="black", label=<{LiftParametersAndBuffersIntoArgsInputStep|inputs : tuple[torch.Tensor, ...]<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.LightTracer" [color="black", fontcolor="black", label=<{LightTracer|graph<br ALIGN="LEFT"/>module_stack : dict<br ALIGN="LEFT"/>node_name_to_scope : dict<br ALIGN="LEFT"/>scope<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy.linalg.LinAlgError" [color="black", fontcolor="red", label=<{LinAlgError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.LineContext" [color="black", fontcolor="black", label=<{LineContext|context : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.sparse.quantized.linear.Linear" [color="black", fontcolor="black", label=<{Linear|in_features<br ALIGN="LEFT"/>out_features<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor], row_block_size: Optional[int], col_block_size: Optional[int]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.sparse.quantized.dynamic.linear.Linear" [color="black", fontcolor="black", label=<{Linear|in_features<br ALIGN="LEFT"/>out_features<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor], row_block_size: Optional[int], col_block_size: Optional[int]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|version : int<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qlinear)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(float_linear, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|in_features<br ALIGN="LEFT"/>out_features<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|bias()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qlinear, output_scale, output_zero_point)<br ALIGN="LEFT"/>set_weight_bias(w: torch.Tensor, b: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.dynamic.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|bias<br ALIGN="LEFT"/>qconfig : NoneType<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.linear.Linear" [color="black", fontcolor="black", label=<{Linear|bias : NoneType<br ALIGN="LEFT"/>buffer<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>in_features : int<br ALIGN="LEFT"/>lin<br ALIGN="LEFT"/>out_features : int<br ALIGN="LEFT"/>qconfig : NoneType<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.LinearActivation" [color="black", fontcolor="black", label=<{LinearActivation|act1<br ALIGN="LEFT"/>act2<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.LinearActivationFunctional" [color="black", fontcolor="black", label=<{LinearActivationFunctional|act1<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>linear3<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearAddModel" [color="black", fontcolor="black", label=<{LinearAddModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.LinearBias" [color="black", fontcolor="black", label=<{LinearBias|seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.LinearBinary" [color="black", fontcolor="black", label=<{LinearBinary|kernel : str<br ALIGN="LEFT"/>|<I>apply_constraint</I>()<br ALIGN="LEFT"/>codegen(wrapper)<br ALIGN="LEFT"/>create(x, y, w, B, attr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.sparse.quantized.utils.LinearBlockSparsePattern" [color="black", fontcolor="black", label=<{LinearBlockSparsePattern|col_block_size : int<br ALIGN="LEFT"/>prev_col_block_size : int<br ALIGN="LEFT"/>prev_row_block_size : int<br ALIGN="LEFT"/>rlock : _RLock<br ALIGN="LEFT"/>row_block_size : int<br ALIGN="LEFT"/>|block_size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearBn1d" [color="black", fontcolor="black", label=<{LinearBn1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d" [color="black", fontcolor="black", label=<{LinearBn1d|bias<br ALIGN="LEFT"/>bn<br ALIGN="LEFT"/>freeze_bn : bool<br ALIGN="LEFT"/>qconfig : NoneType<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>freeze_bn_stats()<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>reset_bn_parameters()<br ALIGN="LEFT"/>reset_parameters()<br ALIGN="LEFT"/>reset_running_stats()<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>train(mode)<br ALIGN="LEFT"/>update_bn_stats()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearBnLeakyReluModel" [color="black", fontcolor="black", label=<{LinearBnLeakyReluModel|bn1d<br ALIGN="LEFT"/>leaky_relu<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>with_bn : bool<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.LinearLR" [color="black", fontcolor="black", label=<{LinearLR|end_factor : float<br ALIGN="LEFT"/>start_factor : float<br ALIGN="LEFT"/>total_iters : int<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearLeakyReLU" [color="black", fontcolor="black", label=<{LinearLeakyReLU|negative_slope<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_mod, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearLeakyReLU" [color="black", fontcolor="black", label=<{LinearLeakyReLU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearModelWithSubmodule" [color="black", fontcolor="black", label=<{LinearModelWithSubmodule|fc<br ALIGN="LEFT"/>subm<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.sparse.quantized.linear.LinearPackedParams" [color="black", fontcolor="black", label=<{LinearPackedParams|dtype<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>set_weight_bias(weight: torch.Tensor, bias: Optional[torch.Tensor], row_block_size: Optional[int], col_block_size: Optional[int]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.linear.LinearPackedParams" [color="black", fontcolor="black", label=<{LinearPackedParams|dtype<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>set_weight_bias(weight: torch.Tensor, bias: Optional[torch.Tensor]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils._expanded_weights.linear_expanded_weights.LinearPerSampleGrad" [color="black", fontcolor="black", label=<{LinearPerSampleGrad|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, _, __)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU" [color="black", fontcolor="black", label=<{LinearReLU|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qlinear_relu)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearReLU" [color="black", fontcolor="black", label=<{LinearReLU|<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_linear_relu, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearReLU" [color="black", fontcolor="black", label=<{LinearReLU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU" [color="black", fontcolor="black", label=<{LinearReLU|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.LinearReLUQuantizeHandler" [color="black", fontcolor="black", label=<{LinearReLUQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearReluAddModel" [color="black", fontcolor="black", label=<{LinearReluAddModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.quantization_torch_package_models.LinearReluFunctional" [color="black", fontcolor="black", label=<{LinearReluFunctional|b1<br ALIGN="LEFT"/>child<br ALIGN="LEFT"/>w1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.quantization_torch_package_models.LinearReluFunctionalChild" [color="black", fontcolor="black", label=<{LinearReluFunctionalChild|b1<br ALIGN="LEFT"/>w1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearReluLinearModel" [color="black", fontcolor="black", label=<{LinearReluLinearModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" [color="black", fontcolor="black", label=<{LinearReluModel|fc<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.LinearReluModel" [color="black", fontcolor="black", label=<{LinearReluModel|fc<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearTanh" [color="black", fontcolor="black", label=<{LinearTanh|scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_mod, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearTanh" [color="black", fontcolor="black", label=<{LinearTanh|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.LinearTanhModel" [color="black", fontcolor="black", label=<{LinearTanhModel|linear<br ALIGN="LEFT"/>tanh<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.LinearUnary" [color="black", fontcolor="black", label=<{LinearUnary|<br ALIGN="LEFT"/>|<I>apply_constraint</I>()<br ALIGN="LEFT"/>codegen(wrapper)<br ALIGN="LEFT"/>create(x, w, B, attr, scalars, algorithm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.mobile_optimizer.LintCode" [color="black", fontcolor="black", label=<{LintCode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.list_contains.ListContains" [color="black", fontcolor="black", label=<{ListContains|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.ListIteratorVariable" [color="black", fontcolor="black", label=<{ListIteratorVariable|index : int<br ALIGN="LEFT"/>items<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]')<br ALIGN="LEFT"/>force_unpack_var_sequence(tx): List[VariableTracker]<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.ListOf" [color="black", fontcolor="black", label=<{ListOf|partial : bool<br ALIGN="LEFT"/>pattern<br ALIGN="LEFT"/>|pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.list_unpack.ListUnpack" [color="black", fontcolor="black", label=<{ListUnpack|<br ALIGN="LEFT"/>|forward(args: List[torch.Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.ListVariable" [color="black", fontcolor="black", label=<{ListVariable|class_type<br ALIGN="LEFT"/>has_grad_fn : bool<br ALIGN="LEFT"/>|call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>var_getattr(tx, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.Lit" [color="black", fontcolor="black", label=<{Lit|s<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dispatch.python.Lit" [color="black", fontcolor="black", label=<{Lit|s<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.mobile.LiteScriptModule" [color="black", fontcolor="black", label=<{LiteScriptModule|<br ALIGN="LEFT"/>|find_method(method_name)<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>run_method(method_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.LiveRange" [color="black", fontcolor="black", label=<{LiveRange|begin : float<br ALIGN="LEFT"/>end : float<br ALIGN="LEFT"/>|contains(other: LiveRange)<br ALIGN="LEFT"/>join(other: LiveRange)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.LiveRanges" [color="black", fontcolor="black", label=<{LiveRanges|begin<br ALIGN="LEFT"/>end<br ALIGN="LEFT"/>ranges<br ALIGN="LEFT"/>|overlaps(other: LiveRanges)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.prune.LnStructured" [color="black", fontcolor="black", label=<{LnStructured|PRUNING_TYPE : str<br ALIGN="LEFT"/>amount<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>n<br ALIGN="LEFT"/>|apply(module, name, amount, n, dim, importance_scores)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization.LoadEndianness" [color="black", fontcolor="black", label=<{LoadEndianness|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.LoadItemType" [color="black", fontcolor="black", label=<{LoadItemType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.LoadPlan" [color="black", fontcolor="black", label=<{LoadPlan|items : List[ReadItem]<br ALIGN="LEFT"/>planner_data : Optional[Any]<br ALIGN="LEFT"/>storage_data : Optional[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.LoadPlanner" [color="black", fontcolor="black", label=<{LoadPlanner|<br ALIGN="LEFT"/>|<I>commit_tensor</I>(read_item: ReadItem, tensor: torch.Tensor): None<br ALIGN="LEFT"/><I>create_global_plan</I>(global_plan: List[LoadPlan]): List[LoadPlan]<br ALIGN="LEFT"/><I>create_local_plan</I>(): LoadPlan<br ALIGN="LEFT"/><I>finish_plan</I>(central_plan: LoadPlan): LoadPlan<br ALIGN="LEFT"/><I>load_bytes</I>(read_item: ReadItem, value: io.BytesIO): None<br ALIGN="LEFT"/><I>resolve_bytes</I>(read_item: ReadItem): io.BytesIO<br ALIGN="LEFT"/><I>resolve_tensor</I>(read_item: ReadItem): torch.Tensor<br ALIGN="LEFT"/><I>set_up_planner</I>(state_dict: STATE_DICT_TYPE, metadata: Optional[Metadata], is_coordinator: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.fx_minifier.LoadTensorMeta" [color="black", fontcolor="black", label=<{LoadTensorMeta|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>size : List[int]<br ALIGN="LEFT"/>stride : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.runtime.autotune_cache.LocalAutotuneCache" [color="black", fontcolor="black", label=<{LocalAutotuneCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_utils.LocalBufferContext" [color="black", fontcolor="black", label=<{LocalBufferContext|exit_stack : ExitStack<br ALIGN="LEFT"/>global_buffers : Dict[str, ir.Buffer]<br ALIGN="LEFT"/>global_to_local : Dict[str, ir.Buffer]<br ALIGN="LEFT"/>kernel_args<br ALIGN="LEFT"/>local_buffers : Dict[str, ir.Buffer]<br ALIGN="LEFT"/>|add_local_buffer(local_buffer: ir.Buffer, global_buffers: Optional[List[ir.Buffer]])<br ALIGN="LEFT"/>localize_function(fn: Callable[..., Any], rewrite_index: Callable[['LocalizeBufferHandler', sympy.Expr, str], sympy.Expr])<br ALIGN="LEFT"/>localize_nodes(nodes: List[ir.IRNode], rewrite_index: Callable[['LocalizeBufferHandler', sympy.Expr, str], sympy.Expr]): List[ir.IRNode]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.LocalCache" [color="black", fontcolor="black", label=<{LocalCache|<br ALIGN="LEFT"/>|lookup(): Optional[Dict[str, Any]]<br ALIGN="LEFT"/>set_value(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.LocalCellSource" [color="black", fontcolor="black", label=<{LocalCellSource|local_name : str<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [color="black", fontcolor="black", label=<{LocalElasticAgent|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.autoheuristic.LocalFeedback" [color="black", fontcolor="black", label=<{LocalFeedback|feedback_fn : Callable[[Choice], Feedback]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._sharding_prop.LocalLRUCache" [color="black", fontcolor="black", label=<{LocalLRUCache|cache<br ALIGN="LEFT"/>|cache_info()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.LocalOptimStateDictConfig" [color="black", fontcolor="black", label=<{LocalOptimStateDictConfig|offload_to_cpu : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest" [color="black", fontcolor="black", label=<{LocalRRefTest|<br ALIGN="LEFT"/>|test_create_local_script_class_rref_in_py()<br ALIGN="LEFT"/>test_create_local_script_module_rref_in_py()<br ALIGN="LEFT"/>test_return_local_script_class_rref_in_py_and_use_in_script()<br ALIGN="LEFT"/>test_return_local_script_module_rref_in_py_and_use_in_script()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.normalization.LocalResponseNorm" [color="black", fontcolor="black", label=<{LocalResponseNorm|alpha : float<br ALIGN="LEFT"/>beta : float<br ALIGN="LEFT"/>k : float<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._shards_wrapper.LocalShardsWrapper" [color="black", fontcolor="black", label=<{LocalShardsWrapper|device<br ALIGN="LEFT"/>is_meta<br ALIGN="LEFT"/>local_chunks<br ALIGN="LEFT"/>|handle_all_gather_into_tensor(args, kwargs)<br ALIGN="LEFT"/>handle_clone(args, kwargs)<br ALIGN="LEFT"/>handle_detach(args, kwargs)<br ALIGN="LEFT"/>handle_equal(args, kwargs)<br ALIGN="LEFT"/>handle_to_copy(args, kwargs)<br ALIGN="LEFT"/>handle_view(args, kwargs)<br ALIGN="LEFT"/>handle_wait_tensor(args, kwargs)<br ALIGN="LEFT"/>is_pinned(): bool<br ALIGN="LEFT"/>local_offsets(): List[torch.Size]<br ALIGN="LEFT"/>local_shards(): List[torch.Tensor]<br ALIGN="LEFT"/>local_sizes(): List[torch.Size]<br ALIGN="LEFT"/>requires_grad_(requires_grad: bool): 'LocalShardsWrapper'<br ALIGN="LEFT"/>storage_metadata(): TensorStorageMetadata<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.LocalSource" [color="black", fontcolor="black", label=<{LocalSource|is_derefed_cell_contents : bool<br ALIGN="LEFT"/>is_input : bool<br ALIGN="LEFT"/>local_name : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.LocalState" [color="black", fontcolor="black", label=<{LocalState|automatic_dynamic : Dict[str, FrameStateSizeEntry]<br ALIGN="LEFT"/>|render(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.LocalStateDictConfig" [color="black", fontcolor="black", label=<{LocalStateDictConfig|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.local_timer.LocalTimerClient" [color="black", fontcolor="black", label=<{LocalTimerClient|<br ALIGN="LEFT"/>|acquire(scope_id, expiration_time)<br ALIGN="LEFT"/>release(scope_id)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.local_timer.LocalTimerServer" [color="black", fontcolor="black", label=<{LocalTimerServer|<br ALIGN="LEFT"/>|clear_timers(worker_ids: Set[int]): None<br ALIGN="LEFT"/>get_expired_timers(deadline: float): Dict[Any, List[TimerRequest]]<br ALIGN="LEFT"/>register_timers(timer_requests: List[TimerRequest]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp_utils.LocalizeBufferHandler" [color="black", fontcolor="black", label=<{LocalizeBufferHandler|global_to_local : Dict[str, ir.Buffer]<br ALIGN="LEFT"/>rewrite_index : Callable[['LocalizeBufferHandler', sympy.Expr, str], sympy.Expr]<br ALIGN="LEFT"/>|load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>localize(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>store_reduction(name, index, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Location" [color="black", fontcolor="black", label=<{Location|end_column : int \| None<br ALIGN="LEFT"/>function : str \| None<br ALIGN="LEFT"/>line : int \| None<br ALIGN="LEFT"/>message : str \| None<br ALIGN="LEFT"/>snippet : str \| None<br ALIGN="LEFT"/>start_column : int \| None<br ALIGN="LEFT"/>uri : str \| None<br ALIGN="LEFT"/>|sarif(): sarif.Location<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._location.Location" [color="black", fontcolor="black", label=<{Location|annotations : Optional[List[_region.Region]]<br ALIGN="LEFT"/>id : int<br ALIGN="LEFT"/>logical_locations : Optional[List[_logical_location.LogicalLocation]]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>physical_location : Optional[_physical_location.PhysicalLocation]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>relationships : Optional[List[_location_relationship.LocationRelationship]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._location_relationship.LocationRelationship" [color="black", fontcolor="black", label=<{LocationRelationship|description : Optional[_message.Message]<br ALIGN="LEFT"/>kinds : List[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>target : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.log_normal.LogNormal" [color="black", fontcolor="black", label=<{LogNormal|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._logging._internal.LogRegistry" [color="black", fontcolor="black", label=<{LogRegistry|artifact_descriptions : Dict[str, str]<br ALIGN="LEFT"/>artifact_log_formatters : Dict[str, logging.Formatter]<br ALIGN="LEFT"/>artifact_log_qnames : Set[str]<br ALIGN="LEFT"/>artifact_names : Set[str]<br ALIGN="LEFT"/>child_log_qnames : Set[str]<br ALIGN="LEFT"/>log_alias_to_log_qnames : Dict[str, List[str]]<br ALIGN="LEFT"/>off_by_default_artifact_names : Set[str]<br ALIGN="LEFT"/>visible_artifacts : Set[str]<br ALIGN="LEFT"/>|get_artifact_log_qnames()<br ALIGN="LEFT"/>get_child_log_qnames()<br ALIGN="LEFT"/>get_log_qnames(): Set[str]<br ALIGN="LEFT"/>is_artifact(name)<br ALIGN="LEFT"/>is_log(alias)<br ALIGN="LEFT"/>is_off_by_default(artifact_qname)<br ALIGN="LEFT"/>register_artifact_log(artifact_log_qname)<br ALIGN="LEFT"/>register_artifact_name(name, description, visible, off_by_default, log_format)<br ALIGN="LEFT"/>register_child_log(log_qname)<br ALIGN="LEFT"/>register_log(alias, log_qnames: Union[str, List[str]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.LogSigmoid" [color="black", fontcolor="black", label=<{LogSigmoid|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.LogSoftmax" [color="black", fontcolor="black", label=<{LogSoftmax|dim : Optional[int]<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._logging._internal.LogState" [color="black", fontcolor="black", label=<{LogState|artifact_names : Set[str]<br ALIGN="LEFT"/>log_qname_to_level : Dict[str, str]<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>enable_artifact(artifact_name)<br ALIGN="LEFT"/>enable_log(log_qnames, log_level)<br ALIGN="LEFT"/>get_log_level_pairs()<br ALIGN="LEFT"/>is_artifact_enabled(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite.Logger" [color="black", fontcolor="black", label=<{Logger|dtype<br ALIGN="LEFT"/>stats : dict<br ALIGN="LEFT"/>|<I>forward</I>(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.LoggingLoggerVariable" [color="black", fontcolor="black", label=<{LoggingLoggerVariable|value<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.LoggingShapeGuardPrinter" [color="black", fontcolor="black", label=<{LoggingShapeGuardPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.logging_tensor.LoggingTensor" [color="black", fontcolor="black", label=<{LoggingTensor|context : nullcontext<br ALIGN="LEFT"/>elem<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.logging_tensor.LoggingTensorHandler" [color="black", fontcolor="black", label=<{LoggingTensorHandler|log_list : List[str]<br ALIGN="LEFT"/>memo<br ALIGN="LEFT"/>next_id : int<br ALIGN="LEFT"/>tracebacks_list : Optional[List]<br ALIGN="LEFT"/>use_shortid_for_all_tensors : bool<br ALIGN="LEFT"/>with_type : bool<br ALIGN="LEFT"/>|emit(record)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.logging_tensor.LoggingTensorMode" [color="black", fontcolor="black", label=<{LoggingTensorMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.logging_tensor.LoggingTensorReentrant" [color="black", fontcolor="black", label=<{LoggingTensorReentrant|context<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.logging_utils.LoggingTestCase" [color="black", fontcolor="black", label=<{LoggingTestCase|<br ALIGN="LEFT"/>|getRecord(records, m)<br ALIGN="LEFT"/>hasRecord(records, m)<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>tearDownClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._logical_location.LogicalLocation" [color="black", fontcolor="black", label=<{LogicalLocation|decorated_name : Optional[str]<br ALIGN="LEFT"/>fully_qualified_name : Optional[str]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>kind : Optional[str]<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>parent_index : int<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.logistic_normal.LogisticNormal" [color="black", fontcolor="black", label=<{LogisticNormal|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli" [color="black", fontcolor="black", label=<{LogitRelaxedBernoulli|arg_constraints : dict<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>temperature<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.LogsDest" [color="black", fontcolor="black", label=<{LogsDest|error_files : Dict[int, str]<br ALIGN="LEFT"/>stderrs : Dict[int, str]<br ALIGN="LEFT"/>stdouts : Dict[int, str]<br ALIGN="LEFT"/>tee_stderrs : Dict[int, str]<br ALIGN="LEFT"/>tee_stdouts : Dict[int, str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.LogsSpecs" [color="black", fontcolor="black", label=<{LogsSpecs|root_log_dir<br ALIGN="LEFT"/>|<I>reify</I>(envs: Dict[int, Dict[str, str]]): LogsDest<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.LongStorage" [color="black", fontcolor="black", label=<{LongStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.LongStorage" [color="black", fontcolor="black", label=<{LongStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.LoopBody" [color="black", fontcolor="black", label=<{LoopBody|indexing : NoneType<br ALIGN="LEFT"/>indexing_exprs : Dict[str, sympy.Expr]<br ALIGN="LEFT"/>indexing_exprs_name : Dict[sympy.Expr, str]<br ALIGN="LEFT"/>indirect_var_ranges : Dict[sympy.Symbol, sympy.Expr]<br ALIGN="LEFT"/>indirect_vars : List[sympy.Symbol]<br ALIGN="LEFT"/>iter_vars<br ALIGN="LEFT"/>memory_usage : Dict[MemoryUsageType, List[MemoryEntry]]<br ALIGN="LEFT"/>op_counts : collections.Counter[str]<br ALIGN="LEFT"/>reduce_vars<br ALIGN="LEFT"/>root_block<br ALIGN="LEFT"/>sizes : tuple<br ALIGN="LEFT"/>subblocks : Dict[str, LoopBodyBlock]<br ALIGN="LEFT"/>submodules : Dict[str, Any]<br ALIGN="LEFT"/>var_ranges<br ALIGN="LEFT"/>vars<br ALIGN="LEFT"/>|add_index_expr(expr: sympy.Expr, mtype: MemoryUsageType, buffer_name: Optional[str], mode: Optional[str])<br ALIGN="LEFT"/>add_indirect(size)<br ALIGN="LEFT"/>add_submodule(block, prefix)<br ALIGN="LEFT"/>bind_masked_shim(name)<br ALIGN="LEFT"/>bind_scan_shim(combine_fn)<br ALIGN="LEFT"/>bind_set_indirect_shim(var, size, check, wrap_neg)<br ALIGN="LEFT"/>bounds()<br ALIGN="LEFT"/>debug_str()<br ALIGN="LEFT"/>get_index(name)<br ALIGN="LEFT"/>get_nodes()<br ALIGN="LEFT"/>get_read_expr(buffer_name)<br ALIGN="LEFT"/>get_read_exprs()<br ALIGN="LEFT"/>get_write_expr(buffer_name)<br ALIGN="LEFT"/>get_write_exprs()<br ALIGN="LEFT"/>has_op(name: str)<br ALIGN="LEFT"/>indexing_from_args(indices)<br ALIGN="LEFT"/>is_memory_copy(): bool<br ALIGN="LEFT"/>merge_loops(): LoopBody<br ALIGN="LEFT"/>reorder_iter_loops(new_order): LoopBody<br ALIGN="LEFT"/>replace_indirect(old, new)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.LoopBodyBlock" [color="black", fontcolor="black", label=<{LoopBodyBlock|body<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|clone(body: LoopBody)<br ALIGN="LEFT"/>contains_only_ops(allowed_ops): bool<br ALIGN="LEFT"/>debug_str(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.LoopLevel" [color="black", fontcolor="black", label=<{LoopLevel|collapsed : bool<br ALIGN="LEFT"/>is_reduction : bool<br ALIGN="LEFT"/>offset : Expr<br ALIGN="LEFT"/>parallel : int<br ALIGN="LEFT"/>simd_nelements : int<br ALIGN="LEFT"/>simd_omp : bool<br ALIGN="LEFT"/>simd_vec : bool<br ALIGN="LEFT"/>size : Optional[sympy.Expr]<br ALIGN="LEFT"/>steps : Expr<br ALIGN="LEFT"/>tiled_size : Expr<br ALIGN="LEFT"/>var : Optional[sympy.Expr]<br ALIGN="LEFT"/>|lines()<br ALIGN="LEFT"/>tile(factor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.LoopNest" [color="black", fontcolor="black", label=<{LoopNest|kernel : Optional[CppKernel]<br ALIGN="LEFT"/>loops : Optional[List[LoopLevel]]<br ALIGN="LEFT"/>|build(kernel: CppKernel)<br ALIGN="LEFT"/>from_loop_level(level: int)<br ALIGN="LEFT"/>get_kernel(): CppKernel<br ALIGN="LEFT"/>is_reduction_only()<br ALIGN="LEFT"/>mark_parallel(par_depth)<br ALIGN="LEFT"/>max_parallel_depth()<br ALIGN="LEFT"/>set_kernel(kernel)<br ALIGN="LEFT"/>tile(depth, factor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.Loops" [color="black", fontcolor="black", label=<{Loops|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>inner_fn : Callable[..., Any]<br ALIGN="LEFT"/>ranges : Sequence[_IntLike]<br ALIGN="LEFT"/>|<I>constant_to_device</I>(device: torch.device): IRNode<br ALIGN="LEFT"/>create(): TensorBox<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_pointwise_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/><I>get_reduction_size</I>(): Sequence[sympy.Expr]<br ALIGN="LEFT"/><I>get_reduction_type</I>(): Optional[str]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[Symbol]<br ALIGN="LEFT"/>has_large_inner_fn(threshold: Optional[int]): bool<br ALIGN="LEFT"/>inner_fn_args(): Sequence[Sequence[_IntLike]]<br ALIGN="LEFT"/>inner_fn_free_unbacked_symbols(): OrderedSet[Symbol]<br ALIGN="LEFT"/>inner_fn_opcount(): OpCountResult<br ALIGN="LEFT"/>inner_fn_str(): str<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.LossOutputSpec" [color="black", fontcolor="black", label=<{LossOutputSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.LossWrapper" [color="black", fontcolor="black", label=<{LossWrapper|loss_fn<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>|<I>forward</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms._comm_hooks.default_hooks.LowPrecisionState" [color="black", fontcolor="black", label=<{LowPrecisionState|parameter_type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal" [color="black", fontcolor="black", label=<{LowRankMultivariateNormal|arg_constraints : dict<br ALIGN="LEFT"/>cov_diag<br ALIGN="LEFT"/>cov_factor<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>|covariance_matrix()<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>precision_matrix()<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>scale_tril()<br ALIGN="LEFT"/>variance()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.LowerCholeskyTransform" [color="black", fontcolor="black", label=<{LowerCholeskyTransform|codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.exc.LoweringException" [color="black", fontcolor="red", label=<{LoweringException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.LoweringPatternEntry" [color="black", fontcolor="black", label=<{LoweringPatternEntry|handler : Callable[..., Any]<br ALIGN="LEFT"/>|apply(match: Match, graph: torch.fx.Graph, node: torch.fx.Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.n_shadows_utils.create_submodule_from_subgraph.M" [color="black", fontcolor="black", label=<{M|<br ALIGN="LEFT"/>|<I>forward</I>(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.PT2EQuantizationTestCase._get_pt2e_quantized_linear.M" [color="black", fontcolor="black", label=<{M|linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.dispatcher.MDNotImplementedError" [color="black", fontcolor="red", label=<{MDNotImplementedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.metadata.MEM_FORMAT_ENCODING" [color="black", fontcolor="black", label=<{MEM_FORMAT_ENCODING|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.MKLPackedLinear" [color="black", fontcolor="black", label=<{MKLPackedLinear|<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x, packed_w, orig_w, B, batch_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.MLP" [color="black", fontcolor="black", label=<{MLP|buffer : NoneType<br ALIGN="LEFT"/>in_proj<br ALIGN="LEFT"/>out_proj<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>reset_parameters()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.MLPModule" [color="black", fontcolor="black", label=<{MLPModule|net1<br ALIGN="LEFT"/>net2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>reset_parameters()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.MLPStack" [color="black", fontcolor="black", label=<{MLPStack|with_seq_parallel : bool<br ALIGN="LEFT"/>|parallelize(tp_mesh: DeviceMesh, dp_mesh: DeviceMesh, use_activation_checkpointing: bool): 'MLPStack'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.MLPStacked" [color="black", fontcolor="black", label=<{MLPStacked|layers<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.artifacts._MMRankingA100.MMRankingA100" [color="black", fontcolor="black", label=<{MMRankingA100|choices : List[Choice]<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>fill_choices(): None<br ALIGN="LEFT"/>get_best_choices(context: AHContext): Optional[List[Tuple[float, int]]]<br ALIGN="LEFT"/>get_choice(idx: int): Optional[str]<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.artifacts._MMRankingH100.MMRankingH100" [color="black", fontcolor="black", label=<{MMRankingH100|choices : List[Choice]<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>fill_choices(): None<br ALIGN="LEFT"/>get_best_choices(context: AHContext): Optional[List[Tuple[float, int]]]<br ALIGN="LEFT"/>get_choice(idx: int): Optional[str]<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.MPSTestBase" [color="black", fontcolor="black", label=<{MPSTestBase|device_type : str<br ALIGN="LEFT"/>primary_device : ClassVar[str]<br ALIGN="LEFT"/>|get_all_devices()<br ALIGN="LEFT"/>get_primary_device()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.MSELoss" [color="black", fontcolor="black", label=<{MSELoss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator.MSPS" [color="black", fontcolor="black", label=<{MSPS|func_names : Set[str]<br ALIGN="LEFT"/>memory : int<br ALIGN="LEFT"/>msps : float<br ALIGN="LEFT"/>op_idx : int<br ALIGN="LEFT"/>runtime : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.worker.ManagerWatchdog" [color="black", fontcolor="black", label=<{ManagerWatchdog|kernel32 : WinDLL<br ALIGN="LEFT"/>manager_dead : bool<br ALIGN="LEFT"/>manager_handle<br ALIGN="LEFT"/>manager_pid<br ALIGN="LEFT"/>|is_alive()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualConvLinearQATModel" [color="black", fontcolor="black", label=<{ManualConvLinearQATModel|conv<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualConvLinearSymmQATModel" [color="black", fontcolor="black", label=<{ManualConvLinearSymmQATModel|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualDropoutQATModel" [color="black", fontcolor="black", label=<{ManualDropoutQATModel|dequant<br ALIGN="LEFT"/>dropout<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [color="black", fontcolor="black", label=<{ManualEmbeddingBagLinear|dequant<br ALIGN="LEFT"/>emb<br ALIGN="LEFT"/>linear<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(input: torch.Tensor, offsets: Optional[torch.Tensor], per_sample_weights: Optional[torch.Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualLinearDynamicQATModel" [color="black", fontcolor="black", label=<{ManualLinearDynamicQATModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ManualLinearQATModel" [color="black", fontcolor="black", label=<{ManualLinearQATModel|dequant<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.map.MapAutogradOp" [color="black", fontcolor="black", label=<{MapAutogradOp|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, fw_graph, joint_graph, num_mapped_args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe.MapDataPipe" [color="black", fontcolor="black", label=<{MapDataPipe|functions : Dict[str, Callable]<br ALIGN="LEFT"/>getstate_hook : Optional[Callable]<br ALIGN="LEFT"/>reduce_ex_hook : Optional[Callable]<br ALIGN="LEFT"/>repr_hook : Optional[Callable]<br ALIGN="LEFT"/>str_hook : Optional[Callable]<br ALIGN="LEFT"/>|register_datapipe_as_function(function_name, cls_to_register)<br ALIGN="LEFT"/>register_function(function_name, function)<br ALIGN="LEFT"/>set_getstate_hook(hook_fn)<br ALIGN="LEFT"/>set_reduce_ex_hook(hook_fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.MapHigherOrderVariable" [color="black", fontcolor="black", label=<{MapHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.map.MapImpl" [color="black", fontcolor="black", label=<{MapImpl|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.MapVariable" [color="black", fontcolor="black", label=<{MapVariable|fn<br ALIGN="LEFT"/>|has_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.map.MapWrapper" [color="black", fontcolor="black", label=<{MapWrapper|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.callable.MapperIterDataPipe" [color="black", fontcolor="black", label=<{MapperIterDataPipe|datapipe<br ALIGN="LEFT"/>fn : Callable<br ALIGN="LEFT"/>input_col : NoneType<br ALIGN="LEFT"/>output_col : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.callable.MapperMapDataPipe" [color="black", fontcolor="black", label=<{MapperMapDataPipe|datapipe<br ALIGN="LEFT"/>fn : Callable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree.MappingKey" [color="black", fontcolor="black", label=<{MappingKey|key : K<br ALIGN="LEFT"/>|get(mapping: Mapping[K, T]): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.MarginRankingLoss" [color="black", fontcolor="black", label=<{MarginRankingLoss|margin : float<br ALIGN="LEFT"/>|forward(input1: Tensor, input2: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.MarkStepBox" [color="black", fontcolor="black", label=<{MarkStepBox|mark_step_counter : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.namedtuple_fields.Marker" [color="black", fontcolor="black", label=<{Marker|index : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._embedding_ops.MaskBuffer" [color="black", fontcolor="black", label=<{MaskBuffer|data : Optional[torch.Tensor]<br ALIGN="LEFT"/>refcount : int<br ALIGN="LEFT"/>|apply_mask(tensor)<br ALIGN="LEFT"/>materialize_mask(mask)<br ALIGN="LEFT"/>release_mask()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor.core.MaskedTensor" [color="black", fontcolor="black", label=<{MaskedTensor|is_sparse<br ALIGN="LEFT"/>|get_data()<br ALIGN="LEFT"/>get_mask()<br ALIGN="LEFT"/>is_sparse_coo()<br ALIGN="LEFT"/>is_sparse_csr()<br ALIGN="LEFT"/>to_tensor(value)<br ALIGN="LEFT"/>unary(fn, data, mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.utils.decoder.MatHandler" [color="black", fontcolor="black", label=<{MatHandler|loadmat_kwargs : dict<br ALIGN="LEFT"/>sio<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.MatMulDimInFP16Pattern" [color="black", fontcolor="black", label=<{MatMulDimInFP16Pattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>skip<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|benchmark(events: List[_ProfilerEvent])<br ALIGN="LEFT"/>match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.subgraph_rewriter.Match" [color="black", fontcolor="black", label=<{Match|anchor<br ALIGN="LEFT"/>nodes_map : Dict[Node, Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.Match" [color="black", fontcolor="black", label=<{Match|args : List[Any]<br ALIGN="LEFT"/>ctx<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>nodes : List[torch.fx.Node]<br ALIGN="LEFT"/>pattern<br ALIGN="LEFT"/>replacement_graph : Optional[torch.fx.GraphModule]<br ALIGN="LEFT"/>targets : Dict[_TargetExpr, torch.fx.node.Target]<br ALIGN="LEFT"/>|bundle(): Match<br ALIGN="LEFT"/>erase_nodes(): None<br ALIGN="LEFT"/>extend(other: Match): None<br ALIGN="LEFT"/>output_node(): torch.fx.Node<br ALIGN="LEFT"/>output_nodes(): List[Optional[torch.fx.Node]]<br ALIGN="LEFT"/>replace_by_example(replacement_fn: ReplaceFn, args: Sequence[Any], trace_fn: Optional[TraceFn], run_functional_passes: bool): None<br ALIGN="LEFT"/>replace_with_graph(replacement_graph: torch.fx.Graph, args: Sequence[Any]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.utils.MatchAllNode" [color="black", fontcolor="black", label=<{MatchAllNode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.MatchContext" [color="black", fontcolor="black", label=<{MatchContext|exclusive_node_set : List[NodeOrConstant]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>outputs : List[Optional[PatternExpr]]<br ALIGN="LEFT"/>pattern_to_node : Dict[PatternExpr, Optional[torch.fx.Node]]<br ALIGN="LEFT"/>|filter_multi_user_patterns(): Dict[PatternExpr, torch.fx.Node]<br ALIGN="LEFT"/>match(pattern: PatternExpr, node: NodeOrConstant): MatchResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.Max" [color="black", fontcolor="black", label=<{Max|identity<br ALIGN="LEFT"/>zero<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxPool1d" [color="black", fontcolor="black", label=<{MaxPool1d|dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxPool2d" [color="black", fontcolor="black", label=<{MaxPool2d|dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxPool3d" [color="black", fontcolor="black", label=<{MaxPool3d|dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxUnpool1d" [color="black", fontcolor="black", label=<{MaxUnpool1d|kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor, indices: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxUnpool2d" [color="black", fontcolor="black", label=<{MaxUnpool2d|kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor, indices: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling.MaxUnpool3d" [color="black", fontcolor="black", label=<{MaxUnpool3d|kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|forward(input: Tensor, indices: Tensor, output_size: Optional[List[int]]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization._correct_bias.MeanShadowLogger" [color="black", fontcolor="black", label=<{MeanShadowLogger|count : int<br ALIGN="LEFT"/>float_sum : NoneType<br ALIGN="LEFT"/>quant_sum : NoneType<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.common.Measurement" [color="black", fontcolor="black", label=<{Measurement|as_row_name<br ALIGN="LEFT"/>env<br ALIGN="LEFT"/>has_warnings<br ALIGN="LEFT"/>iqr<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>median<br ALIGN="LEFT"/>metadata : Optional[Dict[Any, Any]]<br ALIGN="LEFT"/>number_per_run : int<br ALIGN="LEFT"/>raw_times : List[float]<br ALIGN="LEFT"/>significant_figures<br ALIGN="LEFT"/>task_spec<br ALIGN="LEFT"/>times<br ALIGN="LEFT"/>title<br ALIGN="LEFT"/>|meets_confidence(threshold: float): bool<br ALIGN="LEFT"/>merge(measurements: Iterable['Measurement']): List['Measurement']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.memory.MemPool" [color="black", fontcolor="black", label=<{MemPool|allocator<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>|snapshot()<br ALIGN="LEFT"/>use_count(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.memory.MemPoolContext" [color="black", fontcolor="black", label=<{MemPoolContext|<br ALIGN="LEFT"/>|active_pool(): Optional[_MemPool]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler_util.MemRecordsAcc" [color="black", fontcolor="black", label=<{MemRecordsAcc|<br ALIGN="LEFT"/>|in_interval(start_us, end_us)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker.MemTracker" [color="black", fontcolor="black", label=<{MemTracker|memory_tracking<br ALIGN="LEFT"/>|display_modulewise_snapshots(depth: int, units: str, tabulate: bool): None<br ALIGN="LEFT"/>display_snapshot(type: str, units: str, tabulate: bool): None<br ALIGN="LEFT"/>get_tracker_snapshot(type: str): Dict[torch.device, Dict[str, int]]<br ALIGN="LEFT"/>reset_mod_stats(): None<br ALIGN="LEFT"/>track_external(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.MemoizeWithCycleCheck" [color="black", fontcolor="black", label=<{MemoizeWithCycleCheck|cache : Dict[Tuple[str, int], Any]<br ALIGN="LEFT"/>fn : Callable[..., Any]<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies.MemoryDep" [color="black", fontcolor="black", label=<{MemoryDep|index : Expr<br ALIGN="LEFT"/>mode : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>num_vars<br ALIGN="LEFT"/>ranges<br ALIGN="LEFT"/>size : Tuple[sympy.Expr, ...]<br ALIGN="LEFT"/>var_names : Tuple[sympy.Symbol, ...]<br ALIGN="LEFT"/>|decide_loop_order_to_match(other)<br ALIGN="LEFT"/>get_numel(): sympy.Expr<br ALIGN="LEFT"/>get_offset()<br ALIGN="LEFT"/>has_unbacked_symbols()<br ALIGN="LEFT"/>is_contiguous(): bool<br ALIGN="LEFT"/>is_indirect(): bool<br ALIGN="LEFT"/>is_scalar(): bool<br ALIGN="LEFT"/>normalize(): 'MemoryDep'<br ALIGN="LEFT"/>normalize_with_stride_order(prefix)<br ALIGN="LEFT"/>numbytes_hint(): int<br ALIGN="LEFT"/>rename(renames: Dict[str, str]): 'MemoryDep'<br ALIGN="LEFT"/>simplify_with_ranges()<br ALIGN="LEFT"/>stride1_for_last_dim(result_for_complex_expression): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.MemoryEntry" [color="black", fontcolor="black", label=<{MemoryEntry|buffer_name : Optional[str]<br ALIGN="LEFT"/>index_name : str<br ALIGN="LEFT"/>mode : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.MemoryFormat" [color="black", fontcolor="black", label=<{MemoryFormat|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.MemoryPlanner" [color="black", fontcolor="black", label=<{MemoryPlanner|buffer_groups : Optional[List[BufferGroup]]<br ALIGN="LEFT"/>pools<br ALIGN="LEFT"/>wrapper : Any<br ALIGN="LEFT"/>|allocate_groups()<br ALIGN="LEFT"/>compute_buffer_groups(lines)<br ALIGN="LEFT"/>compute_live_ranges(lines)<br ALIGN="LEFT"/>convert_to_pool_lines(lines)<br ALIGN="LEFT"/>drop_removed_buffers(lines)<br ALIGN="LEFT"/>mark_first_last_usage(lines)<br ALIGN="LEFT"/>plan(lines: List[Any]): List[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.memory.MemoryPlanningInfoForBuffer" [color="black", fontcolor="black", label=<{MemoryPlanningInfoForBuffer|size_alloc : int<br ALIGN="LEFT"/>size_free : int<br ALIGN="LEFT"/>succ_nodes : OrderedSet[BaseSchedulerNode]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.memory.MemoryPlanningInfoForNode" [color="black", fontcolor="black", label=<{MemoryPlanningInfoForNode|index : int<br ALIGN="LEFT"/>pred_buffers : OrderedSet[Union[SchedulerBuffer, FreeableInputBuffer]]<br ALIGN="LEFT"/>pred_nodes : OrderedSet[BaseSchedulerNode]<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>succ_nodes : OrderedSet[BaseSchedulerNode]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.MemoryPlanningLine" [color="black", fontcolor="black", label=<{MemoryPlanningLine|wrapper<br ALIGN="LEFT"/>|<I>codegen</I>(code: IndentedBuffer): None<br ALIGN="LEFT"/>plan(state: MemoryPlanningState): MemoryPlanningLine<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.MemoryPlanningState" [color="black", fontcolor="black", label=<{MemoryPlanningState|reuse_pool : Dict[ReuseKey, List[FreeIfNotReusedLine]]<br ALIGN="LEFT"/>total_allocated_buffer_size : int<br ALIGN="LEFT"/>|pop(key: ReuseKey): FreeIfNotReusedLine<br ALIGN="LEFT"/>push(key: ReuseKey, item: FreeIfNotReusedLine): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.MemoryProfile" [color="black", fontcolor="black", label=<{MemoryProfile|timeline<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.memory_tracker.MemoryProfileDispatchMode" [color="black", fontcolor="black", label=<{MemoryProfileDispatchMode|memory_tracker<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.MemoryProfileTimeline" [color="black", fontcolor="black", label=<{MemoryProfileTimeline|categories<br ALIGN="LEFT"/>timeline<br ALIGN="LEFT"/>|export_memory_timeline(path, device_str): None<br ALIGN="LEFT"/>export_memory_timeline_html(path, device_str, figsize, title): None<br ALIGN="LEFT"/>export_memory_timeline_raw(path, device_str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.MemorySplitProtocol" [color="black", fontcolor="black", label=<{MemorySplitProtocol|get_live_ranges : CachedMethod[[], LiveRanges]<br ALIGN="LEFT"/>get_size_hint : CachedMethod[[], int]<br ALIGN="LEFT"/>get_symbolic_size : CachedMethod[[], sympy.Expr]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.memory_tracker.MemoryTracker" [color="black", fontcolor="black", label=<{MemoryTracker|memories_active : Dict[int, Dict[str, float]]<br ALIGN="LEFT"/>memories_allocated : Dict[int, Dict[str, float]]<br ALIGN="LEFT"/>memories_reserved : Dict[int, Dict[str, float]]<br ALIGN="LEFT"/>profile_mode : NoneType<br ALIGN="LEFT"/>|load(path: str): None<br ALIGN="LEFT"/>save_stats(path: str): None<br ALIGN="LEFT"/>show_traces(path: str): None<br ALIGN="LEFT"/>start_monitor(root_module: nn.Module): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>summary(top: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.loop_body.MemoryUsageType" [color="black", fontcolor="black", label=<{MemoryUsageType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.MergeKwargsIntoArgsInputStep" [color="black", fontcolor="black", label=<{MergeKwargsIntoArgsInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._collective_utils.MeshTopoInfo" [color="black", fontcolor="black", label=<{MeshTopoInfo|mesh<br ALIGN="LEFT"/>mesh_dim_bandwidth : List[float]<br ALIGN="LEFT"/>mesh_dim_devices : List[int]<br ALIGN="LEFT"/>mesh_dim_latency : List[float]<br ALIGN="LEFT"/>|build_from_mesh(mesh: DeviceMesh): 'MeshTopoInfo'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._message.Message" [color="black", fontcolor="black", label=<{Message|arguments : Optional[List[str]]<br ALIGN="LEFT"/>id : Optional[str]<br ALIGN="LEFT"/>markdown : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>text : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.meta_tracer.MetaAttribute" [color="black", fontcolor="black", label=<{MetaAttribute|attr : str<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.meta_utils.MetaConverter" [color="black", fontcolor="black", label=<{MetaConverter|arg_cnt : int<br ALIGN="LEFT"/>copy_data : bool<br ALIGN="LEFT"/>del_hook : NoneType<br ALIGN="LEFT"/>describer<br ALIGN="LEFT"/>hit : int<br ALIGN="LEFT"/>miss : int<br ALIGN="LEFT"/>storage_memo : weakref.WeakValueDictionary[MetaStorageId, torch.UntypedStorage]<br ALIGN="LEFT"/>tensor_memo : weakref.WeakValueDictionary[MetaTensorId, _TensorT]<br ALIGN="LEFT"/>|get_storage_memo(s: MetaStorageDesc): Optional[torch.UntypedStorage]<br ALIGN="LEFT"/>get_tensor_memo(t: MetaTensorDesc): Optional[torch.Tensor]<br ALIGN="LEFT"/>meta_storage(s: MetaStorageDesc, callback: Callable[[Callable[[], torch.Tensor]], _TensorT]): torch.UntypedStorage<br ALIGN="LEFT"/>meta_tensor(t: MetaTensorDesc, shape_env: Optional[ShapeEnv], callback: _MetaTensorCallback[_TensorT], source: Optional[Source], symbolic_context: Optional[SymbolicContext]): _TensorT<br ALIGN="LEFT"/>set_storage_memo(s: MetaStorageDesc, v: torch.UntypedStorage): None<br ALIGN="LEFT"/>set_tensor_memo(t: MetaTensorDesc, v: _TensorT): None<br ALIGN="LEFT"/>successful(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.meta_tracer.MetaDeviceAttribute" [color="black", fontcolor="black", label=<{MetaDeviceAttribute|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.proxy.MetaProxy" [color="black", fontcolor="black", label=<{MetaProxy|fake_mode : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.meta_tracer.MetaProxy" [color="black", fontcolor="black", label=<{MetaProxy|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|dim()<br ALIGN="LEFT"/>install_tensor_meta(tensor_meta)<br ALIGN="LEFT"/>size(dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.meta_utils.MetaStorageDesc" [color="black", fontcolor="black", label=<{MetaStorageDesc|data : Optional[torch.UntypedStorage]<br ALIGN="LEFT"/>id : MetaStorageId<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|as_json(describer_id: _DescriberId): Dict[str, object]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.meta_utils.MetaTensorDesc" [color="black", fontcolor="black", label=<{MetaTensorDesc|attrs : Optional[Dict[str, MetaTensorDesc]]<br ALIGN="LEFT"/>autograd_meta_from : Optional[torch.Tensor]<br ALIGN="LEFT"/>base : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>bdim : Optional[int]<br ALIGN="LEFT"/>ccol_indices : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>col_indices : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>creation_meta : Optional[CreationMeta]<br ALIGN="LEFT"/>crow_indices : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>ctx : Optional[object]<br ALIGN="LEFT"/>current_level : Optional[int]<br ALIGN="LEFT"/>data : Optional[torch.Tensor]<br ALIGN="LEFT"/>dense_dim : Optional[int]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>dynamo_dynamic_indices : List[int]<br ALIGN="LEFT"/>fake_mode : Optional[FakeTensorMode]<br ALIGN="LEFT"/>functorch_stack : Optional[List[CInterpreter]]<br ALIGN="LEFT"/>grad : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>id : MetaTensorId<br ALIGN="LEFT"/>is_batchedtensor : bool<br ALIGN="LEFT"/>is_coalesced : Optional[bool]<br ALIGN="LEFT"/>is_conj : bool<br ALIGN="LEFT"/>is_functional : bool<br ALIGN="LEFT"/>is_functorch_wrapped : bool<br ALIGN="LEFT"/>is_gradtrackingtensor : bool<br ALIGN="LEFT"/>is_inference : bool<br ALIGN="LEFT"/>is_leaf : bool<br ALIGN="LEFT"/>is_legacy_batchedtensor : bool<br ALIGN="LEFT"/>is_mkldnn : bool<br ALIGN="LEFT"/>is_neg : bool<br ALIGN="LEFT"/>is_nested : bool<br ALIGN="LEFT"/>is_parameter : bool<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>is_traceable_wrapper_subclass : bool<br ALIGN="LEFT"/>is_view : bool<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>level : Optional[int]<br ALIGN="LEFT"/>ndim : int<br ALIGN="LEFT"/>nested_int : Optional[int]<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>row_indices : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>size : Tuple[int, ...]<br ALIGN="LEFT"/>sparse_dim : Optional[int]<br ALIGN="LEFT"/>storage : Optional[MetaStorageDesc]<br ALIGN="LEFT"/>storage_offset : int<br ALIGN="LEFT"/>stride : Optional[Tuple[int, ...]]<br ALIGN="LEFT"/>type : Optional[Type]<br ALIGN="LEFT"/>unwrapped : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>values : Optional[MetaTensorDesc]<br ALIGN="LEFT"/>view_func : Optional[ViewFunc]<br ALIGN="LEFT"/>|as_json(describer_id: _DescriberId): Dict[str, object]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.meta_utils.MetaTensorDescriber" [color="black", fontcolor="black", label=<{MetaTensorDescriber|copy_data : bool<br ALIGN="LEFT"/>id : _DescriberId<br ALIGN="LEFT"/>lookup_storage<br ALIGN="LEFT"/>lookup_tensor<br ALIGN="LEFT"/>next_storage_id : MetaStorageId<br ALIGN="LEFT"/>next_tensor_id : MetaTensorId<br ALIGN="LEFT"/>traced_storages : Set[int]<br ALIGN="LEFT"/>traced_tensors : Set[int]<br ALIGN="LEFT"/>|describe_storage(s: torch.UntypedStorage): MetaStorageDesc<br ALIGN="LEFT"/>describe_tensor(t: torch.Tensor): MetaTensorDesc<br ALIGN="LEFT"/>get_storage_id(s: torch.UntypedStorage): MetaStorageId<br ALIGN="LEFT"/>get_tensor_id(t: torch.Tensor): MetaTensorId<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.meta_tracer.MetaTracer" [color="black", fontcolor="black", label=<{MetaTracer|allow_insert_stateless_mods : bool<br ALIGN="LEFT"/>meta_args : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>orig_fns : set<br ALIGN="LEFT"/>orig_forward<br ALIGN="LEFT"/>patched_torch_methods<br ALIGN="LEFT"/>prev_module : str<br ALIGN="LEFT"/>|call_module(m, forward, args, kwargs)<br ALIGN="LEFT"/>create_proxy(kind, target, args, kwargs, name, type_expr, proxy_factory_fn)<br ALIGN="LEFT"/>getattr(attr, attr_val, parameter_proxy_cache)<br ALIGN="LEFT"/>path_of_module(mod: torch.nn.Module): str<br ALIGN="LEFT"/>proxy(node)<br ALIGN="LEFT"/>trace(root, meta_args: Dict[str, torch.Tensor], concrete_args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.Metadata" [color="black", fontcolor="black", label=<{Metadata|planner_data : Optional[Any]<br ALIGN="LEFT"/>state_dict_metadata : Dict[str, STORAGE_TYPES]<br ALIGN="LEFT"/>storage_data : Optional[Any]<br ALIGN="LEFT"/>storage_meta : Optional[StorageMeta]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.autograd.make_autograd_impl.Metadata" [color="black", fontcolor="black", label=<{Metadata|keyset<br ALIGN="LEFT"/>keyword_only_args : Dict[str, Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._library.autograd.supports_tensorlist.Metadata" [color="black", fontcolor="black", label=<{Metadata|input_spec<br ALIGN="LEFT"/>output_spec : Optional[spec_t]<br ALIGN="LEFT"/>result_is_tuple : Optional[bool]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.MetadataIndex" [color="black", fontcolor="black", label=<{MetadataIndex|fqn : str<br ALIGN="LEFT"/>index : Optional[int]<br ALIGN="LEFT"/>offset : Optional[torch.Size]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.functional_utils.MetadataKey" [color="black", fontcolor="black", label=<{MetadataKey|is_conj : bool<br ALIGN="LEFT"/>is_neg : bool<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>size : Tuple[SymIntEqByExpr, ...]<br ALIGN="LEFT"/>storage_offset : Optional[SymIntEqByExpr]<br ALIGN="LEFT"/>stride : Optional[Tuple[SymIntEqByExpr, ...]]<br ALIGN="LEFT"/>|make(t)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.MetadataMismatchError" [color="black", fontcolor="red", label=<{MetadataMismatchError|reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.dispatcher.MethodDispatcher" [color="black", fontcolor="black", label=<{MethodDispatcher|cls<br ALIGN="LEFT"/>obj<br ALIGN="LEFT"/>|get_func_params(func)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.MethodWrapperVariable" [color="black", fontcolor="black", label=<{MethodWrapperVariable|method_wrapper<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.metrics.api.MetricHandler" [color="black", fontcolor="black", label=<{MetricHandler|<br ALIGN="LEFT"/>|<I>emit</I>(metric_data: MetricData)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.metrics.api.MetricStream" [color="black", fontcolor="black", label=<{MetricStream|group_name : str<br ALIGN="LEFT"/>handler<br ALIGN="LEFT"/>|add_value(metric_name: str, metric_value: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.metrics.MetricTable" [color="black", fontcolor="black", label=<{MetricTable|column_names : List[str]<br ALIGN="LEFT"/>num_rows_added : int<br ALIGN="LEFT"/>table_name : str<br ALIGN="LEFT"/>|add_row(row_fn)<br ALIGN="LEFT"/>output_filename()<br ALIGN="LEFT"/>register_table(name, column_names)<br ALIGN="LEFT"/>write_header()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.metrics.api.MetricsConfig" [color="black", fontcolor="black", label=<{MetricsConfig|params : Optional[Dict[str, str]], dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.metrics_context.MetricsContext" [color="black", fontcolor="black", label=<{MetricsContext|<br ALIGN="LEFT"/>|add_to_set(metric: str, value: Any): None<br ALIGN="LEFT"/>in_progress(): bool<br ALIGN="LEFT"/>increment(metric: str, value: int): None<br ALIGN="LEFT"/>set(metric: str, value: Any): None<br ALIGN="LEFT"/>set_key_value(metric: str, key: str, value: Any): None<br ALIGN="LEFT"/>update(values: Dict[str, Any]): None<br ALIGN="LEFT"/>update_outer(values: Dict[str, Any]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.Min" [color="black", fontcolor="black", label=<{Min|identity<br ALIGN="LEFT"/>zero<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.partitioners.MinCutOptions" [color="black", fontcolor="black", label=<{MinCutOptions|ban_if_long_fusible_chains : bool<br ALIGN="LEFT"/>ban_if_materialized_backward : bool<br ALIGN="LEFT"/>ban_if_not_in_allowlist : bool<br ALIGN="LEFT"/>ban_if_reduction : bool<br ALIGN="LEFT"/>ban_if_used_far_apart : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.MinMaxBase" [color="black", fontcolor="black", label=<{MinMaxBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.observer.MinMaxObserver" [color="black", fontcolor="black", label=<{MinMaxObserver|max_val<br ALIGN="LEFT"/>min_val<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x_orig)<br ALIGN="LEFT"/>reset_min_max_vals()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.test_minifier_common.MinifierTestBase" [color="black", fontcolor="black", label=<{MinifierTestBase|DEBUG_DIR : bytes, str<br ALIGN="LEFT"/>|setUpClass()<br ALIGN="LEFT"/>tearDownClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.test_minifier_common.MinifierTestResult" [color="black", fontcolor="black", label=<{MinifierTestResult|minifier_code : str<br ALIGN="LEFT"/>repro_code : str<br ALIGN="LEFT"/>|get_exported_program_path()<br ALIGN="LEFT"/>minifier_module()<br ALIGN="LEFT"/>repro_module()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Mish" [color="black", fontcolor="black", label=<{Mish|inplace : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.exc.MissingOperatorWithDecomp" [color="black", fontcolor="red", label=<{MissingOperatorWithDecomp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.exc.MissingOperatorWithoutDecomp" [color="black", fontcolor="red", label=<{MissingOperatorWithoutDecomp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.artifacts._MixedMMA100.MixedMMA100" [color="black", fontcolor="black", label=<{MixedMMA100|choices : List[Choice]<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>fill_choices(): None<br ALIGN="LEFT"/>get_best_choices(context: AHContext): Optional[List[Tuple[float, int]]]<br ALIGN="LEFT"/>get_choice(idx: int): Optional[str]<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.artifacts._MixedMMH100.MixedMMH100" [color="black", fontcolor="black", label=<{MixedMMH100|choices : List[Choice]<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>fill_choices(): None<br ALIGN="LEFT"/>get_best_choices(context: AHContext): Optional[List[Tuple[float, int]]]<br ALIGN="LEFT"/>get_choice(idx: int): Optional[str]<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.MixedPrecision" [color="black", fontcolor="black", label=<{MixedPrecision|buffer_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>cast_forward_inputs : bool<br ALIGN="LEFT"/>cast_root_forward_inputs : bool<br ALIGN="LEFT"/>keep_low_precision_grads : bool<br ALIGN="LEFT"/>param_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>reduce_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.MixedPrecisionPolicy" [color="black", fontcolor="black", label=<{MixedPrecisionPolicy|cast_forward_inputs : bool<br ALIGN="LEFT"/>output_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>param_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>reduce_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.MixtureOfExperts" [color="black", fontcolor="black", label=<{MixtureOfExperts|delay_before_free_ms : int<br ALIGN="LEFT"/>group<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>move_to_device<br ALIGN="LEFT"/>num_expert_params<br ALIGN="LEFT"/>wrap_fsdp : bool<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool, delay_before_free_ms: int)<br ALIGN="LEFT"/>run_backward(loss)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.mixture_same_family.MixtureSameFamily" [color="black", fontcolor="black", label=<{MixtureSameFamily|arg_constraints : Dict[str, constraints.Constraint]<br ALIGN="LEFT"/>component_distribution<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mixture_distribution<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(x)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(x)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.optimization.MklSubgraph" [color="black", fontcolor="black", label=<{MklSubgraph|end_nodes : List[fx.Node]<br ALIGN="LEFT"/>fx_graph<br ALIGN="LEFT"/>nodes : List[fx.Node]<br ALIGN="LEFT"/>start_nodes : List[fx.Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.optimization.optimize_for_inference.MklSupport" [color="black", fontcolor="black", label=<{MklSupport|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnBatchNorm" [color="black", fontcolor="black", label=<{MkldnnBatchNorm|bias<br ALIGN="LEFT"/>eps<br ALIGN="LEFT"/>exponential_average_factor : float<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnConv1d" [color="black", fontcolor="black", label=<{MkldnnConv1d|bias<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnConv2d" [color="black", fontcolor="black", label=<{MkldnnConv2d|bias<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnConv3d" [color="black", fontcolor="black", label=<{MkldnnConv3d|bias<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnLinear" [color="black", fontcolor="black", label=<{MkldnnLinear|bias<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.mkldnn.MkldnnModule" [color="black", fontcolor="black", label=<{MkldnnModule|deterministic<br ALIGN="LEFT"/>enabled<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn.MkldnnPrelu" [color="black", fontcolor="black", label=<{MkldnnPrelu|training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.MkldnnRnnLayer" [color="black", fontcolor="black", label=<{MkldnnRnnLayer|outputs<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(x: 'TensorBox', w0: 'TensorBox', w1: 'TensorBox', w2: 'TensorBox', w3: 'TensorBox', hx: 'TensorBox', cx: 'TensorBox', reverse: bool, batch_sizes: List[int], mode: int, hidden_size: int, num_layers: int, has_biases: bool, bidirectional: bool, batch_first: bool, train: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mock_cache.MockBackend" [color="black", fontcolor="black", label=<{MockBackend|<br ALIGN="LEFT"/>|with_name(name: str): Callable[[], MockBackend]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.output_code.MockFXGraphCacheOutput" [color="black", fontcolor="black", label=<{MockFXGraphCacheOutput|gm : Optional[Any]<br ALIGN="LEFT"/>|<I>post_compile</I>(example_inputs: Sequence[InputType], cudagraphs: BoxedBool, constants: CompiledFxGraphConstants): None<br ALIGN="LEFT"/><I>set_triton_bundle</I>(triton_bundle: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.MockHandler" [color="black", fontcolor="black", label=<{MockHandler|<br ALIGN="LEFT"/>|frexp(x)<br ALIGN="LEFT"/>indirect_indexing(index_var, size, check, wrap_neg): sympy.Symbol<br ALIGN="LEFT"/>masked(mask, body, other): str<br ALIGN="LEFT"/>scan(dtypes, combine_fn, values)<br ALIGN="LEFT"/>sort(dtypes, values, stable, descending)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_stateless_api_with_ddp.MockModule" [color="black", fontcolor="black", label=<{MockModule|l1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_utils.MockProcessGroup" [color="black", fontcolor="black", label=<{MockProcessGroup|<br ALIGN="LEFT"/>|getBackendName()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.MockSparseLinear" [color="black", fontcolor="black", label=<{MockSparseLinear|<br ALIGN="LEFT"/>|from_dense(mod: nn.Linear): 'MockSparseLinear'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._mock.MockedObject" [color="black", fontcolor="black", label=<{MockedObject|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.Mod" [color="black", fontcolor="black", label=<{Mod|is_integer : bool<br ALIGN="LEFT"/>is_nonnegative : bool<br ALIGN="LEFT"/>nargs : tuple<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(p, q)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo._trace_wrapped_higher_order_op.ModIndex" [color="black", fontcolor="black", label=<{ModIndex|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, gradOut)<br ALIGN="LEFT"/>forward(x: Tensor, indices: List[Tensor]): Tensor<br ALIGN="LEFT"/>setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.ModOrder" [color="black", fontcolor="black", label=<{ModOrder|bw_post_order : List[str]<br ALIGN="LEFT"/>bw_pre_order : List[str]<br ALIGN="LEFT"/>fw_post_order : List[str]<br ALIGN="LEFT"/>fw_pre_order : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.ModRuntime" [color="black", fontcolor="black", label=<{ModRuntime|bw : float<br ALIGN="LEFT"/>fw : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.ModStats" [color="black", fontcolor="black", label=<{ModStats|act_bw_per_module : int<br ALIGN="LEFT"/>act_fw_per_module : int<br ALIGN="LEFT"/>act_grad_per_module : int<br ALIGN="LEFT"/>act_total : int<br ALIGN="LEFT"/>breakpoints : List[float]<br ALIGN="LEFT"/>bw_runtime_per_module : float<br ALIGN="LEFT"/>fqn : str<br ALIGN="LEFT"/>fw_runtime_per_module : float<br ALIGN="LEFT"/>grad_per_module : int<br ALIGN="LEFT"/>grad_total : int<br ALIGN="LEFT"/>input_per_module : int<br ALIGN="LEFT"/>intercepts : List[float]<br ALIGN="LEFT"/>is_leaf : bool<br ALIGN="LEFT"/>n_segments : int<br ALIGN="LEFT"/>output_per_module : int<br ALIGN="LEFT"/>param_per_module : int<br ALIGN="LEFT"/>sac_memory : int<br ALIGN="LEFT"/>sac_runtime : float<br ALIGN="LEFT"/>slopes : List[float]<br ALIGN="LEFT"/>tradeoff_curve : OrderedDict[float, float]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.mod_tracker.ModTracker" [color="black", fontcolor="black", label=<{ModTracker|is_bw<br ALIGN="LEFT"/>parents : Set[str]<br ALIGN="LEFT"/>|clear_user_hooks()<br ALIGN="LEFT"/>get_known_fqn(mod)<br ALIGN="LEFT"/>register_user_hooks(pre_fw_hook: Optional[Callable], post_fw_hook: Optional[Callable], pre_bw_hook: Optional[Callable], post_bw_hook: Optional[Callable])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.kernel.flex_attention.Mode" [color="black", fontcolor="black", label=<{Mode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_create_graph.Model" [color="black", fontcolor="black", label=<{Model|p<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.ModelArgs" [color="black", fontcolor="black", label=<{ModelArgs|checkpoint_activations : bool<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>dropout_p : float<br ALIGN="LEFT"/>max_seq_len : int<br ALIGN="LEFT"/>n_heads : int<br ALIGN="LEFT"/>n_layers : int<br ALIGN="LEFT"/>use_attn_mask : bool<br ALIGN="LEFT"/>vocab_size : int<br ALIGN="LEFT"/>weight_tying : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.model_attr_mutation.ModelAttrMutation" [color="black", fontcolor="black", label=<{ModelAttrMutation|attr_list : list<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>recreate_list()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.model_averaging.averagers.ModelAverager" [color="black", fontcolor="black", label=<{ModelAverager|process_group : NoneType<br ALIGN="LEFT"/>step : int<br ALIGN="LEFT"/>|<I>average_parameters</I>(params)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [color="black", fontcolor="black", label=<{ModelForConvTransposeBNFusion|bn1<br ALIGN="LEFT"/>bn2<br ALIGN="LEFT"/>bn3<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>conv3<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelForFusion" [color="black", fontcolor="black", label=<{ModelForFusion|bn1<br ALIGN="LEFT"/>bn2<br ALIGN="LEFT"/>bn3<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>conv3<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>relu2<br ALIGN="LEFT"/>relu3<br ALIGN="LEFT"/>relu4<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelForFusionWithBias" [color="black", fontcolor="black", label=<{ModelForFusionWithBias|bn1<br ALIGN="LEFT"/>bn2<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelForLinearBNFusion" [color="black", fontcolor="black", label=<{ModelForLinearBNFusion|bn<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._analysis.ModelInfo" [color="black", fontcolor="black", label=<{ModelInfo|buffer_count : defaultdict[torch.dtype, int]<br ALIGN="LEFT"/>dispatch_failures : list[tuple[torch.fx.Node, str]]<br ALIGN="LEFT"/>fx_node_count : int<br ALIGN="LEFT"/>fx_node_op_count : defaultdict[str, int]<br ALIGN="LEFT"/>fx_node_target_count : defaultdict[str, int]<br ALIGN="LEFT"/>inputs : dict[str, torch._export.serde.schema.TensorMeta]<br ALIGN="LEFT"/>outputs : dict[str, torch._export.serde.schema.TensorMeta]<br ALIGN="LEFT"/>parameter_count : defaultdict[torch.dtype, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelMultipleOps" [color="black", fontcolor="black", label=<{ModelMultipleOps|avgpool<br ALIGN="LEFT"/>bn1<br ALIGN="LEFT"/>cat<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>downsample<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>relu2<br ALIGN="LEFT"/>skip_add<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [color="black", fontcolor="black", label=<{ModelMultipleOpsNoAvgPool|bn1<br ALIGN="LEFT"/>cat<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>maxpool<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>relu2<br ALIGN="LEFT"/>skip_add<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.model_report.ModelReport" [color="black", fontcolor="black", label=<{ModelReport|<br ALIGN="LEFT"/>|generate_equalization_mapping(): QConfigMapping<br ALIGN="LEFT"/>generate_model_report(remove_inserted_observers: bool): Dict[str, Tuple[str, Dict]]<br ALIGN="LEFT"/>generate_qconfig_mapping(): QConfigMapping<br ALIGN="LEFT"/>generate_visualizer(): ModelReportVisualizer<br ALIGN="LEFT"/>get_desired_reports_names(): Set[str]<br ALIGN="LEFT"/>get_observers_of_interest(): Dict[str, Set[str]]<br ALIGN="LEFT"/>prepare_detailed_calibration(): GraphModule<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.model_report_observer.ModelReportObserver" [color="black", fontcolor="black", label=<{ModelReportObserver|average_batch_activation_range<br ALIGN="LEFT"/>average_percentile_ratio<br ALIGN="LEFT"/>ch_axis : int<br ALIGN="LEFT"/>comp_percentile<br ALIGN="LEFT"/>constant_channels<br ALIGN="LEFT"/>epoch_activation_max<br ALIGN="LEFT"/>epoch_activation_min<br ALIGN="LEFT"/>max_val<br ALIGN="LEFT"/>min_val<br ALIGN="LEFT"/>num_batches_tracked : int<br ALIGN="LEFT"/>percentile_batches_tracked<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>get_batch_to_epoch_ratio()<br ALIGN="LEFT"/>reset_batch_and_epoch_values()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.model_report_visualizer.ModelReportVisualizer" [color="black", fontcolor="black", label=<{ModelReportVisualizer|CHANNEL_NUM_INDEX : int<br ALIGN="LEFT"/>NUM_NON_FEATURE_CHANNEL_HEADERS : int<br ALIGN="LEFT"/>NUM_NON_FEATURE_TENSOR_HEADERS : int<br ALIGN="LEFT"/>TABLE_CHANNEL_KEY : str<br ALIGN="LEFT"/>TABLE_TENSOR_KEY : str<br ALIGN="LEFT"/>generated_reports : OrderedDict[str, Any]<br ALIGN="LEFT"/>|generate_filtered_tables(feature_filter: str, module_fqn_filter: str): Dict[str, Tuple[List, List]]<br ALIGN="LEFT"/>generate_histogram_visualization(feature_filter: str, module_fqn_filter: str, num_bins: int)<br ALIGN="LEFT"/>generate_plot_visualization(feature_filter: str, module_fqn_filter: str)<br ALIGN="LEFT"/>generate_table_visualization(feature_filter: str, module_fqn_filter: str)<br ALIGN="LEFT"/>get_all_unique_feature_names(plottable_features_only: bool): Set[str]<br ALIGN="LEFT"/>get_all_unique_module_fqns(): Set[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs_stop_iteration_sync_bn.ModelWithComm" [color="black", fontcolor="black", label=<{ModelWithComm|lin<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelWithFunctionals" [color="black", fontcolor="black", label=<{ModelWithFunctionals|myadd<br ALIGN="LEFT"/>myadd_relu<br ALIGN="LEFT"/>mycat<br ALIGN="LEFT"/>mymatmul<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ModelWithSequentialFusion" [color="black", fontcolor="black", label=<{ModelWithSequentialFusion|classifier<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>dequant<br ALIGN="LEFT"/>features<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.ModificationWrapper" [color="black", fontcolor="black", label=<{ModificationWrapper|fixed_inputs : Dict[str, Any]<br ALIGN="LEFT"/>kernel<br ALIGN="LEFT"/>mask : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|indirect_indexing(index_var: str, size, check, wrap_neg)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: CSEVariable, mode: StoreMode): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.ModularIndexing" [color="black", fontcolor="black", label=<{ModularIndexing|is_integer : bool<br ALIGN="LEFT"/>nargs : Tuple[int, ...]<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base: sympy.Integer, divisor: sympy.Integer, modulus: sympy.Integer): Optional[sympy.Basic]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization.Modularize" [color="black", fontcolor="black", label=<{Modularize|is_exported_program : bool<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.annotations.Module" [color="black", fontcolor="black", label=<{Module|members<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.module.Module" [color="black", fontcolor="black", label=<{Module|T_destination : T_destination<br ALIGN="LEFT"/>call_super_init : bool<br ALIGN="LEFT"/>dump_patches : bool<br ALIGN="LEFT"/>forward : Callable[..., Any]<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>|add_module(name: str, module: Optional['Module']): None<br ALIGN="LEFT"/>apply(fn: Callable[['Module'], None]): T<br ALIGN="LEFT"/>bfloat16(): T<br ALIGN="LEFT"/>buffers(recurse: bool): Iterator[Tensor]<br ALIGN="LEFT"/>children(): Iterator['Module']<br ALIGN="LEFT"/>compile()<br ALIGN="LEFT"/>cpu(): T<br ALIGN="LEFT"/>cuda(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>double(): T<br ALIGN="LEFT"/>eval(): T<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>float(): T<br ALIGN="LEFT"/>get_buffer(target: str): 'Tensor'<br ALIGN="LEFT"/>get_extra_state(): Any<br ALIGN="LEFT"/>get_parameter(target: str): 'Parameter'<br ALIGN="LEFT"/>get_submodule(target: str): 'Module'<br ALIGN="LEFT"/>half(): T<br ALIGN="LEFT"/>ipu(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>load_state_dict(state_dict: Mapping[str, Any], strict: bool, assign: bool)<br ALIGN="LEFT"/>modules(): Iterator['Module']<br ALIGN="LEFT"/>mtia(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>named_buffers(prefix: str, recurse: bool, remove_duplicate: bool): Iterator[Tuple[str, Tensor]]<br ALIGN="LEFT"/>named_children(): Iterator[Tuple[str, 'Module']]<br ALIGN="LEFT"/>named_modules(memo: Optional[Set['Module']], prefix: str, remove_duplicate: bool)<br ALIGN="LEFT"/>named_parameters(prefix: str, recurse: bool, remove_duplicate: bool): Iterator[Tuple[str, Parameter]]<br ALIGN="LEFT"/>parameters(recurse: bool): Iterator[Parameter]<br ALIGN="LEFT"/>register_backward_hook(hook: Callable[['Module', _grad_t, _grad_t], Union[None, _grad_t]]): RemovableHandle<br ALIGN="LEFT"/>register_buffer(name: str, tensor: Optional[Tensor], persistent: bool): None<br ALIGN="LEFT"/>register_forward_hook(hook: Union[Callable[[T, Tuple[Any, ...], Any], Optional[Any]], Callable[[T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]]): RemovableHandle<br ALIGN="LEFT"/>register_forward_pre_hook(hook: Union[Callable[[T, Tuple[Any, ...]], Optional[Any]], Callable[[T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]]): RemovableHandle<br ALIGN="LEFT"/>register_full_backward_hook(hook: Callable[['Module', _grad_t, _grad_t], Union[None, _grad_t]], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_full_backward_pre_hook(hook: Callable[['Module', _grad_t], Union[None, _grad_t]], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_load_state_dict_post_hook(hook)<br ALIGN="LEFT"/>register_load_state_dict_pre_hook(hook)<br ALIGN="LEFT"/>register_module(name: str, module: Optional['Module']): None<br ALIGN="LEFT"/>register_parameter(name: str, param: Optional[Parameter]): None<br ALIGN="LEFT"/>register_state_dict_post_hook(hook)<br ALIGN="LEFT"/>register_state_dict_pre_hook(hook)<br ALIGN="LEFT"/>requires_grad_(requires_grad: bool): T<br ALIGN="LEFT"/>set_extra_state(state: Any): None<br ALIGN="LEFT"/>set_submodule(target: str, module: 'Module'): None<br ALIGN="LEFT"/>share_memory(): T<br ALIGN="LEFT"/>state_dict(): T_destination<br ALIGN="LEFT"/>to(device: Optional[DeviceLikeType], dtype: Optional[dtype], non_blocking: bool): Self<br ALIGN="LEFT"/>to_empty(): T<br ALIGN="LEFT"/>train(mode: bool): T<br ALIGN="LEFT"/>type(dst_type: Union[dtype, str]): T<br ALIGN="LEFT"/>xpu(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>zero_grad(set_to_none: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.ModuleCallEntry" [color="black", fontcolor="black", label=<{ModuleCallEntry|fqn : Annotated[str, 10]<br ALIGN="LEFT"/>signature : Optional[Annotated[Optional[ModuleCallSignature], 30]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.exported_program.ModuleCallEntry" [color="black", fontcolor="black", label=<{ModuleCallEntry|fqn : str<br ALIGN="LEFT"/>signature : Optional[ModuleCallSignature]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.ModuleCallSignature" [color="black", fontcolor="black", label=<{ModuleCallSignature|forward_arg_names : Optional[Annotated[Optional[List[str]], 50]]<br ALIGN="LEFT"/>in_spec : Annotated[str, 30]<br ALIGN="LEFT"/>inputs : Annotated[List[Argument], 10]<br ALIGN="LEFT"/>out_spec : Annotated[str, 40]<br ALIGN="LEFT"/>outputs : Annotated[List[Argument], 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.exported_program.ModuleCallSignature" [color="black", fontcolor="black", label=<{ModuleCallSignature|forward_arg_names : Optional[List[str]]<br ALIGN="LEFT"/>in_spec<br ALIGN="LEFT"/>inputs : List[ArgumentSpec]<br ALIGN="LEFT"/>out_spec<br ALIGN="LEFT"/>outputs : List[ArgumentSpec]<br ALIGN="LEFT"/>|replace_all_uses_with(original_node, new_node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.ModuleContext" [color="black", fontcolor="black", label=<{ModuleContext|nn_modules : Dict[str, Any]<br ALIGN="LEFT"/>|copy_graphstate()<br ALIGN="LEFT"/>restore_graphstate(state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.ModuleContextCheckpointState" [color="black", fontcolor="black", label=<{ModuleContextCheckpointState|nn_modules : Dict[str, torch.nn.Module]<br ALIGN="LEFT"/>|diff(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.ModuleCreationMode" [color="black", fontcolor="black", label=<{ModuleCreationMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.container.ModuleDict" [color="black", fontcolor="black", label=<{ModuleDict|bias<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>items(): Iterable[Tuple[str, Module]]<br ALIGN="LEFT"/>keys(): Iterable[str]<br ALIGN="LEFT"/>pop(key: str): Module<br ALIGN="LEFT"/>update(modules: Mapping[str, Module]): None<br ALIGN="LEFT"/>values(): Iterable[Module]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.ModuleErrorEnum" [color="black", fontcolor="black", label=<{ModuleErrorEnum|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.fx_symbolic_graph_extractor.ModuleExpansionTracer" [color="black", fontcolor="black", label=<{ModuleExpansionTracer|<br ALIGN="LEFT"/>|is_leaf_module(module: torch.nn.Module, module_qualified_name: str): bool<br ALIGN="LEFT"/>to_bool(obj: torch.fx.Proxy): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.ModuleInfo" [color="black", fontcolor="black", label=<{ModuleInfo|mod_order<br ALIGN="LEFT"/>mod_stats : List[ModStats]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.ModuleInfo" [color="black", fontcolor="black", label=<{ModuleInfo|decorators : tuple<br ALIGN="LEFT"/>dtypes<br ALIGN="LEFT"/>dtypesIfHpu : tuple<br ALIGN="LEFT"/>dtypesIfMPS : tuple<br ALIGN="LEFT"/>formatted_name<br ALIGN="LEFT"/>gradcheck_nondet_tol : float<br ALIGN="LEFT"/>is_lazy<br ALIGN="LEFT"/>module_cls<br ALIGN="LEFT"/>module_error_inputs_func : NoneType<br ALIGN="LEFT"/>module_inputs_func<br ALIGN="LEFT"/>module_memformat_affects_out : bool<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>supports_gradgrad : bool<br ALIGN="LEFT"/>train_and_eval_differ : bool<br ALIGN="LEFT"/>|get_decorators(test_class, test_name, device, dtype, param_kwargs)<br ALIGN="LEFT"/>supported_dtypes(device_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.ModuleInput" [color="black", fontcolor="black", label=<{ModuleInput|constructor_input<br ALIGN="LEFT"/>desc : str<br ALIGN="LEFT"/>forward_input : NoneType<br ALIGN="LEFT"/>reference_fn : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.container.ModuleList" [color="black", fontcolor="black", label=<{ModuleList|<br ALIGN="LEFT"/>|append(module: Module): 'ModuleList'<br ALIGN="LEFT"/>extend(modules: Iterable[Module]): Self<br ALIGN="LEFT"/>insert(index: int, module: Module): None<br ALIGN="LEFT"/>pop(key: Union[int, slice]): Module<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.replay_record.ModuleRecord" [color="black", fontcolor="black", label=<{ModuleRecord|accessed_attrs : Dict[str, Any]<br ALIGN="LEFT"/>module : module<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.ModuleTest" [color="black", fontcolor="black", label=<{ModuleTest|FIXME_no_cuda_gradgrad_comparison<br ALIGN="LEFT"/>check_forward_only<br ALIGN="LEFT"/>check_gradgrad<br ALIGN="LEFT"/>default_dtype<br ALIGN="LEFT"/>jacobian_input<br ALIGN="LEFT"/>precision<br ALIGN="LEFT"/>should_test_cuda<br ALIGN="LEFT"/>should_test_pickle<br ALIGN="LEFT"/>|noncontiguize(obj)<br ALIGN="LEFT"/>test_cuda(test_case)<br ALIGN="LEFT"/>test_noncontig(test_case, module, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.module_tracker.ModuleTracker" [color="black", fontcolor="black", label=<{ModuleTracker|is_bw<br ALIGN="LEFT"/>parents : Set[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.ModuleWithDelay" [color="black", fontcolor="black", label=<{ModuleWithDelay|delay_after_loss_ms : int<br ALIGN="LEFT"/>delay_before_reduction_ms : int<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_input(device)<br ALIGN="LEFT"/>get_loss(input, output)<br ALIGN="LEFT"/>init(module_class: Type[FSDPTestModel])<br ALIGN="LEFT"/>run_backward(loss)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.wrap.ModuleWrapPolicy" [color="black", fontcolor="black", label=<{ModuleWrapPolicy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.cpp.ModuleWrapper" [color="black", fontcolor="black", label=<{ModuleWrapper|cpp_module<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.virtualization.MovePlaceholderToFront" [color="black", fontcolor="black", label=<{MovePlaceholderToFront|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.observer.MovingAverageMinMaxObserver" [color="black", fontcolor="black", label=<{MovingAverageMinMaxObserver|averaging_constant : float<br ALIGN="LEFT"/>|forward(x_orig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver" [color="black", fontcolor="black", label=<{MovingAveragePerChannelMinMaxObserver|averaging_constant : float<br ALIGN="LEFT"/>|forward(x_orig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.MulGenVmap" [color="black", fontcolor="black", label=<{MulGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, y)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, y_tangent)<br ALIGN="LEFT"/>setup_context(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.MulInplaceMul" [color="black", fontcolor="black", label=<{MulInplaceMul|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.multi_kernel.MultiKernel" [color="black", fontcolor="black", label=<{MultiKernel|args : object<br ALIGN="LEFT"/>inplace_update_buffers<br ALIGN="LEFT"/>inplaced_to_remove<br ALIGN="LEFT"/>kernel_name<br ALIGN="LEFT"/>kernels<br ALIGN="LEFT"/>removed_buffers<br ALIGN="LEFT"/>|call_kernel(kernel_name)<br ALIGN="LEFT"/>codegen_nan_check()<br ALIGN="LEFT"/>get_grid_fn()<br ALIGN="LEFT"/>merge_workspaces_inplace(kernels)<br ALIGN="LEFT"/><I>warn_mix_layout</I>(kernel_name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.multi_kernel.MultiKernelCall" [color="black", fontcolor="black", label=<{MultiKernelCall|disable_cache<br ALIGN="LEFT"/>kernels<br ALIGN="LEFT"/>multi_kernel_name<br ALIGN="LEFT"/>picked_kernel : NoneType, int<br ALIGN="LEFT"/>run<br ALIGN="LEFT"/>|benchmark_sub_kernels()<br ALIGN="LEFT"/>cache_file_path()<br ALIGN="LEFT"/>load_cache()<br ALIGN="LEFT"/>lookup_choice(multi_kernel_name: str): str<br ALIGN="LEFT"/>record_choice(multi_kernel_name: str, picked_kernel_name: str)<br ALIGN="LEFT"/>run()<br ALIGN="LEFT"/>store_cache()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.multi_kernel.MultiKernelState" [color="black", fontcolor="black", label=<{MultiKernelState|subkernel_to_kernel_name : dict<br ALIGN="LEFT"/>|define_kernel(kernels)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.MultiLabelMarginLoss" [color="black", fontcolor="black", label=<{MultiLabelMarginLoss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.MultiLabelSoftMarginLoss" [color="black", fontcolor="black", label=<{MultiLabelSoftMarginLoss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.MultiMarginLoss" [color="black", fontcolor="black", label=<{MultiMarginLoss|margin : float<br ALIGN="LEFT"/>p : int<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MultiOutput" [color="black", fontcolor="black", label=<{MultiOutput|indices : List[Tuple[Any, ...]]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>codegen_list_tuple_access(basename, indices)<br ALIGN="LEFT"/>get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MultiOutputLayout" [color="black", fontcolor="black", label=<{MultiOutputLayout|device<br ALIGN="LEFT"/>|get_device(): Optional[torch.device]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.MultiOutputPattern" [color="black", fontcolor="black", label=<{MultiOutputPattern|fns<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>outputs : List[Optional[PatternExpr]]<br ALIGN="LEFT"/>|match(node: torch.fx.Node): MatchResult<br ALIGN="LEFT"/>pattern_eq(other: Any): bool<br ALIGN="LEFT"/>pretty_print(pp: PatternPrettyPrinter): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.MultiProcContinousTest" [color="black", fontcolor="black", label=<{MultiProcContinousTest|rank : int<br ALIGN="LEFT"/>rdvz_file : Optional[str]<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|<I>backend_str</I>(): str<br ALIGN="LEFT"/>opts(high_priority_stream)<br ALIGN="LEFT"/>run_rank(rank: int, world_size: int, rdvz_file: Optional[str])<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>tearDownClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.MultiProcessTestCase" [color="black", fontcolor="black", label=<{MultiProcessTestCase|MAIN_PROCESS_RANK : int<br ALIGN="LEFT"/>TEST_ERROR_EXIT_CODE : int<br ALIGN="LEFT"/>destroy_pg_upon_exit<br ALIGN="LEFT"/>file_name : str<br ALIGN="LEFT"/>is_master<br ALIGN="LEFT"/>pid_to_pipe : dict<br ALIGN="LEFT"/>processes : list<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>skip_return_code_checks : list<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|join_or_run(fn)<br ALIGN="LEFT"/>run_test(test_name: str, parent_pipe): None<br ALIGN="LEFT"/>setUp(): None<br ALIGN="LEFT"/>tearDown(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.MultiStepLR" [color="black", fontcolor="black", label=<{MultiStepLR|gamma : float<br ALIGN="LEFT"/>milestones : Counter<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MultiTemplateBuffer" [color="black", fontcolor="black", label=<{MultiTemplateBuffer|choice_timings<br ALIGN="LEFT"/>make_kernel_render<br ALIGN="LEFT"/>original_inputs : List[IRNode]<br ALIGN="LEFT"/>output_plannable<br ALIGN="LEFT"/>|finalize_as_triton_caller(caller: TritonTemplateCallerBase): None<br ALIGN="LEFT"/>get_min_choice(): Tuple[ChoiceCaller, float]<br ALIGN="LEFT"/>swap_as_triton_caller(caller: TritonTemplateCallerBase)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.MultiThreadedTestCase" [color="black", fontcolor="black", label=<{MultiThreadedTestCase|MAIN_THREAD_RANK : int<br ALIGN="LEFT"/>exception_queue : Queue<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>threads : list<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|assertEqualOnRank(x, y, msg)<br ALIGN="LEFT"/>assertNotEqualOnRank(x, y, msg)<br ALIGN="LEFT"/>join_or_run(fn)<br ALIGN="LEFT"/><I>perThreadSetUp</I>()<br ALIGN="LEFT"/><I>perThreadTearDown</I>()<br ALIGN="LEFT"/>run_test_with_threaded_pg(test_name, rank, world_size)<br ALIGN="LEFT"/>setUp(): None<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.MultiUseParameterConfig" [color="black", fontcolor="black", label=<{MultiUseParameterConfig|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._multiformat_message_string.MultiformatMessageString" [color="black", fontcolor="black", label=<{MultiformatMessageString|markdown : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>text : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.MultiheadAttention" [color="black", fontcolor="black", label=<{MultiheadAttention|<br ALIGN="LEFT"/>|<I>from_float</I>(other)<br ALIGN="LEFT"/>from_observed(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [color="black", fontcolor="black", label=<{MultiheadAttention|bias_k<br ALIGN="LEFT"/>bias_v<br ALIGN="LEFT"/>dequant_k<br ALIGN="LEFT"/>dequant_q<br ALIGN="LEFT"/>dequant_v<br ALIGN="LEFT"/>linear_K<br ALIGN="LEFT"/>linear_Q<br ALIGN="LEFT"/>linear_V<br ALIGN="LEFT"/>out_proj<br ALIGN="LEFT"/>q_scaling_product<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant_attn_output<br ALIGN="LEFT"/>quant_attn_output_weights<br ALIGN="LEFT"/>|dequantize()<br ALIGN="LEFT"/>forward(query: Tensor, key: Tensor, value: Tensor, key_padding_mask: Optional[Tensor], need_weights: bool, attn_mask: Optional[Tensor], average_attn_weights: bool, is_causal: bool): Tuple[Tensor, Optional[Tensor]]<br ALIGN="LEFT"/>from_float(other)<br ALIGN="LEFT"/><I>from_observed</I>(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.MultiheadAttention" [color="black", fontcolor="black", label=<{MultiheadAttention|add_zero_attn : bool<br ALIGN="LEFT"/>batch_first : bool<br ALIGN="LEFT"/>bias_k : Optional[torch.Tensor]<br ALIGN="LEFT"/>bias_v : Optional[torch.Tensor]<br ALIGN="LEFT"/>dropout : float<br ALIGN="LEFT"/>embed_dim<br ALIGN="LEFT"/>head_dim<br ALIGN="LEFT"/>in_proj_bias<br ALIGN="LEFT"/>in_proj_weight<br ALIGN="LEFT"/>k_proj_weight<br ALIGN="LEFT"/>kdim : NoneType<br ALIGN="LEFT"/>num_heads<br ALIGN="LEFT"/>out_proj<br ALIGN="LEFT"/>q_proj_weight<br ALIGN="LEFT"/>v_proj_weight<br ALIGN="LEFT"/>vdim : NoneType<br ALIGN="LEFT"/>|forward(query: Tensor, key: Tensor, value: Tensor, key_padding_mask: Optional[Tensor], need_weights: bool, attn_mask: Optional[Tensor], average_attn_weights: bool, is_causal: bool): Tuple[Tensor, Optional[Tensor]]<br ALIGN="LEFT"/>merge_masks(attn_mask: Optional[Tensor], key_padding_mask: Optional[Tensor], query: Tensor): Tuple[Optional[Tensor], Optional[int]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.multinomial.Multinomial" [color="black", fontcolor="black", label=<{Multinomial|arg_constraints : dict<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>total_count : int<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.Multiple" [color="black", fontcolor="black", label=<{Multiple|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining.MultiplexerIterDataPipe" [color="black", fontcolor="black", label=<{MultiplexerIterDataPipe|buffer : List, list<br ALIGN="LEFT"/>datapipes : tuple<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.MultiplicativeLR" [color="black", fontcolor="black", label=<{MultiplicativeLR|lr_lambdas : List[Callable[[int], float]], list<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.MultiprocessContext" [color="black", fontcolor="black", label=<{MultiprocessContext|start_method : str<br ALIGN="LEFT"/>|pids(): Dict[int, int]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.local_timer.MultiprocessingRequestQueue" [color="black", fontcolor="black", label=<{MultiprocessingRequestQueue|<br ALIGN="LEFT"/>|get(size, timeout: float): List[TimerRequest]<br ALIGN="LEFT"/>size(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.multivariate_normal.MultivariateNormal" [color="black", fontcolor="black", label=<{MultivariateNormal|arg_constraints : dict<br ALIGN="LEFT"/>covariance_matrix<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>precision_matrix<br ALIGN="LEFT"/>scale_tril<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|covariance_matrix()<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>precision_matrix()<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>scale_tril()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MutableBox" [color="black", fontcolor="black", label=<{MutableBox|data<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/>constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>freeze_layout(): None<br ALIGN="LEFT"/>freeze_layout_with_exact_strides(exact_strides: List[_IntLike], allow_padding: bool): None<br ALIGN="LEFT"/>freeze_layout_with_fill_order(order: List[int]): None<br ALIGN="LEFT"/>freeze_layout_with_same_order(stride: List[_IntLike]): None<br ALIGN="LEFT"/>freeze_layout_with_stride_order(order: List[int], allow_padding: bool): None<br ALIGN="LEFT"/>get_defining_op(): Optional[Operation]<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>get_layout(): Layout<br ALIGN="LEFT"/>get_mutation_names(): Sequence[str]<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>get_operation_name(): str<br ALIGN="LEFT"/>get_output_spec(): OutputSpec<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/>get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_storage_numel(): _IntLike<br ALIGN="LEFT"/>get_stride(): Sequence[_IntLike]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>has_exceeded_max_reads(): bool<br ALIGN="LEFT"/>has_large_inner_fn(threshold: Optional[int]): bool<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>is_no_op(): bool<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>mark_reuse(users: int): None<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/>realize(): Optional[str]<br ALIGN="LEFT"/>realize_hint(): None<br ALIGN="LEFT"/>unwrap_view(): IRNode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.MutableMappingVariable" [color="black", fontcolor="black", label=<{MutableMappingVariable|generic_dict_vt<br ALIGN="LEFT"/>mutation_type<br ALIGN="LEFT"/>|var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MutatingFirstArgExternKernel" [color="black", fontcolor="black", label=<{MutatingFirstArgExternKernel|<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.utils.MutationChecker" [color="black", fontcolor="black", label=<{MutationChecker|args_spec<br ALIGN="LEFT"/>flat_args<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>real_pre_hashes<br ALIGN="LEFT"/>|check()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MutationLayoutSHOULDREMOVE" [color="black", fontcolor="black", label=<{MutationLayoutSHOULDREMOVE|stride<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|as_fixed()<br ALIGN="LEFT"/>get_buffer(): Buffer<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>real_layout()<br ALIGN="LEFT"/>realize_into(src, dst, unsafe_alias)<br ALIGN="LEFT"/>storage_size(): sympy.Expr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.MutationOutput" [color="black", fontcolor="black", label=<{MutationOutput|mutating_node<br ALIGN="LEFT"/>mutation_names : list<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|get_defining_op(): Operation<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.mutation_guard.MutationTracker" [color="black", fontcolor="black", label=<{MutationTracker|db<br ALIGN="LEFT"/>mutation_count : int<br ALIGN="LEFT"/>watchers : List[weakref.ReferenceType[Any]], list<br ALIGN="LEFT"/>|on_mutation(name: str): None<br ALIGN="LEFT"/>track(guarded_code: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.base.MutationType" [color="black", fontcolor="black", label=<{MutationType|scope : bool, int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.MutationType" [color="black", fontcolor="black", label=<{MutationType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.autograd_function.MyAutogradFunction" [color="black", fontcolor="black", label=<{MyAutogradFunction|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.MyBackwardFunc" [color="black", fontcolor="black", label=<{MyBackwardFunc|<br ALIGN="LEFT"/>|backward(ctx, input)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyClass" [color="black", fontcolor="black", label=<{MyClass|obj<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyClass" [color="black", fontcolor="black", label=<{MyClass|a<br ALIGN="LEFT"/>other<br ALIGN="LEFT"/>rref<br ALIGN="LEFT"/>|get_value()<br ALIGN="LEFT"/>increment_value(increment)<br ALIGN="LEFT"/>my_class_method(d, e)<br ALIGN="LEFT"/>my_instance_method(b)<br ALIGN="LEFT"/>my_slow_method(my_tensor_arg)<br ALIGN="LEFT"/>my_static_method(f)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyConvNetForMNIST" [color="black", fontcolor="black", label=<{MyConvNetForMNIST|device<br ALIGN="LEFT"/>net<br ALIGN="LEFT"/>|forward(x, is_rref)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyEmbeddingBagModel" [color="black", fontcolor="black", label=<{MyEmbeddingBagModel|eb<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.MyFunc" [color="black", fontcolor="black", label=<{MyFunc|static_grad_ptr : NoneType<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp1, inp2)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy_sparse.MyFunc" [color="black", fontcolor="black", label=<{MyFunc|static_grad_ptr : NoneType<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_grad_copy_sparse_indices_extra_ref.MyFunc" [color="black", fontcolor="black", label=<{MyFunc|static_grad_indices_ref : NoneType<br ALIGN="LEFT"/>static_grad_ptr : NoneType<br ALIGN="LEFT"/>static_grad_values_ref : NoneType<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.MyFuncSingleGrad" [color="black", fontcolor="black", label=<{MyFuncSingleGrad|static_grad_ptr : NoneType<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest.MyLocalCompute" [color="black", fontcolor="black", label=<{MyLocalCompute|next_stage<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_native_mixed_precision.MyModel" [color="black", fontcolor="black", label=<{MyModel|m<br ALIGN="LEFT"/>p<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.MyModel" [color="black", fontcolor="black", label=<{MyModel|sub_module<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_returns_tensor_with_no_grad.MyModel" [color="black", fontcolor="black", label=<{MyModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_new_tensor_in_fwd.MyModel" [color="black", fontcolor="black", label=<{MyModel|device<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>|forward(x, opt_1, opt_2, opt_nested)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_remove_autograd_hooks.MyModel" [color="black", fontcolor="black", label=<{MyModel|error : bool<br ALIGN="LEFT"/>fc1<br ALIGN="LEFT"/>|forward(inp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyModel" [color="black", fontcolor="black", label=<{MyModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|forward(inp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sink_noclone.MyModel" [color="black", fontcolor="black", label=<{MyModel|fc<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_pg_init_no_rpc_init.MyModel" [color="black", fontcolor="black", label=<{MyModel|lin<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.MyModule" [color="black", fontcolor="black", label=<{MyModule|lock : lock<br ALIGN="LEFT"/>w<br ALIGN="LEFT"/>|forward(t1)<br ALIGN="LEFT"/>get_w()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.MyModule" [color="black", fontcolor="black", label=<{MyModule|param1<br ALIGN="LEFT"/>|forward(tensor: Tensor, number: int, word: str): Tuple[str, int, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyModuleInterface" [color="black", fontcolor="black", label=<{MyModuleInterface|<br ALIGN="LEFT"/>|<I>forward</I>(): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.MyModuleInterface" [color="black", fontcolor="black", label=<{MyModuleInterface|<br ALIGN="LEFT"/>|<I>forward</I>(tensor: Tensor, number: int, word: str): Tuple[str, int, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyParameterServer" [color="black", fontcolor="black", label=<{MyParameterServer|futures : list<br ALIGN="LEFT"/>gradient : NoneType<br ALIGN="LEFT"/>iteration : int<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>total : NoneType<br ALIGN="LEFT"/>trainers<br ALIGN="LEFT"/>updates : int<br ALIGN="LEFT"/>|average(rref, riteration, tensor)<br ALIGN="LEFT"/>get_gradient(rref)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass" [color="black", fontcolor="black", label=<{MyPickleClass|t : NoneType<br ALIGN="LEFT"/>|set(val)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest.MyRemoteCompute" [color="black", fontcolor="black", label=<{MyRemoteCompute|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptClass" [color="black", fontcolor="black", label=<{MyScriptClass|a : int<br ALIGN="LEFT"/>|get_value(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModule" [color="black", fontcolor="black", label=<{MyScriptModule|a<br ALIGN="LEFT"/>|custom_func(): Tensor<br ALIGN="LEFT"/>forward(): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModuleWithRRefs" [color="black", fontcolor="black", label=<{MyScriptModuleWithRRefs|rrefs : list<br ALIGN="LEFT"/>|forward(): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel1" [color="black", fontcolor="black", label=<{MyShardedModel1|random_tensor1<br ALIGN="LEFT"/>sharded_tensor1 : NoneType<br ALIGN="LEFT"/>submodule<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel2" [color="black", fontcolor="black", label=<{MyShardedModel2|random_tensor2<br ALIGN="LEFT"/>sharded_tensor2 : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.cond_branch_class_method.MySubModule" [color="black", fontcolor="black", label=<{MySubModule|<br ALIGN="LEFT"/>|foo(x)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.nadam.NAdam" [color="black", fontcolor="black", label=<{NAdam|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.comm_analysis.NCCL_ALGO" [color="black", fontcolor="black", label=<{NCCL_ALGO|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.comm_analysis.NCCL_COLL" [color="black", fontcolor="black", label=<{NCCL_COLL|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.comm_analysis.NCCL_HW" [color="black", fontcolor="black", label=<{NCCL_HW|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.comm_analysis.NCCL_PROTO" [color="black", fontcolor="black", label=<{NCCL_PROTO|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.loss.NLLLoss" [color="black", fontcolor="black", label=<{NLLLoss|ignore_index : int<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.NLLLoss2d" [color="black", fontcolor="black", label=<{NLLLoss2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.NNAPI_FuseCode" [color="black", fontcolor="black", label=<{NNAPI_FuseCode|FUSED_NONE : int<br ALIGN="LEFT"/>FUSED_RELU : int<br ALIGN="LEFT"/>FUSED_RELU1 : int<br ALIGN="LEFT"/>FUSED_RELU6 : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.NNAPI_OperandCode" [color="black", fontcolor="black", label=<{NNAPI_OperandCode|BOOL : int<br ALIGN="LEFT"/>FLOAT16 : int<br ALIGN="LEFT"/>FLOAT32 : int<br ALIGN="LEFT"/>INT32 : int<br ALIGN="LEFT"/>TENSOR_BOOL8 : int<br ALIGN="LEFT"/>TENSOR_FLOAT16 : int<br ALIGN="LEFT"/>TENSOR_FLOAT32 : int<br ALIGN="LEFT"/>TENSOR_INT32 : int<br ALIGN="LEFT"/>TENSOR_QUANT16_ASYMM : int<br ALIGN="LEFT"/>TENSOR_QUANT16_SYMM : int<br ALIGN="LEFT"/>TENSOR_QUANT8_ASYMM : int<br ALIGN="LEFT"/>TENSOR_QUANT8_SYMM_PER_CHANNEL : int<br ALIGN="LEFT"/>UINT32 : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.NNAPI_OperationCode" [color="black", fontcolor="black", label=<{NNAPI_OperationCode|ABS : int<br ALIGN="LEFT"/>ADD : int<br ALIGN="LEFT"/>ARGMAX : int<br ALIGN="LEFT"/>ARGMIN : int<br ALIGN="LEFT"/>AVERAGE_POOL_2D : int<br ALIGN="LEFT"/>AXIS_ALIGNED_BBOX_TRANSFORM : int<br ALIGN="LEFT"/>BATCH_TO_SPACE_ND : int<br ALIGN="LEFT"/>BIDIRECTIONAL_SEQUENCE_LSTM : int<br ALIGN="LEFT"/>BIDIRECTIONAL_SEQUENCE_RNN : int<br ALIGN="LEFT"/>BOX_WITH_NMS_LIMIT : int<br ALIGN="LEFT"/>CAST : int<br ALIGN="LEFT"/>CHANNEL_SHUFFLE : int<br ALIGN="LEFT"/>CONCATENATION : int<br ALIGN="LEFT"/>CONV_2D : int<br ALIGN="LEFT"/>DEPTHWISE_CONV_2D : int<br ALIGN="LEFT"/>DEPTH_TO_SPACE : int<br ALIGN="LEFT"/>DEQUANTIZE : int<br ALIGN="LEFT"/>DETECTION_POSTPROCESSING : int<br ALIGN="LEFT"/>DIV : int<br ALIGN="LEFT"/>EMBEDDING_LOOKUP : int<br ALIGN="LEFT"/>EQUAL : int<br ALIGN="LEFT"/>EXP : int<br ALIGN="LEFT"/>EXPAND_DIMS : int<br ALIGN="LEFT"/>FLOOR : int<br ALIGN="LEFT"/>FULLY_CONNECTED : int<br ALIGN="LEFT"/>GATHER : int<br ALIGN="LEFT"/>GENERATE_PROPOSALS : int<br ALIGN="LEFT"/>GREATER : int<br ALIGN="LEFT"/>GREATER_EQUAL : int<br ALIGN="LEFT"/>GROUPED_CONV_2D : int<br ALIGN="LEFT"/>HASHTABLE_LOOKUP : int<br ALIGN="LEFT"/>HEATMAP_MAX_KEYPOINT : int<br ALIGN="LEFT"/>INSTANCE_NORMALIZATION : int<br ALIGN="LEFT"/>L2_NORMALIZATION : int<br ALIGN="LEFT"/>L2_POOL_2D : int<br ALIGN="LEFT"/>LESS : int<br ALIGN="LEFT"/>LESS_EQUAL : int<br ALIGN="LEFT"/>LOCAL_RESPONSE_NORMALIZATION : int<br ALIGN="LEFT"/>LOG : int<br ALIGN="LEFT"/>LOGICAL_AND : int<br ALIGN="LEFT"/>LOGICAL_NOT : int<br ALIGN="LEFT"/>LOGICAL_OR : int<br ALIGN="LEFT"/>LOGISTIC : int<br ALIGN="LEFT"/>LOG_SOFTMAX : int<br ALIGN="LEFT"/>LSH_PROJECTION : int<br ALIGN="LEFT"/>LSTM : int<br ALIGN="LEFT"/>MAXIMUM : int<br ALIGN="LEFT"/>MAX_POOL_2D : int<br ALIGN="LEFT"/>MEAN : int<br ALIGN="LEFT"/>MINIMUM : int<br ALIGN="LEFT"/>MUL : int<br ALIGN="LEFT"/>NEG : int<br ALIGN="LEFT"/>NOT_EQUAL : int<br ALIGN="LEFT"/>PAD : int<br ALIGN="LEFT"/>PAD_V2 : int<br ALIGN="LEFT"/>POW : int<br ALIGN="LEFT"/>PRELU : int<br ALIGN="LEFT"/>QUANTIZE : int<br ALIGN="LEFT"/>QUANTIZED_16BIT_LSTM : int<br ALIGN="LEFT"/>RANDOM_MULTINOMIAL : int<br ALIGN="LEFT"/>REDUCE_ALL : int<br ALIGN="LEFT"/>REDUCE_ANY : int<br ALIGN="LEFT"/>REDUCE_MAX : int<br ALIGN="LEFT"/>REDUCE_MIN : int<br ALIGN="LEFT"/>REDUCE_PROD : int<br ALIGN="LEFT"/>REDUCE_SUM : int<br ALIGN="LEFT"/>RELU : int<br ALIGN="LEFT"/>RELU1 : int<br ALIGN="LEFT"/>RELU6 : int<br ALIGN="LEFT"/>RESHAPE : int<br ALIGN="LEFT"/>RESIZE_BILINEAR : int<br ALIGN="LEFT"/>RESIZE_NEAREST_NEIGHBOR : int<br ALIGN="LEFT"/>RNN : int<br ALIGN="LEFT"/>ROI_ALIGN : int<br ALIGN="LEFT"/>ROI_POOLING : int<br ALIGN="LEFT"/>RSQRT : int<br ALIGN="LEFT"/>SELECT : int<br ALIGN="LEFT"/>SIN : int<br ALIGN="LEFT"/>SLICE : int<br ALIGN="LEFT"/>SOFTMAX : int<br ALIGN="LEFT"/>SPACE_TO_BATCH_ND : int<br ALIGN="LEFT"/>SPACE_TO_DEPTH : int<br ALIGN="LEFT"/>SPLIT : int<br ALIGN="LEFT"/>SQRT : int<br ALIGN="LEFT"/>SQUEEZE : int<br ALIGN="LEFT"/>STRIDED_SLICE : int<br ALIGN="LEFT"/>SUB : int<br ALIGN="LEFT"/>SVDF : int<br ALIGN="LEFT"/>TANH : int<br ALIGN="LEFT"/>TILE : int<br ALIGN="LEFT"/>TOPK_V2 : int<br ALIGN="LEFT"/>TRANSPOSE : int<br ALIGN="LEFT"/>TRANSPOSE_CONV_2D : int<br ALIGN="LEFT"/>UNIDIRECTIONAL_SEQUENCE_LSTM : int<br ALIGN="LEFT"/>UNIDIRECTIONAL_SEQUENCE_RNN : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.guards.NNModuleAttrAccessorInfo" [color="black", fontcolor="black", label=<{NNModuleAttrAccessorInfo|l1_key : Optional[str]<br ALIGN="LEFT"/>l2_key : Optional[str]<br ALIGN="LEFT"/>present_in_generic_dict : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.NNModuleSource" [color="black", fontcolor="black", label=<{NNModuleSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.NNModuleToString" [color="black", fontcolor="black", label=<{NNModuleToString|safe_reprs : list<br ALIGN="LEFT"/>|can_convert_to_string(gm)<br ALIGN="LEFT"/>convert(gm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.nn_module.NNModuleVariable" [color="black", fontcolor="black", label=<{NNModuleVariable|module_key : str<br ALIGN="LEFT"/>module_type : type<br ALIGN="LEFT"/>nn_module_stack_source : NoneType<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|call_function(tx, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]', constant): 'VariableTracker'<br ALIGN="LEFT"/>convert_to_unspecialized(tx)<br ALIGN="LEFT"/>get_nn_module_stack_source()<br ALIGN="LEFT"/>has_key_in_generic_dict(tx: 'InstructionTranslator', key)<br ALIGN="LEFT"/>is_training(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>set_nn_module_stack_source(source)<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.NNTestCase" [color="black", fontcolor="black", label=<{NNTestCase|<br ALIGN="LEFT"/>|check_jacobian(module, input: _TensorOrTensors, jacobian_input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NO_SUCH_SUBOBJ" [color="black", fontcolor="black", label=<{NO_SUCH_SUBOBJ|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.NO_SUCH_SUBOBJ" [color="black", fontcolor="black", label=<{NO_SUCH_SUBOBJ|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.ns.fx.ns_types.NSSingleResultValuesType" [color="black", fontcolor="black", label=<{NSSingleResultValuesType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.ns.fx.ns_types.NSSubgraph" [color="black", fontcolor="black", label=<{NSSubgraph|base_op_node<br ALIGN="LEFT"/>end_node<br ALIGN="LEFT"/>start_node<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite_fx.NSTracer" [color="black", fontcolor="black", label=<{NSTracer|<br ALIGN="LEFT"/>|is_leaf_module(m: torch.nn.Module, module_qualified_name: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.comm_analysis.NVIDIA_GPU_TYPE" [color="black", fontcolor="black", label=<{NVIDIA_GPU_TYPE|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.NamePattern" [color="black", fontcolor="black", label=<{NamePattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.NamedArgument" [color="black", fontcolor="black", label=<{NamedArgument|arg : Annotated[Argument, 20]<br ALIGN="LEFT"/>name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils._named_member_accessor.NamedMemberAccessor" [color="black", fontcolor="black", label=<{NamedMemberAccessor|memo : Dict[str, torch.nn.Module]<br ALIGN="LEFT"/>module : str<br ALIGN="LEFT"/>|check_keys(keys: Iterable[str]): Tuple[List[str], List[str]]<br ALIGN="LEFT"/>del_tensor(name: str): None<br ALIGN="LEFT"/>del_tensors(names: Iterable[str]): None<br ALIGN="LEFT"/>get_submodule(name: str): 'torch.nn.Module'<br ALIGN="LEFT"/>get_tensor(name: str): torch.Tensor<br ALIGN="LEFT"/>get_tensors(names: Iterable[str]): List[torch.Tensor]<br ALIGN="LEFT"/>named_buffers(remove_duplicate: bool): Iterable[Tuple[str, torch.Tensor]]<br ALIGN="LEFT"/>named_modules(remove_duplicate: bool): Iterable[Tuple[str, 'torch.nn.Module']]<br ALIGN="LEFT"/>named_parameters(remove_duplicate: bool): Iterable[Tuple[str, torch.Tensor]]<br ALIGN="LEFT"/>named_tensors(remove_duplicate: bool): Iterable[Tuple[str, torch.Tensor]]<br ALIGN="LEFT"/>set_tensor(name: str, value: torch.Tensor): None<br ALIGN="LEFT"/>set_tensors(names: Iterable[str], values: Iterable[torch.Tensor]): None<br ALIGN="LEFT"/>set_tensors_dict(named_tensors: Dict[str, torch.Tensor]): None<br ALIGN="LEFT"/>swap_submodule(path: str, value: 'torch.nn.Module'): 'torch.nn.Module'<br ALIGN="LEFT"/>swap_tensor(name: str, value: torch.Tensor, allow_missing: bool): torch.Tensor<br ALIGN="LEFT"/>swap_tensors(names: Iterable[str], values: Iterable[torch.Tensor], allow_missing: bool): List[torch.Tensor]<br ALIGN="LEFT"/>swap_tensors_dict(named_tensors: Dict[str, torch.Tensor], allow_missing: bool): Tuple[Dict[str, torch.Tensor], List[str]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_namedtuple.NamedTupleModule" [color="black", fontcolor="black", label=<{NamedTupleModule|lin<br ALIGN="LEFT"/>|forward(input, expected_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.NamedTupleVariable" [color="black", fontcolor="black", label=<{NamedTupleVariable|dynamic_attributes : dict<br ALIGN="LEFT"/>tuple_cls<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>fields()<br ALIGN="LEFT"/>is_namedtuple()<br ALIGN="LEFT"/>is_structseq()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier.NearlyDiagonalSparsifier" [color="black", fontcolor="black", label=<{NearlyDiagonalSparsifier|<br ALIGN="LEFT"/>|update_mask(module, tensor_name, nearliness)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.NegateSource" [color="black", fontcolor="black", label=<{NegateSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/><I>reconstruct</I>(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.negative_binomial.NegativeBinomial" [color="black", fontcolor="black", label=<{NegativeBinomial|arg_constraints : dict<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>total_count<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>logits()<br ALIGN="LEFT"/>probs()<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._vendor.packaging._structures.NegativeInfinityType" [color="black", fontcolor="black", label=<{NegativeInfinityType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.numbers.NegativeIntInfinity" [color="black", fontcolor="black", label=<{NegativeIntInfinity|is_commutative : bool<br ALIGN="LEFT"/>is_comparable : bool<br ALIGN="LEFT"/>is_extended_negative : bool<br ALIGN="LEFT"/>is_extended_real : bool<br ALIGN="LEFT"/>is_integer : bool<br ALIGN="LEFT"/>is_number : bool<br ALIGN="LEFT"/>is_prime : bool<br ALIGN="LEFT"/>|as_powers_dict()<br ALIGN="LEFT"/>ceiling()<br ALIGN="LEFT"/>floor()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.nested_function.NestedFunction" [color="black", fontcolor="black", label=<{NestedFunction|<br ALIGN="LEFT"/>|forward(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function.NestedIOFunction" [color="black", fontcolor="black", label=<{NestedIOFunction|dirty_tensors : tuple<br ALIGN="LEFT"/>non_differentiable : tuple<br ALIGN="LEFT"/>retain_variables<br ALIGN="LEFT"/>saved_tensors<br ALIGN="LEFT"/>to_save : tuple<br ALIGN="LEFT"/>|backward(): Any<br ALIGN="LEFT"/><I>backward_extended</I>(): None<br ALIGN="LEFT"/>forward(): Any<br ALIGN="LEFT"/><I>forward_extended</I>(): None<br ALIGN="LEFT"/>mark_dirty(): None<br ALIGN="LEFT"/>mark_non_differentiable(): None<br ALIGN="LEFT"/>save_for_backward(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nested._internal.nested_int.NestedIntNode" [color="black", fontcolor="black", label=<{NestedIntNode|coeff : int<br ALIGN="LEFT"/>t_id : int<br ALIGN="LEFT"/>|clone(): 'NestedIntNode'<br ALIGN="LEFT"/>eq(other: Any): Any<br ALIGN="LEFT"/>ge(other: Any): Any<br ALIGN="LEFT"/>gt(other: Any): Any<br ALIGN="LEFT"/>is_bool(): bool<br ALIGN="LEFT"/>is_constant(): bool<br ALIGN="LEFT"/>is_float(): bool<br ALIGN="LEFT"/>is_int(): bool<br ALIGN="LEFT"/>is_nested_int(): bool<br ALIGN="LEFT"/>is_symbolic(): bool<br ALIGN="LEFT"/>le(other: Any): Any<br ALIGN="LEFT"/>lt(other: Any): Any<br ALIGN="LEFT"/>maybe_as_int(): Optional[int]<br ALIGN="LEFT"/>mul(other: Any): 'NestedIntNode'<br ALIGN="LEFT"/>ne(other: Any): Any<br ALIGN="LEFT"/>nested_int(): int<br ALIGN="LEFT"/>nested_int_coeff(): int<br ALIGN="LEFT"/>str(): Any<br ALIGN="LEFT"/>wrap_int(num: int): ConstantIntNode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.NestedLinear" [color="black", fontcolor="black", label=<{NestedLinear|nested_linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.NestedModel" [color="black", fontcolor="black", label=<{NestedModel|fc3<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_static_graph_nested_types.NestedOutputModule" [color="black", fontcolor="black", label=<{NestedOutputModule|lin<br ALIGN="LEFT"/>|forward(inp, output_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.NestedSequentialModel" [color="black", fontcolor="black", label=<{NestedSequentialModel|lin<br ALIGN="LEFT"/>seq1<br ALIGN="LEFT"/>seq2<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nested._internal.nested_tensor.NestedTensor" [color="black", fontcolor="black", label=<{NestedTensor|<br ALIGN="LEFT"/>|lengths()<br ALIGN="LEFT"/>offsets()<br ALIGN="LEFT"/>values()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.NestedTensorTestCase" [color="black", fontcolor="black", label=<{NestedTensorTestCase|<br ALIGN="LEFT"/>|assertEqualIgnoringNestedInts(a, b)<br ALIGN="LEFT"/>assertEqualNoncontigAware(a, b)<br ALIGN="LEFT"/>branch_nested_state()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.NestedUserFunctionVariable" [color="black", fontcolor="black", label=<{NestedUserFunctionVariable|annotations<br ALIGN="LEFT"/>closure<br ALIGN="LEFT"/>code<br ALIGN="LEFT"/>defaults<br ALIGN="LEFT"/>f_globals<br ALIGN="LEFT"/>fn_name<br ALIGN="LEFT"/>kwdefaults<br ALIGN="LEFT"/>wrapped_fn : Optional[VariableTracker]<br ALIGN="LEFT"/>|bind_args(parent, args, kwargs)<br ALIGN="LEFT"/>get_code()<br ALIGN="LEFT"/>get_function()<br ALIGN="LEFT"/>get_globals()<br ALIGN="LEFT"/>has_closure()<br ALIGN="LEFT"/>has_self()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>self_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.NestedWrappedModule" [color="black", fontcolor="black", label=<{NestedWrappedModule|module<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_input(device)<br ALIGN="LEFT"/>get_loss(input, output)<br ALIGN="LEFT"/>init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool): nn.Module<br ALIGN="LEFT"/>run_backward(loss)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.NestedWrappedModuleWithDelay" [color="black", fontcolor="black", label=<{NestedWrappedModuleWithDelay|<br ALIGN="LEFT"/>|init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool, delay_after_loss_ms: int, delay_before_reduction_ms: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_nn._create_basic_net.Net" [color="black", fontcolor="black", label=<{Net|dummy_buf<br ALIGN="LEFT"/>dummy_param<br ALIGN="LEFT"/>l1<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.Net" [color="black", fontcolor="black", label=<{Net|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>fc3<br ALIGN="LEFT"/>no_grad_param<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_build_debug_param_to_name_mapping_requires_grad.Net" [color="black", fontcolor="black", label=<{Net|lin<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_static_graph_multi_forward.Net" [color="black", fontcolor="black", label=<{Net|lin<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.data.network1.Net" [color="black", fontcolor="black", label=<{Net|linear<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.data.network2.Net" [color="black", fontcolor="black", label=<{Net|linear<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.NetWithBuffers" [color="black", fontcolor="black", label=<{NetWithBuffers|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_broadcast_buffer.NetWithBuffers" [color="black", fontcolor="black", label=<{NetWithBuffers|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.NewDim" [color="black", fontcolor="black", label=<{NewDim|size : int<br ALIGN="LEFT"/>|new(size: int): DimSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NewGlobalVariable" [color="black", fontcolor="black", label=<{NewGlobalVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.NewModuleTest" [color="black", fontcolor="black", label=<{NewModuleTest|check_batched_grad<br ALIGN="LEFT"/>check_gradgrad<br ALIGN="LEFT"/>check_inplace<br ALIGN="LEFT"/>constructor_args<br ALIGN="LEFT"/>cudnn<br ALIGN="LEFT"/>gradcheck_fast_mode<br ALIGN="LEFT"/>has_sparse_gradients<br ALIGN="LEFT"/>skip_double<br ALIGN="LEFT"/>skip_half<br ALIGN="LEFT"/>supports_forward_ad<br ALIGN="LEFT"/>supports_fwgrad_bwgrad<br ALIGN="LEFT"/>test_cpu<br ALIGN="LEFT"/>tf32_precision<br ALIGN="LEFT"/>with_tf32<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.prepare.convert_model_to_nnapi.NnapiInterfaceWrapper" [color="black", fontcolor="black", label=<{NnapiInterfaceWrapper|mod<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.prepare.NnapiModule" [color="black", fontcolor="black", label=<{NnapiModule|comp : Optional[torch.classes._nnapi.Compilation]<br ALIGN="LEFT"/>compilation_preference : int<br ALIGN="LEFT"/>inp_mem_fmts : List[int]<br ALIGN="LEFT"/>out_mem_fmts : List[int]<br ALIGN="LEFT"/>out_templates : List[torch.Tensor]<br ALIGN="LEFT"/>relax_f32_to_f16 : bool<br ALIGN="LEFT"/>ser_model<br ALIGN="LEFT"/>shape_compute_module<br ALIGN="LEFT"/>weights : List[torch.Tensor]<br ALIGN="LEFT"/>|forward(args: List[torch.Tensor]): List[torch.Tensor]<br ALIGN="LEFT"/>init(args: List[torch.Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.polyfills.NoEnterTorchFunctionMode" [color="black", fontcolor="black", label=<{NoEnterTorchFunctionMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.NoTest" [color="black", fontcolor="black", label=<{NoTest|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils.NoTracerWarnContextManager" [color="black", fontcolor="black", label=<{NoTracerWarnContextManager|prev<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.NoValidChoicesError" [color="black", fontcolor="red", label=<{NoValidChoicesError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.Node" [color="black", fontcolor="black", label=<{Node|next_functions<br ALIGN="LEFT"/>|<I>metadata</I>(): dict<br ALIGN="LEFT"/><I>name</I>(): str<br ALIGN="LEFT"/><I>register_hook</I>(fn: Callable[..., Any]): RemovableHandle<br ALIGN="LEFT"/><I>register_prehook</I>(fn: Callable[..., Any]): RemovableHandle<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.viz._cycles.Node" [color="black", fontcolor="black", label=<{Node|context : Optional[str]<br ALIGN="LEFT"/>label : str<br ALIGN="LEFT"/>referrents : List[Tuple[str, int]]<br ALIGN="LEFT"/>root : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.node.Node" [color="black", fontcolor="black", label=<{Node|all_input_nodes<br ALIGN="LEFT"/>args<br ALIGN="LEFT"/>graph : str<br ALIGN="LEFT"/>kwargs<br ALIGN="LEFT"/>meta : Dict[str, Any]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>next<br ALIGN="LEFT"/>op : str<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>stack_trace<br ALIGN="LEFT"/>target : str<br ALIGN="LEFT"/>type : Optional[Any]<br ALIGN="LEFT"/>users : Dict['Node', None]<br ALIGN="LEFT"/>|append(x: 'Node'): None<br ALIGN="LEFT"/>format_node(placeholder_names: Optional[List[str]], maybe_return_typename: Optional[List[str]]): Optional[str]<br ALIGN="LEFT"/>insert_arg(idx: int, arg: Argument): None<br ALIGN="LEFT"/>is_impure(): bool<br ALIGN="LEFT"/>normalized_arguments(root: torch.nn.Module, arg_types: Optional[Tuple[Any]], kwarg_types: Optional[Dict[str, Any]], normalize_to_only_use_kwargs: bool): Optional[ArgsKwargsPair]<br ALIGN="LEFT"/>prepend(x: 'Node'): None<br ALIGN="LEFT"/>replace_all_uses_with(replace_with: 'Node', delete_user_cb: Callable[['Node'], bool]): List['Node']<br ALIGN="LEFT"/>replace_input_with(old_input: 'Node', new_input: 'Node'): None<br ALIGN="LEFT"/>update_arg(idx: int, arg: Argument): None<br ALIGN="LEFT"/>update_kwarg(key: str, arg: Argument): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._node.Node" [color="black", fontcolor="black", label=<{Node|children : Optional[List[_node.Node]]<br ALIGN="LEFT"/>id : str<br ALIGN="LEFT"/>label : Optional[_message.Message]<br ALIGN="LEFT"/>location : Optional[_location.Location]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.ilp_utils.Node" [color="black", fontcolor="black", label=<{Node|index : int<br ALIGN="LEFT"/>pos_fw_post_order : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.Node" [color="black", fontcolor="black", label=<{Node|inputs : Annotated[List[NamedArgument], 20]<br ALIGN="LEFT"/>metadata : Annotated[Dict[str, str], 40]<br ALIGN="LEFT"/>outputs : Annotated[List[Argument], 30]<br ALIGN="LEFT"/>target : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e._numeric_debugger.NodeAccuracySummary" [color="black", fontcolor="black", label=<{NodeAccuracySummary|actual_module_stack : str<br ALIGN="LEFT"/>actual_node_name : str<br ALIGN="LEFT"/>handle : int<br ALIGN="LEFT"/>ref_module_stack : str<br ALIGN="LEFT"/>ref_node_name : str<br ALIGN="LEFT"/>results : Sequence[QuantizationComparisonResult]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.tensorboard._pytorch_graph.NodeBase" [color="black", fontcolor="black", label=<{NodeBase|attributes : str<br ALIGN="LEFT"/>debugName : NoneType<br ALIGN="LEFT"/>inputs : NoneType<br ALIGN="LEFT"/>kind : str<br ALIGN="LEFT"/>scope : NoneType<br ALIGN="LEFT"/>tensor_size : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree.NodeDef" [color="black", fontcolor="black", label=<{NodeDef|flatten_fn : Callable<br ALIGN="LEFT"/>flatten_with_keys_fn : Optional[FlattenWithKeysFunc]<br ALIGN="LEFT"/>type : Type[Any]<br ALIGN="LEFT"/>unflatten_fn : Callable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.graph_region_tracker.NodeHashException" [color="black", fontcolor="red", label=<{NodeHashException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.traceback.NodeSource.NodeInfo" [color="black", fontcolor="black", label=<{NodeInfo|graph_id : int<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>target : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.memory.topological_sort_lpmf.NodeInfo" [color="black", fontcolor="black", label=<{NodeInfo|indegree : int<br ALIGN="LEFT"/>memory_to_free : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.memory.topological_sort_bfs.NodeInfo" [color="black", fontcolor="black", label=<{NodeInfo|indegree : int<br ALIGN="LEFT"/>order : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.partitioners.NodeInfo" [color="black", fontcolor="black", label=<{NodeInfo|fw_order : Dict[fx.Node, int]<br ALIGN="LEFT"/>inputs : List[fx.Node]<br ALIGN="LEFT"/>required_bw_nodes : Set[fx.Node]<br ALIGN="LEFT"/>required_fw_nodes<br ALIGN="LEFT"/>unclaimed_nodes : Set[fx.Node]<br ALIGN="LEFT"/>|get_fw_order(n: fx.Node): int<br ALIGN="LEFT"/>is_required_bw(n: fx.Node): bool<br ALIGN="LEFT"/>is_required_fw(n: fx.Node): bool<br ALIGN="LEFT"/>is_unclaimed(n: fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.utils.NodeInputOrOutputType" [color="black", fontcolor="black", label=<{NodeInputOrOutputType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.NodeLatency" [color="black", fontcolor="black", label=<{NodeLatency|computer_latency_sec : float<br ALIGN="LEFT"/>mem_latency_sec : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.pass_infra.node_metadata.NodeMetadata" [color="black", fontcolor="black", label=<{NodeMetadata|data : Dict[str, Any]<br ALIGN="LEFT"/>|copy(): 'NodeMetadata'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.tensorboard._pytorch_graph.NodePy" [color="black", fontcolor="black", label=<{NodePy|inputs : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.tensorboard._pytorch_graph.NodePyIO" [color="black", fontcolor="black", label=<{NodePyIO|debugName : str<br ALIGN="LEFT"/>input_or_output : NoneType<br ALIGN="LEFT"/>inputs : list<br ALIGN="LEFT"/>kind : str<br ALIGN="LEFT"/>tensor_size : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.tensorboard._pytorch_graph.NodePyOP" [color="black", fontcolor="black", label=<{NodePyOP|attributes : str<br ALIGN="LEFT"/>kind<br ALIGN="LEFT"/>scopeName<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd_kernel_features.NodeScheduleMarker" [color="black", fontcolor="black", label=<{NodeScheduleMarker|<br ALIGN="LEFT"/>|is_reduction(): bool<br ALIGN="LEFT"/>only_nodes(it: Iterable[NodeScheduleEntry]): Iterable[SchedulerNode]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.traceback.NodeSource" [color="black", fontcolor="black", label=<{NodeSource|action : Optional['NodeSourceAction']<br ALIGN="LEFT"/>from_node : List['NodeSource']<br ALIGN="LEFT"/>graph_id<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>node_info : Optional['NodeInfo']<br ALIGN="LEFT"/>pass_name : str<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|print_readable(indent)<br ALIGN="LEFT"/>to_dict(): dict<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.traceback.NodeSourceAction" [color="black", fontcolor="black", label=<{NodeSourceAction|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.NodeSpec" [color="black", fontcolor="black", label=<{NodeSpec|op<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|call_function(target)<br ALIGN="LEFT"/>call_method(target)<br ALIGN="LEFT"/>call_module(target)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.events.api.NodeState" [color="black", fontcolor="black", label=<{NodeState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.scheduler.NodeUser" [color="black", fontcolor="black", label=<{NodeUser|can_inplace : bool<br ALIGN="LEFT"/>is_weak : bool<br ALIGN="LEFT"/>node : Union[BaseSchedulerNode, OutputNode]<br ALIGN="LEFT"/>|get_name(): str<br ALIGN="LEFT"/>merge(other: NodeUser): NodeUser<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.memory.topological_sort_bfs.NodeWithPriority" [color="black", fontcolor="black", label=<{NodeWithPriority|node<br ALIGN="LEFT"/>priority : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.NonContGradFunc" [color="black", fontcolor="black", label=<{NonContGradFunc|<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp1)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy_sparse.NonContGradFunc" [color="black", fontcolor="black", label=<{NonContGradFunc|static_grad_ptr : NoneType<br ALIGN="LEFT"/>|backward(ctx, grad)<br ALIGN="LEFT"/>forward(ctx, inp1, inp2)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.linear.NonDynamicallyQuantizableLinear" [color="black", fontcolor="black", label=<{NonDynamicallyQuantizableLinear|bias<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.NonOwningLayout" [color="black", fontcolor="black", label=<{NonOwningLayout|view : Union[BaseView, TensorBox]<br ALIGN="LEFT"/>|make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>maybe_guard_aligned()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.NonUniformReqGradNWM" [color="black", fontcolor="black", label=<{NonUniformReqGradNWM|module<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.NonWrapperTensor" [color="black", fontcolor="black", label=<{NonWrapperTensor|<br ALIGN="LEFT"/>|new_empty(shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.NoneAsConstantBuffer" [color="black", fontcolor="black", label=<{NoneAsConstantBuffer|<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/>get_output_spec(): OutputSpec<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>has_tensor_output(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.NoneLayout" [color="black", fontcolor="black", label=<{NoneLayout|device : Optional[torch.device]<br ALIGN="LEFT"/>size : List[int]<br ALIGN="LEFT"/>stride : List[int]<br ALIGN="LEFT"/>|as_fixed()<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>storage_size(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._comparison.NonePair" [color="black", fontcolor="black", label=<{NonePair|<br ALIGN="LEFT"/>|compare(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.NonzeroWorkspaceNotSupportedError" [color="black", fontcolor="red", label=<{NonzeroWorkspaceNotSupportedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.NoopAliasHandler" [color="black", fontcolor="black", label=<{NoopAliasHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ops_handler.NoopHandler" [color="black", fontcolor="black", label=<{NoopHandler|<br ALIGN="LEFT"/>|frexp(x): Tuple[None, None]<br ALIGN="LEFT"/>indirect_indexing(index_var, size, check, wrap_neg): sympy.Symbol<br ALIGN="LEFT"/>masked(mask, body, other): None<br ALIGN="LEFT"/>scan(dtypes, combine_fn, values): Tuple[None, ...]<br ALIGN="LEFT"/>sort(dtypes, values, stable, descending): Tuple[None, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.NoopObserver" [color="black", fontcolor="black", label=<{NoopObserver|custom_op : str<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.NopInputReader" [color="black", fontcolor="black", label=<{NopInputReader|total : int<br ALIGN="LEFT"/>|storage(storage_hash, nbytes)<br ALIGN="LEFT"/><I>symint</I>()<br ALIGN="LEFT"/><I>tensor</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.NopKernel" [color="black", fontcolor="black", label=<{NopKernel|<br ALIGN="LEFT"/>|get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>is_no_op(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.NopKernelSchedulerNode" [color="black", fontcolor="black", label=<{NopKernelSchedulerNode|last_usage<br ALIGN="LEFT"/>max_order<br ALIGN="LEFT"/>min_order<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._math_ops.NormReduction" [color="black", fontcolor="black", label=<{NormReduction|norm_type : Union[int, float, str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.normal.Normal" [color="black", fontcolor="black", label=<{Normal|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.NormalizationTestModel" [color="black", fontcolor="black", label=<{NormalizationTestModel|fc1<br ALIGN="LEFT"/>group_norm<br ALIGN="LEFT"/>instance_norm1d<br ALIGN="LEFT"/>instance_norm2d<br ALIGN="LEFT"/>instance_norm3d<br ALIGN="LEFT"/>layer_norm<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.normalize.NormalizeArgs" [color="black", fontcolor="black", label=<{NormalizeArgs|node_map : Dict[Proxy, Node]<br ALIGN="LEFT"/>normalize_to_only_use_kwargs : bool<br ALIGN="LEFT"/>|call_function(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any], arg_types: Optional[Tuple[Any, ...]], kwarg_types: Optional[Dict[str, Any]])<br ALIGN="LEFT"/>call_module(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any])<br ALIGN="LEFT"/>run_node(n: Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.normalize.NormalizeOperators" [color="black", fontcolor="black", label=<{NormalizeOperators|binary_magic_method_remap : Dict[Callable[[Any, Any], Any], Callable[[Any, Any], Any]]<br ALIGN="LEFT"/>|call_function(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.pre_grad.NormalizedLinearNode" [color="black", fontcolor="black", label=<{NormalizedLinearNode|node<br ALIGN="LEFT"/>|get_bias(): torch.fx.Node<br ALIGN="LEFT"/>get_input(): torch.fx.Node<br ALIGN="LEFT"/>get_weight(): torch.fx.Node<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.pre_grad.NormalizedMatmulNode" [color="black", fontcolor="black", label=<{NormalizedMatmulNode|node<br ALIGN="LEFT"/>|get_input(): torch.fx.Node<br ALIGN="LEFT"/>get_other(): torch.fx.Node<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.recording.NotEqualError" [color="black", fontcolor="red", label=<{NotEqualError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.frontend.NotSupportedError" [color="black", fontcolor="red", label=<{NotSupportedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.NotView" [color="black", fontcolor="black", label=<{NotView|<br ALIGN="LEFT"/>|regenerate_view(bases_list: List[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._notification.Notification" [color="black", fontcolor="black", label=<{Notification|associated_rule : Optional[_reporting_descriptor_reference.ReportingDescriptorReference]<br ALIGN="LEFT"/>descriptor : Optional[_reporting_descriptor_reference.ReportingDescriptorReference]<br ALIGN="LEFT"/>exception : Optional[_exception.Exception]<br ALIGN="LEFT"/>level : Literal['none', 'note', 'warning', 'error']<br ALIGN="LEFT"/>locations : Optional[List[_location.Location]]<br ALIGN="LEFT"/>message<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>thread_id : Optional[int]<br ALIGN="LEFT"/>time_utc : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.null_context_manager.NullContextManager" [color="black", fontcolor="black", label=<{NullContextManager|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.NullContextVariable" [color="black", fontcolor="black", label=<{NullContextVariable|<br ALIGN="LEFT"/>|enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.virtualized.NullHandler" [color="black", fontcolor="black", label=<{NullHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.virtualized.NullKernelHandler" [color="black", fontcolor="black", label=<{NullKernelHandler|index_dtype : str<br ALIGN="LEFT"/>inplaced_to_remove<br ALIGN="LEFT"/>removed_buffers<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.NullLine" [color="black", fontcolor="black", label=<{NullLine|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.metrics.api.NullMetricHandler" [color="black", fontcolor="black", label=<{NullMetricHandler|<br ALIGN="LEFT"/>|<I>emit</I>(metric_data: MetricData)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NullVariable" [color="black", fontcolor="black", label=<{NullVariable|<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._comparison.NumberPair" [color="black", fontcolor="black", label=<{NumberPair|atol<br ALIGN="LEFT"/>check_dtype : bool<br ALIGN="LEFT"/>equal_nan : bool<br ALIGN="LEFT"/>rtol<br ALIGN="LEFT"/>|compare(): None<br ALIGN="LEFT"/>extra_repr(): Sequence[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.misc_patterns.NumpyCompatNormalization" [color="black", fontcolor="black", label=<{NumpyCompatNormalization|cache : Dict['torch.fx.graph.Target', OrderedSet[str]]<br ALIGN="LEFT"/>inverse_mapping : Dict[str, str]<br ALIGN="LEFT"/>numpy_compat : Dict[str, Tuple[str, ...]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpyCube" [color="black", fontcolor="black", label=<{NumpyCube|<br ALIGN="LEFT"/>|backward(ctx, grad_output, grad_saved)<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>jvp(ctx, input_tangent)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpyCubeNotComposable" [color="black", fontcolor="black", label=<{NumpyCubeNotComposable|<br ALIGN="LEFT"/>|backward(ctx, grad_output, grad_saved)<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NumpyDTypeVariable" [color="black", fontcolor="black", label=<{NumpyDTypeVariable|<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpyExp_" [color="black", fontcolor="black", label=<{NumpyExp_|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>jvp(ctx, x_tangent)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpyMul" [color="black", fontcolor="black", label=<{NumpyMul|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, y)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, y_tangent)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.NumpyNdarrayVariable" [color="black", fontcolor="black", label=<{NumpyNdarrayVariable|<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', proxy)<br ALIGN="LEFT"/>patch_args(name, args, kwargs)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpySort" [color="black", fontcolor="black", label=<{NumpySort|<br ALIGN="LEFT"/>|backward(ctx, grad_output, _0, _1)<br ALIGN="LEFT"/>forward(x, dim)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x, dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.NumpyTake" [color="black", fontcolor="black", label=<{NumpyTake|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, ind, ind_inv, dim)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, ind_tangent, ind_inv_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x, ind, ind_inv, dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.NumpyTensorSource" [color="black", fontcolor="black", label=<{NumpyTensorSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name(): str<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NumpyTypeInfoVariable" [color="black", fontcolor="black", label=<{NumpyTypeInfoVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.NumpyVariable" [color="black", fontcolor="black", label=<{NumpyVariable|constant_fold_functions : tuple<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>can_constant_fold_through(fn)<br ALIGN="LEFT"/>get_constant_collection_for_func(fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.ODictGetItemSource" [color="black", fontcolor="black", label=<{ODictGetItemSource|index : Any<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.ONNXFakeContext" [color="black", fontcolor="black", label=<{ONNXFakeContext|fake_mode<br ALIGN="LEFT"/>state_dict_paths : tuple[str \| io.BytesIO \| dict[str, Any]] \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.registration.ONNXFunction" [color="black", fontcolor="black", label=<{ONNXFunction|is_complex : bool<br ALIGN="LEFT"/>is_custom : bool<br ALIGN="LEFT"/>onnx_function : onnxscript.OnnxFunction \| onnxscript.TracedOnnxFunction<br ALIGN="LEFT"/>op_full_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._onnx_program.ONNXProgram" [color="black", fontcolor="black", label=<{ONNXProgram|exported_program : torch.export.ExportedProgram \| None<br ALIGN="LEFT"/>model<br ALIGN="LEFT"/>model_proto<br ALIGN="LEFT"/>|apply_weights(state_dict: dict[str, torch.Tensor]): None<br ALIGN="LEFT"/>initialize_inference_session(initializer: Callable[[str \| bytes], ort.InferenceSession]): None<br ALIGN="LEFT"/>optimize(): None<br ALIGN="LEFT"/>release(): None<br ALIGN="LEFT"/>save(destination: str \| os.PathLike)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._registration.ONNXRegistry" [color="black", fontcolor="black", label=<{ONNXRegistry|functions : dict[TorchOp \| str, list[OnnxDecompMeta]]<br ALIGN="LEFT"/>opset_version<br ALIGN="LEFT"/>|from_torchlib(): ONNXRegistry<br ALIGN="LEFT"/>get_decomps(target: TorchOp): list[OnnxDecompMeta]<br ALIGN="LEFT"/>is_registered(target: TorchOp): bool<br ALIGN="LEFT"/>register_op(target: TorchOp, function: Callable, is_complex: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.ONNXRuntimeOptions" [color="black", fontcolor="black", label=<{ONNXRuntimeOptions|execution_provider_options : Sequence[dict[Any, Any]] \| None<br ALIGN="LEFT"/>execution_providers : Sequence[str \| tuple[str, dict[Any, Any]]] \| None<br ALIGN="LEFT"/>session_options : Sequence[onnxruntime.SessionOptions] \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.patcher.ONNXTorchPatcher" [color="black", fontcolor="black", label=<{ONNXTorchPatcher|paths : List[Union[str, io.BufferedIOBase]]<br ALIGN="LEFT"/>safetensors_torch_load_file<br ALIGN="LEFT"/>safetensors_torch_load_file_wrapper<br ALIGN="LEFT"/>torch_fx__symbolic_trace__wrapped_methods_to_patch : list<br ALIGN="LEFT"/>torch_load<br ALIGN="LEFT"/>torch_load_wrapper<br ALIGN="LEFT"/>transformers_modeling_utils_safe_load_file<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._trace.ONNXTracedModule" [color="black", fontcolor="black", label=<{ONNXTracedModule|inner<br ALIGN="LEFT"/>strict : bool<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.importer.ObjMismatchError" [color="black", fontcolor="red", label=<{ObjMismatchError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.importer.ObjNotFoundError" [color="black", fontcolor="red", label=<{ObjNotFoundError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._comparison.ObjectPair" [color="black", fontcolor="black", label=<{ObjectPair|<br ALIGN="LEFT"/>|compare(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.ObjectPair" [color="black", fontcolor="black", label=<{ObjectPair|CLS : object<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.backend_config.backend_config.ObservationType" [color="black", fontcolor="black", label=<{ObservationType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ObservedAttributeError" [color="black", fontcolor="red", label=<{ObservedAttributeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ObservedException" [color="black", fontcolor="red", label=<{ObservedException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.graph_module.ObservedGraphModule" [color="black", fontcolor="black", label=<{ObservedGraphModule|preserved_attr_names<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.utils.ObservedGraphModuleAttrs" [color="black", fontcolor="black", label=<{ObservedGraphModuleAttrs|equalization_node_name_to_qconfig : Dict[str, Any]<br ALIGN="LEFT"/>is_observed_standalone_module : bool<br ALIGN="LEFT"/>is_qat : bool<br ALIGN="LEFT"/>node_name_to_qconfig : Dict[str, QConfigAny]<br ALIGN="LEFT"/>node_name_to_scope : Dict[str, Tuple[str, type]]<br ALIGN="LEFT"/>observed_node_names : Set[str]<br ALIGN="LEFT"/>prepare_custom_config<br ALIGN="LEFT"/>qconfig_mapping<br ALIGN="LEFT"/>standalone_module_input_quantized_idxs : Optional[List[int]]<br ALIGN="LEFT"/>standalone_module_output_quantized_idxs : Optional[List[int]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ObservedKeyError" [color="black", fontcolor="red", label=<{ObservedKeyError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.graph_module.ObservedStandaloneGraphModule" [color="black", fontcolor="black", label=<{ObservedStandaloneGraphModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ObservedUserStopIteration" [color="black", fontcolor="red", label=<{ObservedUserStopIteration|value : Optional[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Observer" [color="black", fontcolor="black", label=<{Observer|env<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>|run_episode(agent_rref, n_steps)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.ObserverBase" [color="black", fontcolor="black", label=<{ObserverBase|dtype<br ALIGN="LEFT"/>is_dynamic : bool<br ALIGN="LEFT"/>with_args : classmethod<br ALIGN="LEFT"/>with_callable_args : classmethod<br ALIGN="LEFT"/>|<I>calculate_qparams</I>()<br ALIGN="LEFT"/><I>forward</I>(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.OffloadPolicy" [color="black", fontcolor="black", label=<{OffloadPolicy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.OffloadWrapper" [color="black", fontcolor="black", label=<{OffloadWrapper|<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._random.OffsetBasedRNGTracker" [color="black", fontcolor="black", label=<{OffsetBasedRNGTracker|<br ALIGN="LEFT"/>|get_offset(name: str): int<br ALIGN="LEFT"/>set_offset(name: str, offset: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.OneCycleLR" [color="black", fontcolor="black", label=<{OneCycleLR|cycle_momentum : bool<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>total_steps<br ALIGN="LEFT"/>use_beta1<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.one_hot_categorical.OneHotCategorical" [color="black", fontcolor="black", label=<{OneHotCategorical|arg_constraints : dict<br ALIGN="LEFT"/>has_enumerate_support : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>param_shape<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>enumerate_support(expand)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.one_hot_categorical.OneHotCategoricalStraightThrough" [color="black", fontcolor="black", label=<{OneHotCategoricalStraightThrough|has_rsample : bool<br ALIGN="LEFT"/>|rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx.verification.OnnxBackend" [color="black", fontcolor="black", label=<{OnnxBackend|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._registration.OnnxDecompMeta" [color="black", fontcolor="black", label=<{OnnxDecompMeta|device : Literal['cuda', 'cpu'] \| str \| None<br ALIGN="LEFT"/>fx_target : Union<br ALIGN="LEFT"/>is_complex : bool<br ALIGN="LEFT"/>is_custom : bool<br ALIGN="LEFT"/>onnx_function : Callable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.errors.OnnxExporterError" [color="black", fontcolor="red", label=<{OnnxExporterError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.errors.OnnxExporterWarning" [color="black", fontcolor="red", label=<{OnnxExporterWarning|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher" [color="black", fontcolor="black", label=<{OnnxFunctionDispatcher|diagnostic_context<br ALIGN="LEFT"/>onnx_registry<br ALIGN="LEFT"/>|dispatch(node: torch.fx.Node, onnx_args: Sequence[fx_type_utils.TensorLike \| str \| int \| float \| bool \| list \| complex \| None], onnx_kwargs: dict[str, fx_type_utils.Argument], diagnostic_context: diagnostics.DiagnosticContext): onnxscript.OnnxFunction \| onnxscript.TracedOnnxFunction<br ALIGN="LEFT"/>get_function_overloads(node: torch.fx.Node, diagnostic_context: diagnostics.DiagnosticContext): list[registration.ONNXFunction]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.OnnxRegistry" [color="black", fontcolor="black", label=<{OnnxRegistry|opset_version<br ALIGN="LEFT"/>|get_op_functions(namespace: str, op_name: str, overload: str \| None): list[registration.ONNXFunction] \| None<br ALIGN="LEFT"/>is_registered_op(namespace: str, op_name: str, overload: str \| None): bool<br ALIGN="LEFT"/>register_op(function: onnxscript.OnnxFunction \| onnxscript.TracedOnnxFunction, namespace: str, op_name: str, overload: str \| None, is_complex: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx.verification.OnnxTestCaseRepro" [color="black", fontcolor="black", label=<{OnnxTestCaseRepro|inputs : dict<br ALIGN="LEFT"/>outputs : dict<br ALIGN="LEFT"/>proto<br ALIGN="LEFT"/>repro_dir<br ALIGN="LEFT"/>|create_test_case_repro(proto: bytes, inputs, outputs, dir: str, name: str \| None)<br ALIGN="LEFT"/>validate(options: VerificationOptions)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.Op" [color="black", fontcolor="black", label=<{Op|args : List[Union[Param, Intermediate]]<br ALIGN="LEFT"/>fn_call_name : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>ret<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.optests.generate_tests.OpCheckError" [color="black", fontcolor="red", label=<{OpCheckError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.optests.generate_tests.OpCheckMode" [color="black", fontcolor="black", label=<{OpCheckMode|failures_dict : str<br ALIGN="LEFT"/>failures_dict_path : str<br ALIGN="LEFT"/>namespaces : List[str]<br ALIGN="LEFT"/>prev_dynamo_disable : str<br ALIGN="LEFT"/>prev_is_opcheck_mode : int<br ALIGN="LEFT"/>seen_ops_to_errors : dict<br ALIGN="LEFT"/>test_name : str<br ALIGN="LEFT"/>test_util : Callable<br ALIGN="LEFT"/>test_util_name : str<br ALIGN="LEFT"/>|maybe_raise_errors_on_exit(): None<br ALIGN="LEFT"/>run_test_util(op, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.OpCountResult" [color="black", fontcolor="black", label=<{OpCountResult|nontrivial_read_count : int<br ALIGN="LEFT"/>num_ops : int<br ALIGN="LEFT"/>read_buffers : List[str]<br ALIGN="LEFT"/>used_ops : OrderedSet[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ops_handler.OpCounterCSE" [color="black", fontcolor="black", label=<{OpCounterCSE|op_count : int<br ALIGN="LEFT"/>parent_handler<br ALIGN="LEFT"/>var_names : dict<br ALIGN="LEFT"/>|bucketize(values: T, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[T]): T<br ALIGN="LEFT"/>getvalue()<br ALIGN="LEFT"/>indirect_indexing()<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr): str<br ALIGN="LEFT"/>load_seed(name: str, offset: T)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.OpDTypes" [color="black", fontcolor="black", label=<{OpDTypes|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.OpDecompositions" [color="black", fontcolor="black", label=<{OpDecompositions|<br ALIGN="LEFT"/>|ceil_to_int(a, dtype)<br ALIGN="LEFT"/>erfc(x)<br ALIGN="LEFT"/>erfcx(x)<br ALIGN="LEFT"/>exp2(x)<br ALIGN="LEFT"/>expm1(x)<br ALIGN="LEFT"/>floor_to_int(a, dtype)<br ALIGN="LEFT"/>fma(x, y, z)<br ALIGN="LEFT"/>identity(value)<br ALIGN="LEFT"/>log10(x)<br ALIGN="LEFT"/>log1p(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>reciprocal(x)<br ALIGN="LEFT"/>relu(x)<br ALIGN="LEFT"/>remainder(a, b)<br ALIGN="LEFT"/>round_to_int(a, dtype)<br ALIGN="LEFT"/>sigmoid(x)<br ALIGN="LEFT"/>square(x)<br ALIGN="LEFT"/>trunc_to_int(a, dtype)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._dispatch.OpDispatcher" [color="black", fontcolor="black", label=<{OpDispatcher|sharding_propagator<br ALIGN="LEFT"/>|dispatch(op_call: torch._ops.OpOverload, args: Tuple[object, ...], kwargs: Dict[str, object]): object<br ALIGN="LEFT"/>redistribute_local_args(op_info: OpInfo, suggested_input_schema: OpSchema): None<br ALIGN="LEFT"/>unwrap_to_op_info(op_call: torch._ops.OpOverload, args: Tuple[object, ...], kwargs: Dict[str, object]): OpInfo<br ALIGN="LEFT"/>wrap(res: object, spec: OutputSpecType): object<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.OpDtypeRule" [color="black", fontcolor="black", label=<{OpDtypeRule|override_return_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>type_promotion_kind : ELEMENTWISE_TYPE_PROMOTION_KIND<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.OpDtypeSupport" [color="black", fontcolor="black", label=<{OpDtypeSupport|convert_outputs : Dict[str, bool]<br ALIGN="LEFT"/>supported_dtypes : Dict[str, OrderedSet[torch.dtype]]<br ALIGN="LEFT"/>|register_upcast(func: Callable[..., str], convert_output: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.OpInfo" [color="black", fontcolor="black", label=<{OpInfo|args_tree_spec : Optional[TreeSpec]<br ALIGN="LEFT"/>flat_args_schema : List[object]<br ALIGN="LEFT"/>local_args : Sequence[object]<br ALIGN="LEFT"/>local_kwargs : Dict[str, object]<br ALIGN="LEFT"/>mesh<br ALIGN="LEFT"/>output_sharding : Optional[OutputSharding]<br ALIGN="LEFT"/>schema<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.OpInfo" [color="black", fontcolor="black", label=<{OpInfo|aliases : Optional[Iterable]<br ALIGN="LEFT"/>allow_cow_input_materialize_backward : Optional[List[Union[int, str]]]<br ALIGN="LEFT"/>allow_cow_input_materialize_forward : Optional[List[Union[int, str]]]<br ALIGN="LEFT"/>assert_autodiffed : bool<br ALIGN="LEFT"/>assert_jit_shape_analysis : bool<br ALIGN="LEFT"/>aten_backward_name : Optional[str]<br ALIGN="LEFT"/>aten_name : Optional[str]<br ALIGN="LEFT"/>autodiff_fusible_nodes : Optional[List[str]]<br ALIGN="LEFT"/>autodiff_nonfusible_nodes : Optional[List[str]]<br ALIGN="LEFT"/>backward_dtypes : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>backward_dtypesIfCUDA : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>backward_dtypesIfHpu : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>backward_dtypesIfROCM : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>check_batched_forward_grad : Optional[bool]<br ALIGN="LEFT"/>check_batched_grad : Optional[bool]<br ALIGN="LEFT"/>check_batched_gradgrad : Optional[bool]<br ALIGN="LEFT"/>check_inplace_batched_forward_grad : Optional[bool]<br ALIGN="LEFT"/>decomp_aten_name : Optional[str]<br ALIGN="LEFT"/>decorators : Tuple<br ALIGN="LEFT"/>dtypes : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>dtypesIfCUDA : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>dtypesIfHpu : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>dtypesIfROCM : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>dtypesIfXPU : Optional[_dispatch_dtypes]<br ALIGN="LEFT"/>dynamic_dtypes<br ALIGN="LEFT"/>error_inputs_func : Optional[Callable]<br ALIGN="LEFT"/>error_inputs_sparse_func : Optional[Callable]<br ALIGN="LEFT"/>formatted_name<br ALIGN="LEFT"/>full_name<br ALIGN="LEFT"/>gradcheck_fast_mode : Optional[bool]<br ALIGN="LEFT"/>gradcheck_nondet_tol : float<br ALIGN="LEFT"/>gradcheck_wrapper : Callable<br ALIGN="LEFT"/>inplace_operator_variant : Callable<br ALIGN="LEFT"/>inplace_variant : Callable<br ALIGN="LEFT"/>is_factory_function : bool<br ALIGN="LEFT"/>method_variant : Callable<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>op : Optional[Callable]<br ALIGN="LEFT"/>operator_variant : Callable<br ALIGN="LEFT"/>promotes_int_to_float : bool<br ALIGN="LEFT"/>ref : Optional[Callable]<br ALIGN="LEFT"/>reference_inputs_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_sparse_bsc_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_sparse_bsr_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_sparse_coo_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_sparse_csc_func : Optional[Callable]<br ALIGN="LEFT"/>sample_inputs_sparse_csr_func : Optional[Callable]<br ALIGN="LEFT"/>skip_correctness_check_compile_vs_eager : bool<br ALIGN="LEFT"/>skip_cow_input_backward : bool<br ALIGN="LEFT"/>skips : Tuple<br ALIGN="LEFT"/>supports_autograd : bool<br ALIGN="LEFT"/>supports_cow_input_no_materialize_backward : bool<br ALIGN="LEFT"/>supports_cow_input_no_materialize_forward : bool<br ALIGN="LEFT"/>supports_expanded_weight : bool<br ALIGN="LEFT"/>supports_forward_ad : bool<br ALIGN="LEFT"/>supports_fwgrad_bwgrad : bool<br ALIGN="LEFT"/>supports_gradgrad : Optional[bool]<br ALIGN="LEFT"/>supports_inplace_autograd : Optional[bool]<br ALIGN="LEFT"/>supports_njt : Optional[bool]<br ALIGN="LEFT"/>supports_out : bool<br ALIGN="LEFT"/>supports_scripting : bool<br ALIGN="LEFT"/>supports_sparse : Optional[bool]<br ALIGN="LEFT"/>supports_sparse_bsc : Optional[bool]<br ALIGN="LEFT"/>supports_sparse_bsr : Optional[bool]<br ALIGN="LEFT"/>supports_sparse_csc : Optional[bool]<br ALIGN="LEFT"/>supports_sparse_csr : Optional[bool]<br ALIGN="LEFT"/>supports_tracing : bool<br ALIGN="LEFT"/>supports_varargs : bool<br ALIGN="LEFT"/>test_conjugated_samples : bool<br ALIGN="LEFT"/>test_neg_view : bool<br ALIGN="LEFT"/>variant_test_name : str<br ALIGN="LEFT"/>|conjugate_sample_inputs(device, dtype, requires_grad)<br ALIGN="LEFT"/>error_inputs(device)<br ALIGN="LEFT"/>error_inputs_sparse(device, layout)<br ALIGN="LEFT"/>get_decorators(test_class, test_name, device, dtype, param_kwargs)<br ALIGN="LEFT"/>get_inplace()<br ALIGN="LEFT"/>get_inplace_operator()<br ALIGN="LEFT"/>get_method()<br ALIGN="LEFT"/>get_op()<br ALIGN="LEFT"/>get_operator()<br ALIGN="LEFT"/>reference_inputs(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse(layout, device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse_bsc(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse_bsr(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse_coo(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse_csc(device, dtype, requires_grad)<br ALIGN="LEFT"/>sample_inputs_sparse_csr(device, dtype, requires_grad)<br ALIGN="LEFT"/>supported_backward_dtypes(device_type)<br ALIGN="LEFT"/>supported_dtypes(device_type)<br ALIGN="LEFT"/>supports_dtype(dtype, device_type): bool<br ALIGN="LEFT"/>supports_sparse_layout(layout)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.registration.OpName" [color="black", fontcolor="black", label=<{OpName|namespace : str<br ALIGN="LEFT"/>op_name : str<br ALIGN="LEFT"/>overload : str<br ALIGN="LEFT"/>|from_builtin_function(builtin_function: types.BuiltinFunctionType): OpName<br ALIGN="LEFT"/>from_name_parts(namespace: str, op_name: str, overload: str \| None): OpName<br ALIGN="LEFT"/>from_op_overload(op_overload: torch._ops.OpOverload): OpName<br ALIGN="LEFT"/>from_qualified_name(qualified_name: str): OpName<br ALIGN="LEFT"/>qualified_name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops.OpOverload" [color="black", fontcolor="black", label=<{OpOverload|is_view<br ALIGN="LEFT"/>namespace<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>overloadpacket<br ALIGN="LEFT"/>tags<br ALIGN="LEFT"/>|decompose()<br ALIGN="LEFT"/>has_kernel_for_any_dispatch_key(ks)<br ALIGN="LEFT"/>has_kernel_for_dispatch_key(k)<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>redispatch()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops.OpOverloadPacket" [color="black", fontcolor="black", label=<{OpOverloadPacket|op<br ALIGN="LEFT"/>|overloads()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.OpOverrides" [color="black", fontcolor="black", label=<{OpOverrides|<br ALIGN="LEFT"/>|bitwise_and(x, y)<br ALIGN="LEFT"/>bitwise_left_shift(x, y)<br ALIGN="LEFT"/>bitwise_not(x)<br ALIGN="LEFT"/>bitwise_or(x, y)<br ALIGN="LEFT"/>bitwise_right_shift(x, y)<br ALIGN="LEFT"/>bitwise_xor(x, y)<br ALIGN="LEFT"/>constant(value, dtype)<br ALIGN="LEFT"/>int_truediv(a, b)<br ALIGN="LEFT"/>libdevice_abs(x)<br ALIGN="LEFT"/>libdevice_cos(x)<br ALIGN="LEFT"/>libdevice_exp(x)<br ALIGN="LEFT"/>libdevice_log(x)<br ALIGN="LEFT"/>libdevice_sigmoid(x)<br ALIGN="LEFT"/>libdevice_sin(x)<br ALIGN="LEFT"/>libdevice_sqrt(x)<br ALIGN="LEFT"/>load_seed(name, offset)<br ALIGN="LEFT"/>logical_not(a)<br ALIGN="LEFT"/>paren(string: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sink_noclone.OpPatcher" [color="black", fontcolor="black", label=<{OpPatcher|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._building.OpRecorder" [color="black", fontcolor="black", label=<{OpRecorder|constant_farm : dict[Any, ir.Value]<br ALIGN="LEFT"/>functions : dict[ir.OperatorIdentifier, onnxscript.OnnxFunction \| ir.Function]<br ALIGN="LEFT"/>nodes : list[ir.Node]<br ALIGN="LEFT"/>opset<br ALIGN="LEFT"/>|eval(schema: onnx.defs.OpSchema, args: Sequence[AllowedArgType], kwargs: Mapping[str, AllowedArgType]): _tensors.SymbolicTensor \| Sequence[_tensors.SymbolicTensor]<br ALIGN="LEFT"/>eval_function(function: onnxscript.OnnxFunction, args: Sequence[AllowedArgType], kwargs: Mapping[str, AllowedArgType]): _tensors.SymbolicTensor \| Sequence[_tensors.SymbolicTensor] \| bool \| int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.OpSchema" [color="black", fontcolor="black", label=<{OpSchema|args_schema : Tuple<br ALIGN="LEFT"/>args_spec<br ALIGN="LEFT"/>args_strategy<br ALIGN="LEFT"/>has_symints : bool<br ALIGN="LEFT"/>kwargs_schema : Dict<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>schema_info : Optional[RuntimeSchemaInfo]<br ALIGN="LEFT"/>|arg_type_tensor_or_tensor_list_like(arg_idx: int): bool<br ALIGN="LEFT"/>gen_fake_args(): ArgsType<br ALIGN="LEFT"/>gen_fake_kwargs(): KwargsType<br ALIGN="LEFT"/>return_type_tensor(): bool<br ALIGN="LEFT"/>return_type_tuple_tensor_like(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._schemas.OpSignature" [color="black", fontcolor="black", label=<{OpSignature|domain : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>opset_version : int \| None<br ALIGN="LEFT"/>outputs : Sequence[Parameter]<br ALIGN="LEFT"/>overload : str<br ALIGN="LEFT"/>params : Sequence[Parameter \| AttributeParameter]<br ALIGN="LEFT"/>params_map : Mapping[str, Parameter \| AttributeParameter]<br ALIGN="LEFT"/>|from_function(func, domain: str, name: str \| None, overload: str): OpSignature<br ALIGN="LEFT"/>from_opschema(opschema: onnx.defs.OpSchema): OpSignature<br ALIGN="LEFT"/>get(name: str): Parameter \| AttributeParameter<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.OpStrategy" [color="black", fontcolor="black", label=<{OpStrategy|mesh_shape<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>strategies : List[PlacementStrategy], list<br ALIGN="LEFT"/>|max_num_shards(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.operator_support.OpSupports" [color="black", fontcolor="black", label=<{OpSupports|<br ALIGN="LEFT"/>|decline_if_input_dtype(dtype: torch.dtype): OperatorSupportBase<br ALIGN="LEFT"/>decline_if_node_in_names(disallow_set: t.Set[str]): OperatorSupportBase<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.OpTree" [color="black", fontcolor="black", label=<{OpTree|sorted_nodes<br ALIGN="LEFT"/>|dfs(): Iterator[_ProfilerEvent]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.partitioners.OpTypes" [color="black", fontcolor="black", label=<{OpTypes|compute_intensive_ops : Set[Callable]<br ALIGN="LEFT"/>fusible_ops : Set[Callable]<br ALIGN="LEFT"/>random_ops : Set[Callable]<br ALIGN="LEFT"/>recomputable_ops : Set[Callable]<br ALIGN="LEFT"/>view_ops : Set[Callable]<br ALIGN="LEFT"/>|is_compute_intensive(node: fx.Node)<br ALIGN="LEFT"/>is_fusible(node: fx.Node)<br ALIGN="LEFT"/>is_random(node: fx.Node)<br ALIGN="LEFT"/>is_recomputable(node: fx.Node)<br ALIGN="LEFT"/>is_view(node: fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.make_opaque_unary_fn.OpaqueUnaryFn" [color="black", fontcolor="black", label=<{OpaqueUnaryFn|<br ALIGN="LEFT"/>|eval(a)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.Operand" [color="black", fontcolor="black", label=<{Operand|dim_order<br ALIGN="LEFT"/>op_type : int<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>shape : Tuple[int, ...]<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|use_nchw()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.OperandValueSourceType" [color="black", fontcolor="black", label=<{OperandValueSourceType|IMMEDIATE : int<br ALIGN="LEFT"/>NUMBERED_BUFFER : int<br ALIGN="LEFT"/>NUMBERED_MEMORY : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Operation" [color="black", fontcolor="black", label=<{Operation|operation_name : Optional[str]<br ALIGN="LEFT"/>|<I>get_device</I>(): Optional[torch.device]<br ALIGN="LEFT"/>get_operation_name(): str<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_origins(): OrderedSet[Any]<br ALIGN="LEFT"/><I>get_outputs</I>(): List[Buffer]<br ALIGN="LEFT"/>get_read_names(): OrderedSet[str]<br ALIGN="LEFT"/><I>get_read_writes</I>(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reads(): OrderedSet[Dep]<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>get_workspace_size(): int<br ALIGN="LEFT"/>is_extern(): bool<br ALIGN="LEFT"/>is_no_op(): bool<br ALIGN="LEFT"/>is_user_of(name: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.OperationBuffer" [color="black", fontcolor="black", label=<{OperationBuffer|get_operation_name<br ALIGN="LEFT"/>|get_defining_op(): Operation<br ALIGN="LEFT"/>get_outputs(): List[Buffer]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops.OperatorBase" [color="black", fontcolor="black", label=<{OperatorBase|functorch_table : dict<br ALIGN="LEFT"/>py_kernels : Dict[DispatchKey, Callable[..., Any]]<br ALIGN="LEFT"/>python_key_table : Dict[Union[Type[TorchDispatchMode], Type[torch.Tensor]], Callable[..., Any]]<br ALIGN="LEFT"/>|has_kernel_for_any_dispatch_key(ks)<br ALIGN="LEFT"/>has_kernel_for_dispatch_key(k)<br ALIGN="LEFT"/><I>name</I>()<br ALIGN="LEFT"/>py_functionalize_impl(fn: _F): _F<br ALIGN="LEFT"/>py_impl(k: Any): Callable[[_F], _F]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer_utils.OperatorConfig" [color="black", fontcolor="black", label=<{OperatorConfig|config<br ALIGN="LEFT"/>operators : List[OperatorPatternType]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.exc.OperatorIssue" [color="black", fontcolor="red", label=<{OperatorIssue|<br ALIGN="LEFT"/>|operator_str(target: Any, args: List[Any], kwargs: dict[str, Any]): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.operator_support.OperatorSupport" [color="black", fontcolor="black", label=<{OperatorSupport|<br ALIGN="LEFT"/>|is_node_supported(submodules: t.Mapping[str, torch.nn.Module], node: torch.fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.operator_support.OperatorSupportBase" [color="black", fontcolor="black", label=<{OperatorSupportBase|<br ALIGN="LEFT"/>|<I>is_node_supported</I>(submodules: t.Mapping[str, torch.nn.Module], node: torch.fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ops_handler.OpsHandler" [color="black", fontcolor="black", label=<{OpsHandler|<br ALIGN="LEFT"/>|abs(x0: T): T<br ALIGN="LEFT"/>acos(x0: T): T<br ALIGN="LEFT"/>acosh(x0: T): T<br ALIGN="LEFT"/>add(x0: T, x1: T): T<br ALIGN="LEFT"/>airy_ai(x: T): T<br ALIGN="LEFT"/>and_(x0: T, x1: T): T<br ALIGN="LEFT"/>asin(x0: T): T<br ALIGN="LEFT"/>asinh(x0: T): T<br ALIGN="LEFT"/>atan(x0: T): T<br ALIGN="LEFT"/>atan2(x0: T, x1: T): T<br ALIGN="LEFT"/>atanh(x0: T): T<br ALIGN="LEFT"/>bessel_j0(x: T): T<br ALIGN="LEFT"/>bessel_j1(x: T): T<br ALIGN="LEFT"/>bessel_y0(x: T): T<br ALIGN="LEFT"/>bessel_y1(x: T): T<br ALIGN="LEFT"/>bitwise_and(x0: T, x1: T): T<br ALIGN="LEFT"/>bitwise_left_shift(x0: T, x1: T): T<br ALIGN="LEFT"/>bitwise_not(x0: T): T<br ALIGN="LEFT"/>bitwise_or(x0: T, x1: T): T<br ALIGN="LEFT"/>bitwise_right_shift(x0: T, x1: T): T<br ALIGN="LEFT"/>bitwise_xor(x0: T, x1: T): T<br ALIGN="LEFT"/>bucketize(values: T, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[T]): T<br ALIGN="LEFT"/>ceil(x0: T): T<br ALIGN="LEFT"/>ceil_to_int(x: T, dtype: torch.dtype): T<br ALIGN="LEFT"/>chebyshev_polynomial_t(x: T, y: T): T<br ALIGN="LEFT"/>chebyshev_polynomial_u(x: T, y: T): T<br ALIGN="LEFT"/>chebyshev_polynomial_v(x: T, y: T): T<br ALIGN="LEFT"/>chebyshev_polynomial_w(x: T, y: T): T<br ALIGN="LEFT"/>constant(value: Union[bool, float, int], dtype: torch.dtype): T<br ALIGN="LEFT"/>copysign(x0: T, x1: T): T<br ALIGN="LEFT"/>cos(x0: T): T<br ALIGN="LEFT"/>cosh(x0: T): T<br ALIGN="LEFT"/>digamma(x: T): T<br ALIGN="LEFT"/>div(x0: T, x1: T): T<br ALIGN="LEFT"/>eq(x0: T, x1: T): T<br ALIGN="LEFT"/>erf(x0: T): T<br ALIGN="LEFT"/>erfc(x0: T): T<br ALIGN="LEFT"/>erfcx(x: T): T<br ALIGN="LEFT"/>erfinv(x0: T): T<br ALIGN="LEFT"/>exp(x0: T): T<br ALIGN="LEFT"/>exp2(x0: T): T<br ALIGN="LEFT"/>expm1(x0: T): T<br ALIGN="LEFT"/>floor(x0: T): T<br ALIGN="LEFT"/>floor_to_int(x: T, dtype: torch.dtype): T<br ALIGN="LEFT"/>floordiv(x0: T, x1: T): T<br ALIGN="LEFT"/>fma(x: T, y: T, z: T): T<br ALIGN="LEFT"/>fmod(x0: T, x1: T): T<br ALIGN="LEFT"/>frexp(x0: T)<br ALIGN="LEFT"/>gammainc(x: T, y: T): T<br ALIGN="LEFT"/>gammaincc(x: T, y: T): T<br ALIGN="LEFT"/>ge(x0: T, x1: T): T<br ALIGN="LEFT"/>getitem(x0: T, x1: T): T<br ALIGN="LEFT"/>gt(x0: T, x1: T): T<br ALIGN="LEFT"/>hermite_polynomial_h(x: T, y: T): T<br ALIGN="LEFT"/>hermite_polynomial_he(x: T, y: T): T<br ALIGN="LEFT"/>hypot(x0: T, x1: T): T<br ALIGN="LEFT"/>i0(x: T): T<br ALIGN="LEFT"/>i0e(x: T): T<br ALIGN="LEFT"/>i1(x: T): T<br ALIGN="LEFT"/>i1e(x: T): T<br ALIGN="LEFT"/>identity(x: T): T<br ALIGN="LEFT"/>igamma(x: T, y: T): T<br ALIGN="LEFT"/>igammac(x: T, y: T): T<br ALIGN="LEFT"/>index_expr(expr: sympy.Expr, dtype: torch.dtype): T<br ALIGN="LEFT"/>indirect_indexing(x: T, size: sympy.Expr, check: bool, wrap_neg): sympy.Expr<br ALIGN="LEFT"/>int_truediv(x0: T, x1: T): T<br ALIGN="LEFT"/>invert(x0: T): T<br ALIGN="LEFT"/>isinf(x0: T): T<br ALIGN="LEFT"/>isnan(x0: T): T<br ALIGN="LEFT"/>laguerre_polynomial_l(x: T, y: T): T<br ALIGN="LEFT"/>le(x0: T, x1: T): T<br ALIGN="LEFT"/>legendre_polynomial_p(x: T, y: T): T<br ALIGN="LEFT"/>lgamma(x0: T): T<br ALIGN="LEFT"/>libdevice_abs(x0: T): T<br ALIGN="LEFT"/>libdevice_cos(x0: T): T<br ALIGN="LEFT"/>libdevice_exp(x0: T): T<br ALIGN="LEFT"/>libdevice_log(x0: T): T<br ALIGN="LEFT"/>libdevice_sigmoid(x0: T): T<br ALIGN="LEFT"/>libdevice_sin(x0: T): T<br ALIGN="LEFT"/>libdevice_sqrt(x0: T): T<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr): T<br ALIGN="LEFT"/>load_seed(name: str, offset: T)<br ALIGN="LEFT"/>log(x0: T): T<br ALIGN="LEFT"/>log10(x0: T): T<br ALIGN="LEFT"/>log1p(x0: T): T<br ALIGN="LEFT"/>log2(x0: T): T<br ALIGN="LEFT"/>log_ndtr(x: T): T<br ALIGN="LEFT"/>logical_and(x0: T, x1: T): T<br ALIGN="LEFT"/>logical_not(x0: T): T<br ALIGN="LEFT"/>logical_or(x0: T, x1: T): T<br ALIGN="LEFT"/>logical_xor(x0: T, x1: T): T<br ALIGN="LEFT"/>lshift(x0: T, x1: T): T<br ALIGN="LEFT"/>lt(x0: T, x1: T): T<br ALIGN="LEFT"/>masked(mask: T, body: Callable[[], T], other: T): T<br ALIGN="LEFT"/>matmul(x0: T, x1: T): T<br ALIGN="LEFT"/>maximum(x0: T, x1: T): T<br ALIGN="LEFT"/>minimum(x0: T, x1: T): T<br ALIGN="LEFT"/>mod(x0: T, x1: T): T<br ALIGN="LEFT"/>modified_bessel_i0(x: T): T<br ALIGN="LEFT"/>modified_bessel_i1(x: T): T<br ALIGN="LEFT"/>modified_bessel_k0(x: T): T<br ALIGN="LEFT"/>modified_bessel_k1(x: T): T<br ALIGN="LEFT"/>mul(x0: T, x1: T): T<br ALIGN="LEFT"/>ndtr(x: T): T<br ALIGN="LEFT"/>ndtri(x: T): T<br ALIGN="LEFT"/>ne(x0: T, x1: T): T<br ALIGN="LEFT"/>neg(x0: T): T<br ALIGN="LEFT"/>nextafter(x0: T, x1: T): T<br ALIGN="LEFT"/>or_(x0: T, x1: T): T<br ALIGN="LEFT"/>polygamma(x: T, y: T): T<br ALIGN="LEFT"/>pow(x0: T, x1: T): T<br ALIGN="LEFT"/>rand(seed: T, offset: T): T<br ALIGN="LEFT"/>randint64(seed: T, offset: T, low: T, high: T): T<br ALIGN="LEFT"/>randn(seed: T, offset: T): T<br ALIGN="LEFT"/>reciprocal(x0: T): T<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: T): Union[T, Tuple[T, ...]]<br ALIGN="LEFT"/>relu(x0: T): T<br ALIGN="LEFT"/>remainder(x0: T, x1: T): T<br ALIGN="LEFT"/>round(x0: T): T<br ALIGN="LEFT"/>round_decimal(x0: T, x1: T): T<br ALIGN="LEFT"/>round_to_int(x: T, dtype: torch.dtype): T<br ALIGN="LEFT"/>rshift(x0: T, x1: T): T<br ALIGN="LEFT"/>rsqrt(x0: T): T<br ALIGN="LEFT"/>scaled_modified_bessel_k0(x: T): T<br ALIGN="LEFT"/>scaled_modified_bessel_k1(x: T): T<br ALIGN="LEFT"/>scan(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[T, ...], Tuple[T, ...]], Tuple[T, ...]], values: Tuple[T, ...]): Tuple[T, ...]<br ALIGN="LEFT"/>shifted_chebyshev_polynomial_t(x: T, y: T): T<br ALIGN="LEFT"/>shifted_chebyshev_polynomial_u(x: T, y: T): T<br ALIGN="LEFT"/>shifted_chebyshev_polynomial_v(x: T, y: T): T<br ALIGN="LEFT"/>shifted_chebyshev_polynomial_w(x: T, y: T): T<br ALIGN="LEFT"/>sigmoid(x0: T): T<br ALIGN="LEFT"/>sign(x0: T): T<br ALIGN="LEFT"/>signbit(x0: T): T<br ALIGN="LEFT"/>sin(x0: T): T<br ALIGN="LEFT"/>sinh(x0: T): T<br ALIGN="LEFT"/>sort(dtypes: Tuple[torch.dtype, ...], values: Tuple[T, ...], stable: bool, descending: bool): Tuple[T, ...]<br ALIGN="LEFT"/>spherical_bessel_j0(x: T): T<br ALIGN="LEFT"/>sqrt(x0: T): T<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: T, mode: StoreMode): None<br ALIGN="LEFT"/>store_reduction(name: str, index: sympy.Expr, value: T): T<br ALIGN="LEFT"/>sub(x0: T, x1: T): T<br ALIGN="LEFT"/>tan(x0: T): T<br ALIGN="LEFT"/>tanh(x0: T): T<br ALIGN="LEFT"/>to_dtype(x: T, dtype: torch.dtype, src_dtype: Optional[torch.dtype], use_compute_types): T<br ALIGN="LEFT"/>to_dtype_bitcast(x: T, dtype: torch.dtype, src_dtype: torch.dtype): T<br ALIGN="LEFT"/>truediv(x0: T, x1: T): T<br ALIGN="LEFT"/>trunc(x0: T): T<br ALIGN="LEFT"/>trunc_to_int(x: T, dtype: torch.dtype): T<br ALIGN="LEFT"/>truncdiv(x0: T, x1: T): T<br ALIGN="LEFT"/>where(condition: T, input: T, other: T): T<br ALIGN="LEFT"/>xor(x0: T, x1: T): T<br ALIGN="LEFT"/>zeta(x: T, y: T): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.virtualized.OpsValue" [color="black", fontcolor="black", label=<{OpsValue|value : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.virtualized.OpsWrapper" [color="black", fontcolor="black", label=<{OpsWrapper|<br ALIGN="LEFT"/>|indirect_indexing(index, size, check, wrap_neg)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.opt_einsum.OptEinsumModule" [color="black", fontcolor="black", label=<{OptEinsumModule|enabled<br ALIGN="LEFT"/>strategy : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.amp.grad_scaler.OptState" [color="black", fontcolor="black", label=<{OptState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.OptimStateDictConfig" [color="black", fontcolor="black", label=<{OptimStateDictConfig|offload_to_cpu : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.fully_sharded_data_parallel.OptimStateKeyType" [color="black", fontcolor="black", label=<{OptimStateKeyType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.OptimizationContext" [color="black", fontcolor="black", label=<{OptimizationContext|dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>key : ClassVar[str]<br ALIGN="LEFT"/>ops_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.OptimizeContext" [color="black", fontcolor="black", label=<{OptimizeContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.OptimizedModule" [color="black", fontcolor="black", label=<{OptimizedModule|dynamo_ctx<br ALIGN="LEFT"/>forward<br ALIGN="LEFT"/>get_compiler_config : Callable[[], Any]<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.reference.OptimizedPythonReferenceAnalysis" [color="black", fontcolor="black", label=<{OptimizedPythonReferenceAnalysis|<br ALIGN="LEFT"/>|sym_sum(args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.optimizer.Optimizer" [color="black", fontcolor="black", label=<{Optimizer|OptimizerPostHook : TypeAlias, _ExtensionsSpecialForm<br ALIGN="LEFT"/>OptimizerPreHook : TypeAlias, _ExtensionsSpecialForm<br ALIGN="LEFT"/>defaults : Dict[str, Any]<br ALIGN="LEFT"/>param_groups : List[Dict[str, Any]]<br ALIGN="LEFT"/>state : DefaultDict[torch.Tensor, Any]<br ALIGN="LEFT"/>|add_param_group(param_group: Dict[str, Any]): None<br ALIGN="LEFT"/>load_state_dict(state_dict: StateDict): None<br ALIGN="LEFT"/>profile_hook_step(func: Callable[_P, R]): Callable[_P, R]<br ALIGN="LEFT"/>register_load_state_dict_post_hook(hook: Callable[['Optimizer'], None], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_load_state_dict_pre_hook(hook: Callable[['Optimizer', StateDict], Optional[StateDict]], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_state_dict_post_hook(hook: Callable[['Optimizer', StateDict], Optional[StateDict]], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_state_dict_pre_hook(hook: Callable[['Optimizer'], None], prepend: bool): RemovableHandle<br ALIGN="LEFT"/>register_step_post_hook(hook: OptimizerPostHook): RemovableHandle<br ALIGN="LEFT"/>register_step_pre_hook(hook: OptimizerPreHook): RemovableHandle<br ALIGN="LEFT"/>state_dict(): StateDict<br ALIGN="LEFT"/>step(closure: None): None<br ALIGN="LEFT"/>zero_grad(set_to_none: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.OptimizerErrorEnum" [color="black", fontcolor="black", label=<{OptimizerErrorEnum|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.OptimizerFailingOnConstructor" [color="black", fontcolor="black", label=<{OptimizerFailingOnConstructor|<br ALIGN="LEFT"/>|<I>step</I>(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.OptimizerInfo" [color="black", fontcolor="black", label=<{OptimizerInfo|decorators : tuple<br ALIGN="LEFT"/>has_capturable_arg : bool<br ALIGN="LEFT"/>metadata_for_sparse : tuple<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>not_og_supported_flags : tuple<br ALIGN="LEFT"/>only_supports_sparse_grads : bool<br ALIGN="LEFT"/>optim_cls<br ALIGN="LEFT"/>optim_error_inputs_func : NoneType<br ALIGN="LEFT"/>optim_inputs_func<br ALIGN="LEFT"/>scheduler_inputs : tuple<br ALIGN="LEFT"/>step_requires_closure : bool<br ALIGN="LEFT"/>supported_impls : tuple<br ALIGN="LEFT"/>supports_complex : bool<br ALIGN="LEFT"/>supports_fused_on : tuple<br ALIGN="LEFT"/>supports_multiple_devices : bool<br ALIGN="LEFT"/>supports_param_groups : bool<br ALIGN="LEFT"/>supports_sparse : bool<br ALIGN="LEFT"/>|get_decorators(test_class, test_name, device, dtype, param_kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.OptimizerInput" [color="black", fontcolor="black", label=<{OptimizerInput|desc : str<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>params : Union[List[Parameter], List[Tensor], Dict[Any, Any], List[Dict[str, Any]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.OptimizerSingleTensorPattern" [color="black", fontcolor="black", label=<{OptimizerSingleTensorPattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>optimizers_with_foreach : list<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.OptimizerSource" [color="black", fontcolor="black", label=<{OptimizerSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.optimizer.OptimizerVariable" [color="black", fontcolor="black", label=<{OptimizerVariable|grad_to_source : dict<br ALIGN="LEFT"/>static_tensor_names : set<br ALIGN="LEFT"/>tensor_to_source : dict<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create_finalizer(tx)<br ALIGN="LEFT"/>get_python_args()<br ALIGN="LEFT"/>graph_break_if_pending_mutation(tx)<br ALIGN="LEFT"/>map_sources_and_install_guards(tx)<br ALIGN="LEFT"/>move_step_if_cpu()<br ALIGN="LEFT"/>update_list_args(tx: 'InstructionTranslator', args, kwargs, py_args, py_kwargs)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>wrap_tensor(tx: 'InstructionTranslator', tensor_value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.optional_input.OptionalInput" [color="black", fontcolor="black", label=<{OptionalInput|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.OptionalTensorArgument" [color="black", fontcolor="black", label=<{OptionalTensorArgument|as_none : Annotated[bool, 10]<br ALIGN="LEFT"/>as_tensor : Annotated[TensorArgument, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._script.OrderedDictWrapper" [color="black", fontcolor="black", label=<{OrderedDictWrapper|<br ALIGN="LEFT"/>|items()<br ALIGN="LEFT"/>keys()<br ALIGN="LEFT"/>values()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.cpp.OrderedDictWrapper" [color="black", fontcolor="black", label=<{OrderedDictWrapper|attr<br ALIGN="LEFT"/>cpp_dict<br ALIGN="LEFT"/>cpp_module<br ALIGN="LEFT"/>|items()<br ALIGN="LEFT"/>keys()<br ALIGN="LEFT"/>values()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.importer.OrderedImporter" [color="black", fontcolor="black", label=<{OrderedImporter|<br ALIGN="LEFT"/>|import_module(module_name: str): ModuleType<br ALIGN="LEFT"/>whichmodule(obj: Any, name: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script.OrderedModuleDict" [color="black", fontcolor="black", label=<{OrderedModuleDict|<br ALIGN="LEFT"/>|items()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._ordered_set.OrderedSet" [color="black", fontcolor="black", label=<{OrderedSet|<br ALIGN="LEFT"/>|add(elem: T): None<br ALIGN="LEFT"/>clear(): None<br ALIGN="LEFT"/>copy(): OrderedSet[T]<br ALIGN="LEFT"/>difference(): OrderedSet[T]<br ALIGN="LEFT"/>difference_update(): None<br ALIGN="LEFT"/>discard(elem: T): None<br ALIGN="LEFT"/>intersection(): OrderedSet[T]<br ALIGN="LEFT"/>intersection_update(): None<br ALIGN="LEFT"/>issubset(other: Iterable[T]): bool<br ALIGN="LEFT"/>issuperset(other: Iterable[T]): bool<br ALIGN="LEFT"/>pop(): T<br ALIGN="LEFT"/>symmetric_difference(other: Iterable[T]): OrderedSet[T]<br ALIGN="LEFT"/>symmetric_difference_update(other: Iterable[T]): None<br ALIGN="LEFT"/>union(): OrderedSet[T]<br ALIGN="LEFT"/>update(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.OrderedSetHolder" [color="black", fontcolor="black", label=<{OrderedSetHolder|items : List[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.onnxruntime.OrtBackend" [color="black", fontcolor="black", label=<{OrtBackend|execution_count : int<br ALIGN="LEFT"/>preallocate_output : bool<br ALIGN="LEFT"/>run<br ALIGN="LEFT"/>|clear_cached_instances()<br ALIGN="LEFT"/>compile(graph_module: torch.fx.GraphModule, args): torch.fx.GraphModule<br ALIGN="LEFT"/>get_cached_instance_for_options(options: Optional[Union[OrtBackendOptions, Mapping[str, Any]]]): 'OrtBackend'<br ALIGN="LEFT"/>get_cached_instances()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.onnxruntime.OrtBackendOptions" [color="black", fontcolor="black", label=<{OrtBackendOptions|default_execution_providers : Optional[Sequence[OrtExecutionProvider]]<br ALIGN="LEFT"/>export_options : Optional['torch.onnx.ExportOptions']<br ALIGN="LEFT"/>infer_execution_providers : bool<br ALIGN="LEFT"/>ort_session_options : Optional['onnxruntime.SessionOptions']<br ALIGN="LEFT"/>pre_ort_model_transforms : Optional[Sequence[Callable[['onnx.ModelProto'], None]]]<br ALIGN="LEFT"/>preallocate_output : bool<br ALIGN="LEFT"/>preferred_execution_providers : Optional[Sequence[OrtExecutionProvider]]<br ALIGN="LEFT"/>use_aot_autograd : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.onnxruntime.OrtExecutionInfoForAllGraphModules" [color="black", fontcolor="black", label=<{OrtExecutionInfoForAllGraphModules|execution_info_per_graph_module : Dict[torch.fx.GraphModule, List[OrtExecutionInfoPerSession]]<br ALIGN="LEFT"/>|cache_session_execution_info(graph_module: torch.fx.GraphModule, info: OrtExecutionInfoPerSession)<br ALIGN="LEFT"/>search_reusable_session_execution_info(graph_module: torch.fx.GraphModule)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.onnxruntime.OrtExecutionInfoPerSession" [color="black", fontcolor="black", label=<{OrtExecutionInfoPerSession|example_outputs : Union[Tuple[torch.Tensor, ...], torch.Tensor]<br ALIGN="LEFT"/>input_devices : Tuple[ORTC.OrtDevice, ...]<br ALIGN="LEFT"/>input_names : Tuple[str, ...]<br ALIGN="LEFT"/>input_value_infos : Tuple[onnx.ValueInfoProto, ...]<br ALIGN="LEFT"/>output_devices : Tuple[ORTC.OrtDevice, ...]<br ALIGN="LEFT"/>output_names : Tuple[str, ...]<br ALIGN="LEFT"/>output_value_infos : Tuple[onnx.ValueInfoProto, ...]<br ALIGN="LEFT"/>session<br ALIGN="LEFT"/>|is_supported()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.onnxruntime.OrtOperatorSupport" [color="black", fontcolor="black", label=<{OrtOperatorSupport|<br ALIGN="LEFT"/>|is_node_supported(submodules: Mapping[str, torch.nn.Module], node: torch.fx.Node): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache._worker_task_halide.Out" [color="black", fontcolor="black", label=<{Out|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.OutDtypeHigherOrderVariable" [color="black", fontcolor="black", label=<{OutDtypeHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.out_dtype.OutDtypeOperator" [color="black", fontcolor="black", label=<{OutDtypeOperator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.OuterLoopFusedKernel" [color="black", fontcolor="black", label=<{OuterLoopFusedKernel|inner : List[LoopNest]<br ALIGN="LEFT"/>|decide_parallel_depth(max_parallel_depth, threads): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.OuterLoopFusedSchedulerNode" [color="black", fontcolor="black", label=<{OuterLoopFusedSchedulerNode|outer_fused_nodes : List[Union[FusedSchedulerNode, SchedulerNode]]<br ALIGN="LEFT"/>outer_loop_fusion_depth<br ALIGN="LEFT"/>|check_outer_fusion_loop_level_attr(cpp_kernel_proxy_list, outer_loop_fusion_depth)<br ALIGN="LEFT"/>fuse(node1: BaseSchedulerNode, node2: BaseSchedulerNode, outer_loop_fusion_depth)<br ALIGN="LEFT"/>get_outer_nodes()<br ALIGN="LEFT"/>merge_outer_fusion_kernels(cpp_kernel_proxy_list)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.OutlierDetector" [color="black", fontcolor="black", label=<{OutlierDetector|CHANNEL_AXIS_KEY : str<br ALIGN="LEFT"/>COMP_METRIC_KEY : str<br ALIGN="LEFT"/>CONSTANT_COUNTS_KEY : str<br ALIGN="LEFT"/>DEFAULT_PRE_OBSERVER_NAME : str<br ALIGN="LEFT"/>INPUT_ACTIVATION_PREFIX : str<br ALIGN="LEFT"/>IS_SUFFICIENT_BATCHES_KEY : str<br ALIGN="LEFT"/>MAX_VALS_KEY : str<br ALIGN="LEFT"/>NUM_BATCHES_KEY : str<br ALIGN="LEFT"/>OUTLIER_KEY : str<br ALIGN="LEFT"/>RATIO_THRES_KEY : str<br ALIGN="LEFT"/>REF_PERCENTILE_KEY : str<br ALIGN="LEFT"/>ch_axis : int<br ALIGN="LEFT"/>fraction_batches_used_threshold : float<br ALIGN="LEFT"/>ratio_threshold : float<br ALIGN="LEFT"/>reference_percentile : float<br ALIGN="LEFT"/>|determine_observer_insert_points(prepared_fx_model: GraphModule): Dict[str, Dict[str, Any]]<br ALIGN="LEFT"/>generate_detector_report(model: GraphModule): Tuple[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_detector_name(): str<br ALIGN="LEFT"/>get_qconfig_info(model): Dict[str, DetectorQConfigInfo]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.OutputAdaptStep" [color="black", fontcolor="black", label=<{OutputAdaptStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.OutputAdapter" [color="black", fontcolor="black", label=<{OutputAdapter|<br ALIGN="LEFT"/>|append_step(step: OutputAdaptStep): None<br ALIGN="LEFT"/>apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Sequence[torch.Tensor \| int \| float \| bool \| str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.OutputAliasInfo" [color="black", fontcolor="black", label=<{OutputAliasInfo|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.OutputAliasInfo" [color="black", fontcolor="black", label=<{OutputAliasInfo|base_idx : Optional[int]<br ALIGN="LEFT"/>dynamic_dims : Optional[Set[int]]<br ALIGN="LEFT"/>functional_tensor : Optional[FunctionalTensorMetadataEq]<br ALIGN="LEFT"/>output_type : OutputType<br ALIGN="LEFT"/>raw_type : type<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.output_code.OutputCode" [color="black", fontcolor="black", label=<{OutputCode|<br ALIGN="LEFT"/>|<I>post_compile</I>(example_inputs: Sequence[InputType], cudagraphs: BoxedBool, constants: CompiledFxGraphConstants): None<br ALIGN="LEFT"/><I>set_triton_bundle</I>(triton_bundle: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite_fx.OutputComparisonLogger" [color="black", fontcolor="black", label=<{OutputComparisonLogger|comparison_fn<br ALIGN="LEFT"/>comparison_fn_name : str<br ALIGN="LEFT"/>comparisons : list<br ALIGN="LEFT"/>|forward(x, x_ref)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.OutputGraph" [color="black", fontcolor="black", label=<{OutputGraph|backward_state : Dict[str, VariableTracker]<br ALIGN="LEFT"/>backward_state_proxy : Optional[torch.fx.Proxy]<br ALIGN="LEFT"/>backward_state_var : Optional[str]<br ALIGN="LEFT"/>bound_symbols<br ALIGN="LEFT"/>cleanup_hooks : List[Callable[[], Any]]<br ALIGN="LEFT"/>cleanups : List[CleanupHook]<br ALIGN="LEFT"/>co_fields : dict<br ALIGN="LEFT"/>code_options : dict<br ALIGN="LEFT"/>compile_id : int<br ALIGN="LEFT"/>compile_subgraph_reason : Optional[GraphCompileReason]<br ALIGN="LEFT"/>compiler_fn : Optional[CompilerFn]<br ALIGN="LEFT"/>compliant_custom_ops : Set[torch._ops.OpOverload]<br ALIGN="LEFT"/>current_tracer<br ALIGN="LEFT"/>current_tx<br ALIGN="LEFT"/>dynamo_compile_id : Optional[CompileId]<br ALIGN="LEFT"/>dynamo_flat_name_to_original_fqn : Dict[str, str]<br ALIGN="LEFT"/>export : bool<br ALIGN="LEFT"/>export_constraints<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>frame_state<br ALIGN="LEFT"/>global_scope : Dict<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>graphargs<br ALIGN="LEFT"/>guard_on_key_order : Set[str]<br ALIGN="LEFT"/>guards<br ALIGN="LEFT"/>has_user_defined_allowed_in_graph : bool<br ALIGN="LEFT"/>input_name_to_proxy<br ALIGN="LEFT"/>input_source_to_sizes_strides : Dict[Source, Dict[str, Any]]<br ALIGN="LEFT"/>input_source_to_var : Dict[Source, VariableTracker]<br ALIGN="LEFT"/>installed_globals : Set[str]<br ALIGN="LEFT"/>local_scope : Dict<br ALIGN="LEFT"/>name_of_builtins_dict_key_in_fglobals : str<br ALIGN="LEFT"/>nn_modules<br ALIGN="LEFT"/>non_compliant_ops : Set[torch._ops.OpOverload]<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>output_instructions : List[Instruction]<br ALIGN="LEFT"/>param_name_to_source : NoneType, Optional[Dict[str, Source]]<br ALIGN="LEFT"/>partial_convert : bool<br ALIGN="LEFT"/>placeholders<br ALIGN="LEFT"/>pregraph_bytecode : List[Instruction]<br ALIGN="LEFT"/>random_calls : List[Tuple[Callable[..., object], Tuple[object, ...], Dict[str, object]]]<br ALIGN="LEFT"/>random_values_var : NoneType<br ALIGN="LEFT"/>real_value_cache<br ALIGN="LEFT"/>region_tracker<br ALIGN="LEFT"/>register_finalizer_fns : List[Callable[[fx.GraphModule], None]]<br ALIGN="LEFT"/>root_tracer<br ALIGN="LEFT"/>root_tx : NoneType<br ALIGN="LEFT"/>shape_env<br ALIGN="LEFT"/>should_exit : bool<br ALIGN="LEFT"/>side_effects<br ALIGN="LEFT"/>source_to_user_stacks : Dict[Source, List[traceback.StackSummary]]<br ALIGN="LEFT"/>timestamp : int<br ALIGN="LEFT"/>torch_function_enabled : bool<br ALIGN="LEFT"/>torch_function_mode_enabled<br ALIGN="LEFT"/>torch_function_mode_stack<br ALIGN="LEFT"/>tracers : list<br ALIGN="LEFT"/>tracing_context<br ALIGN="LEFT"/>tracked_fakes : List[TrackedFake]<br ALIGN="LEFT"/>tracked_fakes_id_to_source : Dict[int, List[Source]]<br ALIGN="LEFT"/>unique_var_id : count<br ALIGN="LEFT"/>unspec_variable_map : Dict[str, UnspecializedPythonVariable]<br ALIGN="LEFT"/>variable_tracker_cache<br ALIGN="LEFT"/>|add_backward_state_hook(hook: VariableTracker, prefix)<br ALIGN="LEFT"/>add_cleanup_hook(fn: Callable[[], Any])<br ALIGN="LEFT"/>add_graph_finalizer(register_finalizer: Callable[[fx.GraphModule], None]): None<br ALIGN="LEFT"/>add_output_instructions(prefix: List[Instruction]): None<br ALIGN="LEFT"/>call_cleanup_hooks()<br ALIGN="LEFT"/>call_user_compiler(gm: fx.GraphModule): CompiledFn<br ALIGN="LEFT"/>cleanup(): None<br ALIGN="LEFT"/>cleanup_graph()<br ALIGN="LEFT"/>codegen_suffix(tx, stack_values, cg)<br ALIGN="LEFT"/>compile_and_call_fx_graph(tx, rv, root, replaced_outputs)<br ALIGN="LEFT"/>compile_subgraph(tx, partial_convert, reason: Optional[GraphCompileReason])<br ALIGN="LEFT"/>count_calls()<br ALIGN="LEFT"/>create_node()<br ALIGN="LEFT"/>create_proxy()<br ALIGN="LEFT"/>dedup_pass()<br ALIGN="LEFT"/>example_inputs(): List[torch.Tensor]<br ALIGN="LEFT"/>example_value_from_input_node(node: torch.fx.Node)<br ALIGN="LEFT"/>get_backward_state_proxy()<br ALIGN="LEFT"/>get_graph_sizes(name: str)<br ALIGN="LEFT"/>get_graph_sizes_structured()<br ALIGN="LEFT"/>get_submodule(keys)<br ALIGN="LEFT"/>handle_aliases_for_stolen_lists(tx)<br ALIGN="LEFT"/>init_ambient_guards()<br ALIGN="LEFT"/>install_builtins_dict_in_fglobals()<br ALIGN="LEFT"/>install_global(prefix, value): str<br ALIGN="LEFT"/>install_global_by_id(prefix, value): str<br ALIGN="LEFT"/>install_global_unsafe(name, value): None<br ALIGN="LEFT"/>install_subgraph(name, sub_gm)<br ALIGN="LEFT"/>is_empty_graph()<br ALIGN="LEFT"/>is_root_tracer()<br ALIGN="LEFT"/>module_key_name()<br ALIGN="LEFT"/>new_var(name)<br ALIGN="LEFT"/>pop_tx()<br ALIGN="LEFT"/>push_tx(tx)<br ALIGN="LEFT"/>register_attr_or_module(target: Union[torch.nn.Module, torch.Tensor, Any])<br ALIGN="LEFT"/>remove_node()<br ALIGN="LEFT"/>remove_unused_graphargs(): None<br ALIGN="LEFT"/>restore_global_state()<br ALIGN="LEFT"/>run_compiler_collective(tx)<br ALIGN="LEFT"/>save_global_state(out)<br ALIGN="LEFT"/>set_torch_function_state(enabled: bool): None<br ALIGN="LEFT"/>subtracer(source_target, prior_tracer)<br ALIGN="LEFT"/>synthetic_graph_input(fn, args)<br ALIGN="LEFT"/>update_co_names(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.graph_signature.OutputKind" [color="black", fontcolor="black", label=<{OutputKind|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e._numeric_debugger.OutputLogger" [color="black", fontcolor="black", label=<{OutputLogger|debug_handle : int<br ALIGN="LEFT"/>nn_module_stack : Optional[object]<br ALIGN="LEFT"/>node_name : Optional[str]<br ALIGN="LEFT"/>stats : List[torch.Tensor]<br ALIGN="LEFT"/>|forward(x: object): object<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite_fx.OutputLogger" [color="black", fontcolor="black", label=<{OutputLogger|enabled : bool<br ALIGN="LEFT"/>fqn : Optional[str]<br ALIGN="LEFT"/>index_of_arg : int<br ALIGN="LEFT"/>index_within_arg : int<br ALIGN="LEFT"/>model_name : str<br ALIGN="LEFT"/>prev_node_name : str<br ALIGN="LEFT"/>prev_node_target_type : str<br ALIGN="LEFT"/>qconfig_str : Optional[str]<br ALIGN="LEFT"/>ref_name : str<br ALIGN="LEFT"/>ref_node_name : str<br ALIGN="LEFT"/>ref_node_target_type : str<br ALIGN="LEFT"/>results_type : str<br ALIGN="LEFT"/>save_activations : bool<br ALIGN="LEFT"/>stats : List[torch.Tensor]<br ALIGN="LEFT"/>stats_rnn : List[RNNReturnType]<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite.OutputLogger" [color="black", fontcolor="black", label=<{OutputLogger|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.OutputNode" [color="black", fontcolor="black", label=<{OutputNode|unmet_dependencies<br ALIGN="LEFT"/>|get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>is_reduction(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.n_shadows_utils.OutputProp" [color="black", fontcolor="black", label=<{OutputProp|graph<br ALIGN="LEFT"/>mod<br ALIGN="LEFT"/>modules : dict<br ALIGN="LEFT"/>|propagate()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.OutputSharding" [color="black", fontcolor="black", label=<{OutputSharding|needs_redistribute : bool<br ALIGN="LEFT"/>output_spec : Optional<br ALIGN="LEFT"/>redistribute_schema : Optional[OpSchema]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.OutputSpec" [color="black", fontcolor="black", label=<{OutputSpec|<br ALIGN="LEFT"/>|<I>get_device</I>(): Optional[torch.device]<br ALIGN="LEFT"/><I>storage_size</I>(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.OutputSpec" [color="black", fontcolor="black", label=<{OutputSpec|buffer_mutation : Annotated[BufferMutationSpec, 30]<br ALIGN="LEFT"/>gradient_to_parameter : Annotated[GradientToParameterSpec, 40]<br ALIGN="LEFT"/>gradient_to_user_input : Annotated[GradientToUserInputSpec, 50]<br ALIGN="LEFT"/>loss_output : Annotated[LossOutputSpec, 20]<br ALIGN="LEFT"/>token : Annotated[OutputTokenSpec, 70]<br ALIGN="LEFT"/>user_input_mutation : Annotated[UserInputMutationSpec, 60]<br ALIGN="LEFT"/>user_output : Annotated[UserOutputSpec, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.OutputSpec" [color="black", fontcolor="black", label=<{OutputSpec|arg : Union<br ALIGN="LEFT"/>kind<br ALIGN="LEFT"/>target : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.OutputTokenSpec" [color="black", fontcolor="black", label=<{OutputTokenSpec|arg : Annotated[TokenArgument, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms._optimizer_overlap.optimizer_overlap.OverlappedOptimizer" [color="black", fontcolor="black", label=<{OverlappedOptimizer|optim_cls : Type<br ALIGN="LEFT"/>|<I>register_ddp</I>(ddp: DistributedDataParallel): None<br ALIGN="LEFT"/><I>register_fsdp</I>(fsdp: FullyShardedDataParallel): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.registration.OverrideDict" [color="black", fontcolor="black", label=<{OverrideDict|<br ALIGN="LEFT"/>|get(key: _K, default: Optional[_V])<br ALIGN="LEFT"/>in_base(key: _K): bool<br ALIGN="LEFT"/>overridden(key: _K): bool<br ALIGN="LEFT"/>override(key: _K, value: _V): None<br ALIGN="LEFT"/>remove_override(key: _K): None<br ALIGN="LEFT"/>set_base(key: _K, value: _V): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.OverridesData" [color="black", fontcolor="black", label=<{OverridesData|cpp : Callable[..., str]<br ALIGN="LEFT"/>cppvec : Optional[Callable[..., str]]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>triton : Optional[Callable[..., str]]<br ALIGN="LEFT"/>type_promotion_kind : ELEMENTWISE_TYPE_PROMOTION_KIND<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d.P2POp" [color="black", fontcolor="black", label=<{P2POp|group : NoneType<br ALIGN="LEFT"/>group_peer : NoneType<br ALIGN="LEFT"/>op : Callable<br ALIGN="LEFT"/>peer : NoneType<br ALIGN="LEFT"/>tag : int<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.PContext" [color="black", fontcolor="black", label=<{PContext|args : Dict[int, Tuple]<br ALIGN="LEFT"/>entrypoint : Union[Callable, str]<br ALIGN="LEFT"/>envs : Dict[int, Dict[str, str]]<br ALIGN="LEFT"/>error_files<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>nprocs<br ALIGN="LEFT"/>stderrs<br ALIGN="LEFT"/>stdouts<br ALIGN="LEFT"/>|close(death_sig: Optional[signal.Signals], timeout: int): None<br ALIGN="LEFT"/><I>pids</I>(): Dict[int, int]<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>wait(timeout: float, period: float): Optional[RunProcsResult]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace.PHBase" [color="black", fontcolor="black", label=<{PHBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx._symbolic_trace.PHWithMeta" [color="black", fontcolor="black", label=<{PHWithMeta|ph_key : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.PReLU" [color="black", fontcolor="black", label=<{PReLU|num_parameters : int<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|forward(input: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>set_weight(w: torch.Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.PReLU" [color="black", fontcolor="black", label=<{PReLU|init : float<br ALIGN="LEFT"/>num_parameters : int<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>reset_parameters()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.package.package.PT2ArchiveReader" [color="black", fontcolor="black", label=<{PT2ArchiveReader|archive_file : Optional[zipfile.ZipFile]<br ALIGN="LEFT"/>archive_path : str<br ALIGN="LEFT"/>|extract_to_path(member: str, path: str): str<br ALIGN="LEFT"/>extractall(path: str): None<br ALIGN="LEFT"/>get_file_names(): List[str]<br ALIGN="LEFT"/>read(name: str): bytes<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.package.package.PT2ArchiveWriter" [color="black", fontcolor="black", label=<{PT2ArchiveWriter|archive_file : NoneType, Optional[zipfile.ZipFile]<br ALIGN="LEFT"/>archive_path : Union[str, io.BytesIO]<br ALIGN="LEFT"/>|write_file(name: str, file_path: str): None<br ALIGN="LEFT"/>writestr(name: str, data: Union[bytes, str]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.PT2EQuantizationTestCase" [color="black", fontcolor="black", label=<{PT2EQuantizationTestCase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_exporter.PackageExporter" [color="black", fontcolor="black", label=<{PackageExporter|buffer : Optional[BinaryIO]<br ALIGN="LEFT"/>debug : bool<br ALIGN="LEFT"/>dependency_graph<br ALIGN="LEFT"/>importer<br ALIGN="LEFT"/>patterns : Dict[GlobGroup, _PatternInfo]<br ALIGN="LEFT"/>script_module_serializer<br ALIGN="LEFT"/>serialized_reduces : Dict[int, Any]<br ALIGN="LEFT"/>storage_context<br ALIGN="LEFT"/>zip_file<br ALIGN="LEFT"/>|add_dependency(module_name: str, dependencies)<br ALIGN="LEFT"/>all_paths(src: str, dst: str): str<br ALIGN="LEFT"/>close()<br ALIGN="LEFT"/>denied_modules(): List[str]<br ALIGN="LEFT"/>deny(include: 'GlobPattern')<br ALIGN="LEFT"/>dependency_graph_string(): str<br ALIGN="LEFT"/>extern(include: 'GlobPattern')<br ALIGN="LEFT"/>externed_modules(): List[str]<br ALIGN="LEFT"/>get_rdeps(module_name: str): List[str]<br ALIGN="LEFT"/>get_unique_id(): str<br ALIGN="LEFT"/>intern(include: 'GlobPattern')<br ALIGN="LEFT"/>interned_modules(): List[str]<br ALIGN="LEFT"/>mock(include: 'GlobPattern')<br ALIGN="LEFT"/>mocked_modules(): List[str]<br ALIGN="LEFT"/>register_extern_hook(hook: ActionHook): RemovableHandle<br ALIGN="LEFT"/>register_intern_hook(hook: ActionHook): RemovableHandle<br ALIGN="LEFT"/>register_mock_hook(hook: ActionHook): RemovableHandle<br ALIGN="LEFT"/>save_binary(package, resource, binary: bytes)<br ALIGN="LEFT"/>save_module(module_name: str, dependencies)<br ALIGN="LEFT"/>save_pickle(package: str, resource: str, obj: Any, dependencies: bool, pickle_protocol: int)<br ALIGN="LEFT"/>save_source_file(module_name: str, file_or_directory: str, dependencies)<br ALIGN="LEFT"/>save_source_string(module_name: str, src: str, is_package: bool, dependencies: bool)<br ALIGN="LEFT"/>save_text(package: str, resource: str, text: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.package_importer.PackageImporter" [color="black", fontcolor="black", label=<{PackageImporter|Unpickler<br ALIGN="LEFT"/>extern_modules<br ALIGN="LEFT"/>filename : str<br ALIGN="LEFT"/>last_map_location : NoneType<br ALIGN="LEFT"/>modules : Dict[str, types.ModuleType]<br ALIGN="LEFT"/>patched_builtins : dict<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>storage_context : NoneType, Optional[Any]<br ALIGN="LEFT"/>zip_reader : Any<br ALIGN="LEFT"/>|file_structure(): Directory<br ALIGN="LEFT"/>get_resource_reader(fullname)<br ALIGN="LEFT"/>get_source(module_name): str<br ALIGN="LEFT"/>id()<br ALIGN="LEFT"/>import_module(name: str, package)<br ALIGN="LEFT"/>load_binary(package: str, resource: str): bytes<br ALIGN="LEFT"/>load_pickle(package: str, resource: str, map_location): Any<br ALIGN="LEFT"/>load_text(package: str, resource: str, encoding: str, errors: str): str<br ALIGN="LEFT"/>python_version()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx._pass.PackageInfo" [color="black", fontcolor="black", label=<{PackageInfo|commit_hash : str \| None<br ALIGN="LEFT"/>package_name : str<br ALIGN="LEFT"/>version : str \| None<br ALIGN="LEFT"/>|from_python_class(python_class_name: type \| str): PackageInfo<br ALIGN="LEFT"/>to_onnx_domain_string(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._mangling.PackageMangler" [color="black", fontcolor="black", label=<{PackageMangler|<br ALIGN="LEFT"/>|demangle(mangled: str): str<br ALIGN="LEFT"/>mangle(name): str<br ALIGN="LEFT"/>parent_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._package_pickler.PackagePickler" [color="black", fontcolor="black", label=<{PackagePickler|dispatch : dict<br ALIGN="LEFT"/>importer<br ALIGN="LEFT"/>persistent_id<br ALIGN="LEFT"/>|save_global(obj, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._package_unpickler.PackageUnpickler" [color="black", fontcolor="black", label=<{PackageUnpickler|persistent_load<br ALIGN="LEFT"/>|find_class(module, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.package_exporter.PackagingError" [color="black", fontcolor="red", label=<{PackagingError|dependency_graph<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_exporter.PackagingErrorReason" [color="black", fontcolor="black", label=<{PackagingErrorReason|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.PackedParameter" [color="black", fontcolor="black", label=<{PackedParameter|param<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.rnn.PackedSequence" [color="black", fontcolor="black", label=<{PackedSequence|is_cuda<br ALIGN="LEFT"/>|byte(): Self<br ALIGN="LEFT"/>char(): Self<br ALIGN="LEFT"/>cpu(): Self<br ALIGN="LEFT"/>cuda(): Self<br ALIGN="LEFT"/>double(): Self<br ALIGN="LEFT"/>float(): Self<br ALIGN="LEFT"/>half(): Self<br ALIGN="LEFT"/>int(): Self<br ALIGN="LEFT"/>is_pinned(): bool<br ALIGN="LEFT"/>long(): Self<br ALIGN="LEFT"/>pin_memory(): Self<br ALIGN="LEFT"/>short(): Self<br ALIGN="LEFT"/>to(dtype: torch.dtype, non_blocking: bool, copy: bool): Self<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.rnn.PackedSequence_" [color="black", fontcolor="black", label=<{PackedSequence_|batch_sizes<br ALIGN="LEFT"/>data<br ALIGN="LEFT"/>sorted_indices : Optional[torch.Tensor]<br ALIGN="LEFT"/>unsorted_indices : Optional[torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autoheuristic.artifacts._PadMMA100.PadMMA100" [color="black", fontcolor="black", label=<{PadMMA100|<br ALIGN="LEFT"/>|check_precondition(metadata: AHMetadata, context: AHContext): bool<br ALIGN="LEFT"/>get_confidence_threshold(): float<br ALIGN="LEFT"/>get_feedback(context: AHContext, choice: Choice): float<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>predict(context: AHContext): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.attention.experimental._paged_attention.PagedAttention" [color="black", fontcolor="black", label=<{PagedAttention|capacity<br ALIGN="LEFT"/>empty_pages : list<br ALIGN="LEFT"/>n_pages : int<br ALIGN="LEFT"/>page_size : int<br ALIGN="LEFT"/>page_table<br ALIGN="LEFT"/>physical_to_logical<br ALIGN="LEFT"/>|assign(batch_idx: torch.Tensor, input_pos: torch.Tensor, k_val: torch.Tensor, v_val: torch.Tensor, k_cache: torch.Tensor, v_cache: torch.Tensor): None<br ALIGN="LEFT"/>convert_logical_block_mask(block_mask: BlockMask, batch_idx: Optional[torch.Tensor]): BlockMask<br ALIGN="LEFT"/>erase(batch_idx: torch.Tensor): None<br ALIGN="LEFT"/>get_mask_mod(mask_mod: Optional[_mask_mod_signature]): _mask_mod_signature<br ALIGN="LEFT"/>get_score_mod(score_mod: Optional[_score_mod_signature]): _score_mod_signature<br ALIGN="LEFT"/>reserve(batch_idx: torch.Tensor, seq_len: torch.Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._comparison.Pair" [color="black", fontcolor="black", label=<{Pair|actual : Any<br ALIGN="LEFT"/>expected : Any<br ALIGN="LEFT"/>id : tuple<br ALIGN="LEFT"/>|<I>compare</I>(): None<br ALIGN="LEFT"/>extra_repr(): Sequence[Union[str, Tuple[str, Any]]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.distance.PairwiseDistance" [color="black", fontcolor="black", label=<{PairwiseDistance|eps : float<br ALIGN="LEFT"/>keepdim : bool<br ALIGN="LEFT"/>norm : float<br ALIGN="LEFT"/>|forward(x1: Tensor, x2: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.dataframe_wrapper.PandasWrapper" [color="black", fontcolor="black", label=<{PandasWrapper|<br ALIGN="LEFT"/>|concat(buffer)<br ALIGN="LEFT"/>create_dataframe(data, columns)<br ALIGN="LEFT"/>get_columns(df)<br ALIGN="LEFT"/>get_item(data, idx)<br ALIGN="LEFT"/>get_len(df)<br ALIGN="LEFT"/>is_column(data)<br ALIGN="LEFT"/>is_dataframe(data)<br ALIGN="LEFT"/>iterate(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.ParallelStyle" [color="black", fontcolor="black", label=<{ParallelStyle|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.Param" [color="black", fontcolor="black", label=<{Param|idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.ParamBufferSource" [color="black", fontcolor="black", label=<{ParamBufferSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.ParamInfo" [color="black", fontcolor="black", label=<{ParamInfo|module<br ALIGN="LEFT"/>module_name : str<br ALIGN="LEFT"/>param_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.ParamModuleInfo" [color="black", fontcolor="black", label=<{ParamModuleInfo|module<br ALIGN="LEFT"/>param_name : str<br ALIGN="LEFT"/>shared_modules : List[nn.Module]<br ALIGN="LEFT"/>shared_param_names : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._schemas.Parameter" [color="black", fontcolor="black", label=<{Parameter|default : Any<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>required : bool<br ALIGN="LEFT"/>type_constraint<br ALIGN="LEFT"/>variadic : bool<br ALIGN="LEFT"/>|has_default(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parameter.Parameter" [color="black", fontcolor="black", label=<{Parameter|data<br ALIGN="LEFT"/>grad : NoneType<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.fuzzer.ParameterAlias" [color="black", fontcolor="black", label=<{ParameterAlias|alias_to<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.container.ParameterDict" [color="black", fontcolor="black", label=<{ParameterDict|<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>copy(): 'ParameterDict'<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>fromkeys(keys: Iterable[str], default: Optional[Any]): 'ParameterDict'<br ALIGN="LEFT"/>get(key: str, default: Optional[Any]): Any<br ALIGN="LEFT"/>items(): Iterable[Tuple[str, Any]]<br ALIGN="LEFT"/>keys(): Iterable[str]<br ALIGN="LEFT"/>pop(key: str): Any<br ALIGN="LEFT"/>popitem(): Tuple[str, Any]<br ALIGN="LEFT"/>setdefault(key: str, default: Optional[Any]): Any<br ALIGN="LEFT"/>update(parameters: Union[Mapping[str, Any], 'ParameterDict']): None<br ALIGN="LEFT"/>values(): Iterable[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.container.ParameterList" [color="black", fontcolor="black", label=<{ParameterList|<br ALIGN="LEFT"/>|append(value: Any): 'ParameterList'<br ALIGN="LEFT"/>extend(values: Iterable[Any]): Self<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.proxy.ParameterProxy" [color="black", fontcolor="black", label=<{ParameterProxy|name<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>param<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|dim()<br ALIGN="LEFT"/>nelement()<br ALIGN="LEFT"/>numel()<br ALIGN="LEFT"/>size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.parameter_server_test.ParameterServerTest" [color="black", fontcolor="black", label=<{ParameterServerTest|<br ALIGN="LEFT"/>|test_batch_updating_parameter_server()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.parametrize.ParametrizationList" [color="black", fontcolor="black", label=<{ParametrizationList|is_tensor<br ALIGN="LEFT"/>ntensors : int<br ALIGN="LEFT"/>original<br ALIGN="LEFT"/>unsafe : bool<br ALIGN="LEFT"/>|forward(): Tensor<br ALIGN="LEFT"/>right_inverse(value: Tensor): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.pareto.Pareto" [color="black", fontcolor="black", label=<{Pareto|alpha<br ALIGN="LEFT"/>arg_constraints : dict<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._sources.ParsedDef" [color="black", fontcolor="black", label=<{ParsedDef|ast<br ALIGN="LEFT"/>ctx<br ALIGN="LEFT"/>file_lineno : int<br ALIGN="LEFT"/>filename : Optional[str]<br ALIGN="LEFT"/>source : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.placement_types.Partial" [color="black", fontcolor="black", label=<{Partial|reduce_op : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.PartialRender" [color="black", fontcolor="black", label=<{PartialRender|code<br ALIGN="LEFT"/>replacement_hooks<br ALIGN="LEFT"/>|finalize_all(): str<br ALIGN="LEFT"/>finalize_hook(hook_key: str, strict): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.split_module.Partition" [color="black", fontcolor="black", label=<{Partition|dependencies : Dict[str, None]<br ALIGN="LEFT"/>dependents : Dict[str, None]<br ALIGN="LEFT"/>environment : Dict[Node, Node]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>inputs : Dict[str, None]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>node_names : List[str]<br ALIGN="LEFT"/>outputs : Dict[str, None]<br ALIGN="LEFT"/>submod_name : str<br ALIGN="LEFT"/>targets : Dict[str, Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.infra.partitioner.Partition" [color="black", fontcolor="black", label=<{Partition|id : Optional[int]<br ALIGN="LEFT"/>nodes : dict<br ALIGN="LEFT"/>|add_node(node: Node)<br ALIGN="LEFT"/>remove_node(node: Node)<br ALIGN="LEFT"/>size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.Partition" [color="black", fontcolor="black", label=<{Partition|bfs_level : int<br ALIGN="LEFT"/>children : Set[Partition]<br ALIGN="LEFT"/>left_mem_bytes<br ALIGN="LEFT"/>logical_device_ids : List[int], list<br ALIGN="LEFT"/>nodes : Set[Node]<br ALIGN="LEFT"/>parents : Set[Partition]<br ALIGN="LEFT"/>partition_id : int<br ALIGN="LEFT"/>used_mem_bytes : int<br ALIGN="LEFT"/>|add_node(node)<br ALIGN="LEFT"/>recalculate_mem_size()<br ALIGN="LEFT"/>remove_node(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.PartitionLatency" [color="black", fontcolor="black", label=<{PartitionLatency|computer_latency_sec : float<br ALIGN="LEFT"/>mem_latency_sec : float<br ALIGN="LEFT"/>overall_latency_sec : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.PartitionMode" [color="black", fontcolor="black", label=<{PartitionMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.accelerator_partitioner.PartitionResult" [color="black", fontcolor="black", label=<{PartitionResult|dag<br ALIGN="LEFT"/>module_with_submodules<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.PartitionState" [color="black", fontcolor="black", label=<{PartitionState|cur_count : int<br ALIGN="LEFT"/>cur_partition : List[BaseSchedulerNode]<br ALIGN="LEFT"/>partitions : List[List[BaseSchedulerNode]]<br ALIGN="LEFT"/>|finalize(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.accelerator_partitioner.Partitioner" [color="black", fontcolor="black", label=<{Partitioner|devices : List[Device]<br ALIGN="LEFT"/>graph_module<br ALIGN="LEFT"/>node_to_partition : Dict[Node, int], dict<br ALIGN="LEFT"/>partitions : List[Partition]<br ALIGN="LEFT"/>torch_module<br ALIGN="LEFT"/>|aot_based_partition(node_to_partition_mapping, partition_to_logical_device_mapping)<br ALIGN="LEFT"/>cost_aware_partition(transfer_rate_bytes_per_sec: float, node_to_latency_mapping: Dict[Node, NodeLatency]): None<br ALIGN="LEFT"/>create_partition(): Partition<br ALIGN="LEFT"/>create_single_node_partition(node)<br ALIGN="LEFT"/>do_partition(): GraphModule<br ALIGN="LEFT"/>dump_dag(module_with_submodules: GraphModule): DAG<br ALIGN="LEFT"/>find_single_partition(total_size_of_graph, logical_device_id: int): None<br ALIGN="LEFT"/>kl_based_partition(transfer_rate_bytes_per_sec: float, node_to_latency_mapping: Dict[Node, NodeLatency]): None<br ALIGN="LEFT"/>partition_graph(fx_module: GraphModule, torch_module: torch.nn.Module, partitioner_config: PartitionerConfig): PartitionResult<br ALIGN="LEFT"/>saturate_host(): None<br ALIGN="LEFT"/>size_based_partition(): None<br ALIGN="LEFT"/>sparse_nn_partition(available_mem_bytes: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.partitioner_utils.PartitionerConfig" [color="black", fontcolor="black", label=<{PartitionerConfig|devices : List[Device]<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>node_to_latency_mapping : Dict[Node, NodeLatency]<br ALIGN="LEFT"/>node_to_partition_mapping : Dict[Node, int]<br ALIGN="LEFT"/>partition_to_logical_device_mapping : Dict[int, List[int]]<br ALIGN="LEFT"/>saturate_host : bool<br ALIGN="LEFT"/>transfer_rate_bytes_per_sec : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.infra.pass_base.PassBase" [color="black", fontcolor="black", label=<{PassBase|<br ALIGN="LEFT"/>|<I>call</I>(graph_module: GraphModule): Optional[PassResult]<br ALIGN="LEFT"/><I>ensures</I>(graph_module: GraphModule): None<br ALIGN="LEFT"/><I>requires</I>(graph_module: GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.pass_manager.PassManager" [color="black", fontcolor="black", label=<{PassManager|constraints : List[Callable]<br ALIGN="LEFT"/>passes : List[Callable]<br ALIGN="LEFT"/>|add_constraint(constraint)<br ALIGN="LEFT"/>add_pass(_pass: Callable)<br ALIGN="LEFT"/>build_from_passlist(passes)<br ALIGN="LEFT"/>remove_pass(_passes: List[str])<br ALIGN="LEFT"/>replace_pass(_target, _replacement)<br ALIGN="LEFT"/>validate()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.infra.pass_manager.PassManager" [color="black", fontcolor="black", label=<{PassManager|constraints : List[Callable[[Callable, Callable], bool]]<br ALIGN="LEFT"/>passes : List[Callable[[nn.Module], PassResult]]<br ALIGN="LEFT"/>run_checks_after_each_pass : bool<br ALIGN="LEFT"/>steps : int<br ALIGN="LEFT"/>suppress_check_failures : bool<br ALIGN="LEFT"/>|add_checks(check: Callable): None<br ALIGN="LEFT"/>add_constraint(constraint: Callable)<br ALIGN="LEFT"/>add_pass(_pass: Callable)<br ALIGN="LEFT"/><I>check</I>(module: nn.Module): None<br ALIGN="LEFT"/>solve_constraints()<br ALIGN="LEFT"/>validate_constraints()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.infra.pass_base.PassResult" [color="black", fontcolor="black", label=<{PassResult|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.mock_cache.PatchCaches" [color="black", fontcolor="black", label=<{PatchCaches|<br ALIGN="LEFT"/>|setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.PatchedPropertyBag" [color="black", fontcolor="black", label=<{PatchedPropertyBag|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._trace._normalize_nn_module_stack.normalize_path.Path" [color="black", fontcolor="black", label=<{Path|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.Pattern" [color="black", fontcolor="black", label=<{Pattern|description : str<br ALIGN="LEFT"/>event_tree<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>prof<br ALIGN="LEFT"/>should_benchmark : bool<br ALIGN="LEFT"/>skip<br ALIGN="LEFT"/>tid_root : Dict[int, List[_ProfilerEvent]]<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|benchmark_summary(events: List[_ProfilerEvent])<br ALIGN="LEFT"/>eventTreeTraversal()<br ALIGN="LEFT"/>go_up_until(event: _ProfilerEvent, predicate)<br ALIGN="LEFT"/><I>match</I>(event: _ProfilerEvent)<br ALIGN="LEFT"/>matched_events()<br ALIGN="LEFT"/>next_of(event: _ProfilerEvent)<br ALIGN="LEFT"/>prev_of(event: _ProfilerEvent)<br ALIGN="LEFT"/>report(event: _ProfilerEvent)<br ALIGN="LEFT"/>root_of(event: _ProfilerEvent)<br ALIGN="LEFT"/>siblings_of(event: _ProfilerEvent)<br ALIGN="LEFT"/>summary(events: List[_ProfilerEvent])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.PatternEntry" [color="black", fontcolor="black", label=<{PatternEntry|extra_check : Callable[[Match], bool]<br ALIGN="LEFT"/>pattern<br ALIGN="LEFT"/>|<I>apply</I>(match: Match, graph: torch.fx.Graph, node: torch.fx.Node): None<br ALIGN="LEFT"/>register(pass_dicts: Union[_PassDictsType, Sequence[_PassDictsType]], target: Union[torch.fx.node.Target, None], prepend: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.PatternExpr" [color="black", fontcolor="black", label=<{PatternExpr|<br ALIGN="LEFT"/>|find_anchor_nodes(ctx: MatchContext, searched: OrderedSet[torch.fx.Node]): Generator[Optional[torch.fx.Node], None, None]<br ALIGN="LEFT"/>has_multiple_users(): bool<br ALIGN="LEFT"/>match(node: torch.fx.Node): MatchResult<br ALIGN="LEFT"/>pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.PatternMatcherPass" [color="black", fontcolor="black", label=<{PatternMatcherPass|pass_name : Optional[str]<br ALIGN="LEFT"/>patterns : DefaultDict[Tuple[str, torch.fx.node.Target], List[PatternEntry]]<br ALIGN="LEFT"/>|apply(gm: Union[torch.fx.GraphModule, torch.fx.Graph]): int<br ALIGN="LEFT"/>clear(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.PatternPrettyPrinter" [color="black", fontcolor="black", label=<{PatternPrettyPrinter|memoized_objs_names : Dict[PatternExpr, str]<br ALIGN="LEFT"/>memoized_objs_pp : Dict[PatternExpr, str]<br ALIGN="LEFT"/>namespace<br ALIGN="LEFT"/>|memoize(obj: _TargetArgsExpr): str<br ALIGN="LEFT"/>pretty_print(obj: Any): str<br ALIGN="LEFT"/>run(obj: PatternExpr, output_name: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.memory.reorder_for_peak_memory.PeakMemoryResult" [color="black", fontcolor="black", label=<{PeakMemoryResult|method : str<br ALIGN="LEFT"/>order : List[BaseSchedulerNode]<br ALIGN="LEFT"/>peak_memory : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.PendingUnbackedSymbolNotFound" [color="black", fontcolor="red", label=<{PendingUnbackedSymbolNotFound|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx._model_report.detector.PerChannelDetector" [color="black", fontcolor="black", label=<{PerChannelDetector|BACKEND_KEY : str<br ALIGN="LEFT"/>DEFAULT_BACKEND_PER_CHANNEL_SUPPORTED_MODULES : Dict[str, Set[Any]]<br ALIGN="LEFT"/>PER_CHAN_SUPPORTED_KEY : str<br ALIGN="LEFT"/>PER_CHAN_USED_KEY : str<br ALIGN="LEFT"/>backend_chosen : str<br ALIGN="LEFT"/>supported_modules : set<br ALIGN="LEFT"/>|determine_observer_insert_points(model: nn.Module): Dict<br ALIGN="LEFT"/>generate_detector_report(model: nn.Module): Tuple[str, Dict[str, Any]]<br ALIGN="LEFT"/>get_detector_name(): str<br ALIGN="LEFT"/>get_qconfig_info(model): Dict[str, DetectorQConfigInfo]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.PerChannelMinMaxObserver" [color="black", fontcolor="black", label=<{PerChannelMinMaxObserver|ch_axis : int<br ALIGN="LEFT"/>max_val<br ALIGN="LEFT"/>min_val<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x_orig)<br ALIGN="LEFT"/>reset_min_max_vals()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.PerRowDataFramesPipe" [color="black", fontcolor="black", label=<{PerRowDataFramesPipe|source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms.model_averaging.averagers.PeriodicModelAverager" [color="black", fontcolor="black", label=<{PeriodicModelAverager|period<br ALIGN="LEFT"/>step<br ALIGN="LEFT"/>warmup_steps : int<br ALIGN="LEFT"/>|average_parameters(params: Union[Iterable[torch.nn.Parameter], Iterable[Dict[str, torch.nn.Parameter]]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.PermuteView" [color="black", fontcolor="black", label=<{PermuteView|dims : List[Expr]<br ALIGN="LEFT"/>|create(x, dims)<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>make_reindexer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.PersistentCache" [color="black", fontcolor="black", label=<{PersistentCache|<br ALIGN="LEFT"/>|get_global_cache(): Dict[str, Any]<br ALIGN="LEFT"/>lookup(choices: List[ChoiceCaller], op: str, inputs: str, benchmark: Optional[Callable[[Any], Dict[ChoiceCaller, float]]]): Dict[ChoiceCaller, float]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._decomp.decompositions_for_rng.PhiloxState" [color="black", fontcolor="black", label=<{PhiloxState|base_offset<br ALIGN="LEFT"/>offset_advanced_alteast_once : bool<br ALIGN="LEFT"/>relative_offset : int<br ALIGN="LEFT"/>seed<br ALIGN="LEFT"/>|advance_offset(consumed_offset)<br ALIGN="LEFT"/>get_state_as_tensor()<br ALIGN="LEFT"/>get_state_as_tuple()<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>set_state(seed, base_offset, relative_offset)<br ALIGN="LEFT"/>set_state_from_tensor(state)<br ALIGN="LEFT"/>validate_state()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._decomp.decompositions_for_rng.PhiloxStateTracker" [color="black", fontcolor="black", label=<{PhiloxStateTracker|bwd_state<br ALIGN="LEFT"/>fwd_state<br ALIGN="LEFT"/>running_state<br ALIGN="LEFT"/>|advance_offset(consumed_offset)<br ALIGN="LEFT"/>get_current_relative_offset()<br ALIGN="LEFT"/>get_state_as_tensor()<br ALIGN="LEFT"/>get_state_as_tuple()<br ALIGN="LEFT"/>get_updated_bwd_offset()<br ALIGN="LEFT"/>get_updated_fwd_offset()<br ALIGN="LEFT"/>mark_beginning_of_backward()<br ALIGN="LEFT"/>mark_beginning_of_forward()<br ALIGN="LEFT"/>multiple_of_4(offset)<br ALIGN="LEFT"/>record_state(seed, offset, mode)<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>set_state_from_tensor(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._physical_location.PhysicalLocation" [color="black", fontcolor="black", label=<{PhysicalLocation|address : Optional[_address.Address]<br ALIGN="LEFT"/>artifact_location : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>context_region : Optional[_region.Region]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>region : Optional[_region.Region]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autotune_process.Ping" [color="black", fontcolor="black", label=<{Ping|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.Pipe" [color="black", fontcolor="black", label=<{Pipe|executor<br ALIGN="LEFT"/>has_loss_and_backward : bool<br ALIGN="LEFT"/>loss_spec<br ALIGN="LEFT"/>num_stages : int<br ALIGN="LEFT"/>replicated_params : List[Dict[str, str]]<br ALIGN="LEFT"/>split_gm<br ALIGN="LEFT"/>|build_stage(stage_index: int, device: torch.device, group: Optional[ProcessGroup]): _PipelineStage<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>from_tracing(mod: torch.nn.Module, example_args: Tuple[Any, ...], example_kwargs: Optional[Dict[str, Any]], split_policy: Optional[Callable[[fx.GraphModule], fx.GraphModule]])<br ALIGN="LEFT"/>get_stage_module(stage_idx: int): torch.nn.Module<br ALIGN="LEFT"/>info(): PipeInfo<br ALIGN="LEFT"/>print_readable()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._utils.PipeInfo" [color="black", fontcolor="black", label=<{PipeInfo|graph<br ALIGN="LEFT"/>has_loss_and_backward : bool<br ALIGN="LEFT"/>num_stages : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.PipeSequential" [color="black", fontcolor="black", label=<{PipeSequential|<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_sequential(sequential_instance: torch.nn.Sequential)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.PipeSplitWrapper" [color="black", fontcolor="black", label=<{PipeSplitWrapper|SplitPoint<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.PipelineScheduleMulti" [color="black", fontcolor="black", label=<{PipelineScheduleMulti|pipeline_order : Dict[int, List[Optional[_Action]]]<br ALIGN="LEFT"/>pp_group_size<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>stage_index_to_group_rank<br ALIGN="LEFT"/>|step()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.PipelineScheduleSingle" [color="black", fontcolor="black", label=<{PipelineScheduleSingle|<br ALIGN="LEFT"/>|step()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.stage.PipelineStage" [color="black", fontcolor="black", label=<{PipelineStage|act_send_info : Dict[int, List]<br ALIGN="LEFT"/>inputs : Optional[List[torch.Tensor]]<br ALIGN="LEFT"/>inputs_meta : Optional[Tuple[torch.Tensor, ...]], Tuple[Any, ...], tuple<br ALIGN="LEFT"/>next_rank<br ALIGN="LEFT"/>outputs_grad : List[torch.Tensor]<br ALIGN="LEFT"/>prev_rank<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining._utils.PipeliningShapeError" [color="black", fontcolor="red", label=<{PipeliningShapeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.pixelshuffle.PixelShuffle" [color="black", fontcolor="black", label=<{PixelShuffle|upscale_factor : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pixelshuffle.PixelUnshuffle" [color="black", fontcolor="black", label=<{PixelUnshuffle|downscale_factor : int<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.utils.Placeholder" [color="black", fontcolor="black", label=<{Placeholder|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.PlaceholderInfo" [color="black", fontcolor="black", label=<{PlaceholderInfo|mutating_use_stack_trace : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>stack_trace : Optional[str]<br ALIGN="LEFT"/>users : List[PlaceholderInfo]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.observer.PlaceholderObserver" [color="black", fontcolor="black", label=<{PlaceholderObserver|custom_op : str<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>eps : NoneType<br ALIGN="LEFT"/>qscheme : NoneType<br ALIGN="LEFT"/>quant_max : NoneType<br ALIGN="LEFT"/>quant_min : NoneType<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.placement_types.Placement" [color="black", fontcolor="black", label=<{Placement|<br ALIGN="LEFT"/>|is_partial(): bool<br ALIGN="LEFT"/>is_replicate(): bool<br ALIGN="LEFT"/>is_shard(dim: Optional[int]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.PlacementClassVariable" [color="black", fontcolor="black", label=<{PlacementClassVariable|<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_placement_type(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_spec.api.PlacementSpec" [color="black", fontcolor="black", label=<{PlacementSpec|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.PlacementStrategy" [color="black", fontcolor="black", label=<{PlacementStrategy|input_specs : Optional[Sequence[DTensorSpec]]<br ALIGN="LEFT"/>output_spec<br ALIGN="LEFT"/>output_specs : Union[DTensorSpec, Tuple[Optional[DTensorSpec], ...]]<br ALIGN="LEFT"/>redistribute_cost : Optional[List[List[float]]]<br ALIGN="LEFT"/>|input_spec(index: int): DTensorSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.PlacementVariable" [color="black", fontcolor="black", label=<{PlacementVariable|<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_placement(value)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.PlainTensorMeta" [color="black", fontcolor="black", label=<{PlainTensorMeta|memory_format : Optional[torch.memory_format]<br ALIGN="LEFT"/>unwrapped_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Pointwise" [color="black", fontcolor="black", label=<{Pointwise|<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>store_output(output_name: Optional[str], indexer: Callable[[Sequence[Expr]], Never], vars: Sequence[Expr]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.subgraph_lowering.PointwiseSubgraphLowering" [color="black", fontcolor="black", label=<{PointwiseSubgraphLowering|additional_lowerings : Optional[LoweringDict]<br ALIGN="LEFT"/>allowed_mutations : Optional[OrderedSet[OpOverload]]<br ALIGN="LEFT"/>buffers : List[ir.Buffer]<br ALIGN="LEFT"/>graph_outputs : Optional[List[ir.IRNode]]<br ALIGN="LEFT"/>mutated_buffers : OrderedSet[str]<br ALIGN="LEFT"/>root_graph<br ALIGN="LEFT"/>|call_function(target: TargetType, args: Any, kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>mark_buffer_mutated(name: str): None<br ALIGN="LEFT"/>output(target: str, args: Tuple[Any], kwargs: Dict[str, Any]): None<br ALIGN="LEFT"/>register_buffer(buffer: ir.Buffer): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.poisson.Poisson" [color="black", fontcolor="black", label=<{Poisson|arg_constraints : dict<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>rate<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.PoissonNLLLoss" [color="black", fontcolor="black", label=<{PoissonNLLLoss|eps : float<br ALIGN="LEFT"/>full : bool<br ALIGN="LEFT"/>log_input : bool<br ALIGN="LEFT"/>|forward(log_input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" [color="black", fontcolor="black", label=<{Policy|affine1<br ALIGN="LEFT"/>affine2<br ALIGN="LEFT"/>dropout<br ALIGN="LEFT"/>rewards : list<br ALIGN="LEFT"/>saved_log_probs : list<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.PolyfilledFunctionVariable" [color="black", fontcolor="black", label=<{PolyfilledFunctionVariable|fn : _F<br ALIGN="LEFT"/>polyfill_fn<br ALIGN="LEFT"/>traceable_fn : _F<br ALIGN="LEFT"/>wrapped_fn : _F<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>can_constant_fold_through()<br ALIGN="LEFT"/>create_with_source(value, source)<br ALIGN="LEFT"/>get_function()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.PolynomialLR" [color="black", fontcolor="black", label=<{PolynomialLR|power : float<br ALIGN="LEFT"/>total_iters : int<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.Pong" [color="black", fontcolor="black", label=<{Pong|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.multiprocessing.pool.Pool" [color="black", fontcolor="black", label=<{Pool|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.PoolMemoryPlanningLine" [color="black", fontcolor="black", label=<{PoolMemoryPlanningLine|group<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>timestep : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator.PopulateValidator" [color="black", fontcolor="black", label=<{PopulateValidator|validator : str<br ALIGN="LEFT"/>|call_function(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>placeholder(target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e.port_metadata_pass.PortNodeMetaForQDQ" [color="black", fontcolor="black", label=<{PortNodeMetaForQDQ|<br ALIGN="LEFT"/>|call(graph_module: torch.fx.GraphModule): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.PositiveDefiniteTransform" [color="black", fontcolor="black", label=<{PositiveDefiniteTransform|codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.PostGradBatchLinearFusion" [color="black", fontcolor="black", label=<{PostGradBatchLinearFusion|<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node): Optional[Tuple[str, int, int, int, bool, str]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.post_localSGD_optimizer.PostLocalSGDOptimizer" [color="black", fontcolor="black", label=<{PostLocalSGDOptimizer|averager<br ALIGN="LEFT"/>optim<br ALIGN="LEFT"/>param_groups<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|add_param_group(param_group)<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>zero_grad(set_to_none: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.post_localSGD_hook.PostLocalSGDState" [color="black", fontcolor="black", label=<{PostLocalSGDState|iter : int<br ALIGN="LEFT"/>post_local_gradient_allreduce : bool<br ALIGN="LEFT"/>process_group<br ALIGN="LEFT"/>start_localSGD_iter<br ALIGN="LEFT"/>subgroup<br ALIGN="LEFT"/>|maybe_increase_iter(bucket)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.lightning.callbacks.data_sparsity.PostTrainingDataSparsity" [color="black", fontcolor="black", label=<{PostTrainingDataSparsity|data_sparsifier : Optional[Any]<br ALIGN="LEFT"/>data_sparsifier_args<br ALIGN="LEFT"/>data_sparsifier_class<br ALIGN="LEFT"/>sparsified : Optional[torch.nn.Module]<br ALIGN="LEFT"/>|on_fit_end(trainer, pl_module): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.PowByNatural" [color="black", fontcolor="black", label=<{PowByNatural|is_integer : bool<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(base, exp)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState" [color="black", fontcolor="black", label=<{PowerSGDState|batch_tensors_with_same_shape : bool<br ALIGN="LEFT"/>compression_stats_logging_frequency<br ALIGN="LEFT"/>error_dict : Dict[int, torch.Tensor]<br ALIGN="LEFT"/>iter : int<br ALIGN="LEFT"/>matrix_approximation_rank : int<br ALIGN="LEFT"/>min_compression_rate : int<br ALIGN="LEFT"/>next_stats_report : int<br ALIGN="LEFT"/>orthogonalization_epsilon : int<br ALIGN="LEFT"/>p_memory_dict : Dict[int, torch.Tensor]<br ALIGN="LEFT"/>process_group<br ALIGN="LEFT"/>q_memory_dict : Dict[int, torch.Tensor]<br ALIGN="LEFT"/>rng<br ALIGN="LEFT"/>start_powerSGD_iter : int<br ALIGN="LEFT"/>total_numel_after_compression : int<br ALIGN="LEFT"/>total_numel_before_compression : int<br ALIGN="LEFT"/>use_error_feedback : bool<br ALIGN="LEFT"/>warm_start : bool<br ALIGN="LEFT"/>|compression_stats()<br ALIGN="LEFT"/>maybe_increase_iter(bucket)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.PowerTransform" [color="black", fontcolor="black", label=<{PowerTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>exponent<br ALIGN="LEFT"/>|forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>sign()<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor.PreDispatchTorchFunctionMode" [color="black", fontcolor="black", label=<{PreDispatchTorchFunctionMode|enter_autocast_nodes : List[torch.fx.Node]<br ALIGN="LEFT"/>tracer : Union<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion.PreGradBatchLinearFusion" [color="black", fontcolor="black", label=<{PreGradBatchLinearFusion|<br ALIGN="LEFT"/>|fuse(graph: torch.fx.GraphModule, subset: List[torch.fx.Node])<br ALIGN="LEFT"/>match(node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.custom_config.PrepareCustomConfig" [color="black", fontcolor="black", label=<{PrepareCustomConfig|float_to_observed_mapping : Dict[QuantType, Dict[Type, Type]]<br ALIGN="LEFT"/>input_quantized_indexes : List[int]<br ALIGN="LEFT"/>non_traceable_module_classes : List[Type]<br ALIGN="LEFT"/>non_traceable_module_names : List[str]<br ALIGN="LEFT"/>output_quantized_indexes : List[int]<br ALIGN="LEFT"/>preserved_attributes : List[str]<br ALIGN="LEFT"/>standalone_module_classes : Dict[Type, StandaloneModuleConfigEntry]<br ALIGN="LEFT"/>standalone_module_names : Dict[str, StandaloneModuleConfigEntry]<br ALIGN="LEFT"/>|from_dict(prepare_custom_config_dict: Dict[str, Any]): PrepareCustomConfig<br ALIGN="LEFT"/>set_float_to_observed_mapping(float_class: Type, observed_class: Type, quant_type: QuantType): PrepareCustomConfig<br ALIGN="LEFT"/>set_input_quantized_indexes(indexes: List[int]): PrepareCustomConfig<br ALIGN="LEFT"/>set_non_traceable_module_classes(module_classes: List[Type]): PrepareCustomConfig<br ALIGN="LEFT"/>set_non_traceable_module_names(module_names: List[str]): PrepareCustomConfig<br ALIGN="LEFT"/>set_output_quantized_indexes(indexes: List[int]): PrepareCustomConfig<br ALIGN="LEFT"/>set_preserved_attributes(attributes: List[str]): PrepareCustomConfig<br ALIGN="LEFT"/>set_standalone_module_class(module_class: Type, qconfig_mapping: Optional[QConfigMapping], example_inputs: Tuple[Any, ...], prepare_custom_config: Optional[PrepareCustomConfig], backend_config: Optional[BackendConfig]): PrepareCustomConfig<br ALIGN="LEFT"/>set_standalone_module_name(module_name: str, qconfig_mapping: Optional[QConfigMapping], example_inputs: Tuple[Any, ...], prepare_custom_config: Optional[PrepareCustomConfig], backend_config: Optional[BackendConfig]): PrepareCustomConfig<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.PrepareModuleInput" [color="black", fontcolor="black", label=<{PrepareModuleInput|desired_input_kwarg_layouts : dict<br ALIGN="LEFT"/>desired_input_layouts : NoneType, tuple<br ALIGN="LEFT"/>input_kwarg_layouts : dict<br ALIGN="LEFT"/>input_layouts : NoneType, tuple<br ALIGN="LEFT"/>use_local_output : bool<br ALIGN="LEFT"/>with_kwargs<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.PrepareModuleOutput" [color="black", fontcolor="black", label=<{PrepareModuleOutput|desired_output_layouts : tuple<br ALIGN="LEFT"/>output_layouts : tuple<br ALIGN="LEFT"/>use_local_output : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.PrependParamsAndBuffersAotAutogradOutputStep" [color="black", fontcolor="black", label=<{PrependParamsAndBuffersAotAutogradOutputStep|<br ALIGN="LEFT"/>|apply(model_outputs: Any, model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): Sequence[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.PrependParamsBuffersConstantAotAutogradInputStep" [color="black", fontcolor="black", label=<{PrependParamsBuffersConstantAotAutogradInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.PreserveVersionContextVariable" [color="black", fontcolor="black", label=<{PreserveVersionContextVariable|prev_version<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|constructor(tx)<br ALIGN="LEFT"/><I>enter</I>(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.prim_hop_base.PrimHOPBase" [color="black", fontcolor="black", label=<{PrimHOPBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.prim_hop_base.PrimHOPBaseFunction" [color="black", fontcolor="black", label=<{PrimHOPBaseFunction|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, hop, subgraph, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.PrimHOPBaseVariable" [color="black", fontcolor="black", label=<{PrimHOPBaseVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.PrivateUse1TestBase" [color="black", fontcolor="black", label=<{PrivateUse1TestBase|device_mod : NoneType<br ALIGN="LEFT"/>device_type : str<br ALIGN="LEFT"/>primary_device : ClassVar[str]<br ALIGN="LEFT"/>|get_all_devices()<br ALIGN="LEFT"/>get_primary_device()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.spawn.ProcessContext" [color="black", fontcolor="black", label=<{ProcessContext|error_files<br ALIGN="LEFT"/>processes<br ALIGN="LEFT"/>sentinels<br ALIGN="LEFT"/>|join(timeout: Optional[float], grace_period: Optional[float])<br ALIGN="LEFT"/>pids()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.spawn.ProcessException" [color="black", fontcolor="red", label=<{ProcessException|error_index : int<br ALIGN="LEFT"/>msg : str<br ALIGN="LEFT"/>pid : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.multiprocessing.spawn.ProcessExitedException" [color="black", fontcolor="red", label=<{ProcessExitedException|exit_code : int<br ALIGN="LEFT"/>signal_name : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.errors.ProcessFailure" [color="black", fontcolor="black", label=<{ProcessFailure|error_file : str<br ALIGN="LEFT"/>error_file_data : Dict<br ALIGN="LEFT"/>exitcode : int<br ALIGN="LEFT"/>local_rank : int<br ALIGN="LEFT"/>message : str<br ALIGN="LEFT"/>pid : int<br ALIGN="LEFT"/>timestamp : int<br ALIGN="LEFT"/>|signal_name(): str<br ALIGN="LEFT"/>timestamp_isoformat()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensor.ProcessGroupState" [color="black", fontcolor="black", label=<{ProcessGroupState|global_rank : int<br ALIGN="LEFT"/>global_world_size : int<br ALIGN="LEFT"/>local_rank : int<br ALIGN="LEFT"/>local_world_size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.ProcessGroupVariable" [color="black", fontcolor="black", label=<{ProcessGroupVariable|<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_process_group(value)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.ProcessLocalGroup" [color="black", fontcolor="black", label=<{ProcessLocalGroup|group_name<br ALIGN="LEFT"/>pg_name<br ALIGN="LEFT"/>|allgather(output_tensors, input_tensor, opts)<br ALIGN="LEFT"/>allgather_into_tensor_coalesced(output_tensor_list, input_tensor_list, opts)<br ALIGN="LEFT"/>allreduce(tensor_list, opts)<br ALIGN="LEFT"/>allreduce_coalesced(tensor_list, opts)<br ALIGN="LEFT"/>alltoall(output_tensor_list, input_tensor_list, opts)<br ALIGN="LEFT"/>alltoall_base(output_buffer: torch.Tensor, input_buffer: torch.Tensor, output_split_sizes: Optional[List[int]], input_split_sizes: Optional[List[int]], opts): torch.Tensor<br ALIGN="LEFT"/>barrier(opts)<br ALIGN="LEFT"/>broadcast(tensor_list, opts)<br ALIGN="LEFT"/>exception_handle(exc)<br ALIGN="LEFT"/>gather(output_tensors, input_tensors, opts)<br ALIGN="LEFT"/>getBackendName()<br ALIGN="LEFT"/>reduce_scatter(output_tensor, scatter_list, opts)<br ALIGN="LEFT"/>reduce_scatter_tensor_coalesced(output_tensors, input_tensors, opts)<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>scatter(output_tensors, input_tensors, opts)<br ALIGN="LEFT"/>size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.spawn.ProcessRaisedException" [color="black", fontcolor="red", label=<{ProcessRaisedException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.Prod" [color="black", fontcolor="black", label=<{Prod|products<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.wrapper_benchmark.ProfileEvent" [color="black", fontcolor="black", label=<{ProfileEvent|category : str<br ALIGN="LEFT"/>count : float<br ALIGN="LEFT"/>key : str<br ALIGN="LEFT"/>self_device_time_ms : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.profiler.ProfileMetrics" [color="black", fontcolor="black", label=<{ProfileMetrics|fusions : int<br ALIGN="LEFT"/>graphs : int<br ALIGN="LEFT"/>microseconds : float<br ALIGN="LEFT"/>operators : int<br ALIGN="LEFT"/>|tocsv(): List[float]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.profiler.ProfileResult" [color="black", fontcolor="black", label=<{ProfileResult|captured<br ALIGN="LEFT"/>total<br ALIGN="LEFT"/>unique_graphs : int<br ALIGN="LEFT"/>|percent(): ProfileMetrics<br ALIGN="LEFT"/>tocsv(): List[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.profiler.Profiler" [color="black", fontcolor="black", label=<{Profiler|prof<br ALIGN="LEFT"/>unique_graphs : int<br ALIGN="LEFT"/>|results(): ProfileResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler.profiler.ProfilerAction" [color="black", fontcolor="black", label=<{ProfilerAction|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.types.ProfilerEndHook" [color="black", fontcolor="black", label=<{ProfilerEndHook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.types.ProfilerStartHook" [color="black", fontcolor="black", label=<{ProfilerStartHook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.ProfilingMode" [color="black", fontcolor="black", label=<{ProfilingMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.PropModule" [color="black", fontcolor="black", label=<{PropModule|m<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts" [color="black", fontcolor="black", label=<{PropagateUnbackedSymInts|<br ALIGN="LEFT"/>|run_node(n: torch.fx.Node): Result<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._property_bag.PropertyBag" [color="black", fontcolor="black", label=<{PropertyBag|tags : Optional[List[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.proxy.Proxy" [color="black", fontcolor="black", label=<{Proxy|node<br ALIGN="LEFT"/>tracer : str<br ALIGN="LEFT"/>|keys()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode" [color="black", fontcolor="black", label=<{ProxyTorchDispatchMode|decomp_layers : int<br ALIGN="LEFT"/>emulate_precision_casts : bool<br ALIGN="LEFT"/>enable_tracing<br ALIGN="LEFT"/>enter_stack : List[Optional[ProxyTorchDispatchMode]]<br ALIGN="LEFT"/>pre_dispatch : bool<br ALIGN="LEFT"/>tracer : Union<br ALIGN="LEFT"/>tracing_mode : str<br ALIGN="LEFT"/>|is_infra_mode(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.pass_infra.proxy_value.ProxyValue" [color="black", fontcolor="black", label=<{ProxyValue|data<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>proxy_or_node : Union[torch.fx.Proxy, torch.fx.Node]<br ALIGN="LEFT"/>|is_tensor(): bool<br ALIGN="LEFT"/>to_tensor(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace.ProxyableClassMeta" [color="black", fontcolor="black", label=<{ProxyableClassMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.prune.PruningContainer" [color="black", fontcolor="black", label=<{PruningContainer|<br ALIGN="LEFT"/>|add_pruning_method(method)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.PyCodeCache" [color="black", fontcolor="black", label=<{PyCodeCache|linemaps : Dict[str, List[Tuple[Any, ...]]]<br ALIGN="LEFT"/>modules : List[ModuleType]<br ALIGN="LEFT"/>|cache_clear(purge: bool): None<br ALIGN="LEFT"/>load(source_code: str, extra: str, linemap: Optional[List[Tuple[int, str]]], attrs: Optional[Dict[str, Any]]): ModuleType<br ALIGN="LEFT"/>load_by_key_path(key: str, path: str, linemap: Optional[List[Tuple[int, str]]], attrs: Optional[Dict[str, Any]]): ModuleType<br ALIGN="LEFT"/>stack_frames_for_code(path: str, lineno: int): Optional[List[Dict[str, Any]]]<br ALIGN="LEFT"/>write(source_code: str, extra: str): Tuple[str, str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.codegen.PyCodegen" [color="black", fontcolor="black", label=<{PyCodegen|cell_and_freevars<br ALIGN="LEFT"/>code_options<br ALIGN="LEFT"/>graph_output_var : Optional[str]<br ALIGN="LEFT"/>graph_outputs : Dict[int, GraphOutputEntry]<br ALIGN="LEFT"/>new_var<br ALIGN="LEFT"/>overridden_sources : Dict[Source, Source]<br ALIGN="LEFT"/>root : Optional[torch.nn.Module]<br ALIGN="LEFT"/>tempvars : dict<br ALIGN="LEFT"/>top_of_stack : NoneType, Optional[VariableTracker]<br ALIGN="LEFT"/>tx : NoneType<br ALIGN="LEFT"/>uses : Counter[VariableTracker]<br ALIGN="LEFT"/>value_from_source : bool<br ALIGN="LEFT"/>|add_cache(value)<br ALIGN="LEFT"/>add_graph_output(value)<br ALIGN="LEFT"/>add_push_null(gen_fn, call_function_ex)<br ALIGN="LEFT"/>append_output(inst)<br ALIGN="LEFT"/>call_function(nargs: int, push_null: bool)<br ALIGN="LEFT"/>call_method(nargs)<br ALIGN="LEFT"/>call_reconstruct(value)<br ALIGN="LEFT"/>clear_tos()<br ALIGN="LEFT"/>create_call_function_kw(nargs, kw_names, push_null): List[Instruction]<br ALIGN="LEFT"/>create_delete(value): Instruction<br ALIGN="LEFT"/>create_load(name): Instruction<br ALIGN="LEFT"/>create_load_attr(name): Instruction<br ALIGN="LEFT"/>create_load_attrs(names)<br ALIGN="LEFT"/>create_load_closure(name): Instruction<br ALIGN="LEFT"/>create_load_const(value): Instruction<br ALIGN="LEFT"/>create_load_const_unchecked(value): Instruction<br ALIGN="LEFT"/>create_load_deref(name): Instruction<br ALIGN="LEFT"/>create_load_global(name, add): Instruction<br ALIGN="LEFT"/>create_load_python_module(mod): Instruction<br ALIGN="LEFT"/>create_store(name): Instruction<br ALIGN="LEFT"/>create_store_attr(name): Instruction<br ALIGN="LEFT"/>create_store_deref(name): Instruction<br ALIGN="LEFT"/>dup_top()<br ALIGN="LEFT"/>extend_output(insts)<br ALIGN="LEFT"/>foreach(items)<br ALIGN="LEFT"/>get_instructions(): List[Instruction]<br ALIGN="LEFT"/>graph_output_vars()<br ALIGN="LEFT"/>load_attr(name)<br ALIGN="LEFT"/>load_deref(varname)<br ALIGN="LEFT"/>load_function_name(fn_name, push_null, num_on_stack)<br ALIGN="LEFT"/>load_graph_output(index)<br ALIGN="LEFT"/>load_import_from(module_name, object_name): None<br ALIGN="LEFT"/>load_method(name)<br ALIGN="LEFT"/>make_call_generated_code(fn_name: str): None<br ALIGN="LEFT"/>make_function_with_closure(fn_name: str, code: types.CodeType, push_null: bool, num_on_stack)<br ALIGN="LEFT"/>pop_null()<br ALIGN="LEFT"/>pop_top()<br ALIGN="LEFT"/>restore_stack(stack_values)<br ALIGN="LEFT"/>rot_n(n)<br ALIGN="LEFT"/>setup_globally_cached(name, value)<br ALIGN="LEFT"/>store(varname)<br ALIGN="LEFT"/>store_attr(name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.PyExprCSEPass" [color="black", fontcolor="black", label=<{PyExprCSEPass|ALLOWED_NODE_TYPES : tuple<br ALIGN="LEFT"/>USE_THRESHOLD : int<br ALIGN="LEFT"/>|count(exprs: List[str]): None<br ALIGN="LEFT"/>replace(expr: str): Tuple[List[str], str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization._legacy_save.PyTorchLegacyPickler" [color="black", fontcolor="black", label=<{PyTorchLegacyPickler|<br ALIGN="LEFT"/>|persistent_id(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization._save.PyTorchPickler" [color="black", fontcolor="black", label=<{PyTorchPickler|<br ALIGN="LEFT"/>|persistent_id(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.polyfills.pytree.PyTreeSpec" [color="black", fontcolor="black", label=<{PyTreeSpec|namespace : Literal['torch']<br ALIGN="LEFT"/>none_is_leaf : Literal[True]<br ALIGN="LEFT"/>num_children : int<br ALIGN="LEFT"/>num_leaves : int<br ALIGN="LEFT"/>num_nodes : int<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|child(index: int): PyTreeSpec<br ALIGN="LEFT"/>children(): list[PyTreeSpec]<br ALIGN="LEFT"/>entries(): list[Any]<br ALIGN="LEFT"/>entry(index: int): Any<br ALIGN="LEFT"/>flatten_up_to(tree: PyTree): list[PyTree]<br ALIGN="LEFT"/>is_leaf(): bool<br ALIGN="LEFT"/>unflatten(leaves: Iterable[Any]): PyTree<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph.PythonCode" [color="black", fontcolor="black", label=<{PythonCode|globals : Dict[str, Any]<br ALIGN="LEFT"/>src : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._python_dispatcher.PythonDispatcher" [color="black", fontcolor="black", label=<{PythonDispatcher|alias_keys : list<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>namespace : str<br ALIGN="LEFT"/>ref<br ALIGN="LEFT"/>runtime_keys : list<br ALIGN="LEFT"/>supported_keys : list<br ALIGN="LEFT"/>|dispatchTable()<br ALIGN="LEFT"/>keys()<br ALIGN="LEFT"/>rawDispatchTable()<br ALIGN="LEFT"/>rawRegistrations()<br ALIGN="LEFT"/>register(dispatchKeys)<br ALIGN="LEFT"/>registrations()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.functional_tensor.PythonFunctionalizeAPI" [color="black", fontcolor="black", label=<{PythonFunctionalizeAPI|mode<br ALIGN="LEFT"/>pre_dispatch : bool<br ALIGN="LEFT"/>|commit_update(tensor): None<br ALIGN="LEFT"/>functionalize(inner_f: Callable): Callable<br ALIGN="LEFT"/>mark_mutation_hidden_from_autograd(tensor): None<br ALIGN="LEFT"/>redispatch_to_next(): ContextManager<br ALIGN="LEFT"/>replace(input_tensor, output_tensor): None<br ALIGN="LEFT"/>sync(tensor): None<br ALIGN="LEFT"/>unwrap_tensors(args: Union[torch.Tensor, Tuple[torch.Tensor, ...], List[torch.Tensor]]): Any<br ALIGN="LEFT"/>wrap_tensors(args: Tuple[Any]): Tuple[Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor.PythonKeyTracer" [color="black", fontcolor="black", label=<{PythonKeyTracer|enable_thunkify : bool<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>script_object_tracker : MutableMapping[_AnyScriptObjectType, Proxy]<br ALIGN="LEFT"/>symnode_tracker<br ALIGN="LEFT"/>sympy_expr_tracker : Dict[sympy.Symbol, object]<br ALIGN="LEFT"/>tensor_attrs : dict<br ALIGN="LEFT"/>tensor_tracker : MutableMapping[Tensor, _ProxyTensor]<br ALIGN="LEFT"/>torch_fn_counts : Dict[OpOverload, int]<br ALIGN="LEFT"/>torch_fn_metadata : NoneType<br ALIGN="LEFT"/>|call_module(m: Module, forward: Callable[..., Any], args: Tuple[Any, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>create_arg(a: object): fx.node.Node<br ALIGN="LEFT"/>getattr(attr: str, attr_val: object, parameter_proxy_cache: Dict[str, Proxy]): object<br ALIGN="LEFT"/>unwrap_proxy(e: Tensor): Union[Proxy, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.PythonMod" [color="black", fontcolor="black", label=<{PythonMod|is_integer : bool<br ALIGN="LEFT"/>nargs : Tuple[int, ...]<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(p: sympy.Expr, q: sympy.Expr): Optional[sympy.Expr]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.PythonModuleVariable" [color="black", fontcolor="black", label=<{PythonModuleVariable|is_torch<br ALIGN="LEFT"/>value : module<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.printers.PythonPrinter" [color="black", fontcolor="black", label=<{PythonPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.PythonPrinter" [color="black", fontcolor="black", label=<{PythonPrinter|<br ALIGN="LEFT"/>|doprint(expr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.refs.PythonRefInfo" [color="black", fontcolor="black", label=<{PythonRefInfo|torch_opinfo<br ALIGN="LEFT"/>torch_opinfo_name<br ALIGN="LEFT"/>torch_opinfo_variant_name : str<br ALIGN="LEFT"/>validate_view_consistency : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.reference.PythonReferenceAnalysis" [color="black", fontcolor="black", label=<{PythonReferenceAnalysis|<br ALIGN="LEFT"/>|bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>ceil_to_int(x, dtype)<br ALIGN="LEFT"/>constant(c, dtype)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floor_to_int(x, dtype)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>mod(x, y)<br ALIGN="LEFT"/>not_(a)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>pow_by_natural(a, b)<br ALIGN="LEFT"/>round_decimal(a, b)<br ALIGN="LEFT"/>round_to_int(a, dtype)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>sym_sum(args)<br ALIGN="LEFT"/>to_dtype(x, dtype)<br ALIGN="LEFT"/>truediv(a, b)<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.PythonSysModulesVariable" [color="black", fontcolor="black", label=<{PythonSysModulesVariable|<br ALIGN="LEFT"/>|call_contains(tx: 'InstructionTranslator', key: VariableTracker)<br ALIGN="LEFT"/>call_get(tx: 'InstructionTranslator', key: VariableTracker, default: Optional[VariableTracker])<br ALIGN="LEFT"/>call_getitem(tx: 'InstructionTranslator', key: VariableTracker)<br ALIGN="LEFT"/>call_method(tx: 'InstructionTranslator', name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker])<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" [color="black", fontcolor="black", label=<{PythonWrapperCodegen|add_import_once<br ALIGN="LEFT"/>additional_files : list<br ALIGN="LEFT"/>allocated<br ALIGN="LEFT"/>allocated_workspaces : Dict[str, Any]<br ALIGN="LEFT"/>already_codegened_subgraphs<br ALIGN="LEFT"/>codegened_graph_stack : list<br ALIGN="LEFT"/>comment : str<br ALIGN="LEFT"/>computed_sizes : OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>computed_sizes_stack : list<br ALIGN="LEFT"/>debug_printer<br ALIGN="LEFT"/>declare : str<br ALIGN="LEFT"/>declare_maybe_reference : str<br ALIGN="LEFT"/>ending : str<br ALIGN="LEFT"/>freed<br ALIGN="LEFT"/>header<br ALIGN="LEFT"/>imports<br ALIGN="LEFT"/>kernel_autotune_calls<br ALIGN="LEFT"/>kernel_autotune_defs<br ALIGN="LEFT"/>kernel_autotune_names<br ALIGN="LEFT"/>kernel_numel_expr : OrderedSet[Tuple[str, GraphLowering]]<br ALIGN="LEFT"/>last_seen_device_guard_index : Optional[int]<br ALIGN="LEFT"/>launcher_fn_name : NoneType, str<br ALIGN="LEFT"/>lines : List[Union[MemoryPlanningLine, LineContext]]<br ALIGN="LEFT"/>move_begin : str<br ALIGN="LEFT"/>move_end : str<br ALIGN="LEFT"/>multi_kernel_state<br ALIGN="LEFT"/>none_str : str<br ALIGN="LEFT"/>prefix<br ALIGN="LEFT"/>reuses : Dict[BufferName, BufferName]<br ALIGN="LEFT"/>src_to_kernel : Dict[str, str]<br ALIGN="LEFT"/>subgraph_definitions<br ALIGN="LEFT"/>suffix<br ALIGN="LEFT"/>supports_intermediate_hooks : bool<br ALIGN="LEFT"/>unbacked_symbol_decls<br ALIGN="LEFT"/>user_defined_kernel_cache : Dict[Tuple[Any, ...], Tuple[str, Any]]<br ALIGN="LEFT"/>wrapper_call<br ALIGN="LEFT"/>write_get_raw_stream<br ALIGN="LEFT"/>|add_benchmark_harness(output)<br ALIGN="LEFT"/>add_meta_once(meta: TritonMetaParams): str<br ALIGN="LEFT"/>benchmark_compiled_module(output)<br ALIGN="LEFT"/>can_prove_buffer_has_static_shape(buffer)<br ALIGN="LEFT"/>can_reuse(input_buffer, output_buffer)<br ALIGN="LEFT"/>codegen_alloc_from_pool(name, offset, dtype, shape, stride): str<br ALIGN="LEFT"/>codegen_allocation(buffer: ir.Buffer)<br ALIGN="LEFT"/>codegen_conditional(conditional)<br ALIGN="LEFT"/>codegen_cpp_sizevar(x: Expr): str<br ALIGN="LEFT"/>codegen_deferred_allocation(name, layout)<br ALIGN="LEFT"/>codegen_device_copy(src, dst, non_blocking: bool)<br ALIGN="LEFT"/>codegen_device_guard_enter(device_idx: int): None<br ALIGN="LEFT"/>codegen_device_guard_exit(): None<br ALIGN="LEFT"/>codegen_dynamic_scalar(node)<br ALIGN="LEFT"/>codegen_exact_buffer_reuse(old_name: str, new_name: str, del_line: str)<br ALIGN="LEFT"/>codegen_free(buffer)<br ALIGN="LEFT"/>codegen_inplace_reuse(input_buffer: ir.Buffer, output_buffer: ir.Buffer)<br ALIGN="LEFT"/>codegen_input_nan_asserts(): None<br ALIGN="LEFT"/>codegen_input_size_and_nan_asserts(): None<br ALIGN="LEFT"/>codegen_input_size_asserts(): None<br ALIGN="LEFT"/>codegen_input_symbol_assignment(name: str, value: ir.TensorBox, bound_vars: OrderedSet[sympy.Symbol])<br ALIGN="LEFT"/>codegen_inputs()<br ALIGN="LEFT"/>codegen_invoke_subgraph(invoke_subgraph)<br ALIGN="LEFT"/>codegen_multi_output(name, value)<br ALIGN="LEFT"/>codegen_python_shape_tuple(shape: Sequence[Expr]): str<br ALIGN="LEFT"/>codegen_python_sizevar(x: Expr): str<br ALIGN="LEFT"/>codegen_reinterpret_view(data, size, stride, offset, writeline: Callable[..., None], dtype): str<br ALIGN="LEFT"/>codegen_shape_tuple(shape: Sequence[Expr]): str<br ALIGN="LEFT"/>codegen_sizevar(x: Expr): str<br ALIGN="LEFT"/>codegen_subgraph(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_subgraph_by_inlining(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_subgraph_call(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_subgraph_prefix(subgraph, outer_inputs, outer_outputs)<br ALIGN="LEFT"/>codegen_tuple_access(basename: str, name: str, index: str): str<br ALIGN="LEFT"/>codegen_unbacked_symbol_decl(symbol)<br ALIGN="LEFT"/>codegen_while_loop(while_loop)<br ALIGN="LEFT"/>create(is_subgraph: bool, subgraph_name: str, parent_wrapper: PythonWrapperCodegen)<br ALIGN="LEFT"/>define_kernel(kernel_name: str, kernel_body: str, metadata: Optional[str], gpu)<br ALIGN="LEFT"/>define_subgraph_launcher_fn(fn_code: str)<br ALIGN="LEFT"/>define_user_defined_triton_kernel(kernel, configs, kwargs, restore_value_args, reset_to_zero_args)<br ALIGN="LEFT"/>did_reuse(buffer, reused_buffer)<br ALIGN="LEFT"/>ensure_size_computed(sym: sympy.Symbol)<br ALIGN="LEFT"/>enter_context(ctx)<br ALIGN="LEFT"/><I>finalize_prefix</I>()<br ALIGN="LEFT"/>generate(is_inference)<br ALIGN="LEFT"/>generate_and_run_autotune_block()<br ALIGN="LEFT"/>generate_before_suffix(result: IndentedBuffer): None<br ALIGN="LEFT"/>generate_default_grid(kernel_name: str, grid_args: List[Any], gpu: bool, grid_callable: Optional[Callable[..., Any]])<br ALIGN="LEFT"/>generate_end(result: IndentedBuffer): None<br ALIGN="LEFT"/>generate_end_graph()<br ALIGN="LEFT"/>generate_example_arg_value(arg, arg_type, raw_arg, index)<br ALIGN="LEFT"/>generate_extern_kernel_alloc(extern_kernel, args)<br ALIGN="LEFT"/>generate_extern_kernel_out(kernel: str, out: str, out_view: Optional[str], args: List[str])<br ALIGN="LEFT"/>generate_fallback_kernel(fallback_kernel, args)<br ALIGN="LEFT"/>generate_fallback_kernel_with_runtime_lookup(buf_name: str, python_kernel_name: str, cpp_kernel_name: str, codegen_args: List[str], op_overload: Optional[torch._ops.OpOverload], raw_args, outputs)<br ALIGN="LEFT"/>generate_index_put_fallback(kernel, x, indices, values, accumulate)<br ALIGN="LEFT"/>generate_kernel_call(kernel_name: str, call_args, grid, device_index, gpu, triton, arg_types, raw_args, grid_fn: str, triton_meta, autotune_configs, grid_extra_kwargs)<br ALIGN="LEFT"/>generate_numel_expr(kernel_name: str, tree, suffix: Optional[str])<br ALIGN="LEFT"/>generate_profiler_mark_wrapper_call(stack)<br ALIGN="LEFT"/>generate_reset_kernel_saved_flags()<br ALIGN="LEFT"/>generate_return(output_refs: List[str]): None<br ALIGN="LEFT"/>generate_save_uncompiled_kernels()<br ALIGN="LEFT"/>generate_scatter_fallback(output, inputs, cpp_kernel_name, python_kernel_name, src_is_tensor, reduce, kwargs)<br ALIGN="LEFT"/>generate_start_graph()<br ALIGN="LEFT"/>generate_tma_descriptor(desc)<br ALIGN="LEFT"/>generate_user_defined_triton_kernel(kernel_name: str, raw_args: List[Any], grid: List[Any], configs, triton_meta, constexprs)<br ALIGN="LEFT"/>generate_workspace_allocation(ws: WorkspaceArg)<br ALIGN="LEFT"/>generate_workspace_deallocation(ws: WorkspaceArg)<br ALIGN="LEFT"/>get_codegened_graph()<br ALIGN="LEFT"/>get_output_refs(): List[str]<br ALIGN="LEFT"/><I>include_extra_header</I>(header: str)<br ALIGN="LEFT"/>is_statically_known_list_of_ints(lst)<br ALIGN="LEFT"/>make_allocation(name, device, dtype, shape, stride)<br ALIGN="LEFT"/>make_buffer_allocation(buffer: BufferLike)<br ALIGN="LEFT"/>make_buffer_free(buffer: BufferLike)<br ALIGN="LEFT"/>make_buffer_reuse(old: BufferLike, new: BufferLike, delete_old: bool)<br ALIGN="LEFT"/>make_free_by_names(names_to_del: List[str])<br ALIGN="LEFT"/>make_tensor_alias(new_name, old_name, comment)<br ALIGN="LEFT"/>make_zero_buffer(name)<br ALIGN="LEFT"/>mark_output_type(): None<br ALIGN="LEFT"/>memory_plan()<br ALIGN="LEFT"/>memory_plan_reuse()<br ALIGN="LEFT"/>next_kernel_suffix(): str<br ALIGN="LEFT"/>pop_codegened_graph()<br ALIGN="LEFT"/>pop_computed_sizes()<br ALIGN="LEFT"/>prepare_triton_kernel_call(device_index, call_args)<br ALIGN="LEFT"/>push_codegened_graph(graph)<br ALIGN="LEFT"/>push_computed_sizes(computed_sizes)<br ALIGN="LEFT"/>set_launcher_fn_name(): None<br ALIGN="LEFT"/>static_shape_for_buffer_or_none(buffer)<br ALIGN="LEFT"/>statically_known_int_or_none(x)<br ALIGN="LEFT"/>statically_known_list_of_ints_or_none(lst)<br ALIGN="LEFT"/>val_to_arg_str(s, type_)<br ALIGN="LEFT"/>wrap_kernel_call(name, call_args)<br ALIGN="LEFT"/>write_async_compile_wait(): None<br ALIGN="LEFT"/>write_constant(name: str, hashed: str): None<br ALIGN="LEFT"/>write_get_raw_stream(device_idx: int, graph): str<br ALIGN="LEFT"/>write_get_raw_stream_header_once(): None<br ALIGN="LEFT"/>write_header(): None<br ALIGN="LEFT"/>write_kernel_autotune_defs_header(): None<br ALIGN="LEFT"/>write_prefix(): None<br ALIGN="LEFT"/>write_triton_header_once(): None<br ALIGN="LEFT"/>writeline(line)<br ALIGN="LEFT"/>writelines(lines)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.pytree_flatten.PytreeFlatten" [color="black", fontcolor="black", label=<{PytreeFlatten|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.utils.PytreeThunk" [color="black", fontcolor="black", label=<{PytreeThunk|is_really_simple : Optional[bool]<br ALIGN="LEFT"/>is_simple : Optional[bool]<br ALIGN="LEFT"/>spec : Optional[pytree.TreeSpec]<br ALIGN="LEFT"/>|set(spec: pytree.TreeSpec): None<br ALIGN="LEFT"/>unflatten(x: List[Any]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.qconfig.QConfig" [color="black", fontcolor="black", label=<{QConfig|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.qconfig.QConfigDynamic" [color="black", fontcolor="black", label=<{QConfigDynamic|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.qconfig_mapping.QConfigMapping" [color="black", fontcolor="black", label=<{QConfigMapping|global_qconfig : Optional[QConfigAny]<br ALIGN="LEFT"/>module_name_object_type_order_qconfigs : OrderedDict[Tuple[str, Callable, int], QConfigAny]<br ALIGN="LEFT"/>module_name_qconfigs : OrderedDict[str, QConfigAny]<br ALIGN="LEFT"/>module_name_regex_qconfigs : OrderedDict[str, QConfigAny]<br ALIGN="LEFT"/>object_type_qconfigs : OrderedDict[Union[Callable, str], QConfigAny]<br ALIGN="LEFT"/>|from_dict(qconfig_dict: Dict[str, Any]): QConfigMapping<br ALIGN="LEFT"/>set_global(global_qconfig: QConfigAny): QConfigMapping<br ALIGN="LEFT"/>set_module_name(module_name: str, qconfig: QConfigAny): QConfigMapping<br ALIGN="LEFT"/>set_module_name_object_type_order(module_name: str, object_type: Callable, index: int, qconfig: QConfigAny): QConfigMapping<br ALIGN="LEFT"/>set_module_name_regex(module_name_regex: str, qconfig: QConfigAny): QConfigMapping<br ALIGN="LEFT"/>set_object_type(object_type: Union[Callable, str], qconfig: QConfigAny): QConfigMapping<br ALIGN="LEFT"/>to_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.qconfig_multi_mapping.QConfigMultiMapping" [color="black", fontcolor="black", label=<{QConfigMultiMapping|qconfig_mappings_list : List[QConfigMapping]<br ALIGN="LEFT"/>|from_list_qconfig_mapping(qconfig_mapping_list: List[QConfigMapping]): QConfigMultiMapping<br ALIGN="LEFT"/>set_global(global_qconfig_list: List[QConfigAny]): QConfigMultiMapping<br ALIGN="LEFT"/>set_module_name(module_name: str, qconfig_list: List[QConfigAny]): QConfigMultiMapping<br ALIGN="LEFT"/>set_module_name_object_type_order(module_name: str, object_type: Callable, index: int, qconfig_list: List[QConfigAny]): QConfigMultiMapping<br ALIGN="LEFT"/>set_module_name_regex(module_name_regex: str, qconfig_list: List[QConfigAny]): QConfigMultiMapping<br ALIGN="LEFT"/>set_object_type(object_type: Union[Callable, str], qconfig_list: List[QConfigAny]): QConfigMultiMapping<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.QConvPointWiseBinaryPT2E" [color="black", fontcolor="black", label=<{QConvPointWiseBinaryPT2E|has_bias<br ALIGN="LEFT"/>idx_for_inplace_sum : int<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(qx: 'TensorBox', x_scale: 'TensorBox', x_zero_point: 'TensorBox', qw: 'TensorBox', w_scale, w_zero_point, qaccum: 'TensorBox', bias: 'TensorBox', stride: List[int], padding: List[int], dilation: List[int], groups: int, output_scale: 'TensorBox', output_zero_point: 'TensorBox', output_dtype, accum_scale, accum_zero_point, binary_attr, alpha, unary_attr, unary_scalars, unary_algorithm)<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.QConvPointWisePT2E" [color="black", fontcolor="black", label=<{QConvPointWisePT2E|has_bias<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(qx: 'TensorBox', x_scale: 'TensorBox', x_zero_point: 'TensorBox', qw: 'TensorBox', w_scale: 'TensorBox', w_zero_point: 'TensorBox', bias: 'TensorBox', stride: List[int], padding: List[int], dilation: List[int], groups: int, output_scale: float, output_zero_point: int, output_dtype, attr, scalars, algorithm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.QFunctional" [color="black", fontcolor="black", label=<{QFunctional|activation_post_process<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|add(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_relu(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>add_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>cat(x: List[Tensor], dim: int): Tensor<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>matmul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul(x: Tensor, y: Tensor): Tensor<br ALIGN="LEFT"/>mul_scalar(x: Tensor, y: float): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.QInt32Storage" [color="black", fontcolor="black", label=<{QInt32Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.QInt8Storage" [color="black", fontcolor="black", label=<{QInt8Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.QLinearPointwiseBinaryPT2E" [color="black", fontcolor="black", label=<{QLinearPointwiseBinaryPT2E|has_bias : bool<br ALIGN="LEFT"/>idx_for_inplace_sum : int<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(qx: 'TensorBox', x_scale: 'TensorBox', x_zero_point: 'TensorBox', qw: 'TensorBox', w_scale: 'TensorBox', w_zero_point: 'TensorBox', other: 'TensorBox', bias: 'TensorBox', output_scale: float, output_zero_point: int, output_dtype, other_scale, other_zp, binary_post_op, binary_alpha, unary_post_op, unary_post_op_args, unary_post_op_algorithm)<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mkldnn_ir.QLinearPointwisePT2E" [color="black", fontcolor="black", label=<{QLinearPointwisePT2E|has_bias : bool<br ALIGN="LEFT"/>|codegen(wrapper)<br ALIGN="LEFT"/>create(qx: 'TensorBox', x_scale: 'TensorBox', x_zero_point: 'TensorBox', qw: 'TensorBox', w_scale: 'TensorBox', w_zero_point: 'TensorBox', bias: 'TensorBox', output_scale: float, output_zero_point: int, output_dtype, post_op_name, post_op_args, post_op_algorithm)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.QUInt2x4Storage" [color="black", fontcolor="black", label=<{QUInt2x4Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.QUInt4x2Storage" [color="black", fontcolor="black", label=<{QUInt4x2Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.QUInt8Storage" [color="black", fontcolor="black", label=<{QUInt8Storage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._trace.TracedModule.__init__.QualnameWrapper" [color="black", fontcolor="black", label=<{QualnameWrapper|training<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.stubs.QuantStub" [color="black", fontcolor="black", label=<{QuantStub|qconfig : NoneType<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.QuantStubModel" [color="black", fontcolor="black", label=<{QuantStubModel|dequant<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.QuantSubModel" [color="black", fontcolor="black", label=<{QuantSubModel|fc3<br ALIGN="LEFT"/>sub1<br ALIGN="LEFT"/>sub2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quant_type.QuantType" [color="black", fontcolor="black", label=<{QuantType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" [color="black", fontcolor="black", label=<{QuantWrapper|dequant<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>quant<br ALIGN="LEFT"/>|forward(X)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.QuantizationAnnotation" [color="black", fontcolor="black", label=<{QuantizationAnnotation|allow_implicit_sharing : bool<br ALIGN="LEFT"/>input_qspec_map : Dict[Node, Optional[QuantizationSpecBase]]<br ALIGN="LEFT"/>output_qspec : Optional[QuantizationSpecBase]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e._numeric_debugger.QuantizationComparisonResult" [color="black", fontcolor="black", label=<{QuantizationComparisonResult|actual<br ALIGN="LEFT"/>mse_loss<br ALIGN="LEFT"/>ref<br ALIGN="LEFT"/>sqnr<br ALIGN="LEFT"/>|loss(loss_function: Callable[[torch.Tensor, torch.Tensor], torch.Tensor]): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer_utils.QuantizationConfig" [color="black", fontcolor="black", label=<{QuantizationConfig|bias : Optional[QuantizationSpec]<br ALIGN="LEFT"/>input_activation : Optional[QuantizationSpec]<br ALIGN="LEFT"/>is_qat : bool<br ALIGN="LEFT"/>output_activation : Optional[QuantizationSpec]<br ALIGN="LEFT"/>weight : Optional[QuantizationSpec]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.QuantizationLiteTestCase" [color="black", fontcolor="black", label=<{QuantizationLiteTestCase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.QuantizationSpec" [color="black", fontcolor="black", label=<{QuantizationSpec|ch_axis : Optional[int]<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>is_dynamic : bool<br ALIGN="LEFT"/>observer_or_fake_quant_ctr : Union<br ALIGN="LEFT"/>qscheme : Optional[torch.qscheme]<br ALIGN="LEFT"/>quant_max : Optional[int]<br ALIGN="LEFT"/>quant_min : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.QuantizationSpecBase" [color="black", fontcolor="black", label=<{QuantizationSpecBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.QuantizationTestCase" [color="black", fontcolor="black", label=<{QuantizationTestCase|all_quant_types : list<br ALIGN="LEFT"/>calib_data<br ALIGN="LEFT"/>img_data_1d<br ALIGN="LEFT"/>img_data_1d_train<br ALIGN="LEFT"/>img_data_2d<br ALIGN="LEFT"/>img_data_2d_train<br ALIGN="LEFT"/>img_data_3d<br ALIGN="LEFT"/>img_data_3d_train<br ALIGN="LEFT"/>img_data_dict : dict<br ALIGN="LEFT"/>static_quant_types : list<br ALIGN="LEFT"/>train_data<br ALIGN="LEFT"/>|assert_ns_compare_dict_valid(act_compare_dict: Dict[str, Dict[str, Dict[str, Any]]]): None<br ALIGN="LEFT"/>assert_types_for_matched_subgraph_pairs(matched_subgraph_pairs: Dict[str, Tuple[NSSubgraph, NSSubgraph]], expected_types: Dict[str, Tuple[Tuple[Callable, Callable], Tuple[Callable, Callable]]], gm_a: GraphModule, gm_b: GraphModule): None<br ALIGN="LEFT"/>checkDynamicQuantizedLSTM(mod, reference_module_type, dtype)<br ALIGN="LEFT"/>checkDynamicQuantizedLinear(mod, dtype)<br ALIGN="LEFT"/>checkDynamicQuantizedLinearRelu(mod, dtype)<br ALIGN="LEFT"/>checkDynamicQuantizedModule(mod, reference_module_type, dtype)<br ALIGN="LEFT"/>checkEmbeddingSerialization(qemb, num_embeddings, embedding_dim, indices, offsets, set_qconfig, is_emb_bag, dtype)<br ALIGN="LEFT"/>checkGraphModeFxOp(model, inputs, quant_type, expected_node, expected_node_occurrence, expected_node_list, is_reference, print_debug_info, custom_qconfig_dict, prepare_expected_node, prepare_expected_node_occurrence, prepare_expected_node_list, prepare_custom_config, backend_config)<br ALIGN="LEFT"/>checkGraphModeOp(module, inputs, quantized_op, tracing, debug, check, eval_mode, dynamic, qconfig)<br ALIGN="LEFT"/>checkGraphModuleNodes(graph_module, expected_node, expected_node_occurrence, expected_node_list)<br ALIGN="LEFT"/>checkHasPrepModules(module)<br ALIGN="LEFT"/>checkLinear(mod)<br ALIGN="LEFT"/>checkNoPrepModules(module)<br ALIGN="LEFT"/>checkNoQconfig(module)<br ALIGN="LEFT"/>checkObservers(module, propagate_qconfig_list, prepare_custom_config_dict)<br ALIGN="LEFT"/>checkQuantDequant(mod)<br ALIGN="LEFT"/>checkQuantizedLinear(mod)<br ALIGN="LEFT"/>checkScriptable(orig_mod, calib_data, check_save_load)<br ALIGN="LEFT"/>checkWrappedQuantizedLinear(mod)<br ALIGN="LEFT"/>check_eager_serialization(ref_model, loaded_model, x)<br ALIGN="LEFT"/>check_weight_bias_api(ref_model, weight_keys, bias_keys)<br ALIGN="LEFT"/>printGraphModule(graph_module, print_str)<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.tracer.QuantizationTracer" [color="black", fontcolor="black", label=<{QuantizationTracer|record_stack_traces : bool<br ALIGN="LEFT"/>scope<br ALIGN="LEFT"/>skipped_module_classes : List[Callable]<br ALIGN="LEFT"/>skipped_module_names : List[str]<br ALIGN="LEFT"/>|is_leaf_module(m: torch.nn.Module, module_qualified_name: str): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.Quantize" [color="black", fontcolor="black", label=<{Quantize|dtype<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(X)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [color="black", fontcolor="black", label=<{QuantizeHandler|is_custom_module_ : bool<br ALIGN="LEFT"/>is_standalone_module_ : bool<br ALIGN="LEFT"/>modules : Dict[str, torch.nn.Module]<br ALIGN="LEFT"/>node_pattern : Union<br ALIGN="LEFT"/>num_tensor_args : int<br ALIGN="LEFT"/>root_node<br ALIGN="LEFT"/>|is_custom_module()<br ALIGN="LEFT"/>is_general_tensor_value_op(): bool<br ALIGN="LEFT"/>is_standalone_module()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.quantized.QuantizedEngine" [color="black", fontcolor="black", label=<{QuantizedEngine|engine<br ALIGN="LEFT"/>m<br ALIGN="LEFT"/>supported_engines<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedGRU" [color="black", fontcolor="black", label=<{QuantizedGRU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedGRUCell" [color="black", fontcolor="black", label=<{QuantizedGRUCell|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.graph_module.QuantizedGraphModule" [color="black", fontcolor="black", label=<{QuantizedGraphModule|preserved_attr_names : Set[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedLSTM" [color="black", fontcolor="black", label=<{QuantizedLSTM|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedLSTMCell" [color="black", fontcolor="black", label=<{QuantizedLSTMCell|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedLinear" [color="black", fontcolor="black", label=<{QuantizedLinear|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedLinearFP16" [color="black", fontcolor="black", label=<{QuantizedLinearFP16|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedRNNBase" [color="black", fontcolor="black", label=<{QuantizedRNNBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedRNNCell" [color="black", fontcolor="black", label=<{QuantizedRNNCell|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.quantized.QuantizedRNNCellBase" [color="black", fontcolor="black", label=<{QuantizedRNNCellBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.Quantizer" [color="black", fontcolor="black", label=<{Quantizer|<br ALIGN="LEFT"/>|<I>annotate</I>(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/>prepare_obs_or_fq_callback(model: torch.fx.GraphModule, edge_or_node_to_obs_or_fq: Dict[EdgeOrNode, ObserverOrFakeQuantize]): None<br ALIGN="LEFT"/>transform_for_annotation(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/><I>validate</I>(model: torch.fx.GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.queue.Queue" [color="black", fontcolor="black", label=<{Queue|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.radam.RAdam" [color="black", fontcolor="black", label=<{RAdam|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims_common.REDUCTION_OUTPUT_TYPE_KIND" [color="black", fontcolor="black", label=<{REDUCTION_OUTPUT_TYPE_KIND|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims_common.RETURN_TYPE" [color="black", fontcolor="black", label=<{RETURN_TYPE|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.normalization.RMSNorm" [color="black", fontcolor="black", label=<{RMSNorm|elementwise_affine : bool<br ALIGN="LEFT"/>eps : Optional[float]<br ALIGN="LEFT"/>normalized_shape : Tuple[int, ...]<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.RMSNormPython" [color="black", fontcolor="black", label=<{RMSNormPython|eps : float<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.rmsprop.RMSprop" [color="black", fontcolor="black", label=<{RMSprop|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.RNN" [color="black", fontcolor="black", label=<{RNN|nonlinearity<br ALIGN="LEFT"/>|<I>forward</I>(input: Tensor, hx: Optional[Tensor]): Tuple[Tensor, Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [color="black", fontcolor="black", label=<{RNNBase|batch_first : bool<br ALIGN="LEFT"/>bias : bool<br ALIGN="LEFT"/>bidirectional : bool<br ALIGN="LEFT"/>dropout : float<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>hidden_size<br ALIGN="LEFT"/>input_size<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>num_layers : int<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>version : int<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]): None<br ALIGN="LEFT"/>check_hidden_size(hx: Tensor, expected_hidden_size: Tuple[int, int, int], msg: str): None<br ALIGN="LEFT"/>check_input(input: Tensor, batch_sizes: Optional[Tensor]): None<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>get_bias()<br ALIGN="LEFT"/>get_expected_hidden_size(input: Tensor, batch_sizes: Optional[Tensor]): Tuple[int, int, int]<br ALIGN="LEFT"/>get_weight()<br ALIGN="LEFT"/>permute_hidden(hx: Tensor, permutation: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>set_weight_bias(weight_bias_dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNBase" [color="black", fontcolor="black", label=<{RNNBase|is_decomposed<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.rnn.RNNBase" [color="black", fontcolor="black", label=<{RNNBase|all_weights<br ALIGN="LEFT"/>batch_first : bool<br ALIGN="LEFT"/>bias : bool<br ALIGN="LEFT"/>bidirectional : bool<br ALIGN="LEFT"/>dropout : float<br ALIGN="LEFT"/>hidden_size : int<br ALIGN="LEFT"/>input_size : int<br ALIGN="LEFT"/>mode : str<br ALIGN="LEFT"/>num_layers : int<br ALIGN="LEFT"/>proj_size : int<br ALIGN="LEFT"/>|check_forward_args(input: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor])<br ALIGN="LEFT"/>check_hidden_size(hx: Tensor, expected_hidden_size: Tuple[int, int, int], msg: str): None<br ALIGN="LEFT"/>check_input(input: Tensor, batch_sizes: Optional[Tensor]): None<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>flatten_parameters(): None<br ALIGN="LEFT"/>get_expected_hidden_size(input: Tensor, batch_sizes: Optional[Tensor]): Tuple[int, int, int]<br ALIGN="LEFT"/>permute_hidden(hx: Tensor, permutation: Optional[Tensor])<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNCell" [color="black", fontcolor="black", label=<{RNNCell|nonlinearity : str<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNCell" [color="black", fontcolor="black", label=<{RNNCell|bias_hh<br ALIGN="LEFT"/>bias_ih<br ALIGN="LEFT"/>nonlinearity : str<br ALIGN="LEFT"/>weight_hh<br ALIGN="LEFT"/>weight_ih<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>from_float(mod, weight_qparams_dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.RNNCell" [color="black", fontcolor="black", label=<{RNNCell|nonlinearity : str<br ALIGN="LEFT"/>|forward(input: Tensor, hx: Optional[Tensor]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase" [color="black", fontcolor="black", label=<{RNNCellBase|bias : bool<br ALIGN="LEFT"/>bias_hh<br ALIGN="LEFT"/>bias_ih<br ALIGN="LEFT"/>hidden_size<br ALIGN="LEFT"/>input_size<br ALIGN="LEFT"/>weight_dtype<br ALIGN="LEFT"/>|check_forward_hidden(input: Tensor, hx: Tensor, hidden_label: str): None<br ALIGN="LEFT"/>check_forward_input(input)<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_mod)<br ALIGN="LEFT"/>get_bias()<br ALIGN="LEFT"/>get_weight()<br ALIGN="LEFT"/>set_weight_bias(weight_bias_dict)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase" [color="black", fontcolor="black", label=<{RNNCellBase|is_decomposed<br ALIGN="LEFT"/>|get_quantized_weight_hh()<br ALIGN="LEFT"/>get_quantized_weight_ih()<br ALIGN="LEFT"/>get_weight_hh()<br ALIGN="LEFT"/>get_weight_ih()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.rnn.RNNCellBase" [color="black", fontcolor="black", label=<{RNNCellBase|bias : bool<br ALIGN="LEFT"/>bias_hh<br ALIGN="LEFT"/>bias_ih<br ALIGN="LEFT"/>hidden_size : int<br ALIGN="LEFT"/>input_size : int<br ALIGN="LEFT"/>weight_hh<br ALIGN="LEFT"/>weight_ih<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.RNNCellDynamicModel" [color="black", fontcolor="black", label=<{RNNCellDynamicModel|mod<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.RNNDynamicModel" [color="black", fontcolor="black", label=<{RNNDynamicModel|mod<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.RNNDynamicQuantizeHandler" [color="black", fontcolor="black", label=<{RNNDynamicQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_benchmark_request.ROCmBenchmarkRequest" [color="black", fontcolor="black", label=<{ROCmBenchmarkRequest|DLL : Optional[DLLWrapper]<br ALIGN="LEFT"/>hash_key : str<br ALIGN="LEFT"/>source_code : str<br ALIGN="LEFT"/>source_file : str<br ALIGN="LEFT"/>workspace : NoneType, Optional[torch.Tensor]<br ALIGN="LEFT"/>workspace_size : int<br ALIGN="LEFT"/>|cleanup_run_fn(): None<br ALIGN="LEFT"/>ensure_dll_loaded()<br ALIGN="LEFT"/>make_run_fn(): Callable[[], None]<br ALIGN="LEFT"/>precompile()<br ALIGN="LEFT"/>update_workspace_size(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_cpp_scheduling.ROCmCPPScheduling" [color="black", fontcolor="black", label=<{ROCmCPPScheduling|scheduler<br ALIGN="LEFT"/>|can_fuse_vertical(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>codegen_template(template_node: BaseSchedulerNode, epilogue_nodes: Sequence[BaseSchedulerNode], prologue_nodes: Sequence[BaseSchedulerNode])<br ALIGN="LEFT"/>define_kernel(src_code: str, node_schedule): str<br ALIGN="LEFT"/>group_fn(sizes)<br ALIGN="LEFT"/>is_rocm_cpp_template(node: BaseSchedulerNode): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.ROCmCodeCache" [color="black", fontcolor="black", label=<{ROCmCodeCache|cache : Dict[str, CacheEntry]<br ALIGN="LEFT"/>cache_clear : staticmethod<br ALIGN="LEFT"/>|compile(source_code: str, dst_file_ext: str, extra_args: Optional[List[str]]): Tuple[str, str, str]<br ALIGN="LEFT"/>load(source_code: str, dst_file_ext: str): Tuple[DLLWrapper, str, str]<br ALIGN="LEFT"/>write(source_code: str, dst_file_ext: str): Tuple[str, str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmKernel" [color="black", fontcolor="black", label=<{ROCmKernel|overrides<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_template.ROCmTemplate" [color="black", fontcolor="black", label=<{ROCmTemplate|index_counter : count<br ALIGN="LEFT"/>input_nodes : List[Buffer]<br ALIGN="LEFT"/>input_reorder : Optional[List[int]]<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>|generate(): ROCmTemplateCaller<br ALIGN="LEFT"/>globals(): IndentedBuffer<br ALIGN="LEFT"/>header(): IndentedBuffer<br ALIGN="LEFT"/><I>render</I>(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_template_buffer.ROCmTemplateBuffer" [color="black", fontcolor="black", label=<{ROCmTemplateBuffer|template : str<br ALIGN="LEFT"/>workspace_size : int<br ALIGN="LEFT"/>|get_workspace_size()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmTemplateCaller" [color="black", fontcolor="black", label=<{ROCmTemplateCaller|bmreq<br ALIGN="LEFT"/>category : str<br ALIGN="LEFT"/>info_kwargs : Optional[Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]]<br ALIGN="LEFT"/>make_kernel_render : Callable[[ROCmTemplateBuffer, Optional[List[IRNode]]], str]<br ALIGN="LEFT"/>template : str<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/>call_name(): str<br ALIGN="LEFT"/>hash_key(): str<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]<br ALIGN="LEFT"/>output_node(): TensorBox<br ALIGN="LEFT"/>precompile(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmTemplateKernel" [color="black", fontcolor="black", label=<{ROCmTemplateKernel|kernel_name<br ALIGN="LEFT"/>named_nodes : Dict[str, IRNode]<br ALIGN="LEFT"/>signature : str<br ALIGN="LEFT"/>|arg_name(node: IRNode): Optional[str]<br ALIGN="LEFT"/>call_kernel(name: str, node: 'ROCmTemplateBuffer'): None<br ALIGN="LEFT"/>def_kernel(inputs: List[IRNode], outputs: List[IRNode], size_args: List[str], names_str: str, input_reorder: Optional[List[int]]): str<br ALIGN="LEFT"/>get_signature()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.rpc.internal.RPCExecMode" [color="black", fontcolor="black", label=<{RPCExecMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.activation.RReLU" [color="black", fontcolor="black", label=<{RReLU|inplace : bool<br ALIGN="LEFT"/>lower : float<br ALIGN="LEFT"/>upper : float<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.rpc.api.RRef" [color="black", fontcolor="black", label=<{RRef|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest" [color="black", fontcolor="black", label=<{RRefAPITest|<br ALIGN="LEFT"/>|test_local_rref_local_value()<br ALIGN="LEFT"/>test_rref_is_owner()<br ALIGN="LEFT"/>test_rref_list_mutate()<br ALIGN="LEFT"/>test_rref_local_value()<br ALIGN="LEFT"/>test_user_rrefs_confirmed()<br ALIGN="LEFT"/>test_user_rrefs_confirmed_remote()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.rpc.api.RRefMeta" [color="black", fontcolor="black", label=<{RRefMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.rpc.rref_proxy.RRefProxy" [color="black", fontcolor="black", label=<{RRefProxy|rpc_api<br ALIGN="LEFT"/>rpc_timeout<br ALIGN="LEFT"/>rref<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest" [color="black", fontcolor="black", label=<{RRefTypingTest|<br ALIGN="LEFT"/>|test_my_script_module_with_rrefs()<br ALIGN="LEFT"/>test_rref_as_arg_and_return()<br ALIGN="LEFT"/>test_rref_python_annotation()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.RShift" [color="black", fontcolor="black", label=<{RShift|is_integer : bool<br ALIGN="LEFT"/>|eval(base, shift)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.RandomClassVariable" [color="black", fontcolor="black", label=<{RandomClassVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.sampler.RandomSampler" [color="black", fontcolor="black", label=<{RandomSampler|data_source : Sized<br ALIGN="LEFT"/>generator : NoneType<br ALIGN="LEFT"/>num_samples<br ALIGN="LEFT"/>replacement : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.RandomSeeds" [color="black", fontcolor="black", label=<{RandomSeeds|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.prune.RandomStructured" [color="black", fontcolor="black", label=<{RandomStructured|PRUNING_TYPE : str<br ALIGN="LEFT"/>amount<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>|apply(module, name, amount, dim)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.prune.RandomUnstructured" [color="black", fontcolor="black", label=<{RandomUnstructured|PRUNING_TYPE : str<br ALIGN="LEFT"/>amount<br ALIGN="LEFT"/>|apply(module, name, amount)<br ALIGN="LEFT"/>compute_mask(t, default_mask)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.RandomValueSource" [color="black", fontcolor="black", label=<{RandomValueSource|random_call_index : int<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.RandomVariable" [color="black", fontcolor="black", label=<{RandomVariable|random : Random<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>check_state(state)<br ALIGN="LEFT"/>is_supported_random_obj(val)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>unwrap_state(state)<br ALIGN="LEFT"/>wrap_state(state)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.RandomVariable" [color="black", fontcolor="black", label=<{RandomVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.RangeConstraint" [color="black", fontcolor="black", label=<{RangeConstraint|max_val : Annotated[Optional[int], 20]<br ALIGN="LEFT"/>min_val : Annotated[Optional[int], 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.RangeVariable" [color="black", fontcolor="black", label=<{RangeVariable|<br ALIGN="LEFT"/>|apply_index(index)<br ALIGN="LEFT"/>apply_slice(slice)<br ALIGN="LEFT"/>as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>getitem_const(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>range_length()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>start()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>stop()<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.events.api.RdzvEvent" [color="black", fontcolor="black", label=<{RdzvEvent|error_trace : str<br ALIGN="LEFT"/>hostname : str<br ALIGN="LEFT"/>local_id : Optional[int]<br ALIGN="LEFT"/>master_endpoint : str<br ALIGN="LEFT"/>message : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>node_state<br ALIGN="LEFT"/>pid : int<br ALIGN="LEFT"/>rank : Optional[int]<br ALIGN="LEFT"/>run_id : str<br ALIGN="LEFT"/>|deserialize(data: Union[str, 'RdzvEvent']): 'RdzvEvent'<br ALIGN="LEFT"/>serialize(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.ReInplaceTrigger" [color="black", fontcolor="black", label=<{ReInplaceTrigger|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.activation.ReLU" [color="black", fontcolor="black", label=<{ReLU|inplace : bool<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.ReLU6" [color="black", fontcolor="black", label=<{ReLU6|inplace : bool<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.ReLU6" [color="black", fontcolor="black", label=<{ReLU6|<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.ReadItem" [color="black", fontcolor="black", label=<{ReadItem|dest_index<br ALIGN="LEFT"/>dest_offsets<br ALIGN="LEFT"/>lengths<br ALIGN="LEFT"/>storage_index<br ALIGN="LEFT"/>storage_offsets<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.dependencies.ReadWrites" [color="black", fontcolor="black", label=<{ReadWrites|index_exprs : OrderedSet[IndexExprDep]<br ALIGN="LEFT"/>range_vars : Optional[List[sympy.Expr]]<br ALIGN="LEFT"/>reads : OrderedSet[Dep]<br ALIGN="LEFT"/>var_ranges : Optional[VarRanges]<br ALIGN="LEFT"/>writes : OrderedSet[Dep]<br ALIGN="LEFT"/>|buffer_names(ignore_integer_index)<br ALIGN="LEFT"/>merge(other: 'ReadWrites')<br ALIGN="LEFT"/>merge_list(read_writes: List['ReadWrites'])<br ALIGN="LEFT"/>reads_and_writes()<br ALIGN="LEFT"/>remove_reads(rem_reads)<br ALIGN="LEFT"/>rename(renames: typing.Dict[str, str]): 'ReadWrites'<br ALIGN="LEFT"/>with_read(dep: Union[Dep, OrderedSet[Dep]]): 'ReadWrites'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.repro.after_aot.repro_analyze.ReaderInterp" [color="black", fontcolor="black", label=<{ReaderInterp|<br ALIGN="LEFT"/>|run_node(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.bytecode_analysis.ReadsWrites" [color="black", fontcolor="black", label=<{ReadsWrites|reads : Set[Any]<br ALIGN="LEFT"/>visited : Set[Any]<br ALIGN="LEFT"/>writes : Set[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.test_operators.Realize" [color="black", fontcolor="black", label=<{Realize|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.ReasonFusedNodes" [color="black", fontcolor="black", label=<{ReasonFusedNodes|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.RecompileError" [color="black", fontcolor="red", label=<{RecompileError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.RecompileLimitExceeded" [color="black", fontcolor="red", label=<{RecompileLimitExceeded|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.dependencies.RecordLoadStore" [color="black", fontcolor="black", label=<{RecordLoadStore|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.RecordOptimizationContext" [color="black", fontcolor="black", label=<{RecordOptimizationContext|current_node : Optional[torch.fx.Node]<br ALIGN="LEFT"/>func_name : str<br ALIGN="LEFT"/>opt_ctx : Optional[OptimizationContext]<br ALIGN="LEFT"/>|get_fx_node()<br ALIGN="LEFT"/>get_opt_ctx()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.RecordingObserver" [color="black", fontcolor="black", label=<{RecordingObserver|tensor_val : list<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>get_tensor_value()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._rectangle.Rectangle" [color="black", fontcolor="black", label=<{Rectangle|bottom : Optional[float]<br ALIGN="LEFT"/>left : Optional[float]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>right : Optional[float]<br ALIGN="LEFT"/>top : Optional[float]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._script.RecursiveScriptClass" [color="black", fontcolor="black", label=<{RecursiveScriptClass|<br ALIGN="LEFT"/>|forward_magic_method(method_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script.RecursiveScriptModule" [color="black", fontcolor="black", label=<{RecursiveScriptModule|code<br ALIGN="LEFT"/>code_with_constants<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>inlined_graph<br ALIGN="LEFT"/>original_name<br ALIGN="LEFT"/>|define(src)<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>forward_magic_method(method_name)<br ALIGN="LEFT"/>get_debug_state()<br ALIGN="LEFT"/>graph_for()<br ALIGN="LEFT"/>save(f)<br ALIGN="LEFT"/>save_to_buffer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RedisRemoteCache" [color="black", fontcolor="black", label=<{RedisRemoteCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RedisRemoteCacheBackend" [color="black", fontcolor="black", label=<{RedisRemoteCacheBackend|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._redistribute.Redistribute" [color="black", fontcolor="black", label=<{Redistribute|<br ALIGN="LEFT"/>|backward(ctx, grad_output: 'dtensor.DTensor')<br ALIGN="LEFT"/>forward(ctx, input: 'dtensor.DTensor', device_mesh: DeviceMesh, placements: Tuple[Placement, ...], async_op: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel._functions.ReduceAddCoalesced" [color="black", fontcolor="black", label=<{ReduceAddCoalesced|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, destination, num_inputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.ReduceLROnPlateau" [color="black", fontcolor="black", label=<{ReduceLROnPlateau|best : float<br ALIGN="LEFT"/>cooldown : int<br ALIGN="LEFT"/>cooldown_counter : int<br ALIGN="LEFT"/>default_min_lr : NoneType, int<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>factor : float<br ALIGN="LEFT"/>in_cooldown<br ALIGN="LEFT"/>last_epoch : NoneType, int<br ALIGN="LEFT"/>min_lrs : list<br ALIGN="LEFT"/>mode : Literal['min', 'max']<br ALIGN="LEFT"/>mode_worse : float<br ALIGN="LEFT"/>num_bad_epochs : int<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>patience : int<br ALIGN="LEFT"/>threshold : float<br ALIGN="LEFT"/>threshold_mode : Literal['rel', 'abs']<br ALIGN="LEFT"/>verbose : bool, str<br ALIGN="LEFT"/>|is_better(a, best)<br ALIGN="LEFT"/>load_state_dict(state_dict)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step(metrics: SupportsFloat, epoch)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.ReduceScatter" [color="black", fontcolor="black", label=<{ReduceScatter|op<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.ReduceScatterState" [color="black", fontcolor="black", label=<{ReduceScatterState|event<br ALIGN="LEFT"/>reduce_scatter_input<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._decomp.decompositions.Reduction" [color="black", fontcolor="black", label=<{Reduction|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._math_ops.Reduction" [color="black", fontcolor="black", label=<{Reduction|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Reduction" [color="black", fontcolor="black", label=<{Reduction|reduction_hint<br ALIGN="LEFT"/>reduction_ranges : Sequence[_IntLike]<br ALIGN="LEFT"/>reduction_type : str<br ALIGN="LEFT"/>src_dtype<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>create(device: torch.device, dst_dtype: torch.dtype, src_dtype: torch.dtype, inner_fn: Callable[..., Any], ranges: Sequence[Expr], reduction_ranges: Sequence[Expr], reduction_type: str, reduction_hint: ReductionHint, input_node: Optional[IRNode]): TensorBox<br ALIGN="LEFT"/>create_multilayer(device: torch.device, dst_dtype: torch.dtype, src_dtype: torch.dtype, inner_fn: Callable[..., Any], ranges: Sequence[Expr], reduction_ranges: Sequence[Expr], reduction_type: str, split: _IntLike, reduction_hint: ReductionHint): TensorBox<br ALIGN="LEFT"/>create_multilayer_existing_ranges(device: torch.device, dst_dtype: torch.dtype, src_dtype: torch.dtype, inner_fn: Callable[..., Any], original_ranges: Sequence[Expr], original_reduction_ranges: Sequence[Expr], new_ranges: List[Integer], new_reduction_ranges: List[Integer], reduction_type: str, reduction_hint: ReductionHint): TensorBox<br ALIGN="LEFT"/>create_multilayer_helper(device: torch.device, dst_dtype: torch.dtype, src_dtype: torch.dtype, wrapper_fn: Callable[..., Any], original_ranges: Sequence[Expr], original_reduction_ranges: Sequence[Expr], new_ranges: List[Expr], new_reduction_ranges: List[Integer], reduction_type: str, split: _IntLike, reduction_hint: ReductionHint): TensorBox<br ALIGN="LEFT"/>default_accumulator(reduction_type: str, dtype: torch.dtype): Union[_NumLike, Sequence[_NumLike]]<br ALIGN="LEFT"/>default_value(reduction_type: str, dtype: torch.dtype): Union[_NumLike, Sequence[_NumLike]]<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[Symbol]<br ALIGN="LEFT"/>index_length(): int<br ALIGN="LEFT"/>inner_fn_args(): Sequence[Sequence[Expr]]<br ALIGN="LEFT"/>inner_fn_free_unbacked_symbols(): OrderedSet[Symbol]<br ALIGN="LEFT"/>num_splits(device: torch.device, dst_dtype: torch.dtype, src_dtype: torch.dtype, inner_fn: Callable[..., OpsValue], ranges: Sequence[_IntLike], reduction_ranges: Sequence[_IntLike], reduction_type: str, reduction_numel: Expr, input_node: Optional[IRNode]): Tuple[ReductionHint, _IntLike]<br ALIGN="LEFT"/>store_reduction(output_name: Optional[str], indexer: Callable[[Sequence[Expr]], Never], vars: Sequence[Expr], reduction_vars: Sequence[Symbol]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.ReductionHint" [color="black", fontcolor="black", label=<{ReductionHint|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.ReductionOpInfo" [color="black", fontcolor="black", label=<{ReductionOpInfo|complex_to_real : bool<br ALIGN="LEFT"/>generate_args_kwargs<br ALIGN="LEFT"/>identity : NoneType<br ALIGN="LEFT"/>nan_policy : NoneType<br ALIGN="LEFT"/>promotes_int_to_int64 : bool<br ALIGN="LEFT"/>result_dtype : NoneType<br ALIGN="LEFT"/>supports_multiple_dims : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.refs.ReductionPythonRefInfo" [color="black", fontcolor="black", label=<{ReductionPythonRefInfo|torch_opinfo<br ALIGN="LEFT"/>torch_opinfo_name<br ALIGN="LEFT"/>torch_opinfo_variant_name : str<br ALIGN="LEFT"/>validate_view_consistency : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.ReductionTypePromotionRule" [color="black", fontcolor="black", label=<{ReductionTypePromotionRule|promotion_kind : REDUCTION_OUTPUT_TYPE_KIND<br ALIGN="LEFT"/>|preview_type_promotion(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.resume_execution.ReenterWith" [color="black", fontcolor="black", label=<{ReenterWith|stack_index : int<br ALIGN="LEFT"/>target_values : Optional[Tuple[Any, ...]]<br ALIGN="LEFT"/>|try_except_torch_function_mode(code_options, cleanup: List[Instruction])<br ALIGN="LEFT"/>try_finally(code_options, cleanup: List[Instruction])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.reference.ReferenceAnalysis" [color="black", fontcolor="black", label=<{ReferenceAnalysis|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>add(a, b)<br ALIGN="LEFT"/>and_(a, b)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>ceil_to_int(x, dtype)<br ALIGN="LEFT"/>constant(c, dtype)<br ALIGN="LEFT"/>eq(a, b)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floor_to_int(x, dtype)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>ge(a, b)<br ALIGN="LEFT"/>gt(a, b)<br ALIGN="LEFT"/>int_truediv(a, b)<br ALIGN="LEFT"/>le(a, b)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>lt(a, b)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>mod(x, y)<br ALIGN="LEFT"/>mul(a, b)<br ALIGN="LEFT"/>ne(a, b)<br ALIGN="LEFT"/>neg(x)<br ALIGN="LEFT"/>not_(a)<br ALIGN="LEFT"/>or_(a, b)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>pow_by_natural(a, b)<br ALIGN="LEFT"/>reciprocal(x)<br ALIGN="LEFT"/>round_decimal(a, b)<br ALIGN="LEFT"/>round_to_int(a, dtype)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>square(x)<br ALIGN="LEFT"/>sub(a, b)<br ALIGN="LEFT"/>sym_sum(args)<br ALIGN="LEFT"/>to_dtype(x, dtype)<br ALIGN="LEFT"/>truediv(a, b)<br ALIGN="LEFT"/>trunc_to_int(x, dtype)<br ALIGN="LEFT"/><I>truncdiv</I>(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" [color="black", fontcolor="black", label=<{ReferenceQuantizedModule|is_decomposed : bool<br ALIGN="LEFT"/>weight_axis_int : int<br ALIGN="LEFT"/>weight_dtype<br ALIGN="LEFT"/>weight_qscheme<br ALIGN="LEFT"/>weight_quant_max : typing.Optional[int]<br ALIGN="LEFT"/>weight_quant_min : typing.Optional[int]<br ALIGN="LEFT"/>|get_quantized_weight()<br ALIGN="LEFT"/>get_weight()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.graph_gradual_typechecker.Refine" [color="black", fontcolor="black", label=<{Refine|constraints : list<br ALIGN="LEFT"/>symbol_iter : count<br ALIGN="LEFT"/>traced<br ALIGN="LEFT"/>|convert_to_sympy_symbols(typ)<br ALIGN="LEFT"/>infer_symbolic_relations(n: Node)<br ALIGN="LEFT"/>refine()<br ALIGN="LEFT"/>refine_node(n: Node)<br ALIGN="LEFT"/>replace_dyn_with_fresh_var(typ)<br ALIGN="LEFT"/>symbolic_relations()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReflectionPad1d" [color="black", fontcolor="black", label=<{ReflectionPad1d|padding : Tuple[int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReflectionPad2d" [color="black", fontcolor="black", label=<{ReflectionPad2d|padding : Tuple[int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReflectionPad3d" [color="black", fontcolor="black", label=<{ReflectionPad3d|padding : Tuple[int, int, int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.RegexPatternVariable" [color="black", fontcolor="black", label=<{RegexPatternVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._region.Region" [color="black", fontcolor="black", label=<{Region|byte_length : Optional[int]<br ALIGN="LEFT"/>byte_offset : int<br ALIGN="LEFT"/>char_length : Optional[int]<br ALIGN="LEFT"/>char_offset : int<br ALIGN="LEFT"/>end_column : Optional[int]<br ALIGN="LEFT"/>end_line : Optional[int]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>snippet : Optional[_artifact_content.ArtifactContent]<br ALIGN="LEFT"/>source_language : Optional[str]<br ALIGN="LEFT"/>start_column : Optional[int]<br ALIGN="LEFT"/>start_line : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.RegisterPostBackwardFunction" [color="black", fontcolor="black", label=<{RegisterPostBackwardFunction|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, param_group: FSDPParamGroup)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.utils.RegistrationHandle" [color="black", fontcolor="black", label=<{RegistrationHandle|<br ALIGN="LEFT"/>|destroy(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._torchlib._torchlib_registry.Registry" [color="black", fontcolor="black", label=<{Registry|<br ALIGN="LEFT"/>|register(target: Callable, impl: Callable): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._composable.contract.RegistryItem" [color="black", fontcolor="black", label=<{RegistryItem|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.ReinforcementLearningRpcTest" [color="black", fontcolor="black", label=<{ReinforcementLearningRpcTest|<br ALIGN="LEFT"/>|test_rl_rpc()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.ReinplaceCounters" [color="black", fontcolor="black", label=<{ReinplaceCounters|<br ALIGN="LEFT"/>|add_missed_bytes(trigger: ReInplaceTrigger, bytes: int)<br ALIGN="LEFT"/>add_missed_opportunities(trigger: ReInplaceTrigger, count: int)<br ALIGN="LEFT"/>clear()<br ALIGN="LEFT"/>get_total_missed()<br ALIGN="LEFT"/>get_total_missed_bytes()<br ALIGN="LEFT"/>log()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ReinterpretView" [color="black", fontcolor="black", label=<{ReinterpretView|dtype<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/><I>freeze_layout</I>()<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_layout(): Layout<br ALIGN="LEFT"/>get_name()<br ALIGN="LEFT"/>get_origin_node(): Optional[torch.fx.Node]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_stride()<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>make_indexer(): Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>make_loader(): Callable[[Sequence[Expr]], OpsValue]<br ALIGN="LEFT"/>num_reads(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.relaxed_bernoulli.RelaxedBernoulli" [color="black", fontcolor="black", label=<{RelaxedBernoulli|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>temperature<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.RelaxedBooleanPair" [color="black", fontcolor="black", label=<{RelaxedBooleanPair|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.RelaxedNumberPair" [color="black", fontcolor="black", label=<{RelaxedNumberPair|atol<br ALIGN="LEFT"/>rtol<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" [color="black", fontcolor="black", label=<{RelaxedOneHotCategorical|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>logits<br ALIGN="LEFT"/>probs<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>temperature<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint" [color="black", fontcolor="black", label=<{RelaxedUnspecConstraint|<br ALIGN="LEFT"/>|render(source: Source): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.backends.debugging.ReluCompileError" [color="black", fontcolor="red", label=<{ReluCompileError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteAOTAutogradCache" [color="black", fontcolor="black", label=<{RemoteAOTAutogradCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteAutotuneCache" [color="black", fontcolor="black", label=<{RemoteAutotuneCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteBundledAutotuneCache" [color="black", fontcolor="black", label=<{RemoteBundledAutotuneCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteCache" [color="black", fontcolor="black", label=<{RemoteCache|backend<br ALIGN="LEFT"/>backend_override_cls : Optional[Callable[[], RemoteCacheBackend[Any]]]<br ALIGN="LEFT"/>serde : RemoteCacheSerde[_T, _U]<br ALIGN="LEFT"/>|get(key: str): Optional[_T]<br ALIGN="LEFT"/>put(key: str, value: _T): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteCacheBackend" [color="black", fontcolor="black", label=<{RemoteCacheBackend|<br ALIGN="LEFT"/>|get(key: str): Optional[_T]<br ALIGN="LEFT"/>put(key: str, data: _T): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteCacheJsonSerde" [color="black", fontcolor="black", label=<{RemoteCacheJsonSerde|<br ALIGN="LEFT"/>|decode(data: bytes): JsonDataTy<br ALIGN="LEFT"/>encode(data: JsonDataTy): bytes<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteCachePassthroughSerde" [color="black", fontcolor="black", label=<{RemoteCachePassthroughSerde|<br ALIGN="LEFT"/>|decode(data: _T): _T<br ALIGN="LEFT"/>encode(data: _T): _T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteCacheSerde" [color="black", fontcolor="black", label=<{RemoteCacheSerde|<br ALIGN="LEFT"/>|<I>decode</I>(data: _U): _T<br ALIGN="LEFT"/><I>encode</I>(data: _T): _U<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteDynamoPGOCache" [color="black", fontcolor="black", label=<{RemoteDynamoPGOCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM" [color="black", fontcolor="black", label=<{RemoteEM|em<br ALIGN="LEFT"/>|forward(input: torch.Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache.RemoteFxGraphCache" [color="black", fontcolor="black", label=<{RemoteFxGraphCache|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.nn.api.remote_module.RemoteModule" [color="black", fontcolor="black", label=<{RemoteModule|generated_methods<br ALIGN="LEFT"/>is_scriptable : bool<br ALIGN="LEFT"/>module_rref : rpc.RRef[nn.Module]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest" [color="black", fontcolor="black", label=<{RemoteModuleTest|<br ALIGN="LEFT"/>|test_bad_module()<br ALIGN="LEFT"/>test_forward_async()<br ALIGN="LEFT"/>test_forward_async_script()<br ALIGN="LEFT"/>test_forward_sync()<br ALIGN="LEFT"/>test_forward_sync_script()<br ALIGN="LEFT"/>test_forward_with_kwargs()<br ALIGN="LEFT"/>test_get_module_rref()<br ALIGN="LEFT"/>test_remote_module_py_pickle_not_supported()<br ALIGN="LEFT"/>test_remote_module_py_pickle_not_supported_script()<br ALIGN="LEFT"/>test_remote_parameters()<br ALIGN="LEFT"/>test_send_remote_module_with_a_new_attribute_not_pickled_over_the_wire()<br ALIGN="LEFT"/>test_train_eval()<br ALIGN="LEFT"/>test_unsupported_methods()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.RemoteMyModuleInterface" [color="black", fontcolor="black", label=<{RemoteMyModuleInterface|<br ALIGN="LEFT"/>|<I>forward</I>(tensor: Tensor, number: int, word: str): Tuple[str, int, Tensor]<br ALIGN="LEFT"/><I>forward_async</I>(tensor: Tensor, number: int, word: str): Future[Tuple[str, int, Tensor]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet" [color="black", fontcolor="black", label=<{RemoteNet|fc<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(input: torch.Tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hooks.RemovableHandle" [color="black", fontcolor="black", label=<{RemovableHandle|extra_dict_ref : Tuple, tuple<br ALIGN="LEFT"/>hooks_dict_ref<br ALIGN="LEFT"/>id : int<br ALIGN="LEFT"/>next_id : int<br ALIGN="LEFT"/>|remove(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.RemovableHandleClass" [color="black", fontcolor="black", label=<{RemovableHandleClass|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.RemovableHandleVariable" [color="black", fontcolor="black", label=<{RemovableHandleVariable|REMOVED : int<br ALIGN="LEFT"/>idx : NoneType, int<br ALIGN="LEFT"/>mutation_type : NoneType<br ALIGN="LEFT"/>|call_method(tx: 'InstructionTranslator', method_name, args, kwargs)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.functionalization.RemoveInputMutation" [color="black", fontcolor="black", label=<{RemoveInputMutation|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.RemoveNonTensorInputStep" [color="black", fontcolor="black", label=<{RemoveNonTensorInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter.RemoveNoneInputStep" [color="black", fontcolor="black", label=<{RemoveNoneInputStep|<br ALIGN="LEFT"/>|apply(model_args: Sequence[Any], model_kwargs: Mapping[str, Any], model: torch.nn.Module \| Callable \| torch_export.ExportedProgram \| None): tuple[Sequence[Any], Mapping[str, Any]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend" [color="black", fontcolor="black", label=<{RendezvousBackend|name<br ALIGN="LEFT"/>|<I>get_state</I>(): Optional[Tuple[bytes, Token]]<br ALIGN="LEFT"/><I>set_state</I>(state: bytes, token: Optional[Token]): Optional[Tuple[bytes, Token, bool]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousClosedError" [color="black", fontcolor="red", label=<{RendezvousClosedError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousConnectionError" [color="black", fontcolor="red", label=<{RendezvousConnectionError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousError" [color="black", fontcolor="red", label=<{RendezvousError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousGracefulExitError" [color="black", fontcolor="red", label=<{RendezvousGracefulExitError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousHandler" [color="black", fontcolor="black", label=<{RendezvousHandler|use_agent_store<br ALIGN="LEFT"/>|<I>get_backend</I>(): str<br ALIGN="LEFT"/><I>get_run_id</I>(): str<br ALIGN="LEFT"/><I>is_closed</I>(): bool<br ALIGN="LEFT"/><I>next_rendezvous</I>(): RendezvousInfo<br ALIGN="LEFT"/><I>num_nodes_waiting</I>(): int<br ALIGN="LEFT"/><I>set_closed</I>()<br ALIGN="LEFT"/><I>shutdown</I>(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousHandlerRegistry" [color="black", fontcolor="black", label=<{RendezvousHandlerRegistry|<br ALIGN="LEFT"/>|create_handler(params: RendezvousParameters): RendezvousHandler<br ALIGN="LEFT"/>register(backend: str, creator: RendezvousHandlerCreator): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousInfo" [color="black", fontcolor="black", label=<{RendezvousInfo|bootstrap_store_info<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>store<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousParameters" [color="black", fontcolor="black", label=<{RendezvousParameters|backend : str<br ALIGN="LEFT"/>config : dict<br ALIGN="LEFT"/>endpoint : str<br ALIGN="LEFT"/>local_addr : Optional[str]<br ALIGN="LEFT"/>max_nodes : int<br ALIGN="LEFT"/>min_nodes : int<br ALIGN="LEFT"/>run_id : str<br ALIGN="LEFT"/>|get(key: str, default: Any): Any<br ALIGN="LEFT"/>get_as_bool(key: str, default: Optional[bool]): Optional[bool]<br ALIGN="LEFT"/>get_as_int(key: str, default: Optional[int]): Optional[int]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" [color="black", fontcolor="black", label=<{RendezvousSettings|keep_alive_interval : timedelta<br ALIGN="LEFT"/>keep_alive_max_attempt : int<br ALIGN="LEFT"/>max_nodes : int<br ALIGN="LEFT"/>min_nodes : int<br ALIGN="LEFT"/>run_id : str<br ALIGN="LEFT"/>timeout<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousStateError" [color="black", fontcolor="red", label=<{RendezvousStateError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo" [color="black", fontcolor="black", label=<{RendezvousStoreInfo|MASTER_ADDR_KEY : ClassVar[str]<br ALIGN="LEFT"/>MASTER_PORT_KEY : ClassVar[str]<br ALIGN="LEFT"/>master_addr : str<br ALIGN="LEFT"/>master_port : int<br ALIGN="LEFT"/>|build(rank: int, store: Store, local_addr: Optional[str], server_port: Optional[int]): 'RendezvousStoreInfo'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout" [color="black", fontcolor="black", label=<{RendezvousTimeout|close<br ALIGN="LEFT"/>heartbeat<br ALIGN="LEFT"/>join<br ALIGN="LEFT"/>last_call<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousTimeoutError" [color="black", fontcolor="red", label=<{RendezvousTimeoutError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.Repeat" [color="black", fontcolor="black", label=<{Repeat|input_dim<br ALIGN="LEFT"/>times : int<br ALIGN="LEFT"/>|inputs(): Iterable[DimSpec]<br ALIGN="LEFT"/>new(dim: DimSpec, times: int): DimSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.RepeatIteratorVariable" [color="black", fontcolor="black", label=<{RepeatIteratorVariable|item<br ALIGN="LEFT"/>|next_variable(tx)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.RepeatedExpr" [color="black", fontcolor="black", label=<{RepeatedExpr|fns<br ALIGN="LEFT"/>inner_pattern<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>|pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.ReplaceFn" [color="black", fontcolor="black", label=<{ReplaceFn|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.virtualization.ReplaceGetAttrWithPlaceholder" [color="black", fontcolor="black", label=<{ReplaceGetAttrWithPlaceholder|replaced_attrs<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.passes.replace_view_ops_with_view_copy_ops_pass.ReplaceViewOpsWithViewCopyOpsPass" [color="black", fontcolor="black", label=<{ReplaceViewOpsWithViewCopyOpsPass|<br ALIGN="LEFT"/>|call_operator(op, args, kwargs, meta)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.subgraph_rewriter.ReplacedPatterns" [color="black", fontcolor="black", label=<{ReplacedPatterns|anchor<br ALIGN="LEFT"/>nodes_map : Dict[Node, Node]<br ALIGN="LEFT"/>replacements : List[Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._replacement.Replacement" [color="black", fontcolor="black", label=<{Replacement|deleted_region<br ALIGN="LEFT"/>inserted_content : Optional[_artifact_content.ArtifactContent]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.ReplacementPatternEntry" [color="black", fontcolor="black", label=<{ReplacementPatternEntry|normalize_args : Callable[..., List[Any]]<br ALIGN="LEFT"/>|apply(match: Match, graph: torch.fx.Graph, node: torch.fx.Node): None<br ALIGN="LEFT"/>replace_with_graph(match: Match, graph: torch.fx.Graph, replacement_graph: Union[torch.fx.Graph, torch.fx.GraphModule], args: Sequence[torch.fx.Node]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.Replacer" [color="black", fontcolor="black", label=<{Replacer|preface : List[str]<br ALIGN="LEFT"/>|visit(node: ast.AST): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.ReplacementPatternEntry.replace_with_graph.Replacer" [color="black", fontcolor="black", label=<{Replacer|call_method : NoneType<br ALIGN="LEFT"/>call_module : NoneType<br ALIGN="LEFT"/>get_attr : NoneType<br ALIGN="LEFT"/>|run_node(node: torch.fx.Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.placement_types.Replicate" [color="black", fontcolor="black", label=<{Replicate|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReplicationPad1d" [color="black", fontcolor="black", label=<{ReplicationPad1d|padding : Tuple[int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReplicationPad2d" [color="black", fontcolor="black", label=<{ReplicationPad2d|padding : Tuple[int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding.ReplicationPad3d" [color="black", fontcolor="black", label=<{ReplicationPad3d|padding : Tuple[int, int, int, int, int, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_configuration.ReportingConfiguration" [color="black", fontcolor="black", label=<{ReportingConfiguration|enabled : bool<br ALIGN="LEFT"/>level : Literal['none', 'note', 'warning', 'error']<br ALIGN="LEFT"/>parameters : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>rank : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor.ReportingDescriptor" [color="black", fontcolor="black", label=<{ReportingDescriptor|default_configuration : Optional[_reporting_configuration.ReportingConfiguration]<br ALIGN="LEFT"/>deprecated_guids : Optional[List[str]]<br ALIGN="LEFT"/>deprecated_ids : Optional[List[str]]<br ALIGN="LEFT"/>deprecated_names : Optional[List[str]]<br ALIGN="LEFT"/>full_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>guid : Optional[str]<br ALIGN="LEFT"/>help : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>help_uri : Optional[str]<br ALIGN="LEFT"/>id : str<br ALIGN="LEFT"/>message_strings : Optional[Any]<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>relationships : Optional[List[_reporting_descriptor_relationship.ReportingDescriptorRelationship]]<br ALIGN="LEFT"/>short_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_reference.ReportingDescriptorReference" [color="black", fontcolor="black", label=<{ReportingDescriptorReference|guid : Optional[str]<br ALIGN="LEFT"/>id : Optional[str]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>tool_component : Optional[_tool_component_reference.ToolComponentReference]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_relationship.ReportingDescriptorRelationship" [color="black", fontcolor="black", label=<{ReportingDescriptorRelationship|description : Optional[_message.Message]<br ALIGN="LEFT"/>kinds : List[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.fx_minifier.ReproState" [color="black", fontcolor="black", label=<{ReproState|graph<br ALIGN="LEFT"/>inps : List[torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.api.RequestQueue" [color="black", fontcolor="black", label=<{RequestQueue|<br ALIGN="LEFT"/>|<I>get</I>(size: int, timeout: float): List[TimerRequest]<br ALIGN="LEFT"/><I>size</I>(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.ResNetBase" [color="black", fontcolor="black", label=<{ResNetBase|avgpool<br ALIGN="LEFT"/>bn1<br ALIGN="LEFT"/>conv1<br ALIGN="LEFT"/>downsample<br ALIGN="LEFT"/>fc<br ALIGN="LEFT"/>myop<br ALIGN="LEFT"/>relu1<br ALIGN="LEFT"/>relu2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>fuse_model()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.pgo.ReservedWorkflowIdUserError" [color="black", fontcolor="red", label=<{ReservedWorkflowIdUserError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.ResetRequired" [color="black", fontcolor="red", label=<{ResetRequired|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.ReshapeTransform" [color="black", fontcolor="black", label=<{ReshapeTransform|bijective : bool<br ALIGN="LEFT"/>in_shape<br ALIGN="LEFT"/>out_shape<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd._functions.tensor.Resize" [color="black", fontcolor="black", label=<{Resize|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, tensor, sizes)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ResizeStorageBytes" [color="black", fontcolor="black", label=<{ResizeStorageBytes|cpp_kernel_name : str<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>python_kernel_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [color="black", fontcolor="black", label=<{ResolvedExportOptions|decomposition_table : dict[torch._ops.OpOverload, Callable]<br ALIGN="LEFT"/>diagnostic_context<br ALIGN="LEFT"/>diagnostic_options<br ALIGN="LEFT"/>dynamic_shapes : bool<br ALIGN="LEFT"/>fake_context<br ALIGN="LEFT"/>fx_tracer<br ALIGN="LEFT"/>onnx_registry<br ALIGN="LEFT"/>onnxfunction_dispatcher<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.RestartAnalysis" [color="black", fontcolor="red", label=<{RestartAnalysis|restart_reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.readability.RestoreParameterAndBufferNames" [color="black", fontcolor="black", label=<{RestoreParameterAndBufferNames|original_nn_module<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.RestrictedListSubclassVariable" [color="black", fontcolor="black", label=<{RestrictedListSubclassVariable|user_cls<br ALIGN="LEFT"/>user_cls_source<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/><I>as_python_constant</I>()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>is_matching_cls(user_cls: type)<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>modified(items)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._result.Result" [color="black", fontcolor="black", label=<{Result|analysis_target : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>attachments : Optional[List[_attachment.Attachment]]<br ALIGN="LEFT"/>baseline_state : Optional[Literal['new', 'unchanged', 'updated', 'absent']]<br ALIGN="LEFT"/>code_flows : Optional[List[_code_flow.CodeFlow]]<br ALIGN="LEFT"/>correlation_guid : Optional[str]<br ALIGN="LEFT"/>fingerprints : Optional[Any]<br ALIGN="LEFT"/>fixes : Optional[List[_fix.Fix]]<br ALIGN="LEFT"/>graph_traversals : Optional[List[_graph_traversal.GraphTraversal]]<br ALIGN="LEFT"/>graphs : Optional[List[_graph.Graph]]<br ALIGN="LEFT"/>guid : Optional[str]<br ALIGN="LEFT"/>hosted_viewer_uri : Optional[str]<br ALIGN="LEFT"/>kind : Literal['notApplicable', 'pass', 'fail', 'review', 'open', 'informational']<br ALIGN="LEFT"/>level : Literal['none', 'note', 'warning', 'error']<br ALIGN="LEFT"/>locations : Optional[List[_location.Location]]<br ALIGN="LEFT"/>message<br ALIGN="LEFT"/>occurrence_count : Optional[int]<br ALIGN="LEFT"/>partial_fingerprints : Optional[Any]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>provenance : Optional[_result_provenance.ResultProvenance]<br ALIGN="LEFT"/>rank : float<br ALIGN="LEFT"/>related_locations : Optional[List[_location.Location]]<br ALIGN="LEFT"/>rule : Optional[_reporting_descriptor_reference.ReportingDescriptorReference]<br ALIGN="LEFT"/>rule_id : Optional[str]<br ALIGN="LEFT"/>rule_index : int<br ALIGN="LEFT"/>stacks : Optional[List[_stack.Stack]]<br ALIGN="LEFT"/>suppressions : Optional[List[_suppression.Suppression]]<br ALIGN="LEFT"/>taxa : Optional[List[_reporting_descriptor_reference.ReportingDescriptorReference]]<br ALIGN="LEFT"/>web_request : Optional[_web_request.WebRequest]<br ALIGN="LEFT"/>web_response : Optional[_web_response.WebResponse]<br ALIGN="LEFT"/>work_item_uris : Optional[List[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.Result" [color="black", fontcolor="black", label=<{Result|exception : Exception \| None<br ALIGN="LEFT"/>exported_program : torch.export.ExportedProgram \| None<br ALIGN="LEFT"/>strategy : str<br ALIGN="LEFT"/>success<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.GraphModuleDeserializer.Result" [color="black", fontcolor="black", label=<{Result|constants : Dict[str, Union[torch.Tensor, FakeScriptObject, torch.ScriptObject]]<br ALIGN="LEFT"/>example_inputs : Optional[Tuple[Tuple[torch.Tensor, ...], Dict[str, Any]]]<br ALIGN="LEFT"/>graph_module<br ALIGN="LEFT"/>module_call_graph : List[ep.ModuleCallEntry]<br ALIGN="LEFT"/>names_to_symbols : Dict[str, sympy.Symbol]<br ALIGN="LEFT"/>signature<br ALIGN="LEFT"/>state_dict : Dict[str, Union[torch.Tensor, torch.nn.Parameter]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._result_provenance.ResultProvenance" [color="black", fontcolor="black", label=<{ResultProvenance|conversion_sources : Optional[List[_physical_location.PhysicalLocation]]<br ALIGN="LEFT"/>first_detection_run_guid : Optional[str]<br ALIGN="LEFT"/>first_detection_time_utc : Optional[str]<br ALIGN="LEFT"/>invocation_index : int<br ALIGN="LEFT"/>last_detection_run_guid : Optional[str]<br ALIGN="LEFT"/>last_detection_time_utc : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.resume_execution.ResumeFunctionMetadata" [color="black", fontcolor="black", label=<{ResumeFunctionMetadata|block_target_offset_remap : Optional[Dict[int, int]]<br ALIGN="LEFT"/>code<br ALIGN="LEFT"/>instructions : List[Instruction]<br ALIGN="LEFT"/>prefix_block_target_offset_remap : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._lazy.extract_compiled_graph.ReturnValueHandler" [color="black", fontcolor="black", label=<{ReturnValueHandler|index : List[List[int]]<br ALIGN="LEFT"/>total_count<br ALIGN="LEFT"/>|duplicate_eager_tensors(eager_tensor_list)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.ReturnValueOp" [color="black", fontcolor="red", label=<{ReturnValueOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.observer.ReuseInputObserver" [color="black", fontcolor="black", label=<{ReuseInputObserver|<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.ReuseLine" [color="black", fontcolor="black", label=<{ReuseLine|delete_old : bool<br ALIGN="LEFT"/>node : Union<br ALIGN="LEFT"/>reused_as : Union<br ALIGN="LEFT"/>|codegen(code: IndentedBuffer): None<br ALIGN="LEFT"/>plan(state: MemoryPlanningState): MemoryPlanningLine<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.rewriter.RewritingTracer" [color="black", fontcolor="black", label=<{RewritingTracer|<br ALIGN="LEFT"/>|trace(root: Union[torch.nn.Module, Callable], concrete_args: Optional[Dict[str, Any]]): Graph<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.rewriter._rewrite.rewrite_module.RewrittenModule" [color="black", fontcolor="black", label=<{RewrittenModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.dynamic_shapes.RootDim" [color="black", fontcolor="black", label=<{RootDim|derived : List[str]<br ALIGN="LEFT"/>max : Union[int, None]<br ALIGN="LEFT"/>min : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.functions.RoundDecimal" [color="black", fontcolor="black", label=<{RoundDecimal|is_real : bool<br ALIGN="LEFT"/>|eval(number, ndigits)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel.RoundRobinDispatch" [color="black", fontcolor="black", label=<{RoundRobinDispatch|<br ALIGN="LEFT"/>|codegen_pid_range(kernel: 'ComboKernel', num: int, code: IndentedBuffer): None<br ALIGN="LEFT"/>grid(sub_kernel_numels: List[List[int]], x_blocks_list: List[Union[str, int]], dynamic_shape: bool): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.RoundToInt" [color="black", fontcolor="black", label=<{RoundToInt|is_integer : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.routeddecoder.RoutedDecoderIterDataPipe" [color="black", fontcolor="black", label=<{RoutedDecoderIterDataPipe|datapipe : Iterable[Tuple[str, BufferedIOBase]]<br ALIGN="LEFT"/>decoder<br ALIGN="LEFT"/>|add_handler(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.RowwiseParallel" [color="black", fontcolor="black", label=<{RowwiseParallel|desired_input_layouts : Tuple[Placement, ...], tuple<br ALIGN="LEFT"/>input_layouts : tuple<br ALIGN="LEFT"/>output_layouts : tuple<br ALIGN="LEFT"/>use_local_output : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [color="black", fontcolor="black", label=<{RpcAgentTestFixture|file_init_method<br ALIGN="LEFT"/>init_method<br ALIGN="LEFT"/>rpc_backend<br ALIGN="LEFT"/>rpc_backend_options<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|<I>get_shutdown_error_regex</I>()<br ALIGN="LEFT"/><I>get_timeout_error_regex</I>()<br ALIGN="LEFT"/><I>setup_fault_injection</I>(faulty_messages, messages_to_delay)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest" [color="black", fontcolor="black", label=<{RpcTest|timed_out_rpc_event : NoneType<br ALIGN="LEFT"/>|check_profiling_info(self_worker_name, dst_worker_name, func, rpc_event, rpc_exec_mode)<br ALIGN="LEFT"/>return_callee_id()<br ALIGN="LEFT"/>run_profiling_workload(dst)<br ALIGN="LEFT"/>test_add()<br ALIGN="LEFT"/>test_add_done_callback()<br ALIGN="LEFT"/>test_add_with_id()<br ALIGN="LEFT"/>test_all_gather()<br ALIGN="LEFT"/>test_all_gather_timeout()<br ALIGN="LEFT"/>test_async_add()<br ALIGN="LEFT"/>test_async_class_method()<br ALIGN="LEFT"/>test_async_class_method_remote()<br ALIGN="LEFT"/>test_async_class_rref_proxy()<br ALIGN="LEFT"/>test_async_class_rref_proxy_async()<br ALIGN="LEFT"/>test_async_class_rref_proxy_remote()<br ALIGN="LEFT"/>test_async_function_chained()<br ALIGN="LEFT"/>test_async_function_chained_remote()<br ALIGN="LEFT"/>test_async_function_multi_chained()<br ALIGN="LEFT"/>test_async_function_multi_chained_async()<br ALIGN="LEFT"/>test_async_function_multi_chained_remote()<br ALIGN="LEFT"/>test_async_function_multi_fanout()<br ALIGN="LEFT"/>test_async_function_multi_fanout_async()<br ALIGN="LEFT"/>test_async_function_multi_fanout_remote()<br ALIGN="LEFT"/>test_async_function_nested()<br ALIGN="LEFT"/>test_async_function_nested_remote()<br ALIGN="LEFT"/>test_async_function_raise()<br ALIGN="LEFT"/>test_async_function_raise_async()<br ALIGN="LEFT"/>test_async_function_raise_remote()<br ALIGN="LEFT"/>test_async_function_simple()<br ALIGN="LEFT"/>test_async_function_with_future_ctor()<br ALIGN="LEFT"/>test_async_function_with_future_ctor_remote()<br ALIGN="LEFT"/>test_async_function_wrong_return_type()<br ALIGN="LEFT"/>test_async_function_wrong_return_type_async()<br ALIGN="LEFT"/>test_async_function_wrong_return_type_remote()<br ALIGN="LEFT"/>test_async_record_function_cbs_jit_call()<br ALIGN="LEFT"/>test_async_record_function_double_end_callbacks()<br ALIGN="LEFT"/>test_async_record_function_legacy()<br ALIGN="LEFT"/>test_async_static_method()<br ALIGN="LEFT"/>test_async_static_method_remote()<br ALIGN="LEFT"/>test_build_rpc_profiling_key()<br ALIGN="LEFT"/>test_builtin_remote_ret()<br ALIGN="LEFT"/>test_builtin_remote_self()<br ALIGN="LEFT"/>test_call_method_on_rref()<br ALIGN="LEFT"/>test_callback_chain()<br ALIGN="LEFT"/>test_callback_in_rpc()<br ALIGN="LEFT"/>test_callback_multi()<br ALIGN="LEFT"/>test_callback_none()<br ALIGN="LEFT"/>test_callback_simple()<br ALIGN="LEFT"/>test_callback_with_error()<br ALIGN="LEFT"/>test_callback_with_ret()<br ALIGN="LEFT"/>test_callback_wrong_arg_num()<br ALIGN="LEFT"/>test_callback_wrong_arg_type()<br ALIGN="LEFT"/>test_cannot_infer_backend_from_options()<br ALIGN="LEFT"/>test_custom_exception_throw_during_reconstruction()<br ALIGN="LEFT"/>test_deadlock()<br ALIGN="LEFT"/>test_debug_info()<br ALIGN="LEFT"/>test_default_timeout_used()<br ALIGN="LEFT"/>test_disable_gil_profiling()<br ALIGN="LEFT"/>test_dist_init_decorator()<br ALIGN="LEFT"/>test_duplicate_name()<br ALIGN="LEFT"/>test_duplicate_name_2()<br ALIGN="LEFT"/>test_expected_src()<br ALIGN="LEFT"/>test_function_not_on_callee()<br ALIGN="LEFT"/>test_future_done()<br ALIGN="LEFT"/>test_future_done_exception()<br ALIGN="LEFT"/>test_future_in_rpc()<br ALIGN="LEFT"/>test_future_nested_callback()<br ALIGN="LEFT"/>test_future_wait_twice()<br ALIGN="LEFT"/>test_get_worker_infos()<br ALIGN="LEFT"/>test_graceful_shutdown_with_uneven_workload()<br ALIGN="LEFT"/>test_handle_send_exceptions()<br ALIGN="LEFT"/>test_ignore_rref_leak()<br ALIGN="LEFT"/>test_init_pg_then_rpc()<br ALIGN="LEFT"/>test_init_rpc_then_pg()<br ALIGN="LEFT"/>test_init_rpc_twice()<br ALIGN="LEFT"/>test_int_callee()<br ALIGN="LEFT"/>test_invalid_names()<br ALIGN="LEFT"/>test_local_rref_no_fork()<br ALIGN="LEFT"/>test_local_shutdown()<br ALIGN="LEFT"/>test_local_shutdown_with_rpc()<br ALIGN="LEFT"/>test_local_value_not_on_owner()<br ALIGN="LEFT"/>test_mark_future_twice()<br ALIGN="LEFT"/>test_multi_builtin_remote_ret()<br ALIGN="LEFT"/>test_multi_layer_nested_async_rpc()<br ALIGN="LEFT"/>test_multi_py_udf_remote()<br ALIGN="LEFT"/>test_multi_rpc()<br ALIGN="LEFT"/>test_my_parameter_server()<br ALIGN="LEFT"/>test_nested_remote()<br ALIGN="LEFT"/>test_nested_rpc()<br ALIGN="LEFT"/>test_nested_rref()<br ALIGN="LEFT"/>test_nested_rref_stress()<br ALIGN="LEFT"/>test_non_cont_tensors()<br ALIGN="LEFT"/>test_non_garbage_collected_user_rref_due_to_local_circular_dependency()<br ALIGN="LEFT"/>test_nonzero()<br ALIGN="LEFT"/>test_owner_equality()<br ALIGN="LEFT"/>test_owner_rref_backward()<br ALIGN="LEFT"/>test_pass_local_rrefs()<br ALIGN="LEFT"/>test_pg_init_no_rpc_init()<br ALIGN="LEFT"/>test_pickle_future()<br ALIGN="LEFT"/>test_profiler_export_trace()<br ALIGN="LEFT"/>test_profiler_remote_events_profiled()<br ALIGN="LEFT"/>test_profiler_remote_events_profiled_single_threaded()<br ALIGN="LEFT"/>test_profiler_rpc_key_names()<br ALIGN="LEFT"/>test_profiler_rpc_memory()<br ALIGN="LEFT"/>test_profiler_rpc_record_shapes()<br ALIGN="LEFT"/>test_profiler_with_async_rpc_builtin()<br ALIGN="LEFT"/>test_profiler_with_async_rpc_builtin_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_async_rpc_udf()<br ALIGN="LEFT"/>test_profiler_with_async_rpc_udf_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_autograd_context()<br ALIGN="LEFT"/>test_profiler_with_autograd_context_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_remote_builtin()<br ALIGN="LEFT"/>test_profiler_with_remote_builtin_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_remote_udf()<br ALIGN="LEFT"/>test_profiler_with_remote_udf_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_script_async_rpc()<br ALIGN="LEFT"/>test_profiler_with_script_async_rpc_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_script_remote_rpc()<br ALIGN="LEFT"/>test_profiler_with_script_remote_rpc_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_script_sync_rpc()<br ALIGN="LEFT"/>test_profiler_with_script_sync_rpc_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_sync_rpc_builtin()<br ALIGN="LEFT"/>test_profiler_with_sync_rpc_builtin_single_threaded()<br ALIGN="LEFT"/>test_profiler_with_sync_rpc_udf()<br ALIGN="LEFT"/>test_profiler_with_sync_rpc_udf_single_threaded()<br ALIGN="LEFT"/>test_py_built_in()<br ALIGN="LEFT"/>test_py_class_constructor()<br ALIGN="LEFT"/>test_py_class_instance_method()<br ALIGN="LEFT"/>test_py_class_method()<br ALIGN="LEFT"/>test_py_class_static_method()<br ALIGN="LEFT"/>test_py_function_exception()<br ALIGN="LEFT"/>test_py_multi_async_call()<br ALIGN="LEFT"/>test_py_nested_pickle()<br ALIGN="LEFT"/>test_py_no_return_result()<br ALIGN="LEFT"/>test_py_raise_in_user_func()<br ALIGN="LEFT"/>test_py_raise_in_user_func_escaped_str()<br ALIGN="LEFT"/>test_py_rpc_rref_args()<br ALIGN="LEFT"/>test_py_rref_args()<br ALIGN="LEFT"/>test_py_rref_args_user_share()<br ALIGN="LEFT"/>test_py_tensors()<br ALIGN="LEFT"/>test_py_tensors_in_container()<br ALIGN="LEFT"/>test_py_tensors_multi_async_call()<br ALIGN="LEFT"/>test_py_udf_remote()<br ALIGN="LEFT"/>test_py_user_defined()<br ALIGN="LEFT"/>test_register_rpc_backend_and_set_and_start_rpc_backend(mock_rpc_agent, mock_dist_autograd_init)<br ALIGN="LEFT"/>test_reinit()<br ALIGN="LEFT"/>test_remote_same_worker()<br ALIGN="LEFT"/>test_remote_throw()<br ALIGN="LEFT"/>test_remote_with_exception()<br ALIGN="LEFT"/>test_return_future()<br ALIGN="LEFT"/>test_return_future_async()<br ALIGN="LEFT"/>test_return_future_remote()<br ALIGN="LEFT"/>test_return_local_rrefs()<br ALIGN="LEFT"/>test_rpc_barrier_all()<br ALIGN="LEFT"/>test_rpc_barrier_multithreaded()<br ALIGN="LEFT"/>test_rpc_barrier_partial_subset()<br ALIGN="LEFT"/>test_rpc_barrier_subset()<br ALIGN="LEFT"/>test_rpc_profiling_async_function()<br ALIGN="LEFT"/>test_rpc_profiling_async_function_single_threaded()<br ALIGN="LEFT"/>test_rpc_profiling_remote_record_function()<br ALIGN="LEFT"/>test_rpc_return_rref()<br ALIGN="LEFT"/>test_rpc_timeouts()<br ALIGN="LEFT"/>test_rref_context_debug_info()<br ALIGN="LEFT"/>test_rref_forward_chain()<br ALIGN="LEFT"/>test_rref_get_future()<br ALIGN="LEFT"/>test_rref_leak()<br ALIGN="LEFT"/>test_rref_proxy_class()<br ALIGN="LEFT"/>test_rref_proxy_class_self()<br ALIGN="LEFT"/>test_rref_proxy_non_exist()<br ALIGN="LEFT"/>test_rref_proxy_reuse()<br ALIGN="LEFT"/>test_rref_proxy_tensor()<br ALIGN="LEFT"/>test_rref_proxy_tensor_self()<br ALIGN="LEFT"/>test_rref_py_pickle_not_supported()<br ALIGN="LEFT"/>test_rref_str()<br ALIGN="LEFT"/>test_rref_timeout()<br ALIGN="LEFT"/>test_rref_type_blocking()<br ALIGN="LEFT"/>test_rref_type_non_blocking()<br ALIGN="LEFT"/>test_rref_type_owner_blocking()<br ALIGN="LEFT"/>test_rref_type_owner_non_blocking()<br ALIGN="LEFT"/>test_rref_type_slow_init()<br ALIGN="LEFT"/>test_rref_type_with_error_blocking()<br ALIGN="LEFT"/>test_rref_type_with_error_non_blocking()<br ALIGN="LEFT"/>test_scalar_add()<br ALIGN="LEFT"/>test_self_add()<br ALIGN="LEFT"/>test_self_py_udf_remote()<br ALIGN="LEFT"/>test_self_remote_rref_as_remote_arg()<br ALIGN="LEFT"/>test_self_remote_rref_as_rpc_arg()<br ALIGN="LEFT"/>test_self_remote_rref_as_self_remote_arg()<br ALIGN="LEFT"/>test_self_remote_rref_as_self_rpc_arg()<br ALIGN="LEFT"/>test_send_to_rank()<br ALIGN="LEFT"/>test_server_process_global_profiler()<br ALIGN="LEFT"/>test_set_and_get_default_rpc_timeout()<br ALIGN="LEFT"/>test_shutdown_errors()<br ALIGN="LEFT"/>test_shutdown_followed_by_rpc()<br ALIGN="LEFT"/>test_stress_heavy_rpc()<br ALIGN="LEFT"/>test_stress_heavy_rpc_torchscript()<br ALIGN="LEFT"/>test_stress_light_rpc()<br ALIGN="LEFT"/>test_use_rpc_pickler()<br ALIGN="LEFT"/>test_use_rref_after_shutdown()<br ALIGN="LEFT"/>test_user_rref_backward()<br ALIGN="LEFT"/>test_user_rrefs_confirmed()<br ALIGN="LEFT"/>test_user_rrefs_confirmed_remote()<br ALIGN="LEFT"/>test_wait_all()<br ALIGN="LEFT"/>test_wait_all_exit_early_builtin()<br ALIGN="LEFT"/>test_wait_all_exit_early_python()<br ALIGN="LEFT"/>test_wait_all_exit_early_script_function()<br ALIGN="LEFT"/>test_wait_all_multiple_call()<br ALIGN="LEFT"/>test_wait_all_raise_in_body()<br ALIGN="LEFT"/>test_wait_all_raise_in_user_func()<br ALIGN="LEFT"/>test_wait_all_timeout()<br ALIGN="LEFT"/>test_wait_all_with_exception()<br ALIGN="LEFT"/>test_wait_all_with_partial_exception()<br ALIGN="LEFT"/>test_wait_all_workers_dense()<br ALIGN="LEFT"/>test_wait_all_workers_timeout()<br ALIGN="LEFT"/>test_wait_all_workers_twice_dense()<br ALIGN="LEFT"/>test_worker_id()<br ALIGN="LEFT"/>test_worker_info_pickle()<br ALIGN="LEFT"/>test_world_size_one()<br ALIGN="LEFT"/>test_wrong_types()<br ALIGN="LEFT"/>timed_out_rpc()<br ALIGN="LEFT"/>validate_profiling_workload(dst, prof)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTestCommon" [color="black", fontcolor="black", label=<{RpcTestCommon|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.rprop.Rprop" [color="black", fontcolor="black", label=<{Rprop|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Rule" [color="black", fontcolor="black", label=<{Rule|full_description : str \| None<br ALIGN="LEFT"/>full_description_markdown : str \| None<br ALIGN="LEFT"/>help_uri : str \| None<br ALIGN="LEFT"/>id : str<br ALIGN="LEFT"/>message_default_template : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>short_description : str \| None<br ALIGN="LEFT"/>|format(level: Level): tuple[Rule, Level, str]<br ALIGN="LEFT"/>format_message(): str<br ALIGN="LEFT"/>from_sarif()<br ALIGN="LEFT"/>sarif(): sarif.ReportingDescriptor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.RuleCollection" [color="black", fontcolor="black", label=<{RuleCollection|<br ALIGN="LEFT"/>|custom_collection_from_list(new_collection_class_name: str, rules: Sequence[Rule]): RuleCollection<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._run.Run" [color="black", fontcolor="black", label=<{Run|addresses : Optional[List[_address.Address]]<br ALIGN="LEFT"/>artifacts : Optional[List[_artifact.Artifact]]<br ALIGN="LEFT"/>automation_details : Optional[_run_automation_details.RunAutomationDetails]<br ALIGN="LEFT"/>baseline_guid : Optional[str]<br ALIGN="LEFT"/>column_kind : Optional[Literal['utf16CodeUnits', 'unicodeCodePoints']]<br ALIGN="LEFT"/>conversion : Optional[_conversion.Conversion]<br ALIGN="LEFT"/>default_encoding : Optional[str]<br ALIGN="LEFT"/>default_source_language : Optional[str]<br ALIGN="LEFT"/>external_property_file_references : Optional[_external_property_file_references.ExternalPropertyFileReferences]<br ALIGN="LEFT"/>graphs : Optional[List[_graph.Graph]]<br ALIGN="LEFT"/>invocations : Optional[List[_invocation.Invocation]]<br ALIGN="LEFT"/>language : str<br ALIGN="LEFT"/>logical_locations : Optional[List[_logical_location.LogicalLocation]]<br ALIGN="LEFT"/>newline_sequences : List[str]<br ALIGN="LEFT"/>original_uri_base_ids : Optional[Any]<br ALIGN="LEFT"/>policies : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>redaction_tokens : Optional[List[str]]<br ALIGN="LEFT"/>results : Optional[List[_result.Result]]<br ALIGN="LEFT"/>run_aggregates : Optional[List[_run_automation_details.RunAutomationDetails]]<br ALIGN="LEFT"/>special_locations : Optional[_special_locations.SpecialLocations]<br ALIGN="LEFT"/>taxonomies : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>thread_flow_locations : Optional[List[_thread_flow_location.ThreadFlowLocation]]<br ALIGN="LEFT"/>tool<br ALIGN="LEFT"/>translations : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>version_control_provenance : Optional[List[_version_control_details.VersionControlDetails]]<br ALIGN="LEFT"/>web_requests : Optional[List[_web_request.WebRequest]]<br ALIGN="LEFT"/>web_responses : Optional[List[_web_response.WebResponse]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims.rng_prims.register_run_and_save_rng_state_op.RunAndSaveRngState" [color="black", fontcolor="black", label=<{RunAndSaveRngState|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._run_automation_details.RunAutomationDetails" [color="black", fontcolor="black", label=<{RunAutomationDetails|correlation_guid : Optional[str]<br ALIGN="LEFT"/>description : Optional[_message.Message]<br ALIGN="LEFT"/>guid : Optional[str]<br ALIGN="LEFT"/>id : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.run_const_graph.RunConstGraph" [color="black", fontcolor="black", label=<{RunConstGraph|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.RunOnlyContext" [color="black", fontcolor="black", label=<{RunOnlyContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.RunProcsResult" [color="black", fontcolor="black", label=<{RunProcsResult|failures : Dict[int, ProcessFailure]<br ALIGN="LEFT"/>return_values : Dict[int, Any]<br ALIGN="LEFT"/>stderrs : Dict[int, str]<br ALIGN="LEFT"/>stdouts : Dict[int, str]<br ALIGN="LEFT"/>|is_failed(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.RunResult" [color="black", fontcolor="black", label=<{RunResult|failures : Dict[int, ProcessFailure]<br ALIGN="LEFT"/>return_values : Dict[int, Any]<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|is_failed(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.RunWithRNGStateHigherOrderVariable" [color="black", fontcolor="black", label=<{RunWithRNGStateHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims.rng_prims.register_run_with_rng_state_op.RunWithRngState" [color="black", fontcolor="black", label=<{RunWithRngState|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.comms._schedule_for_comm.Runnable" [color="black", fontcolor="black", label=<{Runnable|score : tuple<br ALIGN="LEFT"/>snode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.RuntimeAssert" [color="black", fontcolor="black", label=<{RuntimeAssert|expr : str<br ALIGN="LEFT"/>msg : str<br ALIGN="LEFT"/>stack<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.context.RuntimeErrorWithDiagnostic" [color="black", fontcolor="red", label=<{RuntimeErrorWithDiagnostic|diagnostic<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.runtime_estimator.RuntimeEstimator" [color="black", fontcolor="black", label=<{RuntimeEstimator|fake_mode<br ALIGN="LEFT"/>mod_bw_post_order : List[str]<br ALIGN="LEFT"/>mod_bw_pre_order : List[str]<br ALIGN="LEFT"/>mod_fw_post_order : List[str]<br ALIGN="LEFT"/>mod_fw_pre_order : List[str]<br ALIGN="LEFT"/>mod_runtimes : Dict[str, Dict[str, float]], defaultdict<br ALIGN="LEFT"/>total_runtime : float<br ALIGN="LEFT"/>|display_modulewise_stats(depth: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.RuntimeSchemaInfo" [color="black", fontcolor="black", label=<{RuntimeSchemaInfo|needs_pytree : bool<br ALIGN="LEFT"/>static_argnum : int<br ALIGN="LEFT"/>static_kwargkey : Optional[List[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.runtime_wrappers.RuntimeWrapper" [color="black", fontcolor="black", label=<{RuntimeWrapper|disable_amp : bool<br ALIGN="LEFT"/>indices_of_inps_to_detach : List[int]<br ALIGN="LEFT"/>trace_joint : bool<br ALIGN="LEFT"/>|post_compile(compiled_fn, aot_config: AOTConfig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.sac_ilp.SACDecision" [color="black", fontcolor="black", label=<{SACDecision|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator.SACEstimator" [color="black", fontcolor="black", label=<{SACEstimator|sac_mod_greedy_order_meta : Dict[str, SACGreedyOrderMeta]<br ALIGN="LEFT"/>sac_mod_stats : Dict[str, SACStats]<br ALIGN="LEFT"/>sac_mod_tradeoff_stats : Dict[str, SACTradeOffStats]<br ALIGN="LEFT"/>|display_modulewise_sac_stats(depth: int, print_tabular: bool): None<br ALIGN="LEFT"/>display_sac_stats(sac_stats: SACStats, print_tabular: bool): None<br ALIGN="LEFT"/>display_sac_tradeoff_stats(greedy_order_meta: SACGreedyOrderMeta, sac_stats: SACStats, print_tabular: bool): None<br ALIGN="LEFT"/>pwlf_sac_tradeoff_curve(n_segments: int, save_tradeoff_graphs: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator.SACGreedyOrderMeta" [color="black", fontcolor="black", label=<{SACGreedyOrderMeta|inplace_op_groups : Dict[int, Set[int]]<br ALIGN="LEFT"/>msps_meta : List[MSPS]<br ALIGN="LEFT"/>random_ops_group : Dict[int, Set[int]]<br ALIGN="LEFT"/>recomputed_ops : Set[int]<br ALIGN="LEFT"/>stored_ops : Set[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator.SACStats" [color="black", fontcolor="black", label=<{SACStats|force_store_random : bool<br ALIGN="LEFT"/>func_names : List[str]<br ALIGN="LEFT"/>inplace_ops : List[Tuple[int, int]]<br ALIGN="LEFT"/>memory : List[int]<br ALIGN="LEFT"/>rand_ops : List[int]<br ALIGN="LEFT"/>runtimes : List[float]<br ALIGN="LEFT"/>saved_autograd_ops : List[int]<br ALIGN="LEFT"/>view_like_ops : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator.SACTradeOffStats" [color="black", fontcolor="black", label=<{SACTradeOffStats|fit_breaks : List[float]<br ALIGN="LEFT"/>intercepts : List[float]<br ALIGN="LEFT"/>n_segments : int<br ALIGN="LEFT"/>sac_memory : int<br ALIGN="LEFT"/>sac_runtime : float<br ALIGN="LEFT"/>slopes : List[float]<br ALIGN="LEFT"/>tradeoff_curve : OrderedDict[float, float]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.SDPAKernelVariable" [color="black", fontcolor="black", label=<{SDPAKernelVariable|prev_backends : list<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', backends)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.sdpa.SDPAParamsVariable" [color="black", fontcolor="black", label=<{SDPAParamsVariable|param_vars<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>create(tx: 'InstructionTranslator', value, source)<br ALIGN="LEFT"/>is_sdpa_params(value)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.SELU" [color="black", fontcolor="black", label=<{SELU|inplace : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.sgd.SGD" [color="black", fontcolor="black", label=<{SGD|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.sharding.SHARDING_PRIORITIES" [color="black", fontcolor="black", label=<{SHARDING_PRIORITIES|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.SIMDKernel" [color="black", fontcolor="black", label=<{SIMDKernel|allow_block_ptr : bool<br ALIGN="LEFT"/>body<br ALIGN="LEFT"/>code_hash : Optional[str]<br ALIGN="LEFT"/>cooperative_reduction : Optional[bool]<br ALIGN="LEFT"/>features<br ALIGN="LEFT"/>index_dtype<br ALIGN="LEFT"/>indexing_code<br ALIGN="LEFT"/>inside_reduction : bool<br ALIGN="LEFT"/>iter_vars_count : count<br ALIGN="LEFT"/>kernel_name : str<br ALIGN="LEFT"/>kexpr : Callable[[sympy.Expr], str]<br ALIGN="LEFT"/>mutations<br ALIGN="LEFT"/>no_x_dim : bool<br ALIGN="LEFT"/>num_reduction_dims<br ALIGN="LEFT"/>numels<br ALIGN="LEFT"/>persistent_reduction : Optional[bool]<br ALIGN="LEFT"/>range_tree_nodes : Dict[sympy.Symbol, IterationRangesEntry]<br ALIGN="LEFT"/>range_trees : List[IterationRangesRoot]<br ALIGN="LEFT"/>sexpr<br ALIGN="LEFT"/>simplify_indexing<br ALIGN="LEFT"/>|active_range_trees(reorder)<br ALIGN="LEFT"/><I>call_kernel</I>(name: str, node: Optional[IRNode]): None<br ALIGN="LEFT"/><I>codegen_body</I>()<br ALIGN="LEFT"/>codegen_indexing(expr: sympy.Expr)<br ALIGN="LEFT"/><I>codegen_iteration_ranges_entry</I>(entry: IterationRangesEntry)<br ALIGN="LEFT"/><I>codegen_kernel</I>()<br ALIGN="LEFT"/><I>codegen_nan_check</I>(): None<br ALIGN="LEFT"/>combine_contiguous_dims(index: sympy.Expr, tree: IterationRangesRoot)<br ALIGN="LEFT"/>combine_modular_indexing_pairs(index)<br ALIGN="LEFT"/>construct_range_trees(pid_cache, inside_reduction, is_reduction, numels, no_x_dim)<br ALIGN="LEFT"/>dense_size_list(): List[str]<br ALIGN="LEFT"/>dense_size_str()<br ALIGN="LEFT"/>disable_reduction()<br ALIGN="LEFT"/><I>dtype_to_str</I>(dtype: torch.dtype): str<br ALIGN="LEFT"/>estimate_kernel_num_bytes()<br ALIGN="LEFT"/><I>finalize_indexing</I>(indices: Sequence[sympy.Expr])<br ALIGN="LEFT"/>get_strides_of_load(index: sympy.Expr)<br ALIGN="LEFT"/>index_to_str(index: sympy.Expr): str<br ALIGN="LEFT"/>indexing_size_str(i)<br ALIGN="LEFT"/>initialize_range_tree(pid_cache)<br ALIGN="LEFT"/>is_broadcasted(index: sympy.Expr)<br ALIGN="LEFT"/>is_compatible(groups: Iterable[sympy.Expr], lengths: Sequence[Sequence[sympy.Expr]])<br ALIGN="LEFT"/>is_indirect_indexing(index: sympy.Expr)<br ALIGN="LEFT"/>map_kernel_groups_to_node_sizes(groups: Sequence[sympy.Expr], lengths: Sequence[Sequence[sympy.Expr]], set_ranges): List[List[sympy.Expr]]<br ALIGN="LEFT"/>mask_loads(mask, value)<br ALIGN="LEFT"/>prepare_indexing(index: sympy.Expr)<br ALIGN="LEFT"/>set_ranges()<br ALIGN="LEFT"/>should_use_cooperative_reduction(): bool<br ALIGN="LEFT"/>should_use_persistent_reduction(): bool<br ALIGN="LEFT"/>split_and_set_ranges(lengths: Sequence[Sequence[sympy.Expr]])<br ALIGN="LEFT"/>store_reduction(name: str, index: sympy.Expr, value: CSEVariable)<br ALIGN="LEFT"/>triton_tensor_ndim()<br ALIGN="LEFT"/>var_ranges()<br ALIGN="LEFT"/>want_no_x_dim()<br ALIGN="LEFT"/>warn_mix_layout(kernel_name)<br ALIGN="LEFT"/>welford_reduce_fallback(dtype, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.simd_kernel_features.SIMDKernelFeatures" [color="black", fontcolor="black", label=<{SIMDKernelFeatures|node_schedule : List[NodeScheduleEntry]<br ALIGN="LEFT"/>numel : Expr<br ALIGN="LEFT"/>reduction_numel : Expr<br ALIGN="LEFT"/>|buf_accesses(): Dict[str, List[Dep]]<br ALIGN="LEFT"/>contains_op(op_name: str): bool<br ALIGN="LEFT"/>get_mutations(): OrderedSet[str]<br ALIGN="LEFT"/>get_reduction_hint(): ReductionHint<br ALIGN="LEFT"/>has_non_contiguous_pw_in_reduction_kernel(): bool<br ALIGN="LEFT"/>is_reduction(): bool<br ALIGN="LEFT"/>op_counts(): collections.Counter[str]<br ALIGN="LEFT"/>reduction_hint(node: Any): ReductionHint<br ALIGN="LEFT"/>reduction_nodes(): List[SchedulerNode]<br ALIGN="LEFT"/>scheduler_nodes(): Iterable[SchedulerNode]<br ALIGN="LEFT"/>select_index_dtype(): torch.dtype<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.simd.SIMDScheduling" [color="black", fontcolor="black", label=<{SIMDScheduling|can_fuse_horizontal<br ALIGN="LEFT"/>can_fuse_vertical<br ALIGN="LEFT"/>kernel_type<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>|can_fuse(node1, node2)<br ALIGN="LEFT"/>can_use_32bit_indexing(numel: sympy.Expr, buffers: Iterable[Union[ir.Buffer, ir.TensorBox]]): bool<br ALIGN="LEFT"/>candidate_tilings(node)<br ALIGN="LEFT"/>codegen_combo_kernel(combo_kernel_node)<br ALIGN="LEFT"/><I>codegen_comment</I>(node_schedule)<br ALIGN="LEFT"/>codegen_node(node: Union[scheduler.FusedSchedulerNode, scheduler.SchedulerNode])<br ALIGN="LEFT"/>codegen_node_schedule(kernel_features: SIMDKernelFeatures)<br ALIGN="LEFT"/>codegen_node_schedule_with_kernel(node_schedule, kernel)<br ALIGN="LEFT"/>codegen_sync()<br ALIGN="LEFT"/>codegen_template(template_node, epilogue_nodes, prologue_nodes): Optional[str]<br ALIGN="LEFT"/>create_kernel_choices(kernel_features: SIMDKernelFeatures, kernel_args, kernel_kwargs): List[SIMDKernel]<br ALIGN="LEFT"/>create_tiling(pw_tiling: Sequence[sympy.Expr], reduction_tiling: Sequence[sympy.Expr]): Dict[str, sympy.Expr]<br ALIGN="LEFT"/><I>define_kernel</I>(src_code, node_schedule, kernel)<br ALIGN="LEFT"/><I>flush</I>()<br ALIGN="LEFT"/>generate_combo_kernel_code(subkernel_nodes: List[BaseSchedulerNode], custom_part_algorithm: bool, enable_autotune: bool, mixed_sizes: bool, only_gen_src_code: bool): List[Tuple[str, Any, Any]]<br ALIGN="LEFT"/>generate_kernel_code_from_nodes(nodes, benchmark_kernel)<br ALIGN="LEFT"/>generate_node_schedule(nodes, numel, rnumel)<br ALIGN="LEFT"/>group_fn(sizes)<br ALIGN="LEFT"/>ready_to_flush(): bool<br ALIGN="LEFT"/>select_tiling(node_schedule, numel, reduction_numel): Dict[str, sympy.Expr]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._guards.SLoc" [color="black", fontcolor="black", label=<{SLoc|framework_loc : Optional[Union[traceback.FrameSummary, str]]<br ALIGN="LEFT"/>maybe_user_loc : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.swa_utils.SWALR" [color="black", fontcolor="black", label=<{SWALR|anneal_epochs : int<br ALIGN="LEFT"/>anneal_func<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.pruner.saliency_pruner.SaliencyPruner" [color="black", fontcolor="black", label=<{SaliencyPruner|<br ALIGN="LEFT"/>|update_mask(module, tensor_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.SampleInput" [color="black", fontcolor="black", label=<{SampleInput|args : NoneType, tuple<br ALIGN="LEFT"/>broadcasts_input : NoneType, bool<br ALIGN="LEFT"/>input<br ALIGN="LEFT"/>kwargs : NoneType, dict<br ALIGN="LEFT"/>name : NoneType, str<br ALIGN="LEFT"/>output_process_fn_grad : NoneType<br ALIGN="LEFT"/>|noncontiguous()<br ALIGN="LEFT"/>numpy()<br ALIGN="LEFT"/>summary()<br ALIGN="LEFT"/>transform(f)<br ALIGN="LEFT"/>with_metadata()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.SampleRule" [color="black", fontcolor="black", label=<{SampleRule|name : str<br ALIGN="LEFT"/>op_match_fn : Optional[Callable[[str, OpInfo], bool]]<br ALIGN="LEFT"/>sample_match_fn : Optional[Callable[[torch.device, SampleInput], bool]]<br ALIGN="LEFT"/>|<I>get_context</I>(test_case)<br ALIGN="LEFT"/><I>type</I>(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.sampler.Sampler" [color="black", fontcolor="black", label=<{Sampler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combinatorics.SamplerIterDataPipe" [color="black", fontcolor="black", label=<{SamplerIterDataPipe|datapipe<br ALIGN="LEFT"/>sampler<br ALIGN="LEFT"/>sampler_args : NoneType, tuple<br ALIGN="LEFT"/>sampler_kwargs : NoneType, dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._sarif_log.SarifLog" [color="black", fontcolor="black", label=<{SarifLog|inline_external_properties : Optional[List[_external_properties.ExternalProperties]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>runs : List[_run.Run]<br ALIGN="LEFT"/>schema_uri : Optional[str]<br ALIGN="LEFT"/>version : Literal['2.1.0']<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.SaveForwardInputsModel" [color="black", fontcolor="black", label=<{SaveForwardInputsModel|c1<br ALIGN="LEFT"/>c2<br ALIGN="LEFT"/>forward_inputs : Dict[nn.Module, torch.Tensor]<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.SaveForwardInputsModule" [color="black", fontcolor="black", label=<{SaveForwardInputsModule|cast_forward_inputs : bool<br ALIGN="LEFT"/>forward_inputs : Dict[nn.Module, torch.Tensor]<br ALIGN="LEFT"/>l<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.SavePlan" [color="black", fontcolor="black", label=<{SavePlan|items : List[WriteItem]<br ALIGN="LEFT"/>planner_data : Optional[Any]<br ALIGN="LEFT"/>storage_data : Optional[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.SavePlanner" [color="black", fontcolor="black", label=<{SavePlanner|<br ALIGN="LEFT"/>|<I>create_global_plan</I>(all_plans: List[SavePlan]): Tuple[List[SavePlan], Metadata]<br ALIGN="LEFT"/><I>create_local_plan</I>(): SavePlan<br ALIGN="LEFT"/><I>finish_plan</I>(new_plan: SavePlan): SavePlan<br ALIGN="LEFT"/><I>resolve_data</I>(write_item: WriteItem): Union[torch.Tensor, io.BytesIO]<br ALIGN="LEFT"/><I>set_up_planner</I>(state_dict: STATE_DICT_TYPE, storage_meta: Optional[StorageMeta], is_coordinator: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.SavedTensorBox" [color="black", fontcolor="black", label=<{SavedTensorBox|tensors : List[VariableTracker]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.scalar_output.ScalarOutput" [color="black", fontcolor="black", label=<{ScalarOutput|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._coreml.preprocess.ScalarType" [color="black", fontcolor="black", label=<{ScalarType|Double : int<br ALIGN="LEFT"/>Float : int<br ALIGN="LEFT"/>Int : int<br ALIGN="LEFT"/>Long : int<br ALIGN="LEFT"/>Undefined : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.ScalarType" [color="black", fontcolor="black", label=<{ScalarType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.ScaleGradGenVmap" [color="black", fontcolor="black", label=<{ScaleGradGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>jvp(ctx, x_tangent)<br ALIGN="LEFT"/><I>setup_context</I>(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.Scan" [color="black", fontcolor="black", label=<{Scan|combine_fn : Callable[[Tuple[Any, ...], Tuple[Any, ...]], Tuple[Any, ...]]<br ALIGN="LEFT"/>dtypes : Tuple[torch.dtype, ...]<br ALIGN="LEFT"/>inner_fns : Tuple[Callable[..., Any], ...]<br ALIGN="LEFT"/>output_index : int<br ALIGN="LEFT"/>reduction_hint<br ALIGN="LEFT"/>reindex : Callable[[Sequence[_IntLike], Sequence[_IntLike]], Sequence[_IntLike]]<br ALIGN="LEFT"/>scan_ranges : List[Integer]<br ALIGN="LEFT"/>size : List[Integer]<br ALIGN="LEFT"/>|create(device: torch.device, dtypes: Tuple[torch.dtype, ...], inner_fns: Tuple[Callable[[Sequence[Expr]], Any], ...], size: List[Integer], axis: int, combine_fn: Callable[[Tuple[Any, ...], Tuple[Any, ...]], Tuple[Any, ...]], reduction_hint: ReductionHint): Sequence[Optional[TensorBox]]<br ALIGN="LEFT"/>get_pointwise_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[Symbol]<br ALIGN="LEFT"/>index_length(): int<br ALIGN="LEFT"/>inner_fn_args(): Sequence[Sequence[_IntLike]]<br ALIGN="LEFT"/>inner_fn_free_unbacked_symbols(): OrderedSet[Symbol]<br ALIGN="LEFT"/>num_splits(device: torch.device, dtype: torch.dtype, inner_fn: Callable[[Sequence[Expr]], OpsValue], axis: int, pointwise_ranges: List[Integer], scan_ranges: List[Integer], combine_fn: Callable[[Tuple[Any, ...], Tuple[Any, ...]], Tuple[Any, ...]], scan_numel: Expr): Tuple[ReductionHint, _IntLike]<br ALIGN="LEFT"/>store_reduction(output_name: Optional[str], indexer: Callable[[Sequence[_IntLike]], Never], vars: Sequence[Expr], scan_vars: Sequence[Symbol]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.ScanHigherOrderVariable" [color="black", fontcolor="black", label=<{ScanHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.scan.ScanOp" [color="black", fontcolor="black", label=<{ScanOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper._invoke.parse_output.ScanState" [color="black", fontcolor="black", label=<{ScanState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Scatter" [color="black", fontcolor="black", label=<{Scatter|output_indexer : Callable[[Sequence[Expr]], Expr]<br ALIGN="LEFT"/>scatter_mode : Optional[str]<br ALIGN="LEFT"/>|constant_to_device(device: torch.device): IRNode<br ALIGN="LEFT"/>store_output(output_name: Optional[str], indexer: Callable[[Sequence[Expr]], Never], vars: Sequence[Expr]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.Scatter" [color="black", fontcolor="black", label=<{Scatter|src<br ALIGN="LEFT"/>|work(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel._functions.Scatter" [color="black", fontcolor="black", label=<{Scatter|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, target_gpus, chunk_sizes, dim, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ScatterFallback" [color="black", fontcolor="black", label=<{ScatterFallback|name<br ALIGN="LEFT"/>src_is_tensor<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_mutation_names()<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.Schedule1F1B" [color="black", fontcolor="black", label=<{Schedule1F1B|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.ScheduleGPipe" [color="black", fontcolor="black", label=<{ScheduleGPipe|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.ScheduleInterleaved1F1B" [color="black", fontcolor="black", label=<{ScheduleInterleaved1F1B|microbatches_per_round<br ALIGN="LEFT"/>n_local_stages<br ALIGN="LEFT"/>number_of_rounds<br ALIGN="LEFT"/>pipeline_order : Dict[int, List[Optional[_Action]]]<br ALIGN="LEFT"/>pp_group_size<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble" [color="black", fontcolor="black", label=<{ScheduleInterleavedZeroBubble|microbatches_per_round<br ALIGN="LEFT"/>n_local_stages<br ALIGN="LEFT"/>number_of_rounds<br ALIGN="LEFT"/>pipeline_order : Dict[int, List[Optional[_Action]]], dict<br ALIGN="LEFT"/>pp_group_size<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.ScheduleLoopedBFS" [color="black", fontcolor="black", label=<{ScheduleLoopedBFS|pipeline_order : Dict[int, List[Optional[_Action]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules.ScheduleZBVZeroBubble" [color="black", fontcolor="black", label=<{ScheduleZBVZeroBubble|n_local_stages<br ALIGN="LEFT"/>num_stages<br ALIGN="LEFT"/>pipeline_order : Dict[int, List[Optional[_Action]]]<br ALIGN="LEFT"/>pp_group_size<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.scheduler.Scheduler" [color="black", fontcolor="black", label=<{Scheduler|available_buffer_names<br ALIGN="LEFT"/>backends : Dict[torch.device, BaseScheduling]<br ALIGN="LEFT"/>buffer_names_to_free<br ALIGN="LEFT"/>completed_operations<br ALIGN="LEFT"/>current_device<br ALIGN="LEFT"/>logged_slow_fusion<br ALIGN="LEFT"/>mutation_real_name : Dict[str, str]<br ALIGN="LEFT"/>mutation_renames : Dict[str, str]<br ALIGN="LEFT"/>name_to_buf : Dict[str, SchedulerBuffer]<br ALIGN="LEFT"/>name_to_donated_buffer : Dict[str, SchedulerDonatedBuffer]<br ALIGN="LEFT"/>name_to_fused_node : Dict[str, BaseSchedulerNode]<br ALIGN="LEFT"/>name_to_node : Dict[str, BaseSchedulerNode]<br ALIGN="LEFT"/>nodes : list<br ALIGN="LEFT"/>num_orig_nodes<br ALIGN="LEFT"/>origin_to_index : Dict[torch.fx.Node, int]<br ALIGN="LEFT"/>post_grad_graph_id<br ALIGN="LEFT"/>|are_long_distant_nodes(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>benchmark_combo_kernel(node_list: Sequence[BaseSchedulerNode]): Tuple[float, float, str]<br ALIGN="LEFT"/>benchmark_fused_nodes(nodes: Sequence[BaseSchedulerNode]): Tuple[float, str]<br ALIGN="LEFT"/>can_buffer_be_removed_through_fusion(name: str, fused_node_names: OrderedSet[str]): bool<br ALIGN="LEFT"/>can_fuse(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>can_fuse_vertical(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>can_fusion_increase_peak_memory(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>codegen(): None<br ALIGN="LEFT"/>codegen_extern_call(scheduler_node: ExternKernelSchedulerNode): None<br ALIGN="LEFT"/>compute_ancestors(): None<br ALIGN="LEFT"/>compute_dependencies(): None<br ALIGN="LEFT"/>compute_last_usage(): None<br ALIGN="LEFT"/>create_backend(device: torch.device): BaseScheduling<br ALIGN="LEFT"/>create_combo_kernel_nodes(num_ck_nodes: Optional[int]): None<br ALIGN="LEFT"/>create_foreach_nodes(): None<br ALIGN="LEFT"/>create_scheduler_node(node: ir.Operation): BaseSchedulerNode<br ALIGN="LEFT"/>dead_node_elimination(): None<br ALIGN="LEFT"/>debug_draw_graph(): None<br ALIGN="LEFT"/>debug_print_nodes(label: str): None<br ALIGN="LEFT"/>decide_fusion_fail_reason(node1: BaseSchedulerNode, node2: BaseSchedulerNode, common_buf_names: Tuple[str, ...]): str<br ALIGN="LEFT"/>dep_size_hint(dep: Dep): int<br ALIGN="LEFT"/>enter_context(node: BaseSchedulerNode): None<br ALIGN="LEFT"/>finalize_multi_template_buffers(): None<br ALIGN="LEFT"/>flush(): None<br ALIGN="LEFT"/>free_buffers(): None<br ALIGN="LEFT"/>fusable_read_and_write(read: Dep, write: MemoryDep): bool<br ALIGN="LEFT"/>fusable_weak_dep(weak_dep: WeakDep, node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>fuse_nodes(nodes: List[BaseSchedulerNode]): List[BaseSchedulerNode]<br ALIGN="LEFT"/>fuse_nodes_once(nodes: List[BaseSchedulerNode]): List[BaseSchedulerNode]<br ALIGN="LEFT"/>get_backend(device: Optional[torch.device]): BaseScheduling<br ALIGN="LEFT"/>get_buffer_layout(buf_name: str): ir.Layout<br ALIGN="LEFT"/>get_donated_buffers(): Dict[str, SchedulerDonatedBuffer]<br ALIGN="LEFT"/>get_possible_fusions(nodes: List[BaseSchedulerNode]): List[Tuple[BaseSchedulerNode, BaseSchedulerNode]]<br ALIGN="LEFT"/>get_possible_fusions_with_highest_priority(possible_fusions: List[Tuple[BaseSchedulerNode, BaseSchedulerNode]]): List[Tuple[BaseSchedulerNode, BaseSchedulerNode]]<br ALIGN="LEFT"/>merge_loops(): None<br ALIGN="LEFT"/>process_grouped_nodes(): None<br ALIGN="LEFT"/>prune_redundant_deps(nodes: List[BaseSchedulerNode]): None<br ALIGN="LEFT"/>score_fusion_key(nodes: Tuple[BaseSchedulerNode, BaseSchedulerNode]): Any<br ALIGN="LEFT"/>score_fusion_memory(node1: BaseSchedulerNode, node2: BaseSchedulerNode): int<br ALIGN="LEFT"/>shared_data_after_reordering_loop(node1: BaseSchedulerNode, node2: BaseSchedulerNode): int<br ALIGN="LEFT"/>speedup_by_combo_kernel(nodes: List[BaseSchedulerNode]): bool<br ALIGN="LEFT"/>speedup_by_fusion(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>topological_sort_schedule(nodes: List[BaseSchedulerNode]): List[BaseSchedulerNode]<br ALIGN="LEFT"/>unfusable_node(node: BaseSchedulerNode): bool<br ALIGN="LEFT"/>update_zero_dim_cpu_tensor(): None<br ALIGN="LEFT"/>will_fusion_create_cycle(node1: BaseSchedulerNode, node2: BaseSchedulerNode): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.SchedulerBuffer" [color="black", fontcolor="black", label=<{SchedulerBuffer|defining_op<br ALIGN="LEFT"/>mpi_buffer<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>scheduler<br ALIGN="LEFT"/>users : List[NodeUser]<br ALIGN="LEFT"/>|allocate(): None<br ALIGN="LEFT"/>can_free(): bool<br ALIGN="LEFT"/>debug_str(): str<br ALIGN="LEFT"/>get_aliases(): Sequence[str]<br ALIGN="LEFT"/>get_mutations(): Sequence[str]<br ALIGN="LEFT"/>get_name(): str<br ALIGN="LEFT"/>set_users(users: List[NodeUser]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.scheduler.SchedulerDonatedBuffer" [color="black", fontcolor="black", label=<{SchedulerDonatedBuffer|defining_op : Optional[BaseSchedulerNode]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.scheduler.SchedulerNode" [color="black", fontcolor="black", label=<{SchedulerNode|group : tuple<br ALIGN="LEFT"/>last_usage<br ALIGN="LEFT"/>max_order<br ALIGN="LEFT"/>min_order<br ALIGN="LEFT"/>|apply_new_loop_order(new_order: Sequence[int]): None<br ALIGN="LEFT"/>can_inplace(read_dep: dependencies.Dep): bool<br ALIGN="LEFT"/>codegen(index_vars: Sequence[Sequence[sympy.Expr]]): None<br ALIGN="LEFT"/>debug_str_extra(): str<br ALIGN="LEFT"/>get_ranges(): Sequence[Sequence[sympy.Expr]]<br ALIGN="LEFT"/>get_template_node(): Optional[ir.TemplateBuffer]<br ALIGN="LEFT"/>is_reduction(): bool<br ALIGN="LEFT"/>is_split_scan(): bool<br ALIGN="LEFT"/>is_template(): bool<br ALIGN="LEFT"/>pointwise_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>ranges_from_index_vars(index_vars: Sequence[Sequence[sympy.Expr]]): Dict[sympy.Expr, sympy.Expr]<br ALIGN="LEFT"/>recompute_size_and_body(extra_indexing_constraints: Optional[Tuple[Dict[Any, Any], List[Any]]], recompute_sizes_body_func: Optional[Callable[..., Any]]): None<br ALIGN="LEFT"/>refresh_dependencies(normalize: bool): None<br ALIGN="LEFT"/>reorder_loops_by_dep_pair(self_dep: MemoryDep, other_dep: MemoryDep): None<br ALIGN="LEFT"/>run(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.schema_check_mode.SchemaCheckMode" [color="black", fontcolor="black", label=<{SchemaCheckMode|aliasing : list<br ALIGN="LEFT"/>mutated : list<br ALIGN="LEFT"/>ops : list<br ALIGN="LEFT"/>|display_ops()<br ALIGN="LEFT"/>reset_cache()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._python_dispatch.SchemaInfo" [color="black", fontcolor="black", label=<{SchemaInfo|args : List[AliasInfo]<br ALIGN="LEFT"/>outs : List[AliasInfo]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.SchemaMatcher" [color="black", fontcolor="black", label=<{SchemaMatcher|<br ALIGN="LEFT"/>|inputs_are_mutable(t: _ExtraFields_TorchOp): Tuple[Optional[bool], ...]<br ALIGN="LEFT"/>lookup_schemas(name: str): Optional[Tuple[FunctionSchema, ...]]<br ALIGN="LEFT"/>match_schemas(t: _ExtraFields_TorchOp): Tuple[FunctionSchema, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema_check.SchemaUpdateError" [color="black", fontcolor="red", label=<{SchemaUpdateError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SchemaVersion" [color="black", fontcolor="black", label=<{SchemaVersion|major : Annotated[int, 10]<br ALIGN="LEFT"/>minor : Annotated[int, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.proxy.Scope" [color="black", fontcolor="black", label=<{Scope|module_path : str<br ALIGN="LEFT"/>module_type : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.tracer.ScopeContextManager" [color="black", fontcolor="black", label=<{ScopeContextManager|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.proxy.ScopeContextManager" [color="black", fontcolor="black", label=<{ScopeContextManager|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.ScopedDict" [color="black", fontcolor="black", label=<{ScopedDict|new_items : dict<br ALIGN="LEFT"/>original_dict<br ALIGN="LEFT"/>|get(key, default)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script.ScriptMeta" [color="black", fontcolor="black", label=<{ScriptMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._script.ScriptModule" [color="black", fontcolor="black", label=<{ScriptModule|forward : Callable[..., Any]<br ALIGN="LEFT"/>|define(src)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.custom_obj.ScriptObjectMeta" [color="black", fontcolor="black", label=<{ScriptObjectMeta|class_fqn : str<br ALIGN="LEFT"/>constant_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.ScriptObjectQualifiedNameSource" [color="black", fontcolor="black", label=<{ScriptObjectQualifiedNameSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script.ScriptWarning" [color="black", fontcolor="red", label=<{ScriptWarning|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.SearchFn" [color="black", fontcolor="black", label=<{SearchFn|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.Select" [color="black", fontcolor="black", label=<{Select|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, idx)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, output)<br ALIGN="LEFT"/>vmap(info, in_dims, x, idx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.SelectGenVmap" [color="black", fontcolor="black", label=<{SelectGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, idx)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.checkpoint.SelectiveCheckpointContext" [color="black", fontcolor="black", label=<{SelectiveCheckpointContext|is_recompute<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree.SequenceKey" [color="black", fontcolor="black", label=<{SequenceKey|idx : int<br ALIGN="LEFT"/>|get(sequence: Sequence[T]): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.parallel.style.SequenceParallel" [color="black", fontcolor="black", label=<{SequenceParallel|sequence_sharding : tuple<br ALIGN="LEFT"/>use_local_output : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.utils.SequenceWrapperMapDataPipe" [color="black", fontcolor="black", label=<{SequenceWrapperMapDataPipe|sequence<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.container.Sequential" [color="black", fontcolor="black", label=<{Sequential|<br ALIGN="LEFT"/>|append(module: Module): 'Sequential'<br ALIGN="LEFT"/>extend(sequential): 'Sequential'<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>insert(index: int, module: Module): 'Sequential'<br ALIGN="LEFT"/>pop(key: Union[int, slice]): Module<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel.SequentialDispatch" [color="black", fontcolor="black", label=<{SequentialDispatch|<br ALIGN="LEFT"/>|codegen_pid_range(kernel: 'ComboKernel', num: int, code: IndentedBuffer): None<br ALIGN="LEFT"/>grid(sub_kernel_numels: List[List[int]], x_blocks_list: List[Union[str, int]], dynamic_shape: bool): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.SequentialLR" [color="black", fontcolor="black", label=<{SequentialLR|last_epoch : int<br ALIGN="LEFT"/>optimizer<br ALIGN="LEFT"/>|load_state_dict(state_dict)<br ALIGN="LEFT"/>recursive_undo(sched)<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.sampler.SequentialSampler" [color="black", fontcolor="black", label=<{SequentialSampler|data_source : Sized<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.aot_autograd.SerializableAOTDispatchCompiler" [color="black", fontcolor="black", label=<{SerializableAOTDispatchCompiler|compiler_fn : Callable[[torch.fx.GraphModule, Sequence[InputType]], TOutputCode]<br ALIGN="LEFT"/>output_code_ty : Type[TOutputCode]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.Serialization" [color="black", fontcolor="black", label=<{Serialization|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.SerializeError" [color="black", fontcolor="red", label=<{SerializeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize.SerializedArtifact" [color="black", fontcolor="black", label=<{SerializedArtifact|constants : bytes<br ALIGN="LEFT"/>example_inputs : bytes<br ALIGN="LEFT"/>exported_program : bytes<br ALIGN="LEFT"/>state_dict : bytes<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.SetFwdGradEnabledContextManager" [color="black", fontcolor="black", label=<{SetFwdGradEnabledContextManager|prev_state<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_values)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.SetPair" [color="black", fontcolor="black", label=<{SetPair|CLS : set<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.SetSourceTensorKernel" [color="black", fontcolor="black", label=<{SetSourceTensorKernel|mutation_outputs : list<br ALIGN="LEFT"/>|get_inputs_that_alias_output(): Sequence[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" [color="black", fontcolor="black", label=<{SetVariable|set_items<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>getitem_const(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite.Shadow" [color="black", fontcolor="black", label=<{Shadow|dequant : DeQuantize<br ALIGN="LEFT"/>logger<br ALIGN="LEFT"/>orig_module<br ALIGN="LEFT"/>shadow_module<br ALIGN="LEFT"/>|add(x: torch.Tensor, y: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>add_relu(x: torch.Tensor, y: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>add_scalar(x: torch.Tensor, y: float): torch.Tensor<br ALIGN="LEFT"/>cat(x: List[torch.Tensor], dim: int): torch.Tensor<br ALIGN="LEFT"/>forward(): torch.Tensor<br ALIGN="LEFT"/>mul(x: torch.Tensor, y: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>mul_scalar(x: torch.Tensor, y: float): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns._numeric_suite.ShadowLogger" [color="black", fontcolor="black", label=<{ShadowLogger|<br ALIGN="LEFT"/>|forward(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.ShapeAsConstantBuffer" [color="black", fontcolor="black", label=<{ShapeAsConstantBuffer|expr : Expr<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>has_tensor_output(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._nnapi.prepare.process_for_nnapi.ShapeComputeModule" [color="black", fontcolor="black", label=<{ShapeComputeModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnv" [color="black", fontcolor="black", label=<{ShapeEnv|allow_complex_guards_as_runtime_asserts<br ALIGN="LEFT"/>allow_dynamic_output_shape_ops<br ALIGN="LEFT"/>allow_scalar_outputs<br ALIGN="LEFT"/>assume_static_by_default<br ALIGN="LEFT"/>axioms : Dict[sympy.Expr, sympy.Expr]<br ALIGN="LEFT"/>check_recorded_events<br ALIGN="LEFT"/>co_fields : dict<br ALIGN="LEFT"/>counter : Counter[str]<br ALIGN="LEFT"/>deferred_runtime_asserts : Dict[Optional[sympy.Symbol], List[RuntimeAssert]]<br ALIGN="LEFT"/>dim_constraints : Optional[DimConstraints]<br ALIGN="LEFT"/>divisible : Set[sympy.Expr], set<br ALIGN="LEFT"/>duck_shape<br ALIGN="LEFT"/>events : List[ShapeEnvEvent]<br ALIGN="LEFT"/>fake_tensor_cache : Dict[torch._subclasses.fake_tensor._DispatchCacheKey, torch._subclasses.fake_tensor._DispatchCacheEntry]<br ALIGN="LEFT"/>frozen : bool<br ALIGN="LEFT"/>fx_node_cache : Dict[Tuple[Callable, Tuple[Any, ...]], torch.fx.Node]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>guards : List[ShapeGuard]<br ALIGN="LEFT"/>is_recording : bool<br ALIGN="LEFT"/>log : NoneType, RootLogger<br ALIGN="LEFT"/>name_to_node : Dict[str, torch.fx.Node]<br ALIGN="LEFT"/>num_deferred_runtime_asserts : int<br ALIGN="LEFT"/>oblivious_var_to_val : Dict[sympy.Symbol, sympy.Integer]<br ALIGN="LEFT"/>pending_fresh_unbacked_symbols : List[sympy.Symbol]<br ALIGN="LEFT"/>prefer_deferred_runtime_asserts_over_guards<br ALIGN="LEFT"/>replacements : Dict[sympy.Symbol, sympy.Expr]<br ALIGN="LEFT"/>replacements_slocs : Dict[sympy.Symbol, SLoc]<br ALIGN="LEFT"/>runtime_asserts_frozen : bool<br ALIGN="LEFT"/>settings<br ALIGN="LEFT"/>should_record_events : NoneType<br ALIGN="LEFT"/>size_like : Set[sympy.Symbol]<br ALIGN="LEFT"/>source_name_to_debug_name : Dict[str, str]<br ALIGN="LEFT"/>source_to_symbol : Dict[str, sympy.Symbol]<br ALIGN="LEFT"/>source_to_var : Dict[str, sympy.Symbol]<br ALIGN="LEFT"/>specialize_zero_one<br ALIGN="LEFT"/>symbol_guard_counter : Counter[sympy.Symbol]<br ALIGN="LEFT"/>tracked_fakes : NoneType<br ALIGN="LEFT"/>unbacked_alloc_order : Dict[sympy.Symbol, int]<br ALIGN="LEFT"/>unbacked_renamings : Dict[sympy.Symbol, sympy.Symbol]<br ALIGN="LEFT"/>unbacked_symfloat_counter : count<br ALIGN="LEFT"/>unbacked_symint_counter : count<br ALIGN="LEFT"/>unbacked_var_to_val : Dict[sympy.Symbol, sympy.Integer]<br ALIGN="LEFT"/>val_to_var : Dict[int, sympy.Symbol], dict<br ALIGN="LEFT"/>validator<br ALIGN="LEFT"/>var_to_range : Dict[sympy.Symbol, ValueRanges]<br ALIGN="LEFT"/>var_to_range_sloc : Dict[sympy.Symbol, ValueRangesSLoc]<br ALIGN="LEFT"/>var_to_sources : Dict[sympy.Symbol, List[Source]]<br ALIGN="LEFT"/>var_to_stack : Dict[sympy.Symbol, CapturedTraceback]<br ALIGN="LEFT"/>var_to_val : Dict[sympy.Symbol, sympy.Integer]<br ALIGN="LEFT"/>|add_var_to_val(expr: sympy.Symbol, val: int): None<br ALIGN="LEFT"/>bind_symbols(placeholders: Sequence[FakeTensor], args: Sequence[Tensor]): Dict[sympy.Symbol, int]<br ALIGN="LEFT"/>bound_sympy(expr: sympy.Expr, size_oblivious: bool): ValueRanges<br ALIGN="LEFT"/>check_equal(other: ShapeEnv): None<br ALIGN="LEFT"/>cleanup(): None<br ALIGN="LEFT"/>constrain_symbol_range(s: sympy.Symbol, compiler_min: int, compiler_max: int): None<br ALIGN="LEFT"/>create_symbol(val: int, source: Source, dynamic_dim: DimDynamic, constraint_dim: DimConstraint, positive: Optional[bool], do_not_specialize_zero_one: bool, symbolic_context: Optional[StatelessSymbolicContext]): sympy.Expr<br ALIGN="LEFT"/>create_symbolic_sizes_strides_storage_offset(ex: torch.Tensor, source: Source): Tuple[Tuple[Union[int, SymInt], ...], Tuple[Union[int, SymInt], ...], Union[int, SymInt]]<br ALIGN="LEFT"/>create_symboolnode(sym: sympy.Expr): SymBool<br ALIGN="LEFT"/>create_symfloatnode(sym: sympy.Expr): Union[float, SymFloat]<br ALIGN="LEFT"/>create_symintnode(sym: sympy.Expr): Union[int, SymInt]<br ALIGN="LEFT"/>create_unbacked_symbool(): SymBool<br ALIGN="LEFT"/>create_unbacked_symfloat(): SymFloat<br ALIGN="LEFT"/>create_unbacked_symint(source: Optional[Source]): SymInt<br ALIGN="LEFT"/>create_unspecified_symbol(val: Union[int, SymInt, float, SymFloat], source: Source, dynamic_dim: DimDynamic, constraint_dim: DimConstraint, symbolic_context: Optional[StatelessSymbolicContext]): sympy.Expr<br ALIGN="LEFT"/>create_unspecified_symint_and_symbol(value: int, source: Source, dynamic_dim: DimDynamic): Union[int, SymInt]<br ALIGN="LEFT"/>defer_runtime_assert(orig_expr: SympyBoolean, msg: str, fx_node: Optional[torch.fx.Node]): bool<br ALIGN="LEFT"/>deserialize_symexpr(code: str): Union[SymInt, SymFloat, SymBool]<br ALIGN="LEFT"/>evaluate_expr(orig_expr: sympy.Basic, hint: Optional[Union[int, bool, float]], fx_node: Optional[torch.fx.Node], size_oblivious: bool): sympy.Basic<br ALIGN="LEFT"/>evaluate_guards_expression(code: str, args: Sequence[object]): bool<br ALIGN="LEFT"/>evaluate_guards_for_args(placeholders: Sequence[FakeTensor], args: Sequence[Tensor]): bool<br ALIGN="LEFT"/>evaluate_symexpr(code: str): Union[int, float, bool]<br ALIGN="LEFT"/>format_guards(verbose: bool): str<br ALIGN="LEFT"/>freeze(): None<br ALIGN="LEFT"/>freeze_runtime_asserts(): None<br ALIGN="LEFT"/>get_axioms(symbols: Optional[Tuple[sympy.Symbol]], compute_hint: bool): Tuple[SympyBoolean, ...]<br ALIGN="LEFT"/>get_implications(e: SympyBoolean): Tuple[Tuple[SympyBoolean, sympy.logic.boolalg.BooleanAtom], ...]<br ALIGN="LEFT"/>get_nontrivial_guards(): List[SympyBoolean]<br ALIGN="LEFT"/>get_pruned_guards(symints: Sequence[torch.SymInt]): List[ShapeGuard]<br ALIGN="LEFT"/>has_hint(expr: sympy.Expr): bool<br ALIGN="LEFT"/>ignore_fresh_unbacked_symbols(): Iterator[None]<br ALIGN="LEFT"/>is_unbacked_symint(symbol: sympy.Symbol): bool<br ALIGN="LEFT"/>produce_guards(): List[str]<br ALIGN="LEFT"/>produce_guards_expression(placeholders: Sequence[Union[SymInt, FakeTensor]]): Optional[str]<br ALIGN="LEFT"/>produce_guards_verbose(placeholders: Sequence[FakeTensor], sources: Sequence[Source], source_ref: Callable[[Source], str]): Tuple[List[str], List[str]]<br ALIGN="LEFT"/>replace(expr: _SympyT): _SympyT<br ALIGN="LEFT"/>set_unbacked_var_to_val(k: sympy.Symbol, v: int): None<br ALIGN="LEFT"/>simplify(expr: _SympyT): _SympyT<br ALIGN="LEFT"/>size_hint(expr: sympy.Basic): Optional[sympy.Basic]<br ALIGN="LEFT"/>suppress_guards(): _GeneratorContextManager[None]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.recording.ShapeEnvEvent" [color="black", fontcolor="black", label=<{ShapeEnvEvent|args : Optional[List[Any]]<br ALIGN="LEFT"/>f : Callable<br ALIGN="LEFT"/>kwargs : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>tracked_fakes : Optional[List[Any]]<br ALIGN="LEFT"/>|is_create_fx_call_function(): bool<br ALIGN="LEFT"/>is_defer_runtime_assert(): bool<br ALIGN="LEFT"/>is_evaluate_expr(): bool<br ALIGN="LEFT"/>run(shape_env): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnvSettings" [color="black", fontcolor="black", label=<{ShapeEnvSettings|allow_complex_guards_as_runtime_asserts : bool<br ALIGN="LEFT"/>allow_dynamic_output_shape_ops : bool<br ALIGN="LEFT"/>allow_scalar_outputs : bool<br ALIGN="LEFT"/>assume_static_by_default : bool<br ALIGN="LEFT"/>duck_shape : bool<br ALIGN="LEFT"/>prefer_deferred_runtime_asserts_over_guards : bool<br ALIGN="LEFT"/>specialize_zero_one : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.ShapeEnvSource" [color="black", fontcolor="black", label=<{ShapeEnvSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.ShapeFuncInfo" [color="black", fontcolor="black", label=<{ShapeFuncInfo|ref<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.ShapeGuard" [color="black", fontcolor="black", label=<{ShapeGuard|expr : Boolean<br ALIGN="LEFT"/>sloc<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeGuardPrinter" [color="black", fontcolor="black", label=<{ShapeGuardPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeGuardPythonPrinter" [color="black", fontcolor="black", label=<{ShapeGuardPythonPrinter|<br ALIGN="LEFT"/>|print_source(source: Source): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.shape_prop.ShapeProp" [color="black", fontcolor="black", label=<{ShapeProp|fake_mode : NoneType<br ALIGN="LEFT"/>fake_module : NoneType<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>real_module<br ALIGN="LEFT"/>|propagate()<br ALIGN="LEFT"/>run_node(n: Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.dynamic_shapes.ShapesCollection" [color="black", fontcolor="black", label=<{ShapesCollection|<br ALIGN="LEFT"/>|dynamic_shapes(m, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.placement_types.Shard" [color="black", fontcolor="black", label=<{Shard|dim : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.shard.Shard" [color="black", fontcolor="black", label=<{Shard|metadata<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|from_tensor_and_offsets(tensor: torch.Tensor, shard_offsets: List[int], rank: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.metadata.ShardMetadata" [color="black", fontcolor="black", label=<{ShardMetadata|placement : Optional[_remote_device]<br ALIGN="LEFT"/>shard_offsets : List[int]<br ALIGN="LEFT"/>shard_sizes : List[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.sharded_grad_scaler.ShardedGradScaler" [color="black", fontcolor="black", label=<{ShardedGradScaler|process_group<br ALIGN="LEFT"/>|scale(outputs: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>unscale_(optimizer: torch.optim.Optimizer): None<br ALIGN="LEFT"/>update(new_scale: Optional[Union[float, torch.Tensor]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.ShardedOptimStateDictConfig" [color="black", fontcolor="black", label=<{ShardedOptimStateDictConfig|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_optim.api.ShardedOptimizer" [color="black", fontcolor="black", label=<{ShardedOptimizer|named_params : Mapping[str, Union[Tensor, ShardedTensor]]<br ALIGN="LEFT"/>param_groups<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|<I>add_param_group</I>(param_group: Any)<br ALIGN="LEFT"/><I>load_state_dict</I>(state_dict: Mapping[str, Any])<br ALIGN="LEFT"/><I>state_dict</I>(): Dict[str, Any]<br ALIGN="LEFT"/>step(closure)<br ALIGN="LEFT"/>zero_grad(set_to_none: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.ShardedState" [color="black", fontcolor="black", label=<{ShardedState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.ShardedStateDictConfig" [color="black", fontcolor="black", label=<{ShardedStateDictConfig|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensor" [color="black", fontcolor="black", label=<{ShardedTensor|<br ALIGN="LEFT"/>|cpu(memory_format, process_group): ShardedTensor<br ALIGN="LEFT"/>cuda(device, non_blocking, memory_format, process_group): ShardedTensor<br ALIGN="LEFT"/>gather(dst: int, out: Optional[torch.Tensor], enforce_dtype: bool, dtype: Optional[torch.dtype]): None<br ALIGN="LEFT"/>is_pinned(): bool<br ALIGN="LEFT"/>local_tensor(): torch.Tensor<br ALIGN="LEFT"/>remote_shards(): Dict[int, List[rpc.RRef[Shard]]]<br ALIGN="LEFT"/>reshard(resharding_spec: shard_spec.ShardingSpec): ShardedTensor<br ALIGN="LEFT"/>sharding_spec(): shard_spec.ShardingSpec<br ALIGN="LEFT"/>to(): ShardedTensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensorBase" [color="black", fontcolor="black", label=<{ShardedTensorBase|<br ALIGN="LEFT"/>|local_shards(): List[Shard]<br ALIGN="LEFT"/>metadata(): ShardedTensorMetadata<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.metadata.ShardedTensorMetadata" [color="black", fontcolor="black", label=<{ShardedTensorMetadata|shards_metadata : List[ShardMetadata]<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>tensor_properties<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed._shard.sharded_tensor.ShardedTensorTestBase" [color="black", fontcolor="black", label=<{ShardedTensorTestBase|world_size<br ALIGN="LEFT"/>|assert_sharded_tensor_equal(st1, st2)<br ALIGN="LEFT"/>destroy_comms(destroy_rpc)<br ALIGN="LEFT"/>init_comms(init_rpc, backend)<br ALIGN="LEFT"/>init_pg(backend)<br ALIGN="LEFT"/>init_rpc()<br ALIGN="LEFT"/>setUp(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharder.Sharder" [color="black", fontcolor="black", label=<{Sharder|<br ALIGN="LEFT"/>|<I>shard</I>(module: nn.Module): nn.Module<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe" [color="black", fontcolor="black", label=<{ShardingFilterIterDataPipe|groups : Dict[int, Tuple[int, int]]<br ALIGN="LEFT"/>instance_id : int<br ALIGN="LEFT"/>num_of_instances : int<br ALIGN="LEFT"/>sharding_group_filter : NoneType<br ALIGN="LEFT"/>source_datapipe<br ALIGN="LEFT"/>|apply_sharding(num_of_instances, instance_id, sharding_group)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_plan.api.ShardingPlan" [color="black", fontcolor="black", label=<{ShardingPlan|output_plan : Optional[Dict[str, ShardingSpec]]<br ALIGN="LEFT"/>plan : Dict[str, Union[ShardingSpec, Sharder]]<br ALIGN="LEFT"/>return_local_tensor : Optional[List[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_plan.api.ShardingPlanner" [color="black", fontcolor="black", label=<{ShardingPlanner|<br ALIGN="LEFT"/>|<I>build_plan</I>(module: nn.Module): ShardingPlan<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._sharding_prop.ShardingPropagator" [color="black", fontcolor="black", label=<{ShardingPropagator|op_strategy_funcs : Dict[OpOverload, Callable[[DeviceMesh, OpSchema], StrategyType]]<br ALIGN="LEFT"/>op_to_rules : Dict[OpOverload, Callable[[OpSchema], OutputSharding]]<br ALIGN="LEFT"/>op_to_schema_info : Dict[OpOverload, RuntimeSchemaInfo]<br ALIGN="LEFT"/>op_to_shape_and_stride_idx : Dict[OpOverload, Union[int, Tuple[int, int]]]<br ALIGN="LEFT"/>propagate_op_sharding<br ALIGN="LEFT"/>|propagate(op_info: OpInfo): None<br ALIGN="LEFT"/>propagate_op_sharding_non_cached(op_schema: OpSchema): OutputSharding<br ALIGN="LEFT"/>register_op_strategy(op_overload: OpOverload, strategy_func: Callable[[DeviceMesh, OpSchema], StrategyType], schema_info: Optional[RuntimeSchemaInfo])<br ALIGN="LEFT"/>register_sharding_prop_rule(op_overload: OpOverload, rule_func: Callable[[OpSchema], OutputSharding], schema_info: Optional[RuntimeSchemaInfo])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharding_spec.api.ShardingSpec" [color="black", fontcolor="black", label=<{ShardingSpec|<br ALIGN="LEFT"/>|<I>build_metadata</I>(tensor_sizes: torch.Size, tensor_properties: sharded_tensor_meta.TensorProperties): sharded_tensor_meta.ShardedTensorMetadata<br ALIGN="LEFT"/><I>shard</I>(tensor: torch.Tensor, src_rank: int, process_group): 'ShardedTensor'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.ShardingStrategy" [color="black", fontcolor="black", label=<{ShardingStrategy|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.multiprocessing.reductions.SharedCache" [color="black", fontcolor="black", label=<{SharedCache|limit : int<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>|free_dead_references()<br ALIGN="LEFT"/>get(key)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param.SharedParamInfo" [color="black", fontcolor="black", label=<{SharedParamInfo|module<br ALIGN="LEFT"/>module_name : str<br ALIGN="LEFT"/>param_name : str<br ALIGN="LEFT"/>prim_module<br ALIGN="LEFT"/>prim_module_name : str<br ALIGN="LEFT"/>prim_param_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.quantizer.SharedQuantizationSpec" [color="black", fontcolor="black", label=<{SharedQuantizationSpec|edge_or_node : Union<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.FallbackKernel.codegen_args.Shim" [color="black", fontcolor="black", label=<{Shim|ref : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen.val_to_arg_str.Shim" [color="black", fontcolor="black", label=<{Shim|ref : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ShortStorage" [color="black", fontcolor="black", label=<{ShortStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ShortStorage" [color="black", fontcolor="black", label=<{ShortStorage|<br ALIGN="LEFT"/>|dtype()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.dataframe.datapipes.ShuffleDataFramesPipe" [color="black", fontcolor="black", label=<{ShuffleDataFramesPipe|source_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.combinatorics.ShufflerIterDataPipe" [color="black", fontcolor="black", label=<{ShufflerIterDataPipe|datapipe : MapDataPipe[_T_co]<br ALIGN="LEFT"/>indices : NoneType, list<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>set_seed(seed: int)<br ALIGN="LEFT"/>set_shuffle(shuffle)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combinatorics.ShufflerIterDataPipe" [color="black", fontcolor="black", label=<{ShufflerIterDataPipe|buffer_size : int<br ALIGN="LEFT"/>datapipe : IterDataPipe[_T_co]<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>set_seed(seed: int)<br ALIGN="LEFT"/>set_shuffle(shuffle)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.SiLU" [color="black", fontcolor="black", label=<{SiLU|inplace : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.side_effects.SideEffects" [color="black", fontcolor="black", label=<{SideEffects|ca_final_callbacks_var : NoneType<br ALIGN="LEFT"/>id_to_variable : Dict[int, VariableTracker]<br ALIGN="LEFT"/>keepalive : List[Any]<br ALIGN="LEFT"/>output_graph_weakref<br ALIGN="LEFT"/>save_for_backward : list<br ALIGN="LEFT"/>store_attr_mutations : Dict[VariableTracker, Dict[str, VariableTracker]]<br ALIGN="LEFT"/>tensor_hooks : dict<br ALIGN="LEFT"/>track_mutable<br ALIGN="LEFT"/>|check_allowed_side_effect(item)<br ALIGN="LEFT"/>clear()<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>cls_supports_mutation_side_effects(cls)<br ALIGN="LEFT"/>codegen_hooks(cg)<br ALIGN="LEFT"/>codegen_save_tempvars(cg: PyCodegen)<br ALIGN="LEFT"/>codegen_update_mutated(cg: PyCodegen)<br ALIGN="LEFT"/>diff(other: 'SideEffects'): Optional[str]<br ALIGN="LEFT"/>get_ca_final_callbacks_var()<br ALIGN="LEFT"/>has_pending_mutation(item)<br ALIGN="LEFT"/>has_pending_mutation_of_attr(item, name)<br ALIGN="LEFT"/>is_attribute_mutation(item)<br ALIGN="LEFT"/>is_empty()<br ALIGN="LEFT"/>is_modified(item)<br ALIGN="LEFT"/>load_attr(item, name, deleted_ok, check)<br ALIGN="LEFT"/>load_cell(cellvar)<br ALIGN="LEFT"/>load_global(gvar: VariableTracker, name: str)<br ALIGN="LEFT"/>mutation(var)<br ALIGN="LEFT"/>prune_dead_object_new(tx)<br ALIGN="LEFT"/>register_hook(tensor, hook, handle, name)<br ALIGN="LEFT"/>remove_hook(idx)<br ALIGN="LEFT"/>should_allow_side_effects_under_checkpoint()<br ALIGN="LEFT"/>store_attr(item: VariableTracker, name: str, value: VariableTracker)<br ALIGN="LEFT"/>store_cell(cellvar, value)<br ALIGN="LEFT"/>store_global(gvar: VariableTracker, name: str, value: VariableTracker)<br ALIGN="LEFT"/>track_cell_existing(source: Optional[Source], cell: CellType, contents: VariableTracker)<br ALIGN="LEFT"/>track_cell_new()<br ALIGN="LEFT"/>track_global_existing(source: Source, item: Any)<br ALIGN="LEFT"/>track_object_existing(item: Any, variable: VariableTracker)<br ALIGN="LEFT"/>track_object_new(cls_source: Source, user_cls: Any, variable_cls: Any, options)<br ALIGN="LEFT"/>track_object_new_from_user_defined_class(cls_variable: 'variables.UserDefinedClassVariable')<br ALIGN="LEFT"/>track_save_for_backward(ctx, args)<br ALIGN="LEFT"/>track_tensor_variables_from_runahead_side_effects(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.Sigmoid" [color="black", fontcolor="black", label=<{Sigmoid|output_scale : float<br ALIGN="LEFT"/>output_zero_point : int<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Sigmoid" [color="black", fontcolor="black", label=<{Sigmoid|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.SigmoidTransform" [color="black", fontcolor="black", label=<{SigmoidTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>sign : int<br ALIGN="LEFT"/>|log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.SignalException" [color="black", fontcolor="red", label=<{SignalException|sigval : Signals<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ops_handler.SimpleCSEHandler" [color="black", fontcolor="black", label=<{SimpleCSEHandler|cse_cache : Dict[str, Union[T, Tuple[T, ...]]]<br ALIGN="LEFT"/>mock<br ALIGN="LEFT"/>|indirect_indexing(): sympy.Expr<br ALIGN="LEFT"/><I>store</I>(): T<br ALIGN="LEFT"/><I>store_reduction</I>(): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" [color="black", fontcolor="black", label=<{SimpleConditionalModel|nn1<br ALIGN="LEFT"/>nn2<br ALIGN="LEFT"/>nn3<br ALIGN="LEFT"/>nn4<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>state : int<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.SimpleConv2d" [color="black", fontcolor="black", label=<{SimpleConv2d|conv2d1<br ALIGN="LEFT"/>conv2d2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.SimpleElasticAgent" [color="black", fontcolor="black", label=<{SimpleElasticAgent|<br ALIGN="LEFT"/>|get_event_failed(): Event<br ALIGN="LEFT"/>get_event_succeeded(): Event<br ALIGN="LEFT"/>get_worker_group(role: str): WorkerGroup<br ALIGN="LEFT"/>record_duration(state: str)<br ALIGN="LEFT"/>run(role: str): RunResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.simple_registry.SimpleLibraryRegistry" [color="black", fontcolor="black", label=<{SimpleLibraryRegistry|<br ALIGN="LEFT"/>|find(qualname: str): 'SimpleOperatorEntry'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_pruning.SimpleLinear" [color="black", fontcolor="black", label=<{SimpleLinear|linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._shard.test_common.SimpleMegatronLM" [color="black", fontcolor="black", label=<{SimpleMegatronLM|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>gelu<br ALIGN="LEFT"/>|forward(inp)<br ALIGN="LEFT"/>get_bias_grads()<br ALIGN="LEFT"/>get_biases()<br ALIGN="LEFT"/>get_weight_grads()<br ALIGN="LEFT"/>get_weights()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._library.simple_registry.SimpleOperatorEntry" [color="black", fontcolor="black", label=<{SimpleOperatorEntry|abstract_impl<br ALIGN="LEFT"/>fake_impl<br ALIGN="LEFT"/>qualname : str<br ALIGN="LEFT"/>torch_dispatch_rules<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._debug_utils.SimpleProfiler" [color="black", fontcolor="black", label=<{SimpleProfiler|profiling : Set[str]<br ALIGN="LEFT"/>results : Dict[str, float]<br ALIGN="LEFT"/>|dump_and_reset(msg: str): None<br ALIGN="LEFT"/>profile(profile_type: str): Iterator[None]<br ALIGN="LEFT"/>reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.queue.SimpleQueue" [color="black", fontcolor="black", label=<{SimpleQueue|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.sizevars.SimplifyIndexing" [color="black", fontcolor="black", label=<{SimplifyIndexing|name : str<br ALIGN="LEFT"/>|check_bounds(index, size, lower, upper)<br ALIGN="LEFT"/>index_expr(index, dtype)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>store_reduction(name, index, value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.SimulateBackwardError" [color="black", fontcolor="black", label=<{SimulateBackwardError|<br ALIGN="LEFT"/>|backward(ctx, input)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_remove_autograd_hooks.SimulateError" [color="black", fontcolor="black", label=<{SimulateError|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SingleLayerFunctionalConvModel" [color="black", fontcolor="black", label=<{SingleLayerFunctionalConvModel|conv1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SingleLayerFunctionalLinearModel" [color="black", fontcolor="black", label=<{SingleLayerFunctionalLinearModel|linear1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel" [color="black", fontcolor="black", label=<{SingleLayerLinearDynamicModel|fc1<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SingleLayerLinearModel" [color="black", fontcolor="black", label=<{SingleLayerLinearModel|fc1<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.Singleton" [color="black", fontcolor="black", label=<{Singleton|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.singleton_int.SingletonInt" [color="black", fontcolor="black", label=<{SingletonInt|free_symbols<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.SizeArg" [color="black", fontcolor="black", label=<{SizeArg|alias_of<br ALIGN="LEFT"/>expr : Expr<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.SizeMap" [color="black", fontcolor="black", label=<{SizeMap|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.sizevars.SizeVarAllocator" [color="black", fontcolor="black", label=<{SizeVarAllocator|inv_precomputed_replacements : Dict[sympy.Symbol, Expr]<br ALIGN="LEFT"/>precomputed_replacements : Dict[Expr, sympy.Symbol]<br ALIGN="LEFT"/>replacements : Dict[sympy.Symbol, Expr]<br ALIGN="LEFT"/>shape_env : NoneType<br ALIGN="LEFT"/>simplify_with_ranges<br ALIGN="LEFT"/>stride_vars<br ALIGN="LEFT"/>var_to_val : dict<br ALIGN="LEFT"/>|atomically_apply_size_hint(expr: Union[Expr, int]): Union[Expr, int]<br ALIGN="LEFT"/>combine_modular_indexing_pairs(index: sympy.Expr): sympy.Expr<br ALIGN="LEFT"/>evaluate_expr(left: Union[Expr, sympy.logic.boolalg.Boolean]): bool<br ALIGN="LEFT"/>evaluate_max(left: Expr, right: Expr): Expr<br ALIGN="LEFT"/>evaluate_min(left: Expr, right: Expr): Expr<br ALIGN="LEFT"/>evaluate_static_shape(left: Union[Expr, int]): int<br ALIGN="LEFT"/>evaluate_static_shapes(left: Sequence[Union[Expr, int]]): List[int]<br ALIGN="LEFT"/>expand_floor_div(index: sympy.Expr): Union[bool, Tuple[sympy.Expr, sympy.Expr]]<br ALIGN="LEFT"/>free_symbols(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>guard_equals(left: Expr, right: Expr): Expr<br ALIGN="LEFT"/>guard_leq(left: Expr, right: Expr): None<br ALIGN="LEFT"/>guard_lt(left: Expr, right: Expr): None<br ALIGN="LEFT"/>guarded_order(seq)<br ALIGN="LEFT"/>is_expr_static_and_true(expr: Union[sympy.Basic, bool]): bool<br ALIGN="LEFT"/>lookup_precomputed_size(expr: Expr): Expr<br ALIGN="LEFT"/>make_simplify_loops_cache()<br ALIGN="LEFT"/>make_simplify_with_ranges_cache(): Callable[[Expr, VarRanges], Expr]<br ALIGN="LEFT"/>make_stride_vars_cache()<br ALIGN="LEFT"/>offset_var(index: Expr, vars: List[sympy.Symbol]): Expr<br ALIGN="LEFT"/>remove_precomputed_replacements(expr: Expr): Expr<br ALIGN="LEFT"/>simplify(expr: Expr)<br ALIGN="LEFT"/>size_hint(expr: Union[Expr, int]): int<br ALIGN="LEFT"/>size_hints(exprs: Iterable[Expr]): Tuple[int, ...]<br ALIGN="LEFT"/>statically_known_equals(left: Union[Expr, int], right: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_geq(left: Expr, right: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_gt(left: Expr, right: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_leq(left: Expr, right: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_list_equals(left: List[Expr], right: List[Expr]): bool<br ALIGN="LEFT"/>statically_known_lt(left: Expr, right: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_multiple_of(numerator: Expr, denominator: Union[Expr, int]): bool<br ALIGN="LEFT"/>statically_known_power_of_2(expr: Expr): bool<br ALIGN="LEFT"/>stride_hints(index: Expr, vars: Sequence[sympy.Symbol], support_vars: Optional[Sequence[sympy.Symbol]]): List[int]<br ALIGN="LEFT"/>stride_order(index: Expr, vars: List[sympy.Symbol]): List[int]<br ALIGN="LEFT"/>symbolic_hint(expr: Union[Expr, int]): Union[Expr, int]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.SizeVariable" [color="black", fontcolor="black", label=<{SizeVariable|class_type<br ALIGN="LEFT"/>has_grad_fn : bool<br ALIGN="LEFT"/>proxy : Optional[torch.fx.Proxy]<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>get_item_dyn(tx: 'InstructionTranslator', arg: VariableTracker)<br ALIGN="LEFT"/>numel(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.SkipCodeRecursiveException" [color="black", fontcolor="red", label=<{SkipCodeRecursiveException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.SkipFrame" [color="black", fontcolor="red", label=<{SkipFrame|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.SkipFunctionVariable" [color="black", fontcolor="black", label=<{SkipFunctionVariable|reason : NoneType<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create_with_source(value, source)<br ALIGN="LEFT"/>fold_through_function_to_wrapper()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.SkipModel" [color="black", fontcolor="black", label=<{SkipModel|linear<br ALIGN="LEFT"/>linear_skip<br ALIGN="LEFT"/>nested_linear<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.SkipModule" [color="black", fontcolor="black", label=<{SkipModule|lin<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SkipQuantModel" [color="black", fontcolor="black", label=<{SkipQuantModel|fc<br ALIGN="LEFT"/>sub<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>fuse_modules()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.trace_rules.SkipResult" [color="black", fontcolor="black", label=<{SkipResult|reason : Optional[str]<br ALIGN="LEFT"/>skipped : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.SkipRule" [color="black", fontcolor="black", label=<{SkipRule|type<br ALIGN="LEFT"/>|get_context(test_case)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.SliceVariable" [color="black", fontcolor="black", label=<{SliceVariable|<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.SliceView" [color="black", fontcolor="black", label=<{SliceView|<br ALIGN="LEFT"/>|create(x, dim, start, end, step, clamp)<br ALIGN="LEFT"/>normalize_start_end(x, dim, start, end)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.SliceViewInfo" [color="black", fontcolor="black", label=<{SliceViewInfo|dim : Union[int, torch.SymInt]<br ALIGN="LEFT"/>end : Union[int, torch.SymInt]<br ALIGN="LEFT"/>start : Union[int, torch.SymInt]<br ALIGN="LEFT"/>|regenerate_view(bases_list: List[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.SlowPickleClass" [color="black", fontcolor="black", label=<{SlowPickleClass|t<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.loss.SmoothL1Loss" [color="black", fontcolor="black", label=<{SmoothL1Loss|beta : float<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.quasirandom.SobolEngine" [color="black", fontcolor="black", label=<{SobolEngine|MAXBIT : int<br ALIGN="LEFT"/>MAXDIM : int<br ALIGN="LEFT"/>dimension<br ALIGN="LEFT"/>num_generated : int<br ALIGN="LEFT"/>quasi<br ALIGN="LEFT"/>scramble : bool<br ALIGN="LEFT"/>seed : NoneType<br ALIGN="LEFT"/>shift<br ALIGN="LEFT"/>sobolstate<br ALIGN="LEFT"/>|draw(n: int, out: Optional[torch.Tensor], dtype: Optional[torch.dtype]): torch.Tensor<br ALIGN="LEFT"/>draw_base2(m: int, out: Optional[torch.Tensor], dtype: Optional[torch.dtype]): torch.Tensor<br ALIGN="LEFT"/>fast_forward(n)<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.SoftMarginLoss" [color="black", fontcolor="black", label=<{SoftMarginLoss|<br ALIGN="LEFT"/>|forward(input: Tensor, target: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.activation.Softmax" [color="black", fontcolor="black", label=<{Softmax|dim : NoneType<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(mod, scale, zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softmax" [color="black", fontcolor="black", label=<{Softmax|dim : Optional[int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softmax2d" [color="black", fontcolor="black", label=<{Softmax2d|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.SoftmaxTransform" [color="black", fontcolor="black", label=<{SoftmaxTransform|codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softmin" [color="black", fontcolor="black", label=<{Softmin|dim : Optional[int]<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softplus" [color="black", fontcolor="black", label=<{Softplus|beta : float<br ALIGN="LEFT"/>threshold : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.SoftplusTransform" [color="black", fontcolor="black", label=<{SoftplusTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>sign : int<br ALIGN="LEFT"/>|log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softshrink" [color="black", fontcolor="black", label=<{Softshrink|lambd : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Softsign" [color="black", fontcolor="black", label=<{Softsign|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.Sort" [color="black", fontcolor="black", label=<{Sort|descending : bool<br ALIGN="LEFT"/>dtypes : Tuple[torch.dtype, ...]<br ALIGN="LEFT"/>inner_fns : Tuple[Callable[..., Any], ...]<br ALIGN="LEFT"/>output_index : int<br ALIGN="LEFT"/>reduction_hint<br ALIGN="LEFT"/>reindex : Callable[[Sequence[Expr], Sequence[Expr]], Sequence[Expr]]<br ALIGN="LEFT"/>size : List[Integer]<br ALIGN="LEFT"/>sort_ranges : List[Integer]<br ALIGN="LEFT"/>stable : bool<br ALIGN="LEFT"/>|create(device: torch.device, dtypes: Tuple[torch.dtype, ...], inner_fns: Tuple[Callable[[List[Expr]], Any], ...], size: List[Integer], axis: int, stable: bool, descending: bool, reduction_hint: ReductionHint): Sequence[Optional[TensorBox]]<br ALIGN="LEFT"/>get_pointwise_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_reduction_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>get_size(): Sequence[Expr]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[Symbol]<br ALIGN="LEFT"/>index_length(): int<br ALIGN="LEFT"/>inner_fn_args(): Sequence[Sequence[Expr]]<br ALIGN="LEFT"/>inner_fn_free_unbacked_symbols(): OrderedSet[Symbol]<br ALIGN="LEFT"/>store_reduction(output_name: Optional[str], indexer: Callable[[Sequence[Expr]], Expr], vars: Sequence[Expr], reduction_vars: Sequence[Expr]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.SortGenVmap" [color="black", fontcolor="black", label=<{SortGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, grad_output, _0, _1)<br ALIGN="LEFT"/>forward(x, dim)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.choices.Sortable" [color="black", fontcolor="black", label=<{Sortable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.Source" [color="black", fontcolor="black", label=<{Source|<br ALIGN="LEFT"/>|<I>guard_source</I>(): GuardSource<br ALIGN="LEFT"/>is_dict_key()<br ALIGN="LEFT"/>is_ephemeral()<br ALIGN="LEFT"/>is_specialized_nn_module(): bool<br ALIGN="LEFT"/>make_guard(fn): Guard<br ALIGN="LEFT"/><I>name</I>(): str<br ALIGN="LEFT"/><I>reconstruct</I>(codegen)<br ALIGN="LEFT"/>subguards_allowed()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization.SourceChangeWarning" [color="black", fontcolor="red", label=<{SourceChangeWarning|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._sources.SourceContext" [color="black", fontcolor="black", label=<{SourceContext|filename<br ALIGN="LEFT"/>funcname : NoneType<br ALIGN="LEFT"/>uses_true_division : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._recursive.SourceContext" [color="black", fontcolor="black", label=<{SourceContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._jit_internal.SourceLoader" [color="black", fontcolor="black", label=<{SourceLoader|content : dict<br ALIGN="LEFT"/>|cache(fn, source)<br ALIGN="LEFT"/>get_source(fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.utils.source_matcher_utils.SourcePartition" [color="black", fontcolor="black", label=<{SourcePartition|input_nodes : List[Node]<br ALIGN="LEFT"/>nodes : List[Node]<br ALIGN="LEFT"/>output_nodes : List[Node]<br ALIGN="LEFT"/>params : List[Node]<br ALIGN="LEFT"/>source : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.SourceType" [color="black", fontcolor="black", label=<{SourceType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.SourcelessBuilder" [color="black", fontcolor="black", label=<{SourcelessBuilder|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', value): VariableTracker<br ALIGN="LEFT"/>make_type_handlers()<br ALIGN="LEFT"/>wrap_constant_literal(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.SourcelessGraphModuleVariable" [color="black", fontcolor="black", label=<{SourcelessGraphModuleVariable|<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.SourcelessUserDefinedObjectBuilder" [color="black", fontcolor="black", label=<{SourcelessUserDefinedObjectBuilder|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', value): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.sparse_adam.SparseAdam" [color="black", fontcolor="black", label=<{SparseAdam|<br ALIGN="LEFT"/>|step(closure)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SparseNNModel" [color="black", fontcolor="black", label=<{SparseNNModel|dense_top<br ALIGN="LEFT"/>model_sparse<br ALIGN="LEFT"/>|forward(sparse_indices: torch.Tensor, sparse_offsets: torch.Tensor, dense: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.sparse.semi_structured.SparseSemiStructuredTensor" [color="black", fontcolor="black", label=<{SparseSemiStructuredTensor|BACKEND : str<br ALIGN="LEFT"/>SPARSE_DISPATCH : Dict[Callable, Callable]<br ALIGN="LEFT"/>alg_id_cusparselt : int<br ALIGN="LEFT"/>compressed_swizzled_bitmask : Optional[torch.Tensor]<br ALIGN="LEFT"/>fuse_transpose_cusparselt : bool<br ALIGN="LEFT"/>meta : Optional[torch.Tensor]<br ALIGN="LEFT"/>meta_t : Optional[torch.Tensor]<br ALIGN="LEFT"/>packed : Optional[torch.Tensor]<br ALIGN="LEFT"/>packed_t : Optional[torch.Tensor]<br ALIGN="LEFT"/>|<I>from_dense</I>(original_tensor: torch.Tensor): 'SparseSemiStructuredTensor'<br ALIGN="LEFT"/>to_dense()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.sparse.semi_structured.SparseSemiStructuredTensorCUSPARSELT" [color="black", fontcolor="black", label=<{SparseSemiStructuredTensorCUSPARSELT|BACKEND : str<br ALIGN="LEFT"/>|from_dense(original_tensor: torch.Tensor): 'SparseSemiStructuredTensorCUSPARSELT'<br ALIGN="LEFT"/>prune_dense_static_sort(original_tensor: torch.Tensor, algorithm): 'SparseSemiStructuredTensor'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.sparse.semi_structured.SparseSemiStructuredTensorCUTLASS" [color="black", fontcolor="black", label=<{SparseSemiStructuredTensorCUTLASS|BACKEND : str<br ALIGN="LEFT"/>|from_dense(original_tensor: torch.Tensor): 'SparseSemiStructuredTensorCUTLASS'<br ALIGN="LEFT"/>prune_dense_static_sort(original_tensor: torch.Tensor, algorithm): 'SparseSemiStructuredTensor'<br ALIGN="LEFT"/>to_dense()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.SparseTensor" [color="black", fontcolor="black", label=<{SparseTensor|indices<br ALIGN="LEFT"/>values<br ALIGN="LEFT"/>|from_dense(t)<br ALIGN="LEFT"/>get_wrapper_properties(size, values, indices, requires_grad)<br ALIGN="LEFT"/>sparse_to_dense()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.SpatialSplit" [color="black", fontcolor="black", label=<{SpatialSplit|left<br ALIGN="LEFT"/>right<br ALIGN="LEFT"/>|create(left, extra_space)<br ALIGN="LEFT"/>finalize(pool, offset)<br ALIGN="LEFT"/>get_live_ranges()<br ALIGN="LEFT"/>get_size_hint(): int<br ALIGN="LEFT"/>get_symbolic_size(): sympy.Expr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.multiprocessing.spawn.SpawnContext" [color="black", fontcolor="black", label=<{SpawnContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc_utils.SpawnHelper" [color="black", fontcolor="black", label=<{SpawnHelper|<br ALIGN="LEFT"/>|setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.verifier.SpecViolationError" [color="black", fontcolor="red", label=<{SpecViolationError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._special_locations.SpecialLocations" [color="black", fontcolor="black", label=<{SpecialLocations|display_base : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.specialized_attribute.SpecializedAttribute" [color="black", fontcolor="black", label=<{SpecializedAttribute|a : str<br ALIGN="LEFT"/>b : int<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.SpectralFuncInfo" [color="black", fontcolor="black", label=<{SpectralFuncInfo|ndimensional<br ALIGN="LEFT"/>ref : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.definitions.fft.SpectralFuncPythonRefInfo" [color="black", fontcolor="black", label=<{SpectralFuncPythonRefInfo|torch_opinfo<br ALIGN="LEFT"/>torch_opinfo_name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.spectral_norm.SpectralNorm" [color="black", fontcolor="black", label=<{SpectralNorm|dim : int<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>n_power_iterations : int<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|apply(module: Module, name: str, n_power_iterations: int, dim: int, eps: float): 'SpectralNorm'<br ALIGN="LEFT"/>compute_weight(module: Module, do_power_iteration: bool): torch.Tensor<br ALIGN="LEFT"/>remove(module: Module): None<br ALIGN="LEFT"/>reshape_weight_to_matrix(weight: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.spectral_norm.SpectralNormLoadStateDictPreHook" [color="black", fontcolor="black", label=<{SpectralNormLoadStateDictPreHook|fn<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.spectral_norm.SpectralNormStateDictHook" [color="black", fontcolor="black", label=<{SpectralNormStateDictHook|fn<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.op_fuzzers.spectral.SpectralOpFuzzer" [color="black", fontcolor="black", label=<{SpectralOpFuzzer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.SpeculationEntry" [color="black", fontcolor="black", label=<{SpeculationEntry|failed : bool<br ALIGN="LEFT"/>filename : str<br ALIGN="LEFT"/>inst<br ALIGN="LEFT"/>instruction_pointer : int<br ALIGN="LEFT"/>lineno : int<br ALIGN="LEFT"/>reason : Optional[GraphCompileReason]<br ALIGN="LEFT"/>|fail_and_restart_analysis()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.SpeculationLog" [color="black", fontcolor="black", label=<{SpeculationLog|entries : List[SpeculationEntry]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>next(filename: str, lineno: int, instruction_pointer, inst): SpeculationEntry<br ALIGN="LEFT"/>restart()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.SpeculationRestartAnalysis" [color="black", fontcolor="red", label=<{SpeculationRestartAnalysis|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._view_ops.Split" [color="black", fontcolor="black", label=<{Split|group_shape : Tuple<br ALIGN="LEFT"/>input_dim<br ALIGN="LEFT"/>split_id : int<br ALIGN="LEFT"/>|inputs(): Iterable[DimSpec]<br ALIGN="LEFT"/>new(dim: DimSpec, group_shape: Tuple[int, ...], idx: int): DimSpec<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.split_cat.SplitCatSimplifier" [color="black", fontcolor="black", label=<{SplitCatSimplifier|<br ALIGN="LEFT"/>|erase_old_nodes(graph: torch.fx.Graph, split_node: torch.fx.Node, next_users: List[torch.fx.Node])<br ALIGN="LEFT"/>fill_gaps(ranges: List[_Range], min_: int, max_: int): List[_Range]<br ALIGN="LEFT"/>get_merged_user_inputs(split_node: torch.fx.Node, cat_node: torch.fx.Node): List[Union[torch.fx.Node, _Range]]<br ALIGN="LEFT"/>get_non_cat_node_input(split_node: torch.fx.Node, node: torch.fx.Node): List[_Range]<br ALIGN="LEFT"/>get_simplified_split_ranges(split_sections, next_users, user_inputs_list: List[List[Union[torch.fx.Node, _Range]]]): Optional[List[_Range]]<br ALIGN="LEFT"/>get_transform_params(split_node: torch.fx.Node, next_users: List[torch.fx.Node], user_inputs_list: List[List[Union[torch.fx.Node, _Range]]]): Optional[List[List[_TransformParam]]]<br ALIGN="LEFT"/>get_user_input_list(split_node: torch.fx.Node, next_users: List[torch.fx.Node]): List[List[Union[torch.fx.Node, _Range]]]<br ALIGN="LEFT"/>has_non_overlapping_ranges(ranges: List[_Range]): bool<br ALIGN="LEFT"/>merge_consecutive_inputs(inputs: List[Union[torch.fx.Node, int]]): List[Union[torch.fx.Node, _Range]]<br ALIGN="LEFT"/>replace_cat(graph: torch.fx.Graph, split_node: torch.fx.Node, next_users: List[torch.fx.Node], user_inputs_list_new, transform_params_list: List[List[_TransformParam]])<br ALIGN="LEFT"/>replace_split(graph: torch.fx.Graph, split_node: torch.fx.Node, split_sections: List[int], user_inputs_list: List[List[Union[torch.fx.Node, _Range]]], split_ranges: List[_Range]): List[List[torch.fx.Node]]<br ALIGN="LEFT"/>simplify(graph: torch.fx.Graph, split_node: torch.fx.Node, split_sections: List[int])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.jit_metaprogramming_utils.SplitInputs" [color="black", fontcolor="black", label=<{SplitInputs|all_tensors : List[Any]<br ALIGN="LEFT"/>arg_types : List[str]<br ALIGN="LEFT"/>kwarg_order : List[str]<br ALIGN="LEFT"/>kwarg_types : Dict[str, Any]<br ALIGN="LEFT"/>nontensor_args : List[Any]<br ALIGN="LEFT"/>nontensor_kwargs : Dict[str, Any]<br ALIGN="LEFT"/>tensor_args : List[Any]<br ALIGN="LEFT"/>tensor_kwargs : Dict[str, Any]<br ALIGN="LEFT"/>|nontensors_match(other: 'SplitInputs')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.SplitPoint" [color="black", fontcolor="black", label=<{SplitPoint|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base.SplitResult" [color="black", fontcolor="black", label=<{SplitResult|non_acc_submodule_prefix : str<br ALIGN="LEFT"/>split_module<br ALIGN="LEFT"/>submodule_inputs : Dict[str, Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.SplitScan" [color="black", fontcolor="black", label=<{SplitScan|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.SqueezeView" [color="black", fontcolor="black", label=<{SqueezeView|<br ALIGN="LEFT"/>|create(x)<br ALIGN="LEFT"/>squeezer(size: Sequence[sympy.Expr])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Stack" [color="black", fontcolor="black", label=<{Stack|frames : list[StackFrame]<br ALIGN="LEFT"/>message : str \| None<br ALIGN="LEFT"/>|sarif(): sarif.Stack<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._stack.Stack" [color="black", fontcolor="black", label=<{Stack|frames : List[_stack_frame.StackFrame]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.dataset.StackDataset" [color="black", fontcolor="black", label=<{StackDataset|datasets : Union[tuple, dict]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.StackFrame" [color="black", fontcolor="black", label=<{StackFrame|location<br ALIGN="LEFT"/>|sarif(): sarif.StackFrame<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._stack_frame.StackFrame" [color="black", fontcolor="black", label=<{StackFrame|location : Optional[_location.Location]<br ALIGN="LEFT"/>module : Optional[str]<br ALIGN="LEFT"/>parameters : Optional[List[str]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>thread_id : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.bytecode_analysis.StackSize" [color="black", fontcolor="black", label=<{StackSize|fixed_point<br ALIGN="LEFT"/>high : Union[int, float]<br ALIGN="LEFT"/>low : Union[int, float]<br ALIGN="LEFT"/>|exn_tab_jump(depth)<br ALIGN="LEFT"/>offset_of(other, n)<br ALIGN="LEFT"/>zero()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.StackTransform" [color="black", fontcolor="black", label=<{StackTransform|bijective<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>transforms : List[Transform]<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry" [color="black", fontcolor="black", label=<{StandaloneModuleConfigEntry|backend_config : Optional[BackendConfig]<br ALIGN="LEFT"/>example_inputs : Tuple[Any, ...]<br ALIGN="LEFT"/>prepare_custom_config : Optional[PrepareCustomConfig]<br ALIGN="LEFT"/>qconfig_mapping : Optional[QConfigMapping]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx.quantize_handler.StandaloneModuleQuantizeHandler" [color="black", fontcolor="black", label=<{StandaloneModuleQuantizeHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.dependencies.StarDep" [color="black", fontcolor="black", label=<{StarDep|index<br ALIGN="LEFT"/>mode : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|get_numel(): sympy.Expr<br ALIGN="LEFT"/>has_unbacked_symbols()<br ALIGN="LEFT"/>is_contiguous(): bool<br ALIGN="LEFT"/>is_indirect(): bool<br ALIGN="LEFT"/>is_scalar(): bool<br ALIGN="LEFT"/>numbytes_hint()<br ALIGN="LEFT"/>rename(renames: Dict[str, str]): 'StarDep'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.StateDictConfig" [color="black", fontcolor="black", label=<{StateDictConfig|offload_to_cpu : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.state_dict.StateDictOptions" [color="black", fontcolor="black", label=<{StateDictOptions|broadcast_from_rank0 : bool<br ALIGN="LEFT"/>cpu_offload : bool<br ALIGN="LEFT"/>flatten_optimizer_state_dict : bool<br ALIGN="LEFT"/>full_state_dict : bool<br ALIGN="LEFT"/>ignore_frozen_params : bool<br ALIGN="LEFT"/>keep_submodule_prefixes : bool<br ALIGN="LEFT"/>strict : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.StateDictSettings" [color="black", fontcolor="black", label=<{StateDictSettings|optim_state_dict_config<br ALIGN="LEFT"/>state_dict_config<br ALIGN="LEFT"/>state_dict_type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.api.StateDictType" [color="black", fontcolor="black", label=<{StateDictType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._optim_utils.StateInfo" [color="black", fontcolor="black", label=<{StateInfo|non_tensors : Dict[str, Any]<br ALIGN="LEFT"/>scalar_tensors : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>tensors : Dict[str, _PosDimTensorInfo]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.stateful.Stateful" [color="black", fontcolor="black", label=<{Stateful|<br ALIGN="LEFT"/>|load_state_dict(state_dict: Dict[str, Any]): None<br ALIGN="LEFT"/>state_dict(): Dict[str, Any]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext" [color="black", fontcolor="black", label=<{StatefulSymbolicContext|shape_env_to_source_to_symbol_cache : Optional[Dict[int, Dict[str, sympy.Expr]]]<br ALIGN="LEFT"/>tensor_source : Optional[Source]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext" [color="black", fontcolor="black", label=<{StatelessSymbolicContext|constraint_sizes : Optional[DimList[DimConstraint]]<br ALIGN="LEFT"/>constraint_strides : Optional[DimList[DimConstraint]]<br ALIGN="LEFT"/>dynamic_sizes : DimList[DimDynamic]<br ALIGN="LEFT"/>dynamic_strides : Optional[DimList[DimDynamic]]<br ALIGN="LEFT"/>view_base_context : Optional[SymbolicContext]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.static_for_loop.StaticForLoop" [color="black", fontcolor="black", label=<{StaticForLoop|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.static_if.StaticIf" [color="black", fontcolor="black", label=<{StaticIf|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.static_module.StaticModule" [color="black", fontcolor="black", label=<{StaticModule|static_module<br ALIGN="LEFT"/>|benchmark(args, kwargs, warmup_runs, main_runs)<br ALIGN="LEFT"/>benchmark_individual_ops(args, kwargs, warmup_runs, main_runs)<br ALIGN="LEFT"/>runAsync(args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.static_tcp_rendezvous.StaticTCPRendezvous" [color="black", fontcolor="black", label=<{StaticTCPRendezvous|master_addr : str<br ALIGN="LEFT"/>master_port : int<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>run_id : str<br ALIGN="LEFT"/>timeout : timedelta<br ALIGN="LEFT"/>use_agent_store<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|get_backend(): str<br ALIGN="LEFT"/>get_run_id(): str<br ALIGN="LEFT"/>is_closed()<br ALIGN="LEFT"/>next_rendezvous(): RendezvousInfo<br ALIGN="LEFT"/>num_nodes_waiting()<br ALIGN="LEFT"/><I>set_closed</I>()<br ALIGN="LEFT"/>shutdown(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mock_cache.Stats" [color="black", fontcolor="black", label=<{Stats|num_get_hit : int<br ALIGN="LEFT"/>num_get_miss : int<br ALIGN="LEFT"/>num_put : int<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.Std" [color="black", fontcolor="black", label=<{Std|name<br ALIGN="LEFT"/>|from_str(vm: str): Union['Std', Dict[int, 'Std']]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler.StepLR" [color="black", fontcolor="black", label=<{StepLR|gamma : float<br ALIGN="LEFT"/>step_size : int<br ALIGN="LEFT"/>|get_lr()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.StickBreakingTransform" [color="black", fontcolor="black", label=<{StickBreakingTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>|forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.frontend.StmtBuilder" [color="black", fontcolor="black", label=<{StmtBuilder|augassign_map : dict<br ALIGN="LEFT"/>|build_AnnAssign(ctx, stmt)<br ALIGN="LEFT"/>build_Assert(ctx, stmt)<br ALIGN="LEFT"/>build_Assign(ctx, stmt)<br ALIGN="LEFT"/>build_AugAssign(ctx, stmt)<br ALIGN="LEFT"/>build_Break(ctx, stmt)<br ALIGN="LEFT"/>build_Continue(ctx, stmt)<br ALIGN="LEFT"/>build_Delete(ctx, stmt)<br ALIGN="LEFT"/>build_Expr(ctx, stmt)<br ALIGN="LEFT"/>build_For(ctx, stmt)<br ALIGN="LEFT"/>build_If(ctx, stmt)<br ALIGN="LEFT"/>build_Pass(ctx, stmt)<br ALIGN="LEFT"/>build_Print(ctx, stmt)<br ALIGN="LEFT"/>build_Raise(ctx, stmt)<br ALIGN="LEFT"/>build_Return(ctx, stmt)<br ALIGN="LEFT"/>build_While(ctx, stmt)<br ALIGN="LEFT"/>build_With(ctx, stmt)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.types.Storage" [color="black", fontcolor="black", label=<{Storage|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>|<I>cpu</I>(): 'Storage'<br ALIGN="LEFT"/><I>data_ptr</I>(): int<br ALIGN="LEFT"/><I>element_size</I>(): int<br ALIGN="LEFT"/><I>from_file</I>(filename: str, shared: bool, nbytes: int): 'Storage'<br ALIGN="LEFT"/><I>is_shared</I>(): bool<br ALIGN="LEFT"/><I>nbytes</I>(): int<br ALIGN="LEFT"/><I>share_memory_</I>(): 'Storage'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.StorageBox" [color="black", fontcolor="black", label=<{StorageBox|data<br ALIGN="LEFT"/>|has_exceeded_max_reads(): bool<br ALIGN="LEFT"/>is_input_buffer()<br ALIGN="LEFT"/>is_module_buffer()<br ALIGN="LEFT"/>mark_reuse(users: int): None<br ALIGN="LEFT"/>num_reads()<br ALIGN="LEFT"/>realize(): Optional[str]<br ALIGN="LEFT"/>realize_hint(): None<br ALIGN="LEFT"/>should_realize_on_reuse(users)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.StorageMeta" [color="black", fontcolor="black", label=<{StorageMeta|checkpoint_id : Optional[Union[str, os.PathLike, None]]<br ALIGN="LEFT"/>load_id : Optional[str]<br ALIGN="LEFT"/>save_id : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.StorageOverlap" [color="black", fontcolor="black", label=<{StorageOverlap|non_overlapping_sources : List[Source]<br ALIGN="LEFT"/>overlapping_sources : List[Source]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.storage.StorageReader" [color="black", fontcolor="black", label=<{StorageReader|<br ALIGN="LEFT"/>|<I>prepare_global_plan</I>(plans: List[LoadPlan]): List[LoadPlan]<br ALIGN="LEFT"/><I>prepare_local_plan</I>(plan: LoadPlan): LoadPlan<br ALIGN="LEFT"/><I>read_data</I>(plan: LoadPlan, planner: LoadPlanner): Future[None]<br ALIGN="LEFT"/><I>read_metadata</I>(): Metadata<br ALIGN="LEFT"/><I>reset</I>(checkpoint_id: Union[str, os.PathLike, None]): None<br ALIGN="LEFT"/><I>set_up_storage_reader</I>(metadata: Metadata, is_coordinator: bool): None<br ALIGN="LEFT"/><I>validate_checkpoint_id</I>(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization.StorageType" [color="black", fontcolor="black", label=<{StorageType|dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.multiprocessing.reductions.StorageWeakRef" [color="black", fontcolor="black", label=<{StorageWeakRef|cdata : Any<br ALIGN="LEFT"/>|expired()<br ALIGN="LEFT"/>from_weakref(cdata)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.StorageWeakRefWrapper" [color="black", fontcolor="black", label=<{StorageWeakRefWrapper|extra_ref_check : NoneType, Optional[Callable[[], bool]]<br ALIGN="LEFT"/>ref<br ALIGN="LEFT"/>storage_ref : Optional[StorageWeakRef]<br ALIGN="LEFT"/>|data_ptr(): int<br ALIGN="LEFT"/>expired(): bool<br ALIGN="LEFT"/>from_weakref_and_data_ptr(cdata: Any, data_ptr: int, extra_ref_check: Optional[Callable[[], bool]]): StorageWeakRefWrapper<br ALIGN="LEFT"/>remove_extra_reference(): None<br ALIGN="LEFT"/>swap_weakref(cdata: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.storage.StorageWriter" [color="black", fontcolor="black", label=<{StorageWriter|<br ALIGN="LEFT"/>|<I>finish</I>(metadata: Metadata, results: List[List[WriteResult]]): None<br ALIGN="LEFT"/><I>prepare_global_plan</I>(plans: List[SavePlan]): List[SavePlan]<br ALIGN="LEFT"/><I>prepare_local_plan</I>(plan: SavePlan): SavePlan<br ALIGN="LEFT"/><I>reset</I>(checkpoint_id: Union[str, os.PathLike, None]): None<br ALIGN="LEFT"/><I>set_up_storage_writer</I>(is_coordinator: bool): None<br ALIGN="LEFT"/>storage_meta(): Optional[StorageMeta]<br ALIGN="LEFT"/><I>validate_checkpoint_id</I>(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/><I>write_data</I>(plan: SavePlan, planner: SavePlanner): Future[List[WriteResult]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.TritonTemplateKernel.load_input.StoreOutputSubstitution" [color="black", fontcolor="black", label=<{StoreOutputSubstitution|<br ALIGN="LEFT"/>|store(name: str, index: sympy.Expr, value: 'CSEVariable', mode: 'StoreMode')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.StrategyType" [color="black", fontcolor="black", label=<{StrategyType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.xpu.streams.Stream" [color="black", fontcolor="black", label=<{Stream|<br ALIGN="LEFT"/>|query(): bool<br ALIGN="LEFT"/>record_event(event)<br ALIGN="LEFT"/>synchronize(): None<br ALIGN="LEFT"/>wait_event(event): None<br ALIGN="LEFT"/>wait_stream(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceInterface.Stream" [color="black", fontcolor="black", label=<{Stream|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cpu.Stream" [color="black", fontcolor="black", label=<{Stream|<br ALIGN="LEFT"/>|<I>wait_stream</I>(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.streams.Stream" [color="black", fontcolor="black", label=<{Stream|<br ALIGN="LEFT"/>|query(): bool<br ALIGN="LEFT"/>record_event(event)<br ALIGN="LEFT"/>synchronize(): None<br ALIGN="LEFT"/>wait_event(event): None<br ALIGN="LEFT"/>wait_stream(stream): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.xpu.StreamContext" [color="black", fontcolor="black", label=<{StreamContext|cur_stream : Optional['torch.xpu.Stream']<br ALIGN="LEFT"/>dst_prev_stream<br ALIGN="LEFT"/>idx : NoneType, int<br ALIGN="LEFT"/>src_prev_stream<br ALIGN="LEFT"/>stream : Optional['torch.xpu.Stream']<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cpu.StreamContext" [color="black", fontcolor="black", label=<{StreamContext|cur_stream : Optional[Stream]<br ALIGN="LEFT"/>prev_stream<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.StreamContext" [color="black", fontcolor="black", label=<{StreamContext|cur_stream : Optional['torch.cuda.Stream']<br ALIGN="LEFT"/>dst_prev_stream : NoneType<br ALIGN="LEFT"/>idx : int<br ALIGN="LEFT"/>src_prev_stream : NoneType<br ALIGN="LEFT"/>stream : Optional['torch.cuda.Stream']<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.mtia.StreamContext" [color="black", fontcolor="black", label=<{StreamContext|cur_stream : Optional['torch.mtia.Stream']<br ALIGN="LEFT"/>dst_prev_stream : NoneType<br ALIGN="LEFT"/>idx : NoneType, int<br ALIGN="LEFT"/>src_prev_stream : NoneType<br ALIGN="LEFT"/>stream : Optional['torch.mtia.Stream']<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.StreamContextVariable" [color="black", fontcolor="black", label=<{StreamContextVariable|device<br ALIGN="LEFT"/>set_stream<br ALIGN="LEFT"/>set_stream_id<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_value)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.streamreader.StreamReaderIterDataPipe" [color="black", fontcolor="black", label=<{StreamReaderIterDataPipe|chunk : NoneType<br ALIGN="LEFT"/>datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.StreamSynchronizations" [color="black", fontcolor="black", label=<{StreamSynchronizations|current_sync_states : Dict[StreamId, Dict[StreamId, SeqNum]]<br ALIGN="LEFT"/>host_sync_state : Dict[StreamId, SeqNum]<br ALIGN="LEFT"/>recorded_sync_states : Dict[EventId, Dict[StreamId, SeqNum]]<br ALIGN="LEFT"/>|all_streams_wait_for_event(event: EventId): None<br ALIGN="LEFT"/>all_streams_wait_for_stream(stream: StreamId): None<br ALIGN="LEFT"/>create_event(event: EventId): None<br ALIGN="LEFT"/>create_stream(stream: StreamId): None<br ALIGN="LEFT"/>delete_event(event: EventId): None<br ALIGN="LEFT"/>is_ordered_after(current_stream: StreamId, seq_num: SeqNum, other_stream: StreamId): bool<br ALIGN="LEFT"/>record_state(event: EventId, stream: StreamId): None<br ALIGN="LEFT"/>stream_wait_for_event(stream: StreamId, event: EventId): None<br ALIGN="LEFT"/>sync_all_streams(): None<br ALIGN="LEFT"/>update_seq_num(stream: StreamId, seq_num: SeqNum): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.StreamVariable" [color="black", fontcolor="black", label=<{StreamVariable|device<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.utils.common.StreamWrapper" [color="black", fontcolor="black", label=<{StreamWrapper|child_counter : int<br ALIGN="LEFT"/>close_on_last_child : bool<br ALIGN="LEFT"/>closed : bool<br ALIGN="LEFT"/>debug_unclosed_streams : bool<br ALIGN="LEFT"/>file_obj<br ALIGN="LEFT"/>name : NoneType<br ALIGN="LEFT"/>parent_stream : NoneType<br ALIGN="LEFT"/>session_streams : Dict[Any, int]<br ALIGN="LEFT"/>|autoclose()<br ALIGN="LEFT"/>close()<br ALIGN="LEFT"/>close_streams(v, depth)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint" [color="black", fontcolor="black", label=<{StrictMinMaxConstraint|vr<br ALIGN="LEFT"/>|render(source: Source): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.strict_mode.StrictMode" [color="black", fontcolor="black", label=<{StrictMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.StrictModeHigherOrderVariable" [color="black", fontcolor="black", label=<{StrictModeHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.StringFormatVariable" [color="black", fontcolor="black", label=<{StringFormatVariable|format_string<br ALIGN="LEFT"/>sym_args<br ALIGN="LEFT"/>sym_kwargs<br ALIGN="LEFT"/>|create(format_string, sym_args, sym_kwargs)<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.StringPair" [color="black", fontcolor="black", label=<{StringPair|CLS : tuple<br ALIGN="LEFT"/>TYPE_NAME : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler_util.StringTable" [color="black", fontcolor="black", label=<{StringTable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._strobelight.cli_function_profiler.StrobelightCLIFunctionProfiler" [color="black", fontcolor="black", label=<{StrobelightCLIFunctionProfiler|current_run_id : NoneType, Optional[int]<br ALIGN="LEFT"/>max_profile_duration_sec : int<br ALIGN="LEFT"/>run_user_name : str<br ALIGN="LEFT"/>sample_each : float<br ALIGN="LEFT"/>sample_tags : NoneType<br ALIGN="LEFT"/>stop_at_error : bool<br ALIGN="LEFT"/>timeout_wait_for_finished_sec : int<br ALIGN="LEFT"/>timeout_wait_for_running_sec : int<br ALIGN="LEFT"/>|profile(work_function: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._strobelight.cli_function_profiler.StrobelightCLIFunctionProfiler" [color="black", fontcolor="black", label=<{StrobelightCLIFunctionProfiler|current_run_id : NoneType, Optional[int]<br ALIGN="LEFT"/>max_profile_duration_sec : int<br ALIGN="LEFT"/>profile_result : NoneType, Optional[List[str]], list<br ALIGN="LEFT"/>run_user_name : str<br ALIGN="LEFT"/>sample_each : float<br ALIGN="LEFT"/>sample_tags : NoneType<br ALIGN="LEFT"/>stop_at_error : bool<br ALIGN="LEFT"/>timeout_wait_for_finished_sec : int<br ALIGN="LEFT"/>timeout_wait_for_running_sec : int<br ALIGN="LEFT"/>|profile(work_function: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._strobelight.cli_function_profiler.StrobelightCLIProfilerError" [color="black", fontcolor="red", label=<{StrobelightCLIProfilerError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._strobelight.cli_function_profiler.StrobelightCLIProfilerError" [color="black", fontcolor="red", label=<{StrobelightCLIProfilerError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._strobelight.compile_time_profiler.StrobelightCompileTimeProfiler" [color="black", fontcolor="black", label=<{StrobelightCompileTimeProfiler|current_phase : Optional[str]<br ALIGN="LEFT"/>enabled : bool<br ALIGN="LEFT"/>failed_profile_count : int<br ALIGN="LEFT"/>identifier : Optional[str]<br ALIGN="LEFT"/>ignored_profile_runs : int<br ALIGN="LEFT"/>inside_profile_compile_time : bool<br ALIGN="LEFT"/>max_profile_time : int<br ALIGN="LEFT"/>max_stack_length : int<br ALIGN="LEFT"/>profiler : Optional[Any]<br ALIGN="LEFT"/>sample_each : int<br ALIGN="LEFT"/>success_profile_count : int<br ALIGN="LEFT"/>|enable(profiler_class: Any): None<br ALIGN="LEFT"/>profile_compile_time(func: Any, phase_name: str): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.StubRpcAgent" [color="black", fontcolor="black", label=<{StubRpcAgent|world_size<br ALIGN="LEFT"/>|get_worker_infos()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.studentT.StudentT" [color="black", fontcolor="black", label=<{StudentT|arg_constraints : dict<br ALIGN="LEFT"/>df<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._config_module.SubConfigProxy" [color="black", fontcolor="black", label=<{SubConfigProxy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SubModelForFusion" [color="black", fontcolor="black", label=<{SubModelForFusion|bn<br ALIGN="LEFT"/>conv<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.SubModelWithoutFusion" [color="black", fontcolor="black", label=<{SubModelWithoutFusion|conv<br ALIGN="LEFT"/>qconfig : NoneType<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" [color="black", fontcolor="black", label=<{SubModule|bn<br ALIGN="LEFT"/>embedding_net<br ALIGN="LEFT"/>lin<br ALIGN="LEFT"/>lin_layer<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.SubclassAttrListSource" [color="black", fontcolor="black", label=<{SubclassAttrListSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.SubclassCreationMeta" [color="black", fontcolor="black", label=<{SubclassCreationMeta|arg_count : int<br ALIGN="LEFT"/>attrs : Dict[str, Union['SubclassCreationMeta', PlainTensorMeta]]<br ALIGN="LEFT"/>flat_tensor_start_idx : int<br ALIGN="LEFT"/>included_subclass_symints : bool<br ALIGN="LEFT"/>memory_format : Optional[torch.memory_format]<br ALIGN="LEFT"/>meta : Any<br ALIGN="LEFT"/>original_subclass : Optional[torch.Tensor]<br ALIGN="LEFT"/>original_subclass_type : Optional[type]<br ALIGN="LEFT"/>outer_size : Iterable[Union[None, int, torch.SymInt]]<br ALIGN="LEFT"/>outer_stride : Iterable[Union[None, int, torch.SymInt]]<br ALIGN="LEFT"/>subclass_type : list<br ALIGN="LEFT"/>|compute_outer_size_and_stride(all_args)<br ALIGN="LEFT"/>creation_fn(all_args)<br ALIGN="LEFT"/>make_runtime_safe()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.SubclassInfo" [color="black", fontcolor="black", label=<{SubclassInfo|closed_under_ops : bool<br ALIGN="LEFT"/>create_fn<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.SubclassMeta" [color="black", fontcolor="black", label=<{SubclassMeta|fw_metadata<br ALIGN="LEFT"/>grad_input_metas : Optional[List[Union[PlainTensorMeta, SubclassCreationMeta]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext" [color="black", fontcolor="black", label=<{SubclassSymbolicContext|inner_contexts : Optional[Dict[str, SymbolicContext]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.SubclassWithTensorFactory" [color="black", fontcolor="black", label=<{SubclassWithTensorFactory|src<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base.Subgraph" [color="black", fontcolor="black", label=<{Subgraph|device_ordinal : Optional[int]<br ALIGN="LEFT"/>is_acc : bool<br ALIGN="LEFT"/>nodes : List<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.Subgraph" [color="black", fontcolor="black", label=<{Subgraph|graph : Optional[GraphLowering]<br ALIGN="LEFT"/>graph_module<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.SubgraphInfo" [color="black", fontcolor="black", label=<{SubgraphInfo|body<br ALIGN="LEFT"/>compute<br ALIGN="LEFT"/>indexing_code<br ALIGN="LEFT"/>loads<br ALIGN="LEFT"/>numels : NoneType<br ALIGN="LEFT"/>only_copy_if_non_none_fields : tuple<br ALIGN="LEFT"/>ops_handler : Optional[V.WrapperHandler]<br ALIGN="LEFT"/>range_trees : Optional[List['IterationRangesRoot']]<br ALIGN="LEFT"/>stores<br ALIGN="LEFT"/>template_mask : Optional[str]<br ALIGN="LEFT"/>template_out : Optional[str]<br ALIGN="LEFT"/>|to_dict()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.graph.SubgraphLowering" [color="black", fontcolor="black", label=<{SubgraphLowering|parent<br ALIGN="LEFT"/>|init_wrapper_code(is_subgraph: bool, subgraph_name: Optional[str], parent_wrapper_code: Optional[PythonWrapperCodegen]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.exc.SubgraphLoweringException" [color="black", fontcolor="red", label=<{SubgraphLoweringException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.utils.matcher_utils.SubgraphMatcher" [color="black", fontcolor="black", label=<{SubgraphMatcher|ignore_literals : bool<br ALIGN="LEFT"/>match_output : bool<br ALIGN="LEFT"/>match_placeholder : bool<br ALIGN="LEFT"/>pattern<br ALIGN="LEFT"/>pattern_anchors : List[Node], list<br ALIGN="LEFT"/>pattern_placeholder_nodes<br ALIGN="LEFT"/>pattern_returning_nodes : List[Node]<br ALIGN="LEFT"/>remove_overlapping_matches : bool<br ALIGN="LEFT"/>|match(graph: Graph): List[InternalMatch]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.utils.matcher_with_name_node_map_utils.SubgraphMatcherWithNameNodeMap" [color="black", fontcolor="black", label=<{SubgraphMatcherWithNameNodeMap|name_node_map : dict<br ALIGN="LEFT"/>|match(graph: Graph): List[InternalMatch]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.SubgraphPythonWrapperCodegen" [color="black", fontcolor="black", label=<{SubgraphPythonWrapperCodegen|launcher_fn_name<br ALIGN="LEFT"/>parent_wrapper<br ALIGN="LEFT"/>subgraph_name<br ALIGN="LEFT"/>|<I>add_benchmark_harness</I>(output)<br ALIGN="LEFT"/><I>benchmark_compiled_module</I>(output)<br ALIGN="LEFT"/>next_kernel_suffix(): str<br ALIGN="LEFT"/>set_launcher_fn_name(): None<br ALIGN="LEFT"/><I>write_async_compile_wait</I>()<br ALIGN="LEFT"/>write_get_raw_stream_header_once(): None<br ALIGN="LEFT"/><I>write_header</I>(): None<br ALIGN="LEFT"/>write_triton_header_once(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.SubgraphTracer" [color="black", fontcolor="black", label=<{SubgraphTracer|allow_side_effects_under_checkpoint : bool<br ALIGN="LEFT"/>bound_symbols : Dict[sympy.Symbol, Union[torch.fx.Proxy, LazyProxy]]<br ALIGN="LEFT"/>debug_level : int<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>input_name_to_proxy : Dict[str, fx.Proxy]<br ALIGN="LEFT"/>is_export : bool<br ALIGN="LEFT"/>lifted_freevars : dict<br ALIGN="LEFT"/>output_graph<br ALIGN="LEFT"/>parent : NoneType<br ALIGN="LEFT"/>prev_inst : NoneType<br ALIGN="LEFT"/>real_value_cache : Dict[fx.Node, torch.Tensor]<br ALIGN="LEFT"/>source_fn_stack : list<br ALIGN="LEFT"/>under_activation_checkpoint : bool<br ALIGN="LEFT"/>|create_graph_input(name, type_expr, example_value, before, source)<br ALIGN="LEFT"/>create_node(op, target, args, kwargs, name, type_expr)<br ALIGN="LEFT"/>create_proxy(kind, target, args, kwargs, name, type_expr, proxy_factory_fn)<br ALIGN="LEFT"/>lift_tracked_freevar_to_input(proxy)<br ALIGN="LEFT"/>lookup_unbound_symbols(s: torch.SymInt): List[sympy.Symbol]<br ALIGN="LEFT"/>maybe_lift_tracked_freevar_to_input(arg)<br ALIGN="LEFT"/>remove_node(node)<br ALIGN="LEFT"/>track_unbacked_symbols(example_value, e_proxy: Union[LazyProxy, torch.fx.Proxy])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.graph_matcher.SubgraphTypeRelationship" [color="black", fontcolor="black", label=<{SubgraphTypeRelationship|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.backends.distributed.SubmodCompiler" [color="black", fontcolor="black", label=<{SubmodCompiler|compiler<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>|compile_submod(input_mod, args, kwargs)<br ALIGN="LEFT"/>run_node(n: Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compile_worker.subproc_pool.SubprocException" [color="black", fontcolor="red", label=<{SubprocException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compile_worker.subproc_pool.SubprocMain" [color="black", fontcolor="black", label=<{SubprocMain|nprocs : int<br ALIGN="LEFT"/>pool : ProcessPoolExecutor<br ALIGN="LEFT"/>read_pipe : BinaryIO<br ALIGN="LEFT"/>running : bool<br ALIGN="LEFT"/>write_lock : lock<br ALIGN="LEFT"/>write_pipe : BinaryIO<br ALIGN="LEFT"/>|do_job(data: bytes): bytes<br ALIGN="LEFT"/>main(): None<br ALIGN="LEFT"/>submit(job_id: int, data: bytes): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compile_worker.subproc_pool.SubprocPool" [color="black", fontcolor="black", label=<{SubprocPool|futures_lock : lock<br ALIGN="LEFT"/>job_id_count : count<br ALIGN="LEFT"/>pending_futures : Dict[int, Future[Any]]<br ALIGN="LEFT"/>process : Popen<br ALIGN="LEFT"/>read_pipe<br ALIGN="LEFT"/>read_thread : Thread<br ALIGN="LEFT"/>ready_future : Future<br ALIGN="LEFT"/>running : bool<br ALIGN="LEFT"/>write_lock : lock<br ALIGN="LEFT"/>write_pipe<br ALIGN="LEFT"/>|shutdown(): None<br ALIGN="LEFT"/>submit(job_fn: Callable[_P, _T]): Future[_T]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.api.SubprocessContext" [color="black", fontcolor="black", label=<{SubprocessContext|subprocess_handlers : Dict[int, SubprocessHandler]<br ALIGN="LEFT"/>|pids(): Dict[int, int]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.subprocess_handler.subprocess_handler.SubprocessHandler" [color="black", fontcolor="black", label=<{SubprocessHandler|local_rank_id : int<br ALIGN="LEFT"/>proc : Popen<br ALIGN="LEFT"/>|close(death_sig: Optional[signal.Signals]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataset.Subset" [color="black", fontcolor="black", label=<{Subset|dataset : Dataset[_T_co]<br ALIGN="LEFT"/>indices : Sequence[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.sampler.SubsetRandomSampler" [color="black", fontcolor="black", label=<{SubsetRandomSampler|generator : NoneType<br ALIGN="LEFT"/>indices : Sequence[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compiler_bisector.Subsystem" [color="black", fontcolor="black", label=<{Subsystem|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.SumLikeReductionTypePromotionRule" [color="black", fontcolor="black", label=<{SumLikeReductionTypePromotionRule|<br ALIGN="LEFT"/>|preview_type_promotion(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.tensorboard.writer.SummaryWriter" [color="black", fontcolor="black", label=<{SummaryWriter|all_writers : NoneType, dict<br ALIGN="LEFT"/>default_bins : list<br ALIGN="LEFT"/>file_writer : NoneType<br ALIGN="LEFT"/>filename_suffix : str<br ALIGN="LEFT"/>flush_secs : int<br ALIGN="LEFT"/>log_dir : NoneType<br ALIGN="LEFT"/>max_queue : int<br ALIGN="LEFT"/>purge_step : NoneType<br ALIGN="LEFT"/>|add_audio(tag, snd_tensor, global_step, sample_rate, walltime)<br ALIGN="LEFT"/>add_custom_scalars(layout)<br ALIGN="LEFT"/>add_custom_scalars_marginchart(tags, category, title)<br ALIGN="LEFT"/>add_custom_scalars_multilinechart(tags, category, title)<br ALIGN="LEFT"/>add_embedding(mat, metadata, label_img, global_step, tag, metadata_header)<br ALIGN="LEFT"/>add_figure(tag: str, figure: Union['Figure', List['Figure']], global_step: Optional[int], close: bool, walltime: Optional[float]): None<br ALIGN="LEFT"/>add_graph(model, input_to_model, verbose, use_strict_trace)<br ALIGN="LEFT"/>add_histogram(tag, values, global_step, bins, walltime, max_bins)<br ALIGN="LEFT"/>add_histogram_raw(tag, min, max, num, sum, sum_squares, bucket_limits, bucket_counts, global_step, walltime)<br ALIGN="LEFT"/>add_hparams(hparam_dict, metric_dict, hparam_domain_discrete, run_name, global_step)<br ALIGN="LEFT"/>add_image(tag, img_tensor, global_step, walltime, dataformats)<br ALIGN="LEFT"/>add_image_with_boxes(tag, img_tensor, box_tensor, global_step, walltime, rescale, dataformats, labels)<br ALIGN="LEFT"/>add_images(tag, img_tensor, global_step, walltime, dataformats)<br ALIGN="LEFT"/>add_mesh(tag, vertices, colors, faces, config_dict, global_step, walltime)<br ALIGN="LEFT"/>add_onnx_graph(prototxt)<br ALIGN="LEFT"/>add_pr_curve(tag, labels, predictions, global_step, num_thresholds, weights, walltime)<br ALIGN="LEFT"/>add_pr_curve_raw(tag, true_positive_counts, false_positive_counts, true_negative_counts, false_negative_counts, precision, recall, global_step, num_thresholds, weights, walltime)<br ALIGN="LEFT"/>add_scalar(tag, scalar_value, global_step, walltime, new_style, double_precision)<br ALIGN="LEFT"/>add_scalars(main_tag, tag_scalar_dict, global_step, walltime)<br ALIGN="LEFT"/>add_tensor(tag, tensor, global_step, walltime)<br ALIGN="LEFT"/>add_text(tag, text_string, global_step, walltime)<br ALIGN="LEFT"/>add_video(tag, vid_tensor, global_step, fps, walltime)<br ALIGN="LEFT"/>close()<br ALIGN="LEFT"/>flush()<br ALIGN="LEFT"/>get_logdir()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.SuperVariable" [color="black", fontcolor="black", label=<{SuperVariable|objvar : NoneType<br ALIGN="LEFT"/>typevar<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.case.SupportLevel" [color="black", fontcolor="black", label=<{SupportLevel|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._suppression.Suppression" [color="black", fontcolor="black", label=<{Suppression|guid : Optional[str]<br ALIGN="LEFT"/>justification : Optional[str]<br ALIGN="LEFT"/>kind : Literal['inSource', 'external']<br ALIGN="LEFT"/>location : Optional[_location.Location]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>state : Optional[Literal['accepted', 'underReview', 'rejected']]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.SwapTensorsGuard" [color="black", fontcolor="black", label=<{SwapTensorsGuard|swap_tensors_restore : bool<br ALIGN="LEFT"/>use_swap_tensors<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.SymBool" [color="black", fontcolor="black", label=<{SymBool|node<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymBool" [color="black", fontcolor="black", label=<{SymBool|as_bool : Annotated[bool, 20]<br ALIGN="LEFT"/>as_expr : Annotated[SymExpr, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymBoolArgument" [color="black", fontcolor="black", label=<{SymBoolArgument|as_bool : Annotated[bool, 20]<br ALIGN="LEFT"/>as_name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.SymBoolArgument" [color="black", fontcolor="black", label=<{SymBoolArgument|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymExpr" [color="black", fontcolor="black", label=<{SymExpr|expr_str : Annotated[str, 10]<br ALIGN="LEFT"/>hint : Optional[Annotated[Optional[SymExprHint], 20]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymExprHint" [color="black", fontcolor="black", label=<{SymExprHint|as_bool : Annotated[bool, 20]<br ALIGN="LEFT"/>as_float : Annotated[float, 30]<br ALIGN="LEFT"/>as_int : Annotated[int, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.SymExprPrinter" [color="black", fontcolor="black", label=<{SymExprPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.SymFloat" [color="black", fontcolor="black", label=<{SymFloat|node<br ALIGN="LEFT"/>|as_integer_ratio(): _Tuple[builtins.int, builtins.int]<br ALIGN="LEFT"/>conjugate(): 'SymFloat'<br ALIGN="LEFT"/>hex(): str<br ALIGN="LEFT"/>is_integer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.SymFloat" [color="black", fontcolor="black", label=<{SymFloat|as_expr : Annotated[SymExpr, 10]<br ALIGN="LEFT"/>as_float : Annotated[float, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymFloatArgument" [color="black", fontcolor="black", label=<{SymFloatArgument|as_float : Annotated[float, 20]<br ALIGN="LEFT"/>as_name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.SymFloatArgument" [color="black", fontcolor="black", label=<{SymFloatArgument|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.SymInt" [color="black", fontcolor="black", label=<{SymInt|node<br ALIGN="LEFT"/>|as_integer_ratio(): _Tuple['SymInt', builtins.int]<br ALIGN="LEFT"/>bit_length(): builtins.int<br ALIGN="LEFT"/>conjugate(): 'SymInt'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.SymInt" [color="black", fontcolor="black", label=<{SymInt|as_expr : Annotated[SymExpr, 10]<br ALIGN="LEFT"/>as_int : Annotated[int, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.SymIntArgument" [color="black", fontcolor="black", label=<{SymIntArgument|as_int : Annotated[int, 20]<br ALIGN="LEFT"/>as_name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.SymIntArgument" [color="black", fontcolor="black", label=<{SymIntArgument|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.SymIntEqByExpr" [color="black", fontcolor="black", label=<{SymIntEqByExpr|val : Union[torch.SymInt, int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.sym_node.SymNode" [color="black", fontcolor="black", label=<{SymNode|constant : Optional[Union[int, float, bool]]<br ALIGN="LEFT"/>expr<br ALIGN="LEFT"/>fx_node<br ALIGN="LEFT"/>hint<br ALIGN="LEFT"/>pytype<br ALIGN="LEFT"/>shape_env<br ALIGN="LEFT"/>|abs(): SymNode<br ALIGN="LEFT"/>add(other): SymNode<br ALIGN="LEFT"/>and_(other): SymNode<br ALIGN="LEFT"/>bitwise_and(other)<br ALIGN="LEFT"/>bitwise_or(other)<br ALIGN="LEFT"/>bool_()<br ALIGN="LEFT"/>ceil(): SymNode<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>eq(other): SymNode<br ALIGN="LEFT"/>expect_size(file, line)<br ALIGN="LEFT"/>expect_true(file, line)<br ALIGN="LEFT"/>float_pow(other): SymNode<br ALIGN="LEFT"/>float_truediv(other): SymNode<br ALIGN="LEFT"/>floor(): SymNode<br ALIGN="LEFT"/>floordiv(other): SymNode<br ALIGN="LEFT"/>ge(other): SymNode<br ALIGN="LEFT"/>gt(other): SymNode<br ALIGN="LEFT"/>guard_bool(file, line)<br ALIGN="LEFT"/>guard_float(file, line)<br ALIGN="LEFT"/>guard_int(file, line)<br ALIGN="LEFT"/>guard_size_oblivious(file, line)<br ALIGN="LEFT"/>has_hint()<br ALIGN="LEFT"/>int_()<br ALIGN="LEFT"/>int_floordiv(other): SymNode<br ALIGN="LEFT"/>int_truediv(other): SymNode<br ALIGN="LEFT"/>is_bool()<br ALIGN="LEFT"/>is_channels_last_contiguous_2d(sizes, strides): SymNode<br ALIGN="LEFT"/>is_channels_last_contiguous_3d(sizes, strides): SymNode<br ALIGN="LEFT"/>is_channels_last_strides_2d(sizes, strides): SymNode<br ALIGN="LEFT"/>is_channels_last_strides_3d(sizes, strides): SymNode<br ALIGN="LEFT"/>is_constant()<br ALIGN="LEFT"/>is_contiguous(sizes, strides): SymNode<br ALIGN="LEFT"/>is_float()<br ALIGN="LEFT"/>is_int()<br ALIGN="LEFT"/>is_integer(): SymNode<br ALIGN="LEFT"/>is_nested_int()<br ALIGN="LEFT"/>is_non_overlapping_and_dense(sizes, strides)<br ALIGN="LEFT"/>is_non_overlapping_and_dense_indicator(sizes, strides): SymNode<br ALIGN="LEFT"/>is_symbolic()<br ALIGN="LEFT"/>le(other): SymNode<br ALIGN="LEFT"/>lshift(other): SymNode<br ALIGN="LEFT"/>lt(other): SymNode<br ALIGN="LEFT"/>maybe_as_bool()<br ALIGN="LEFT"/>maybe_as_float()<br ALIGN="LEFT"/>maybe_as_int()<br ALIGN="LEFT"/>mod(other): SymNode<br ALIGN="LEFT"/>mul(other): SymNode<br ALIGN="LEFT"/>ne(other): SymNode<br ALIGN="LEFT"/>neg(): SymNode<br ALIGN="LEFT"/>nested_int()<br ALIGN="LEFT"/>or_(other): SymNode<br ALIGN="LEFT"/>pos(): SymNode<br ALIGN="LEFT"/>pow(other)<br ALIGN="LEFT"/>pow_by_natural(other): SymNode<br ALIGN="LEFT"/>require_hint(fallback)<br ALIGN="LEFT"/>round(ndigits): SymNode<br ALIGN="LEFT"/>rshift(other): SymNode<br ALIGN="LEFT"/>str()<br ALIGN="LEFT"/>sub(other): SymNode<br ALIGN="LEFT"/>sym_and(other)<br ALIGN="LEFT"/>sym_float(): SymNode<br ALIGN="LEFT"/>sym_int(): SymNode<br ALIGN="LEFT"/>sym_ite(then_val, else_val): SymNode<br ALIGN="LEFT"/>sym_max(other): SymNode<br ALIGN="LEFT"/>sym_min(other): SymNode<br ALIGN="LEFT"/>sym_not(): SymNode<br ALIGN="LEFT"/>sym_or(other)<br ALIGN="LEFT"/>sym_sum(args): SymNode<br ALIGN="LEFT"/>truediv(other)<br ALIGN="LEFT"/>trunc(): SymNode<br ALIGN="LEFT"/>with_shape_env(shape_env: ShapeEnv): SymNode<br ALIGN="LEFT"/>wrap_bool(num)<br ALIGN="LEFT"/>wrap_float(num)<br ALIGN="LEFT"/>wrap_int(num)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.SymNodeVariable" [color="black", fontcolor="black", label=<{SymNodeVariable|proxy<br ALIGN="LEFT"/>sym_num<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_tensor(tx, dtype)<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create(tx, proxy, sym_num)<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>evaluate_expr(output_graph)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.SymNumberMemoDescriptor" [color="black", fontcolor="black", label=<{SymNumberMemoDescriptor|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.index_propagation.SymPyOps" [color="black", fontcolor="black", label=<{SymPyOps|<br ALIGN="LEFT"/>|abs(x: TypedExpr): TypedExpr<br ALIGN="LEFT"/>add(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>constant(value: Union[int, float, bool], dtype: torch.dtype): TypedExpr<br ALIGN="LEFT"/>floordiv(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>identity(value: Any): Any<br ALIGN="LEFT"/>index_expr(value: Union[sympy.Expr, int], dtype: torch.dtype): TypedExpr<br ALIGN="LEFT"/>maximum(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>minimum(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>mod(x: TypedExpr, y: TypedExpr): Optional[TypedExpr]<br ALIGN="LEFT"/>mul(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>neg(x: TypedExpr): TypedExpr<br ALIGN="LEFT"/>remainder(x: TypedExpr, y: TypedExpr): Optional[TypedExpr]<br ALIGN="LEFT"/>square(x: TypedExpr): TypedExpr<br ALIGN="LEFT"/>sub(x: TypedExpr, y: TypedExpr): TypedExpr<br ALIGN="LEFT"/>to_dtype(value: TypedExpr, dtype: torch.dtype, src_dtype: Optional[torch.dtype], use_compute_types: bool): TypedExpr<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.value_ranges.SymPyValueRangeAnalysis" [color="black", fontcolor="black", label=<{SymPyValueRangeAnalysis|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>add(a, b)<br ALIGN="LEFT"/>and_(a, b)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>ceil_to_int(x, dtype)<br ALIGN="LEFT"/>constant(value, dtype)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>eq(a, b)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>expr_cond_pair(a, b)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floor_to_int(x, dtype)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>ge(a, b)<br ALIGN="LEFT"/>gt(a, b)<br ALIGN="LEFT"/>identity(a)<br ALIGN="LEFT"/>int_truediv(a, b)<br ALIGN="LEFT"/>is_non_overlapping_and_dense_indicator()<br ALIGN="LEFT"/>le(a, b)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>lt(a, b)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>min_or_max(a, b, fn)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>mod(x, y)<br ALIGN="LEFT"/>modular_indexing(a, b, c)<br ALIGN="LEFT"/>mul(a, b)<br ALIGN="LEFT"/>ne(a, b)<br ALIGN="LEFT"/>not_(a)<br ALIGN="LEFT"/>or_(a, b)<br ALIGN="LEFT"/>piecewise()<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>pow_by_natural(a, b)<br ALIGN="LEFT"/>reciprocal(x)<br ALIGN="LEFT"/>round_decimal(number, ndigits)<br ALIGN="LEFT"/>round_to_int(number, dtype)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>tan(x)<br ALIGN="LEFT"/>tanh(x)<br ALIGN="LEFT"/>to_dtype(a, dtype, src_dtype)<br ALIGN="LEFT"/>truediv(a, b)<br ALIGN="LEFT"/>trunc(x)<br ALIGN="LEFT"/>trunc_to_int(a, dtype)<br ALIGN="LEFT"/>where(a, b, c)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.symbol.SymT" [color="black", fontcolor="black", label=<{SymT|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.SymbolicCallArg" [color="black", fontcolor="black", label=<{SymbolicCallArg|inner : str<br ALIGN="LEFT"/>inner_expr : Expr<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.SymbolicContext" [color="black", fontcolor="black", label=<{SymbolicContext|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.registration.SymbolicRegistry" [color="black", fontcolor="black", label=<{SymbolicRegistry|<br ALIGN="LEFT"/>|all_functions(): Set[str]<br ALIGN="LEFT"/>get_function_group(name: str): Optional[_SymbolicFunctionGroup]<br ALIGN="LEFT"/>is_registered_op(name: str, version: int): bool<br ALIGN="LEFT"/>register(name: str, opset: OpsetVersion, func: Callable, custom: bool): None<br ALIGN="LEFT"/>unregister(name: str, opset: OpsetVersion): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._tensors.SymbolicTensor" [color="black", fontcolor="black", label=<{SymbolicTensor|rank<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.SymbolicTorchFunctionState" [color="black", fontcolor="black", label=<{SymbolicTorchFunctionState|cur_mode : NoneType<br ALIGN="LEFT"/>mode_stack : Deque[TorchFunctionModeVariable]<br ALIGN="LEFT"/>torch_function_mode_enabled<br ALIGN="LEFT"/>torch_function_subclass_enabled<br ALIGN="LEFT"/>|call_torch_function_mode(tx, fn, types, args, kwargs)<br ALIGN="LEFT"/>in_torch_function_mode()<br ALIGN="LEFT"/>pop_torch_function_mode()<br ALIGN="LEFT"/>push_torch_function_mode(mode_var)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx.errors.SymbolicValueError" [color="black", fontcolor="red", label=<{SymbolicValueError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator.SympyToZ3" [color="black", fontcolor="black", label=<{SympyToZ3|OPERATOR_HANDLES : set<br ALIGN="LEFT"/>|ceil_to_int(x: z3.ArithRef, dtype: torch.dtype): z3.ArithRef<br ALIGN="LEFT"/>constant(value: Any, dtype: torch.dtype): z3.ExprRef<br ALIGN="LEFT"/>div(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>floor_to_int(x: z3.ArithRef, dtype: torch.dtype): z3.ArithRef<br ALIGN="LEFT"/>floordiv(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>int_truediv(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>mod(p: z3.ArithRef, q: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>pow(base: z3.ArithRef, exp: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>pow_by_natural(base: z3.ArithRef, exp: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>round_to_int(x: z3.ArithRef, dtype: torch.dtype): z3.ArithRef<br ALIGN="LEFT"/>run(expr: sympy.Basic): z3.ExprRef<br ALIGN="LEFT"/>to_dtype(x: z3.ArithRef, dtype: torch.dtype): z3.ArithRef<br ALIGN="LEFT"/>truediv(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>trunc_to_int(x: z3.ArithRef, dtype: torch.dtype): z3.ArithRef<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm.SyncBatchNorm" [color="black", fontcolor="black", label=<{SyncBatchNorm|bias<br ALIGN="LEFT"/>num_batches_tracked<br ALIGN="LEFT"/>process_group : Optional[Any]<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|convert_sync_batchnorm(module, process_group)<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules._functions.SyncBatchNorm" [color="black", fontcolor="black", label=<{SyncBatchNorm|<br ALIGN="LEFT"/>|backward(self, grad_output)<br ALIGN="LEFT"/>forward(self, input, weight, bias, running_mean, running_var, eps, momentum, process_group, world_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.collective_utils.SyncPayload" [color="black", fontcolor="black", label=<{SyncPayload|exception : Optional[Exception]<br ALIGN="LEFT"/>payload : T<br ALIGN="LEFT"/>stage_name : Optional[str]<br ALIGN="LEFT"/>success : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.SynchronizationError" [color="black", fontcolor="red", label=<{SynchronizationError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._pattern_matcher.SynchronizedDataLoaderPattern" [color="black", fontcolor="black", label=<{SynchronizedDataLoaderPattern|description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>url : str<br ALIGN="LEFT"/>|match(event: _ProfilerEvent)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.SyntheticLocalSource" [color="black", fontcolor="black", label=<{SyntheticLocalSource|local_name : str<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.T" [color="black", fontcolor="black", label=<{T|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.TGreatestUpperBound" [color="black", fontcolor="black", label=<{TGreatestUpperBound|res<br ALIGN="LEFT"/>rhs1<br ALIGN="LEFT"/>rhs2<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.TMADescriptor" [color="black", fontcolor="black", label=<{TMADescriptor|block_dims : List[Union[int, torch.SymInt]]<br ALIGN="LEFT"/>dims : List[Union[int, torch.SymInt]]<br ALIGN="LEFT"/>element_size : Optional[int]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(tensor: IRNode, dims: List[Union[int, torch.SymInt]], block_dims: List[Union[int, torch.SymInt]], element_size: Optional[int])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.TMADescriptorArg" [color="black", fontcolor="black", label=<{TMADescriptorArg|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.TMADescriptorVariable" [color="black", fontcolor="black", label=<{TMADescriptorVariable|block_dims : str<br ALIGN="LEFT"/>data_ptr : str<br ALIGN="LEFT"/>dims : str<br ALIGN="LEFT"/>element_size : str<br ALIGN="LEFT"/>|reconstruct(codegen)<br ALIGN="LEFT"/>to_metadata()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.TODO_UNKNOWN" [color="black", fontcolor="black", label=<{TODO_UNKNOWN|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.converter.TS2EPConverter" [color="black", fontcolor="black", label=<{TS2EPConverter|name_to_buffer : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>name_to_constant : Dict[str, Any]<br ALIGN="LEFT"/>name_to_non_tensor_attributes : Dict[str, Any]<br ALIGN="LEFT"/>name_to_param : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>params : list<br ALIGN="LEFT"/>sample_args : Tuple[Any, ...]<br ALIGN="LEFT"/>sample_kwargs : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>ts_graph<br ALIGN="LEFT"/>ts_model : Union[torch.jit.ScriptModule, torch.jit.ScriptFunction]<br ALIGN="LEFT"/>|convert(): ExportedProgram<br ALIGN="LEFT"/>explain(print_output)<br ALIGN="LEFT"/>lift_get_attr()<br ALIGN="LEFT"/>retrace_as_exported_program(gm: torch.fx.GraphModule, name_to_constant: Dict[str, Any])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.converter.TS2FXGraphConverter" [color="black", fontcolor="black", label=<{TS2FXGraphConverter|blocks_to_lifted_attrs : Dict[torch._C.Block, Set[str]]<br ALIGN="LEFT"/>fx_graph<br ALIGN="LEFT"/>input_specs : List[InputSpec]<br ALIGN="LEFT"/>name_to_attribute_fqn : Dict[str, str]<br ALIGN="LEFT"/>name_to_buffer : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>name_to_constant : Dict[str, Any]<br ALIGN="LEFT"/>name_to_node : Dict[str, Union[torch.fx.Node, List[torch.fx.Node], Dict[Any, torch.fx.Node]]]<br ALIGN="LEFT"/>name_to_non_tensor_attribute : Dict[str, Any]<br ALIGN="LEFT"/>name_to_non_tensor_attribute_node : Dict[str, Any]<br ALIGN="LEFT"/>name_to_param : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>name_update_from_subblock_to_parent : Set[str]<br ALIGN="LEFT"/>output_specs : List[OutputSpec]<br ALIGN="LEFT"/>subgraphs : Dict[str, torch.fx.GraphModule]<br ALIGN="LEFT"/>ts_graph : Union[torch._C.Graph, torch._C.Block]<br ALIGN="LEFT"/>|add_subgraph(subgraph): str<br ALIGN="LEFT"/>convert(): torch.fx.GraphModule<br ALIGN="LEFT"/>convert_aten_Bool(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_Float(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_Int(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten___getitem__(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten__convolution(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_add(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_append(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_div(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_tensor(node: torch._C.Node)<br ALIGN="LEFT"/>convert_aten_to(node: torch._C.Node)<br ALIGN="LEFT"/>convert_call_function_op(node: torch._C.Node)<br ALIGN="LEFT"/>convert_graph_inputs()<br ALIGN="LEFT"/>convert_graph_outputs()<br ALIGN="LEFT"/>convert_node(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_CallMethod(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_Constant(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_CreateObject(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_DictConstruct(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_Enter(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_Exit(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_GetAttr(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_If(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_ListConstruct(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_ListUnpack(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_Loop(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_NumToTensor(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_SetAttr(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_TupleConstruct(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_TupleUnpack(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_Uninitialized(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_device(node: torch._C.Node)<br ALIGN="LEFT"/>convert_prim_tolist(node: torch._C.Node)<br ALIGN="LEFT"/>convert_profiler__record_function_exit(node: torch._C.Node)<br ALIGN="LEFT"/>get_args_kwargs(node: torch._C.Node, schema)<br ALIGN="LEFT"/>get_fx_value_by_fqn(name)<br ALIGN="LEFT"/>get_fx_value_by_ir_value(value: torch._C.Value)<br ALIGN="LEFT"/>is_top_level_graph()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.TVar" [color="black", fontcolor="black", label=<{TVar|tvar<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.compare.Table" [color="black", fontcolor="black", label=<{Table|column_keys : list<br ALIGN="LEFT"/>columns : tuple<br ALIGN="LEFT"/>label<br ALIGN="LEFT"/>results : List[common.Measurement]<br ALIGN="LEFT"/>row_keys : list<br ALIGN="LEFT"/>rows : tuple<br ALIGN="LEFT"/>time_scale<br ALIGN="LEFT"/>time_unit<br ALIGN="LEFT"/>|col_fn(m: common.Measurement): Optional[str]<br ALIGN="LEFT"/>populate_rows_and_columns(): Tuple[Tuple[_Row, ...], Tuple[_Column, ...]]<br ALIGN="LEFT"/>render(): str<br ALIGN="LEFT"/>row_fn(m: common.Measurement): Tuple[int, Optional[str], str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Tag" [color="black", fontcolor="black", label=<{Tag|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.wrap.TagActivationCheckpoint" [color="black", fontcolor="black", label=<{TagActivationCheckpoint|<br ALIGN="LEFT"/>|divide_kwargs(kwargs)<br ALIGN="LEFT"/>tag_nodes(gmod, is_sac)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.multiprocessing.tail_log.TailLog" [color="black", fontcolor="black", label=<{TailLog|<br ALIGN="LEFT"/>|start(): 'TailLog'<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>stopped(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.TakeGenVmap" [color="black", fontcolor="black", label=<{TakeGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(x, ind, ind_inv, dim)<br ALIGN="LEFT"/>jvp(ctx, x_tangent, ind_tangent, ind_inv_tangent, _)<br ALIGN="LEFT"/>setup_context(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Tanh" [color="black", fontcolor="black", label=<{Tanh|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms.TanhTransform" [color="black", fontcolor="black", label=<{TanhTransform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>sign : int<br ALIGN="LEFT"/>|log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Tanhshrink" [color="black", fontcolor="black", label=<{Tanhshrink|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.Task" [color="black", fontcolor="black", label=<{Task|p<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.common.TaskSpec" [color="black", fontcolor="black", label=<{TaskSpec|description : Optional[str]<br ALIGN="LEFT"/>env : Optional[str]<br ALIGN="LEFT"/>global_setup : str<br ALIGN="LEFT"/>label : Optional[str]<br ALIGN="LEFT"/>num_threads : int<br ALIGN="LEFT"/>setup : str<br ALIGN="LEFT"/>stmt : str<br ALIGN="LEFT"/>sub_label : Optional[str]<br ALIGN="LEFT"/>title<br ALIGN="LEFT"/>|setup_str(): str<br ALIGN="LEFT"/>summarize(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.TemplateBuffer" [color="black", fontcolor="black", label=<{TemplateBuffer|inputs : list<br ALIGN="LEFT"/>make_kernel_render : Callable[..., Any]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>|extract_read_writes(normalize)<br ALIGN="LEFT"/>get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_reduction_size(): Sequence[sympy.Expr]<br ALIGN="LEFT"/>get_reduction_type(): Optional[str]<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>simplify_and_reorder(extra_indexing_constraints: Optional[Tuple[Dict[Any, Any], List[Any]]], recompute_sizes_body_func: Optional[Callable[..., Any]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.memory_planning.TemporalSplit" [color="black", fontcolor="black", label=<{TemporalSplit|allocations : List[AllocationTreeNode]<br ALIGN="LEFT"/>|finalize(pool, offset)<br ALIGN="LEFT"/>get_live_ranges(): LiveRanges<br ALIGN="LEFT"/>get_size_hint(): int<br ALIGN="LEFT"/>get_symbolic_size(): sympy.Expr<br ALIGN="LEFT"/>is_empty()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._tensor.Tensor" [color="black", fontcolor="black", label=<{Tensor|data<br ALIGN="LEFT"/>detach<br ALIGN="LEFT"/>detach_<br ALIGN="LEFT"/>imag<br ALIGN="LEFT"/>real<br ALIGN="LEFT"/>requires_grad<br ALIGN="LEFT"/>|align_to()<br ALIGN="LEFT"/>backward(gradient, retain_graph, create_graph, inputs)<br ALIGN="LEFT"/>dim_order()<br ALIGN="LEFT"/>eig(eigenvectors)<br ALIGN="LEFT"/>is_shared()<br ALIGN="LEFT"/>istft(n_fft: int, hop_length: Optional[int], win_length: Optional[int], window: 'Optional[Tensor]', center: bool, normalized: bool, onesided: Optional[bool], length: Optional[int], return_complex: bool)<br ALIGN="LEFT"/>lstsq(other)<br ALIGN="LEFT"/>lu(pivot, get_infos)<br ALIGN="LEFT"/>module_load(other, assign)<br ALIGN="LEFT"/>norm(p: Optional[Union[float, str]], dim, keepdim, dtype)<br ALIGN="LEFT"/>refine_names()<br ALIGN="LEFT"/>register_hook(hook)<br ALIGN="LEFT"/>register_post_accumulate_grad_hook(hook)<br ALIGN="LEFT"/>reinforce(reward)<br ALIGN="LEFT"/>rename()<br ALIGN="LEFT"/>rename_()<br ALIGN="LEFT"/>resize()<br ALIGN="LEFT"/>resize_as(tensor)<br ALIGN="LEFT"/>share_memory_()<br ALIGN="LEFT"/>solve(other)<br ALIGN="LEFT"/>split(split_size, dim)<br ALIGN="LEFT"/>stft(n_fft: int, hop_length: Optional[int], win_length: Optional[int], window: 'Optional[Tensor]', center: bool, pad_mode: str, normalized: bool, onesided: Optional[bool], return_complex: Optional[bool])<br ALIGN="LEFT"/>storage()<br ALIGN="LEFT"/>storage_type()<br ALIGN="LEFT"/>symeig(eigenvectors)<br ALIGN="LEFT"/>to_sparse_coo()<br ALIGN="LEFT"/>unflatten(dim, sizes)<br ALIGN="LEFT"/>unique(sorted, return_inverse, return_counts, dim)<br ALIGN="LEFT"/>unique_consecutive(return_inverse, return_counts, dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.TensorAlias" [color="black", fontcolor="black", label=<{TensorAlias|alias<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.common.TensorArg" [color="black", fontcolor="black", label=<{TensorArg|alias_of : Optional[str]<br ALIGN="LEFT"/>buffer : str<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>offset : Expr<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.TensorArgument" [color="black", fontcolor="black", label=<{TensorArgument|name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.TensorArgument" [color="black", fontcolor="black", label=<{TensorArgument|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.sparse._triton_ops.TensorAsKey" [color="black", fontcolor="black", label=<{TensorAsKey|key : tuple<br ALIGN="LEFT"/>obj<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.TensorBox" [color="black", fontcolor="black", label=<{TensorBox|<br ALIGN="LEFT"/>|create(data)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.microbatch.TensorChunkSpec" [color="black", fontcolor="black", label=<{TensorChunkSpec|split_dim : int<br ALIGN="LEFT"/>|from_dict(chunk_dims: Dict[str, int])<br ALIGN="LEFT"/>from_tuple(chunk_dims: Tuple[int, ...])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.debug_utils.aot_graph_input_parser.TensorContainer" [color="black", fontcolor="black", label=<{TensorContainer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.dataset.TensorDataset" [color="black", fontcolor="black", label=<{TensorDataset|tensors : Tuple[Tensor, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils.TensorExprTestOptions" [color="black", fontcolor="black", label=<{TensorExprTestOptions|old_cpu_fuser_state<br ALIGN="LEFT"/>old_fusion_inlining<br ALIGN="LEFT"/>old_gpu_fuser_state<br ALIGN="LEFT"/>old_profiling_executor<br ALIGN="LEFT"/>old_profiling_mode<br ALIGN="LEFT"/>old_te_must_use_llvm_cpu<br ALIGN="LEFT"/>texpr_fuser_state<br ALIGN="LEFT"/>|restore()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda._sanitizer.TensorInfo" [color="black", fontcolor="black", label=<{TensorInfo|allocation_stack_trace : Optional[traceback.StackSummary]<br ALIGN="LEFT"/>reads : List[Access]<br ALIGN="LEFT"/>write : Optional[Access]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler.TensorKey" [color="black", fontcolor="black", label=<{TensorKey|id : int<br ALIGN="LEFT"/>storage<br ALIGN="LEFT"/>|from_allocation(alloc: _ExtraFields_Allocation): Optional['TensorKey']<br ALIGN="LEFT"/>from_tensor(t: Optional[_TensorMetadata]): Optional['TensorKey']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.type_utils.TensorLike" [color="black", fontcolor="black", label=<{TensorLike|dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._comparison.TensorLikePair" [color="black", fontcolor="black", label=<{TensorLikePair|atol<br ALIGN="LEFT"/>check_device : bool<br ALIGN="LEFT"/>check_dtype : bool<br ALIGN="LEFT"/>check_layout : bool<br ALIGN="LEFT"/>check_stride : bool<br ALIGN="LEFT"/>equal_nan : bool<br ALIGN="LEFT"/>rtol<br ALIGN="LEFT"/>|compare(): None<br ALIGN="LEFT"/>extra_repr(): Sequence[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._dtensor_spec.TensorMeta" [color="black", fontcolor="black", label=<{TensorMeta|dtype<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>stride : Tuple[int, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TensorMeta" [color="black", fontcolor="black", label=<{TensorMeta|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>offset : int<br ALIGN="LEFT"/>sizes : Union<br ALIGN="LEFT"/>strides : Union<br ALIGN="LEFT"/>|from_irnodes(irnodes: Union[LayoutOrBuffer, Sequence[LayoutOrBuffer]]): Union[TensorMeta, List[TensorMeta]]<br ALIGN="LEFT"/>to_tensor(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.TensorMeta" [color="black", fontcolor="black", label=<{TensorMeta|device : Annotated[Device, 40]<br ALIGN="LEFT"/>dtype : Annotated[ScalarType, 10]<br ALIGN="LEFT"/>layout : Annotated[Layout, 70]<br ALIGN="LEFT"/>requires_grad : Annotated[bool, 30]<br ALIGN="LEFT"/>sizes : Annotated[List[SymInt], 20]<br ALIGN="LEFT"/>storage_offset : Annotated[SymInt, 60]<br ALIGN="LEFT"/>strides : Annotated[List[SymInt], 50]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.shape_prop.TensorMetadata" [color="black", fontcolor="black", label=<{TensorMetadata|dtype<br ALIGN="LEFT"/>is_quantized : bool<br ALIGN="LEFT"/>memory_format : Optional[torch.memory_format]<br ALIGN="LEFT"/>qparams : Dict[str, Any]<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>stride : Tuple[int, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.TensorMetadata" [color="black", fontcolor="black", label=<{TensorMetadata|dense_dim : Optional[int]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>is_coalesced : Optional[bool]<br ALIGN="LEFT"/>is_conj : bool<br ALIGN="LEFT"/>is_inference : bool<br ALIGN="LEFT"/>is_neg : bool<br ALIGN="LEFT"/>is_quantized : bool<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>memory_format : Optional[torch.memory_format]<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>shape : Tuple[_MetadataIntLike, ...]<br ALIGN="LEFT"/>sparse_dim : Optional[int]<br ALIGN="LEFT"/>storage_bytes : Optional[_MetadataIntLike]<br ALIGN="LEFT"/>storage_offset : Union<br ALIGN="LEFT"/>stride : Tuple[_MetadataIntLike, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codecache.TensorMetadataAndValues" [color="black", fontcolor="black", label=<{TensorMetadataAndValues|tensor_metadata<br ALIGN="LEFT"/>values : List[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.debug.TensorMetadataHolder" [color="black", fontcolor="black", label=<{TensorMetadataHolder|device<br ALIGN="LEFT"/>tensor_metadata : TensorMetadata<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TensorOrArrayPair" [color="black", fontcolor="black", label=<{TensorOrArrayPair|atol<br ALIGN="LEFT"/>rtol<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentCudaRpcTest" [color="black", fontcolor="black", label=<{TensorPipeAgentCudaRpcTest|<br ALIGN="LEFT"/>|test_async_execution_nested_with_cuda_future()<br ALIGN="LEFT"/>test_async_execution_with_cuda_future()<br ALIGN="LEFT"/>test_cuda_future_callback_changes_devices()<br ALIGN="LEFT"/>test_cuda_future_can_extract_cuda_sparse_tensor()<br ALIGN="LEFT"/>test_cuda_future_can_extract_cuda_tensor()<br ALIGN="LEFT"/>test_cuda_future_can_extract_custom_class_with_cuda_sparse_tensor()<br ALIGN="LEFT"/>test_cuda_future_can_extract_custom_class_with_cuda_tensor()<br ALIGN="LEFT"/>test_cuda_future_can_extract_list_with_cuda_sparse_tensor()<br ALIGN="LEFT"/>test_cuda_future_can_extract_list_with_cuda_tensor()<br ALIGN="LEFT"/>test_cuda_future_device_as_device()<br ALIGN="LEFT"/>test_cuda_future_device_as_int()<br ALIGN="LEFT"/>test_cuda_future_device_as_str()<br ALIGN="LEFT"/>test_cuda_future_device_not_cuda()<br ALIGN="LEFT"/>test_cuda_future_modify_tensor_inplace()<br ALIGN="LEFT"/>test_cuda_future_replace_tensor()<br ALIGN="LEFT"/>test_cuda_future_value_on_bad_device()<br ALIGN="LEFT"/>test_custom_stream()<br ALIGN="LEFT"/>test_custom_stream_multi()<br ALIGN="LEFT"/>test_custom_stream_nested()<br ALIGN="LEFT"/>test_custom_stream_nested_multi()<br ALIGN="LEFT"/>test_device_map_cpu()<br ALIGN="LEFT"/>test_device_map_cpu_to_gpu_default()<br ALIGN="LEFT"/>test_device_map_cpu_to_gpu_non_default()<br ALIGN="LEFT"/>test_device_map_gpu_default()<br ALIGN="LEFT"/>test_device_map_gpu_default_to_non_default()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_1()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_2()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_3()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_4()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_5()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_6()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_7()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_8()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_1()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_2()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_3()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_4()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_5()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_6()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_7()<br ALIGN="LEFT"/>test_device_map_gpu_mixed_self_8()<br ALIGN="LEFT"/>test_device_map_gpu_non_default()<br ALIGN="LEFT"/>test_device_map_gpu_non_default_to_default()<br ALIGN="LEFT"/>test_device_map_gpu_to_cpu_default()<br ALIGN="LEFT"/>test_device_map_gpu_to_cpu_non_default()<br ALIGN="LEFT"/>test_device_maps_gpu()<br ALIGN="LEFT"/>test_device_maps_in_options()<br ALIGN="LEFT"/>test_device_maps_invalid_max_local_device()<br ALIGN="LEFT"/>test_device_maps_invalid_max_remote_device()<br ALIGN="LEFT"/>test_device_maps_invalid_min_device()<br ALIGN="LEFT"/>test_device_maps_many_to_one()<br ALIGN="LEFT"/>test_device_maps_missing_config()<br ALIGN="LEFT"/>test_device_maps_missing_config_loop()<br ALIGN="LEFT"/>test_device_maps_missing_config_not_timeout()<br ALIGN="LEFT"/>test_device_maps_missing_config_remote()<br ALIGN="LEFT"/>test_device_maps_missing_config_remote_response()<br ALIGN="LEFT"/>test_device_maps_missing_config_response()<br ALIGN="LEFT"/>test_device_maps_missing_config_response_loop()<br ALIGN="LEFT"/>test_device_maps_multi_gpu()<br ALIGN="LEFT"/>test_device_maps_multi_gpu_self()<br ALIGN="LEFT"/>test_device_maps_one_to_many()<br ALIGN="LEFT"/>test_device_maps_remote()<br ALIGN="LEFT"/>test_device_maps_return_to_gpu()<br ALIGN="LEFT"/>test_device_maps_return_to_gpu_self()<br ALIGN="LEFT"/>test_device_maps_wrong_worker_name()<br ALIGN="LEFT"/>test_device_mismatch()<br ALIGN="LEFT"/>test_devices_option_mismatch()<br ALIGN="LEFT"/>test_devices_option_mismatch_reverse()<br ALIGN="LEFT"/>test_owner_rref_forward_synchronization1()<br ALIGN="LEFT"/>test_owner_rref_forward_synchronization2()<br ALIGN="LEFT"/>test_owner_rref_forward_synchronization3()<br ALIGN="LEFT"/>test_owner_rref_forward_synchronization4()<br ALIGN="LEFT"/>test_rref_as_arg_synchronization1()<br ALIGN="LEFT"/>test_rref_as_arg_synchronization2()<br ALIGN="LEFT"/>test_rref_as_arg_synchronization3()<br ALIGN="LEFT"/>test_rref_as_arg_synchronization4()<br ALIGN="LEFT"/>test_rref_as_arg_synchronization5()<br ALIGN="LEFT"/>test_rref_forward_synchronization1()<br ALIGN="LEFT"/>test_rref_forward_synchronization2()<br ALIGN="LEFT"/>test_rref_forward_synchronization3()<br ALIGN="LEFT"/>test_rref_forward_synchronization4()<br ALIGN="LEFT"/>test_rref_to_here_synchronization1()<br ALIGN="LEFT"/>test_rref_to_here_synchronization2()<br ALIGN="LEFT"/>test_rref_to_here_synchronization3()<br ALIGN="LEFT"/>test_rref_to_here_synchronization4()<br ALIGN="LEFT"/>test_rref_with_unpickleable_attributes()<br ALIGN="LEFT"/>test_tensor_view_as_return_value()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeAgentDistAutogradTest" [color="black", fontcolor="black", label=<{TensorPipeAgentDistAutogradTest|<br ALIGN="LEFT"/>|test_backward_different_dtypes_sparse()<br ALIGN="LEFT"/>test_backward_multiple_round_trips_sparse()<br ALIGN="LEFT"/>test_backward_no_grad_on_tensor_sparse()<br ALIGN="LEFT"/>test_backward_rref_multi_sparse()<br ALIGN="LEFT"/>test_backward_rref_nested_sparse()<br ALIGN="LEFT"/>test_backward_rref_sparse()<br ALIGN="LEFT"/>test_backward_simple_python_udf_sparse()<br ALIGN="LEFT"/>test_backward_simple_script_call_sparse()<br ALIGN="LEFT"/>test_backward_simple_self_sparse()<br ALIGN="LEFT"/>test_backward_simple_sparse()<br ALIGN="LEFT"/>test_backwards_nested_python_udf_sparse()<br ALIGN="LEFT"/>test_context_cleanup_nested_rpc_sparse()<br ALIGN="LEFT"/>test_context_cleanup_tensor_no_grad_sparse()<br ALIGN="LEFT"/>test_context_cleanup_tensor_with_grad_sparse()<br ALIGN="LEFT"/>test_embedding_bag_with_no_grad_tensors()<br ALIGN="LEFT"/>test_graph_for_builtin_call_sparse()<br ALIGN="LEFT"/>test_graph_for_builtin_remote_call_sparse()<br ALIGN="LEFT"/>test_graph_for_py_nested_call_itself_sparse()<br ALIGN="LEFT"/>test_graph_for_py_nested_call_sparse()<br ALIGN="LEFT"/>test_graph_for_py_nested_remote_call_itself_sparse()<br ALIGN="LEFT"/>test_graph_for_py_nested_remote_call_sparse()<br ALIGN="LEFT"/>test_graph_for_python_call_sparse()<br ALIGN="LEFT"/>test_graph_for_python_remote_call_sparse()<br ALIGN="LEFT"/>test_mixed_requires_grad_sparse()<br ALIGN="LEFT"/>test_multiple_backward_sparse()<br ALIGN="LEFT"/>test_nested_backward_accumulate_grads_sparse()<br ALIGN="LEFT"/>test_no_graph_with_tensors_not_require_grad_remote_sparse()<br ALIGN="LEFT"/>test_no_graph_with_tensors_not_require_grad_sparse()<br ALIGN="LEFT"/>test_remote_complex_args_sparse()<br ALIGN="LEFT"/>test_rpc_complex_args_sparse()<br ALIGN="LEFT"/>test_trainer_ps_sparse()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest" [color="black", fontcolor="black", label=<{TensorPipeAgentRpcTest|<br ALIGN="LEFT"/>|test_builtin_remote_ret_sparse()<br ALIGN="LEFT"/>test_builtin_remote_self_sparse()<br ALIGN="LEFT"/>test_dynamic_and_static_init_rpc_together()<br ALIGN="LEFT"/>test_dynamic_rpc_existing_rank_can_communicate_with_new_rank()<br ALIGN="LEFT"/>test_dynamic_rpc_existing_rank_can_communicate_with_new_rank_cuda()<br ALIGN="LEFT"/>test_dynamic_rpc_init_rpc()<br ALIGN="LEFT"/>test_dynamic_rpc_init_rpc_without_rank()<br ALIGN="LEFT"/>test_dynamic_rpc_new_rank_can_communicated_with_existing_rank()<br ALIGN="LEFT"/>test_infer_backend_from_options()<br ALIGN="LEFT"/>test_mismatched_type_for_options()<br ALIGN="LEFT"/>test_multi_builtin_remote_ret_sparse()<br ALIGN="LEFT"/>test_multi_py_udf_remote_sparse()<br ALIGN="LEFT"/>test_multi_rpc_sparse()<br ALIGN="LEFT"/>test_my_parameter_server_sparse()<br ALIGN="LEFT"/>test_nested_remote_sparse()<br ALIGN="LEFT"/>test_nested_rpc_sparse()<br ALIGN="LEFT"/>test_nested_rref_sparse()<br ALIGN="LEFT"/>test_nested_rref_stress_sparse()<br ALIGN="LEFT"/>test_op_with_invalid_args()<br ALIGN="LEFT"/>test_py_rpc_rref_args_sparse()<br ALIGN="LEFT"/>test_py_rref_args_sparse()<br ALIGN="LEFT"/>test_py_rref_args_user_share_sparse()<br ALIGN="LEFT"/>test_py_sparse_tensors_in_container()<br ALIGN="LEFT"/>test_rref_get_type_timeout_blocking()<br ALIGN="LEFT"/>test_rref_get_type_timeout_non_blocking()<br ALIGN="LEFT"/>test_rref_proxy_timeout()<br ALIGN="LEFT"/>test_self_py_udf_remote_sparse()<br ALIGN="LEFT"/>test_self_remote_rref_as_remote_arg_sparse()<br ALIGN="LEFT"/>test_self_remote_rref_as_rpc_arg_sparse()<br ALIGN="LEFT"/>test_self_remote_rref_as_self_remote_arg_sparse()<br ALIGN="LEFT"/>test_self_remote_rref_as_self_rpc_arg_sparse()<br ALIGN="LEFT"/>test_send_to_rank_sparse()<br ALIGN="LEFT"/>test_set_and_get_num_worker_threads()<br ALIGN="LEFT"/>test_stress_heavy_rpc_sparse()<br ALIGN="LEFT"/>test_tensorpipe_options_throw_on_timedelta_timeout()<br ALIGN="LEFT"/>test_tensorpipe_set_default_timeout()<br ALIGN="LEFT"/>test_wait_all_workers_sparse()<br ALIGN="LEFT"/>test_wait_all_workers_twice_sparse()<br ALIGN="LEFT"/>test_world_size_one_sparse()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest" [color="black", fontcolor="black", label=<{TensorPipeCudaDistAutogradTest|<br ALIGN="LEFT"/>|test_device_maps_backward_pass()<br ALIGN="LEFT"/>test_dist_autograd_sync_streams()<br ALIGN="LEFT"/>test_gradients_synchronizations()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture" [color="black", fontcolor="black", label=<{TensorPipeRpcAgentTestFixture|rpc_backend<br ALIGN="LEFT"/>rpc_backend_options<br ALIGN="LEFT"/>|get_shutdown_error_regex()<br ALIGN="LEFT"/>get_timeout_error_regex()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.rpc.options.TensorPipeRpcBackendOptions" [color="black", fontcolor="black", label=<{TensorPipeRpcBackendOptions|devices : list<br ALIGN="LEFT"/>init_method : str<br ALIGN="LEFT"/>|set_device_map(to: str, device_map: Dict[DeviceType, DeviceType])<br ALIGN="LEFT"/>set_devices(devices: List[DeviceType])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._shard.sharded_tensor.metadata.TensorProperties" [color="black", fontcolor="black", label=<{TensorProperties|dtype<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>memory_format<br ALIGN="LEFT"/>pin_memory : bool<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|create_from_tensor(tensor: torch.Tensor): 'TensorProperties'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.TensorProperties" [color="black", fontcolor="black", label=<{TensorProperties|dtype<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>memory_format<br ALIGN="LEFT"/>pin_memory : bool<br ALIGN="LEFT"/>requires_grad : bool<br ALIGN="LEFT"/>|create_from_tensor(tensor: torch.Tensor): 'TensorProperties'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.TensorProperty" [color="black", fontcolor="black", label=<{TensorProperty|name<br ALIGN="LEFT"/>|method_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.TensorPropertySource" [color="black", fontcolor="black", label=<{TensorPropertySource|idx : Optional[int]<br ALIGN="LEFT"/>prop<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.reference.TensorReferenceAnalysis" [color="black", fontcolor="black", label=<{TensorReferenceAnalysis|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>add(a, b)<br ALIGN="LEFT"/>and_(a, b)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>ceil_to_int(x, dtype)<br ALIGN="LEFT"/>constant(c, dtype)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>eq(a, b)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floor_to_int(x, dtype)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>ge(a, b)<br ALIGN="LEFT"/>gt(a, b)<br ALIGN="LEFT"/><I>int_truediv</I>(a, b)<br ALIGN="LEFT"/>le(a, b)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>lt(a, b)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/><I>mod</I>(x, y)<br ALIGN="LEFT"/>mul(a, b)<br ALIGN="LEFT"/>ne(a, b)<br ALIGN="LEFT"/>neg(x)<br ALIGN="LEFT"/>not_(a)<br ALIGN="LEFT"/>or_(a, b)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>pow_by_natural(a, b)<br ALIGN="LEFT"/>reciprocal(x)<br ALIGN="LEFT"/><I>round_decimal</I>(a, b)<br ALIGN="LEFT"/>round_to_int(a, dtype)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>square(x)<br ALIGN="LEFT"/>sub(a, b)<br ALIGN="LEFT"/>tan(x)<br ALIGN="LEFT"/>tanh(x)<br ALIGN="LEFT"/>to_dtype(x, dtype)<br ALIGN="LEFT"/>truediv(a, b)<br ALIGN="LEFT"/>trunc_to_int(x, dtype)<br ALIGN="LEFT"/><I>truncdiv</I>(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.tensor_setattr.TensorSetattr" [color="black", fontcolor="black", label=<{TensorSetattr|<br ALIGN="LEFT"/>|forward(x, attr)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils.TensorStaticReason" [color="black", fontcolor="black", label=<{TensorStaticReason|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata.TensorStorageMetadata" [color="black", fontcolor="black", label=<{TensorStorageMetadata|chunks : List[ChunkStorageMetadata]<br ALIGN="LEFT"/>properties<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.TensorSubclassVariable" [color="black", fontcolor="black", label=<{TensorSubclassVariable|value<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.TensorTracker" [color="black", fontcolor="black", label=<{TensorTracker|assert_eq_kwargs : NoneType, dict<br ALIGN="LEFT"/>tensors : list<br ALIGN="LEFT"/>|add(tensor)<br ALIGN="LEFT"/>all_popped()<br ALIGN="LEFT"/>pop_check_set(tensor_to_set, testcase)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.tensor_type.TensorType" [color="black", fontcolor="black", label=<{TensorType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.TensorVariable" [color="black", fontcolor="black", label=<{TensorVariable|class_type<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>has_grad_fn<br ALIGN="LEFT"/>is_contiguous : NoneType<br ALIGN="LEFT"/>is_nested<br ALIGN="LEFT"/>is_quantized<br ALIGN="LEFT"/>is_sparse<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>method_ndimension<br ALIGN="LEFT"/>method_nelement<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>requires_grad<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>stride : NoneType<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>call_id(tx)<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>dynamic_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>get_real_value()<br ALIGN="LEFT"/>has_unpack_var_sequence(tx)<br ALIGN="LEFT"/>method___contains__(arg)<br ALIGN="LEFT"/>method___getitem__()<br ALIGN="LEFT"/>method___len__()<br ALIGN="LEFT"/>method___setitem__(key, value)<br ALIGN="LEFT"/>method_add_(other)<br ALIGN="LEFT"/>method_addcdiv_(tensor1, tensor2)<br ALIGN="LEFT"/>method_addcmul_(tensor1, tensor2)<br ALIGN="LEFT"/>method_as_subclass(cls)<br ALIGN="LEFT"/>method_attr__version(tx)<br ALIGN="LEFT"/>method_attr_data(tx)<br ALIGN="LEFT"/>method_attr_device(tx)<br ALIGN="LEFT"/>method_attr_dtype(tx)<br ALIGN="LEFT"/>method_attr_grad_fn(tx)<br ALIGN="LEFT"/>method_attr_is_cuda(tx)<br ALIGN="LEFT"/>method_attr_is_nested(tx)<br ALIGN="LEFT"/>method_attr_is_quantized(tx)<br ALIGN="LEFT"/>method_attr_is_sparse(tx)<br ALIGN="LEFT"/>method_attr_layout(tx)<br ALIGN="LEFT"/>method_attr_ndim(tx)<br ALIGN="LEFT"/>method_attr_requires_grad(tx)<br ALIGN="LEFT"/>method_attr_shape(tx)<br ALIGN="LEFT"/>method_backward()<br ALIGN="LEFT"/>method_data_ptr()<br ALIGN="LEFT"/>method_dim()<br ALIGN="LEFT"/>method_element_size()<br ALIGN="LEFT"/>method_get_device()<br ALIGN="LEFT"/>method_is_complex()<br ALIGN="LEFT"/>method_is_contiguous(memory_format)<br ALIGN="LEFT"/>method_is_floating_point()<br ALIGN="LEFT"/>method_is_inference()<br ALIGN="LEFT"/>method_item()<br ALIGN="LEFT"/>method_new()<br ALIGN="LEFT"/>method_numel()<br ALIGN="LEFT"/>method_numpy()<br ALIGN="LEFT"/>method_redistribute()<br ALIGN="LEFT"/>method_register_hook()<br ALIGN="LEFT"/>method_register_post_accumulate_grad_hook()<br ALIGN="LEFT"/>method_requires_grad_(requires_grad)<br ALIGN="LEFT"/>method_resize_()<br ALIGN="LEFT"/>method_resize_as_()<br ALIGN="LEFT"/>method_set_()<br ALIGN="LEFT"/>method_size()<br ALIGN="LEFT"/>method_sparse_resize_()<br ALIGN="LEFT"/>method_sparse_resize_and_clear_()<br ALIGN="LEFT"/>method_stride()<br ALIGN="LEFT"/>method_to_local()<br ALIGN="LEFT"/>method_tolist()<br ALIGN="LEFT"/>method_type(dtype, non_blocking)<br ALIGN="LEFT"/>method_untyped_storage()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>set_name_hint(name: str)<br ALIGN="LEFT"/>specialize(value: torch.Tensor)<br ALIGN="LEFT"/>unpack_var_sequence(tx: 'InstructionTranslator', idxes)<br ALIGN="LEFT"/>valid_size()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.weak.TensorWeakRef" [color="black", fontcolor="black", label=<{TensorWeakRef|ref : WeakRef[Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._python_dispatch.TensorWithFlatten" [color="black", fontcolor="black", label=<{TensorWithFlatten|shape<br ALIGN="LEFT"/>|dim(): int<br ALIGN="LEFT"/>size(dim: None): Tuple[int, ...]<br ALIGN="LEFT"/>storage_offset(): int<br ALIGN="LEFT"/>stride(dim: None): Tuple[int, ...]<br ALIGN="LEFT"/>to(dtype: torch.types._dtype, non_blocking: bool, copy: bool): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.TensorWithTFOverrideVariable" [color="black", fontcolor="black", label=<{TensorWithTFOverrideVariable|torch_function_fn<br ALIGN="LEFT"/>|call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_torch_function(tx: 'InstructionTranslator', fn, types, args, kwargs)<br ALIGN="LEFT"/>class_type_var(tx)<br ALIGN="LEFT"/>from_tensor_var(tx, tensor_var, class_type, torch_function_fn)<br ALIGN="LEFT"/>global_mangled_class_name(tx)<br ALIGN="LEFT"/>install_global(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_device.TensorWrapper" [color="black", fontcolor="black", label=<{TensorWrapper|moved_to_gpu : bool<br ALIGN="LEFT"/>t<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorWrapper" [color="black", fontcolor="black", label=<{TensorWrapper|event<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>thread : Thread<br ALIGN="LEFT"/>|increase(v)<br ALIGN="LEFT"/>sum()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.TensorWriteData" [color="black", fontcolor="black", label=<{TensorWriteData|chunk<br ALIGN="LEFT"/>properties<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.monitor.TensorboardEventHandler" [color="black", fontcolor="black", label=<{TensorboardEventHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.TensorifyScalarRestartAnalysis" [color="black", fontcolor="red", label=<{TensorifyScalarRestartAnalysis|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.symbolic_convert.TensorifyState" [color="black", fontcolor="black", label=<{TensorifyState|force_specializations : Set[Source]<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>should_specialize(index: Source): bool<br ALIGN="LEFT"/>specialize(index: Source): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autocast_test_lists.TestAutocast" [color="black", fontcolor="black", label=<{TestAutocast|<br ALIGN="LEFT"/>|args_maybe_kwargs(op_with_args)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_nn.TestBase" [color="black", fontcolor="black", label=<{TestBase|constructor<br ALIGN="LEFT"/>constructor_args<br ALIGN="LEFT"/>desc : str<br ALIGN="LEFT"/>extra_args<br ALIGN="LEFT"/>fullname : NoneType<br ALIGN="LEFT"/>reference_fn : NoneType<br ALIGN="LEFT"/>|get_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TestBenchmarkRequest" [color="black", fontcolor="black", label=<{TestBenchmarkRequest|value : Optional[float]<br ALIGN="LEFT"/>|benchmark(): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.test_case.TestCase" [color="black", fontcolor="black", label=<{TestCase|handler : NullHandler<br ALIGN="LEFT"/>|setUp(): None<br ALIGN="LEFT"/>setUpClass(): None<br ALIGN="LEFT"/>tearDown(): None<br ALIGN="LEFT"/>tearDownClass(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.test_case.TestCase" [color="black", fontcolor="black", label=<{TestCase|<br ALIGN="LEFT"/>|setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TestCase" [color="black", fontcolor="black", label=<{TestCase|maxDiff : NoneType<br ALIGN="LEFT"/>precision<br ALIGN="LEFT"/>rel_tol<br ALIGN="LEFT"/>|assertAtenOp(onnx_model, operator, overload_name)<br ALIGN="LEFT"/>assertEqual(x, y, msg: Optional[Union[str, Callable[[str], str]]])<br ALIGN="LEFT"/>assertEqualBroadcasting(x, y): None<br ALIGN="LEFT"/>assertEqualIgnoreType(): None<br ALIGN="LEFT"/>assertEqualTypeString(x, y): None<br ALIGN="LEFT"/>assertExpected(s, subname)<br ALIGN="LEFT"/>assertExpectedInline(actual, expect, skip, ignore_comments, ignore_empty_lines)<br ALIGN="LEFT"/>assertExpectedInlineMunged(exc_type, callable, expect)<br ALIGN="LEFT"/>assertExpectedRaises(exc_type, callable)<br ALIGN="LEFT"/>assertExpectedStripMangled(s, subname)<br ALIGN="LEFT"/>assertGreaterAlmostEqual(first, second, places, msg, delta)<br ALIGN="LEFT"/>assertLeaksNoCudaTensors(name)<br ALIGN="LEFT"/>assertLogs(logger, level)<br ALIGN="LEFT"/>assertNoLogs(logger, level)<br ALIGN="LEFT"/>assertNoUnraisable(callable)<br ALIGN="LEFT"/>assertNotEqual(x, y, msg: Optional[str]): None<br ALIGN="LEFT"/>assertNotWarn(callable, msg)<br ALIGN="LEFT"/>assertObjectIn(obj: Any, iterable: Iterable[Any]): None<br ALIGN="LEFT"/>assertRaises(expected_exception)<br ALIGN="LEFT"/>assertRaisesRegex(expected_exception, expected_regex)<br ALIGN="LEFT"/>assertWarnsOnceRegex(category, regex)<br ALIGN="LEFT"/>check_nondeterministic_alert(fn, caller_name, should_alert)<br ALIGN="LEFT"/>compare_with_numpy(torch_fn, np_fn, tensor_like, device, dtype)<br ALIGN="LEFT"/>compare_with_reference(torch_fn, ref_fn, sample_input)<br ALIGN="LEFT"/>enforceNonDefaultStream()<br ALIGN="LEFT"/>genSparseBSCTensor(size, blocksize, nnz)<br ALIGN="LEFT"/>genSparseBSRTensor(size, blocksize, nnz)<br ALIGN="LEFT"/>genSparseCSCTensor(size, nnz)<br ALIGN="LEFT"/>genSparseCSRTensor(size, nnz)<br ALIGN="LEFT"/>genSparseCompressedTensor(size, nnz)<br ALIGN="LEFT"/>genSparseTensor(size, sparse_dim, nnz, is_uncoalesced, device, dtype)<br ALIGN="LEFT"/>generate_simple_inputs(layout, device, dtype, index_dtype, pin_memory, members_pin_memory, enable_batch, enable_hybrid, enable_zero_sized, enable_non_contiguous_indices, enable_non_contiguous_values, enable_batch_variable_nse, output_tensor, patterns)<br ALIGN="LEFT"/>remove_comment_lines(input_string)<br ALIGN="LEFT"/>remove_empty_lines(input_string)<br ALIGN="LEFT"/>run(result)<br ALIGN="LEFT"/>runWithPytorchAPIUsageStderr(code)<br ALIGN="LEFT"/>run_process_no_exception(code, env)<br ALIGN="LEFT"/>safeToDense(t)<br ALIGN="LEFT"/>setUp()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>wrap_method_with_policy(method, policy)<br ALIGN="LEFT"/>wrap_with_cuda_memory_check(method)<br ALIGN="LEFT"/>wrap_with_cuda_policy(method_name, policy)<br ALIGN="LEFT"/>wrap_with_policy(method_name, policy)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TestCaseBase" [color="black", fontcolor="black", label=<{TestCaseBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.get_pytest_test_cases.TestCollectorPlugin" [color="black", fontcolor="black", label=<{TestCollectorPlugin|tests : list<br ALIGN="LEFT"/>|pytest_collection_finish(session)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.TestDebugInfoFunc" [color="black", fontcolor="black", label=<{TestDebugInfoFunc|<br ALIGN="LEFT"/>|backward(ctx, input)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.TestDistBackend" [color="black", fontcolor="black", label=<{TestDistBackend|destroy_pg_upon_exit<br ALIGN="LEFT"/>file_name<br ALIGN="LEFT"/>init_method<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>skip_return_code_checks : list<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|setUp()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>tearDown()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TestEnvironment" [color="black", fontcolor="black", label=<{TestEnvironment|repro_env_vars : dict<br ALIGN="LEFT"/>|def_flag(name, env_var, default, include_in_repro, enabled_fn, implied_by_fn)<br ALIGN="LEFT"/>def_setting(name, env_var, default, include_in_repro, parse_fn)<br ALIGN="LEFT"/>repro_env_var_prefix(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.compile_worker.subproc_pool.TestException" [color="black", fontcolor="red", label=<{TestException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TestGradients" [color="black", fontcolor="black", label=<{TestGradients|exact_dtype : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules" [color="black", fontcolor="black", label=<{TestHelperModules|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_ignore_params_arg.TestModel" [color="black", fontcolor="black", label=<{TestModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.TestNamedTupleInput_1" [color="black", fontcolor="black", label=<{TestNamedTupleInput_1|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.tests.test_pass_manager.TestPassManager" [color="black", fontcolor="black", label=<{TestPassManager|<br ALIGN="LEFT"/>|test_pass_manager_builder(): None<br ALIGN="LEFT"/>test_these_before_those_pass_constraint(): None<br ALIGN="LEFT"/>test_this_before_that_pass_constraint(): None<br ALIGN="LEFT"/>test_two_pass_managers(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_use_rpc_pickler.TestPickler" [color="black", fontcolor="black", label=<{TestPickler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_distributed.TestSkip" [color="black", fontcolor="black", label=<{TestSkip|exit_code : int<br ALIGN="LEFT"/>message : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.backends.debugging.TestingOnlyCompileError" [color="black", fontcolor="red", label=<{TestingOnlyCompileError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_metaprogramming_utils.create_script_module.script_module.TheModule" [color="black", fontcolor="black", label=<{TheModule|submodule<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._thread_flow.ThreadFlow" [color="black", fontcolor="black", label=<{ThreadFlow|id : Optional[str]<br ALIGN="LEFT"/>immutable_state : Optional[Any]<br ALIGN="LEFT"/>initial_state : Optional[Any]<br ALIGN="LEFT"/>locations : List[_thread_flow_location.ThreadFlowLocation]<br ALIGN="LEFT"/>message : Optional[_message.Message]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.ThreadFlowLocation" [color="black", fontcolor="black", label=<{ThreadFlowLocation|index : int<br ALIGN="LEFT"/>location<br ALIGN="LEFT"/>stack : Stack \| None<br ALIGN="LEFT"/>state : Mapping[str, str]<br ALIGN="LEFT"/>|sarif(): sarif.ThreadFlowLocation<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._thread_flow_location.ThreadFlowLocation" [color="black", fontcolor="black", label=<{ThreadFlowLocation|execution_order : int<br ALIGN="LEFT"/>execution_time_utc : Optional[str]<br ALIGN="LEFT"/>importance : Literal['important', 'essential', 'unimportant']<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>kinds : Optional[List[str]]<br ALIGN="LEFT"/>location : Optional[_location.Location]<br ALIGN="LEFT"/>module : Optional[str]<br ALIGN="LEFT"/>nesting_level : Optional[int]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>stack : Optional[_stack.Stack]<br ALIGN="LEFT"/>state : Optional[Any]<br ALIGN="LEFT"/>taxa : Optional[List[_reporting_descriptor_reference.ReportingDescriptorReference]]<br ALIGN="LEFT"/>web_request : Optional[_web_request.WebRequest]<br ALIGN="LEFT"/>web_response : Optional[_web_response.WebResponse]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.ThreadLocalWorld" [color="black", fontcolor="black", label=<{ThreadLocalWorld|default_pg<br ALIGN="LEFT"/>group_count<br ALIGN="LEFT"/>pg_backend_config<br ALIGN="LEFT"/>pg_coalesce_state<br ALIGN="LEFT"/>pg_group_ranks<br ALIGN="LEFT"/>pg_map<br ALIGN="LEFT"/>pg_names<br ALIGN="LEFT"/>pg_to_tag<br ALIGN="LEFT"/>tags_to_pg<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ThreeAdd" [color="black", fontcolor="black", label=<{ThreeAdd|<br ALIGN="LEFT"/>|forward(x1, x2, x3, x4)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.nn.api.remote_module_test.ThreeWorkersRemoteModuleTest" [color="black", fontcolor="black", label=<{ThreeWorkersRemoteModuleTest|world_size<br ALIGN="LEFT"/>|test_create_remote_module_from_module_rref()<br ALIGN="LEFT"/>test_send_remote_module_over_the_wire()<br ALIGN="LEFT"/>test_send_remote_module_over_the_wire_script_not_supported()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.activation.Threshold" [color="black", fontcolor="black", label=<{Threshold|inplace : bool<br ALIGN="LEFT"/>threshold : float<br ALIGN="LEFT"/>value : float<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.throughput_benchmark.ThroughputBenchmark" [color="black", fontcolor="black", label=<{ThroughputBenchmark|<br ALIGN="LEFT"/>|add_input()<br ALIGN="LEFT"/>benchmark(num_calling_threads, num_warmup_iters, num_iters, profiler_output_path)<br ALIGN="LEFT"/>run_once()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._thunk.Thunk" [color="black", fontcolor="black", label=<{Thunk|f : Optional[Callable[[], R]]<br ALIGN="LEFT"/>r : Optional[R]<br ALIGN="LEFT"/>|force(): R<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.hints.TileHint" [color="black", fontcolor="black", label=<{TileHint|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.TilingSelect" [color="black", fontcolor="black", label=<{TilingSelect|<br ALIGN="LEFT"/>|select_tiling(fn_list, var_sizes_list): Tuple[List[int], List[int]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils._stubs.TimeitModuleType" [color="black", fontcolor="black", label=<{TimeitModuleType|<br ALIGN="LEFT"/>|timeit(number: int): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.timer.Timer" [color="black", fontcolor="black", label=<{Timer|<br ALIGN="LEFT"/>|adaptive_autorange(threshold: float): common.Measurement<br ALIGN="LEFT"/><I>autorange</I>(callback: Optional[Callable[[int, float], NoReturn]]): None<br ALIGN="LEFT"/>blocked_autorange(callback: Optional[Callable[[int, float], NoReturn]], min_run_time: float): common.Measurement<br ALIGN="LEFT"/>collect_callgrind(number: int): valgrind_timer_interface.CallgrindStats<br ALIGN="LEFT"/><I>repeat</I>(repeat: int, number: int): None<br ALIGN="LEFT"/>timeit(number: int): common.Measurement<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils._stubs.TimerClass" [color="black", fontcolor="black", label=<{TimerClass|<br ALIGN="LEFT"/>|timeit(number: int): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.api.TimerClient" [color="black", fontcolor="black", label=<{TimerClient|<br ALIGN="LEFT"/>|<I>acquire</I>(scope_id: str, expiration_time: float): None<br ALIGN="LEFT"/><I>release</I>(scope_id: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.api.TimerRequest" [color="black", fontcolor="black", label=<{TimerRequest|expiration_time : float<br ALIGN="LEFT"/>scope_id : str<br ALIGN="LEFT"/>worker_id : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.timer.api.TimerServer" [color="black", fontcolor="black", label=<{TimerServer|<br ALIGN="LEFT"/>|<I>clear_timers</I>(worker_ids: Set[Any]): None<br ALIGN="LEFT"/><I>get_expired_timers</I>(deadline: float): Dict[str, List[TimerRequest]]<br ALIGN="LEFT"/><I>register_timers</I>(timer_requests: List[TimerRequest]): None<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>stop(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.ToFloat" [color="black", fontcolor="black", label=<{ToFloat|is_real : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.TokenArgument" [color="black", fontcolor="black", label=<{TokenArgument|name : Annotated[str, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.graph_signature.TokenArgument" [color="black", fontcolor="black", label=<{TokenArgument|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool.Tool" [color="black", fontcolor="black", label=<{Tool|driver<br ALIGN="LEFT"/>extensions : Optional[List[_tool_component.ToolComponent]]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool_component.ToolComponent" [color="black", fontcolor="black", label=<{ToolComponent|associated_component : Optional[_tool_component_reference.ToolComponentReference]<br ALIGN="LEFT"/>contents : List[Literal['localizedData', 'nonLocalizedData']]<br ALIGN="LEFT"/>dotted_quad_file_version : Optional[str]<br ALIGN="LEFT"/>download_uri : Optional[str]<br ALIGN="LEFT"/>full_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>full_name : Optional[str]<br ALIGN="LEFT"/>global_message_strings : Optional[Any]<br ALIGN="LEFT"/>guid : Optional[str]<br ALIGN="LEFT"/>information_uri : Optional[str]<br ALIGN="LEFT"/>is_comprehensive : Optional[bool]<br ALIGN="LEFT"/>language : str<br ALIGN="LEFT"/>localized_data_semantic_version : Optional[str]<br ALIGN="LEFT"/>locations : Optional[List[_artifact_location.ArtifactLocation]]<br ALIGN="LEFT"/>minimum_required_localized_data_semantic_version : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>notifications : Optional[List[_reporting_descriptor.ReportingDescriptor]]<br ALIGN="LEFT"/>organization : Optional[str]<br ALIGN="LEFT"/>product : Optional[str]<br ALIGN="LEFT"/>product_suite : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>release_date_utc : Optional[str]<br ALIGN="LEFT"/>rules : Optional[List[_reporting_descriptor.ReportingDescriptor]]<br ALIGN="LEFT"/>semantic_version : Optional[str]<br ALIGN="LEFT"/>short_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>supported_taxonomies : Optional[List[_tool_component_reference.ToolComponentReference]]<br ALIGN="LEFT"/>taxa : Optional[List[_reporting_descriptor.ReportingDescriptor]]<br ALIGN="LEFT"/>translation_metadata : Optional[_translation_metadata.TranslationMetadata]<br ALIGN="LEFT"/>version : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool_component_reference.ToolComponentReference" [color="black", fontcolor="black", label=<{ToolComponentReference|guid : Optional[str]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>name : Optional[str]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._trace.TopLevelTracedModule" [color="black", fontcolor="black", label=<{TopLevelTracedModule|forward : Callable[..., Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.TorchBindObject" [color="black", fontcolor="black", label=<{TorchBindObject|name : str<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|codegen_reference(writer: Optional[IndentedBuffer]): str<br ALIGN="LEFT"/>get_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops.TorchBindOpOverload" [color="black", fontcolor="black", label=<{TorchBindOpOverload|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.torch.TorchCtxManagerClassVariable" [color="black", fontcolor="black", label=<{TorchCtxManagerClassVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>is_matching_cls(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._python_dispatch.TorchDispatchMode" [color="black", fontcolor="black", label=<{TorchDispatchMode|old_dispatch_mode_flags : Deque[bool]<br ALIGN="LEFT"/>old_non_infra_dispatch_mode_flags : Deque[bool]<br ALIGN="LEFT"/>|is_infra_mode()<br ALIGN="LEFT"/>push()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.TorchDynamoException" [color="black", fontcolor="red", label=<{TorchDynamoException|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._errors.TorchExportError" [color="black", fontcolor="red", label=<{TorchExportError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.TorchExportNonStrictStrategy" [color="black", fontcolor="black", label=<{TorchExportNonStrictStrategy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.TorchExportStrategy" [color="black", fontcolor="black", label=<{TorchExportStrategy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.TorchFunctionDisableVariable" [color="black", fontcolor="black", label=<{TorchFunctionDisableVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor.TorchFunctionMetadataMode" [color="black", fontcolor="black", label=<{TorchFunctionMetadataMode|tracer : Union<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.overrides.TorchFunctionMode" [color="black", fontcolor="black", label=<{TorchFunctionMode|inner : str<br ALIGN="LEFT"/>|push()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.TorchFunctionModeStackSource" [color="black", fontcolor="black", label=<{TorchFunctionModeStackSource|ind : int<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.TorchFunctionModeStackStateManager" [color="black", fontcolor="black", label=<{TorchFunctionModeStackStateManager|stack : list<br ALIGN="LEFT"/>|temp_restore_stack()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.TorchFunctionModeStackVariable" [color="black", fontcolor="black", label=<{TorchFunctionModeStackVariable|offset : int<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>stack_value_singleton : object<br ALIGN="LEFT"/>symbolic_stack<br ALIGN="LEFT"/>|clear_default_device(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>get_mode_index(ind)<br ALIGN="LEFT"/>is_device_context(var)<br ALIGN="LEFT"/>register_device_context_insertion(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>register_mutation(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.torch_function.TorchFunctionModeVariable" [color="black", fontcolor="black", label=<{TorchFunctionModeVariable|cm_obj<br ALIGN="LEFT"/>source : NoneType<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|call_torch_function(tx: 'InstructionTranslator', fn, types, args, kwargs)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>exit_on_graph_break()<br ALIGN="LEFT"/>fn_name()<br ALIGN="LEFT"/>is_supported_torch_function_mode(ty)<br ALIGN="LEFT"/>module_name()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>reconstruct_type(codegen)<br ALIGN="LEFT"/>supports_graph_breaks()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [color="black", fontcolor="black", label=<{TorchHigherOrderOperatorVariable|source : Optional[Source]<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>make(value, source)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.torch.TorchInGraphFunctionVariable" [color="black", fontcolor="black", label=<{TorchInGraphFunctionVariable|class_type<br ALIGN="LEFT"/>has_grad_fn : bool<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_nn_parameter(tx, data, requires_grad)<br ALIGN="LEFT"/>call_tensor_method(tx, args, kwargs)<br ALIGN="LEFT"/>get_function()<br ALIGN="LEFT"/>is_tensor_method()<br ALIGN="LEFT"/>torch_function_override_enabled(tx, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._logging._internal.TorchLogsFormatter" [color="black", fontcolor="black", label=<{TorchLogsFormatter|<br ALIGN="LEFT"/>|format(record)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.TorchPatcher" [color="black", fontcolor="black", label=<{TorchPatcher|<br ALIGN="LEFT"/>|patch()<br ALIGN="LEFT"/>suppress_torch_distributed_warnings(fn)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._prims.context.TorchRefsMode" [color="black", fontcolor="black", label=<{TorchRefsMode|prims_mode_cls : nullcontext<br ALIGN="LEFT"/>should_fallback_fn<br ALIGN="LEFT"/>strict : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.TorchRuntimeError" [color="black", fontcolor="red", label=<{TorchRuntimeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer.TorchScalarTypes" [color="black", fontcolor="black", label=<{TorchScalarTypes|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.script_object.TorchScriptObjectVariable" [color="black", fontcolor="black", label=<{TorchScriptObjectVariable|proxy<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>call_method(tx, name, args, kwargs)<br ALIGN="LEFT"/>create(proxy, value)<br ALIGN="LEFT"/>is_matching_cls(user_cls: type)<br ALIGN="LEFT"/>var_getattr(tx, name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._diagnostic.TorchScriptOnnxExportDiagnostic" [color="black", fontcolor="black", label=<{TorchScriptOnnxExportDiagnostic|cpp_call_stack : infra.Stack \| None<br ALIGN="LEFT"/>python_call_stack : infra.Stack \| None<br ALIGN="LEFT"/>|record_cpp_call_stack(frames_to_skip: int): infra.Stack<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.split_cat.TorchSplit" [color="black", fontcolor="black", label=<{TorchSplit|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.db.examples.unsupported_operator.TorchSymMin" [color="black", fontcolor="black", label=<{TorchSymMin|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._core.TorchTensor" [color="black", fontcolor="black", label=<{TorchTensor|raw<br ALIGN="LEFT"/>|numpy(): npt.NDArray<br ALIGN="LEFT"/>tobytes(): bytes<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.torch_version.TorchVersion" [color="black", fontcolor="black", label=<{TorchVersion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.TorchVersionVariable" [color="black", fontcolor="black", label=<{TorchVersionVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_zero_output_features.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|net1<br ALIGN="LEFT"/>net2<br ALIGN="LEFT"/>relu<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_unused_params_rebuild_buckets_exception.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|net1<br ALIGN="LEFT"/>net2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_shared_grad_acc_unused_params.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|bias<br ALIGN="LEFT"/>net1<br ALIGN="LEFT"/>net2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_device.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|lin<br ALIGN="LEFT"/>|forward(x, expected_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_control_flow_different_across_ranks.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|lin1<br ALIGN="LEFT"/>lin2<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_different_graph_across_ranks.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|lin1<br ALIGN="LEFT"/>lin2<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_detect_ddp_is_actually_static.ToyModel" [color="black", fontcolor="black", label=<{ToyModel|net1<br ALIGN="LEFT"/>net2<br ALIGN="LEFT"/>|forward(x, find_unused, dynamic)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.create_parameter_op.TracableCreateParameter" [color="black", fontcolor="black", label=<{TracableCreateParameter|<br ALIGN="LEFT"/>|backward(ctx: Any): Tuple[None, torch.Tensor]<br ALIGN="LEFT"/>forward(ctx: Any, tensor: Any, placeholder: Any): torch.nn.Parameter<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.proxy.TraceError" [color="black", fontcolor="red", label=<{TraceError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher.TraceFn" [color="black", fontcolor="black", label=<{TraceFn|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.TraceId" [color="black", fontcolor="black", label=<{TraceId|attempt : int<br ALIGN="LEFT"/>compile_id : CompileId<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo._trace_wrapped_higher_order_op.TraceWrapped" [color="black", fontcolor="black", label=<{TraceWrapped|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.TraceWrappedHigherOrderOperatorVariable" [color="black", fontcolor="black", label=<{TraceWrappedHigherOrderOperatorVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.TraceableTritonKernelWrapper" [color="black", fontcolor="black", label=<{TraceableTritonKernelWrapper|grid : Optional['TritonGridType']<br ALIGN="LEFT"/>kernel : str<br ALIGN="LEFT"/>kernel_idx : Optional[int]<br ALIGN="LEFT"/>|run(): Any<br ALIGN="LEFT"/>specialize_symbolic(arg: Sequence[Any]): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._trace.TracedModule" [color="black", fontcolor="black", label=<{TracedModule|<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace.Tracer" [color="black", fontcolor="black", label=<{Tracer|graph<br ALIGN="LEFT"/>module_stack : OrderedDict<br ALIGN="LEFT"/>node_name_to_scope : Dict[str, Tuple[str, type]]<br ALIGN="LEFT"/>num_calls : Dict[str, int]<br ALIGN="LEFT"/>param_shapes_constant : bool<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>root_module_name : str<br ALIGN="LEFT"/>scope<br ALIGN="LEFT"/>submodule_paths : NoneType, Optional[Dict[torch.nn.Module, str]]<br ALIGN="LEFT"/>tensor_attrs : Dict[Union[torch.Tensor, ScriptObject, FakeScriptObject], str]<br ALIGN="LEFT"/>|call_module(m: torch.nn.Module, forward: Callable[..., Any], args: Tuple[Any, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>create_arg(a: Any): 'Argument'<br ALIGN="LEFT"/>create_args_for_root(root_fn, is_module, concrete_args)<br ALIGN="LEFT"/>get_fresh_qualname(prefix: str): str<br ALIGN="LEFT"/>getattr(attr: str, attr_val: Any, parameter_proxy_cache: Dict[str, Any])<br ALIGN="LEFT"/>is_leaf_module(m: torch.nn.Module, module_qualified_name: str): bool<br ALIGN="LEFT"/>path_of_module(mod: torch.nn.Module): str<br ALIGN="LEFT"/>trace(root: Union[torch.nn.Module, Callable[..., Any]], concrete_args: Optional[Dict[str, Any]]): Graph<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.proxy.TracerBase" [color="black", fontcolor="black", label=<{TracerBase|check_mutable_operations : bool<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>module_stack : OrderedDict[str, Tuple[str, Any]]<br ALIGN="LEFT"/>node_name_to_scope : Dict[str, Tuple[str, type]]<br ALIGN="LEFT"/>proxy_buffer_attributes : bool<br ALIGN="LEFT"/>record_stack_traces : bool<br ALIGN="LEFT"/>scope<br ALIGN="LEFT"/>trace_asserts : bool<br ALIGN="LEFT"/>traced_func_name : str<br ALIGN="LEFT"/>|create_arg(a: Any): Argument<br ALIGN="LEFT"/>create_node(kind: str, target: Target, args: Tuple[Argument, ...], kwargs: Dict[str, Argument], name: Optional[str], type_expr: Optional[Any]): Node<br ALIGN="LEFT"/>create_proxy(kind: str, target: Target, args: Tuple[Any, ...], kwargs: Dict[str, Any], name: Optional[str], type_expr: Optional[Any], proxy_factory_fn: Callable[[Node], 'Proxy'])<br ALIGN="LEFT"/>iter(obj: 'Proxy'): Iterator<br ALIGN="LEFT"/>keys(obj: 'Proxy'): Any<br ALIGN="LEFT"/>proxy(node: Node): 'Proxy'<br ALIGN="LEFT"/>to_bool(obj: 'Proxy'): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._trace.TracerWarning" [color="black", fontcolor="red", label=<{TracerWarning|<br ALIGN="LEFT"/>|ignore_lib_warnings()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._trace.TracingCheckError" [color="black", fontcolor="red", label=<{TracingCheckError|message : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._trace_utils.TracingConfig" [color="black", fontcolor="black", label=<{TracingConfig|concrete_args : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._guards.TracingContext" [color="black", fontcolor="black", label=<{TracingContext|aot_graph_name : NoneType<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>fakify_first_call : bool<br ALIGN="LEFT"/>force_unspec_int_unbacked_size_like : bool<br ALIGN="LEFT"/>frame_summary_stack : list<br ALIGN="LEFT"/>fw_metadata : NoneType<br ALIGN="LEFT"/>global_context<br ALIGN="LEFT"/>guards_context<br ALIGN="LEFT"/>hop_dispatch_set_cache<br ALIGN="LEFT"/>loc_in_frame : NoneType<br ALIGN="LEFT"/>module_context<br ALIGN="LEFT"/>output_strides : Optional[List[Optional[Tuple[int, ...]]]]<br ALIGN="LEFT"/>params_flat : NoneType<br ALIGN="LEFT"/>params_flat_unwrap_subclasses : NoneType<br ALIGN="LEFT"/>params_unwrapped_to_flat_index : NoneType<br ALIGN="LEFT"/>tensor_to_context<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>clear_frame()<br ALIGN="LEFT"/>current_frame(frame_summary)<br ALIGN="LEFT"/>extract_stack()<br ALIGN="LEFT"/>get(): TracingContext<br ALIGN="LEFT"/>patch()<br ALIGN="LEFT"/>report_output_strides()<br ALIGN="LEFT"/>set_current_loc(filename, lineno, frame_name)<br ALIGN="LEFT"/>try_get(): Optional[TracingContext]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.subgraph_lowering.TracingOpsHandler" [color="black", fontcolor="black", label=<{TracingOpsHandler|placeholders<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|output(): torch.fx.Node<br ALIGN="LEFT"/>placeholder(idx: int): torch.fx.Proxy<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.TracingTritonHOPifier" [color="black", fontcolor="black", label=<{TracingTritonHOPifier|<br ALIGN="LEFT"/>|call_HOP(variable: 'TraceableTritonKernelWrapper', grids: List['TritonGridTupleType'], combined_args: Dict[str, Any], tx: None): None<br ALIGN="LEFT"/>call_grid(grid: 'TritonGridCallableType', meta: 'TritonMetaParamsType', tx: None): Tuple[Union[int, sympy.Expr, SymInt], ...]<br ALIGN="LEFT"/>check_grid(grid: 'TritonGridType'): Tuple[Union[int, sympy.Expr, SymInt], ...]<br ALIGN="LEFT"/>get_value(val: Any): Any<br ALIGN="LEFT"/>is_callable(maybe_callable: Any): bool<br ALIGN="LEFT"/>raise_unsupported(msg: str): Never<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.TrackedFake" [color="black", fontcolor="black", label=<{TrackedFake|fake : Union[FakeTensor, SymInt]<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>symbolic_context : Optional[SymbolicContext]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TrackedInput" [color="black", fontcolor="black", label=<{TrackedInput|index : int<br ALIGN="LEFT"/>type_desc : str<br ALIGN="LEFT"/>val : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TrackedInputIter" [color="black", fontcolor="black", label=<{TrackedInputIter|child_iter : enumerate<br ALIGN="LEFT"/>input_type_desc<br ALIGN="LEFT"/>item_callback : NoneType<br ALIGN="LEFT"/>restrict_to_index : NoneType<br ALIGN="LEFT"/>set_seed : bool<br ALIGN="LEFT"/>test_fn : NoneType<br ALIGN="LEFT"/>track_callback : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.convert_frame.Tracker" [color="black", fontcolor="black", label=<{Tracker|seen : List[ReferenceType[CodeType]]<br ALIGN="LEFT"/>seen_ids : Set[int]<br ALIGN="LEFT"/>|add(strong_obj: CodeType): None<br ALIGN="LEFT"/>clear(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer" [color="black", fontcolor="black", label=<{Trainer|ddp_params : tuple<br ALIGN="LEFT"/>hybrid_module<br ALIGN="LEFT"/>non_ddp_params : tuple<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>remote_em_rref : RRef<br ALIGN="LEFT"/>remote_net_rref : RRef<br ALIGN="LEFT"/>trainer_group : NoneType<br ALIGN="LEFT"/>|destroy_pg()<br ALIGN="LEFT"/>train_batch(mini_batch: FeatureSet, trainer_has_less_inputs: bool, simulate_uneven_inputs: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.examples.parameter_server_test.Trainer" [color="black", fontcolor="black", label=<{Trainer|loss_fn<br ALIGN="LEFT"/>ps_rref<br ALIGN="LEFT"/>|get_next_batch()<br ALIGN="LEFT"/>train()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.lightning.callbacks.data_sparsity.TrainingAwareDataSparsity" [color="black", fontcolor="black", label=<{TrainingAwareDataSparsity|data_scheduler : Optional[Any]<br ALIGN="LEFT"/>data_scheduler_args<br ALIGN="LEFT"/>data_scheduler_class<br ALIGN="LEFT"/>data_sparsifier : Optional[Any]<br ALIGN="LEFT"/>data_sparsifier_args<br ALIGN="LEFT"/>data_sparsifier_class<br ALIGN="LEFT"/>data_sparsifier_state_dict : Optional[Any]<br ALIGN="LEFT"/>sparsified : Optional[torch.nn.Module]<br ALIGN="LEFT"/>|on_train_end(trainer, pl_module)<br ALIGN="LEFT"/>on_train_epoch_end(trainer, pl_module)<br ALIGN="LEFT"/>on_train_epoch_start(trainer, pl_module)<br ALIGN="LEFT"/>on_train_start(trainer, pl_module): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.verifier.TrainingIRVerifier" [color="black", fontcolor="black", label=<{TrainingIRVerifier|dialect : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._common_utils.TrainingState" [color="black", fontcolor="black", label=<{TrainingState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.TrainingState" [color="black", fontcolor="black", label=<{TrainingState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transforms.Transform" [color="black", fontcolor="black", label=<{Transform|bijective : bool<br ALIGN="LEFT"/>codomain<br ALIGN="LEFT"/>domain<br ALIGN="LEFT"/>event_dim<br ALIGN="LEFT"/>inv<br ALIGN="LEFT"/>sign<br ALIGN="LEFT"/>|forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/><I>log_abs_det_jacobian</I>(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx._pass.Transform" [color="black", fontcolor="black", label=<{Transform|diagnostic_context<br ALIGN="LEFT"/>fake_mode : fake_tensor.FakeTensorMode \| None<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>|run(): torch.fx.GraphModule<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo._trace_wrapped_higher_order_op.TransformGetItemToIndex" [color="black", fontcolor="black", label=<{TransformGetItemToIndex|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.transformed_distribution.TransformedDistribution" [color="black", fontcolor="black", label=<{TransformedDistribution|arg_constraints : Dict[str, constraints.Constraint]<br ALIGN="LEFT"/>base_dist : NoneType<br ALIGN="LEFT"/>has_rsample<br ALIGN="LEFT"/>transforms : list<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.interpreter.Transformer" [color="black", fontcolor="black", label=<{Transformer|new_graph<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|call_function(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>call_module(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>get_attr(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Proxy<br ALIGN="LEFT"/>placeholder(target: 'Target', args: Tuple[Argument, ...], kwargs: Dict[str, Any]): Proxy<br ALIGN="LEFT"/>transform(): GraphModule<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [color="black", fontcolor="black", label=<{Transformer|checkpoint_activations<br ALIGN="LEFT"/>dropout<br ALIGN="LEFT"/>layers<br ALIGN="LEFT"/>max_seq_len<br ALIGN="LEFT"/>model_args<br ALIGN="LEFT"/>norm<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>pos_embeddings<br ALIGN="LEFT"/>tok_embeddings<br ALIGN="LEFT"/>|forward(tokens)<br ALIGN="LEFT"/>parallelize(module: 'Transformer', device_mesh: DeviceMesh, use_seq_parallel: bool, local_output_for_attn: bool): nn.Module<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.transformer.Transformer" [color="black", fontcolor="black", label=<{Transformer|batch_first : bool<br ALIGN="LEFT"/>d_model : int<br ALIGN="LEFT"/>decoder<br ALIGN="LEFT"/>encoder<br ALIGN="LEFT"/>nhead : int<br ALIGN="LEFT"/>|forward(src: Tensor, tgt: Tensor, src_mask: Optional[Tensor], tgt_mask: Optional[Tensor], memory_mask: Optional[Tensor], src_key_padding_mask: Optional[Tensor], tgt_key_padding_mask: Optional[Tensor], memory_key_padding_mask: Optional[Tensor], src_is_causal: Optional[bool], tgt_is_causal: Optional[bool], memory_is_causal: bool): Tensor<br ALIGN="LEFT"/>generate_square_subsequent_mask(sz: int, device: Optional[torch.device], dtype: Optional[torch.dtype]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" [color="black", fontcolor="black", label=<{TransformerBlock|attention<br ALIGN="LEFT"/>attention_norm<br ALIGN="LEFT"/>feed_forward<br ALIGN="LEFT"/>ffn_norm<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.transformer.TransformerDecoder" [color="black", fontcolor="black", label=<{TransformerDecoder|layers<br ALIGN="LEFT"/>norm : Optional[Module]<br ALIGN="LEFT"/>num_layers : int<br ALIGN="LEFT"/>|forward(tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor], memory_mask: Optional[Tensor], tgt_key_padding_mask: Optional[Tensor], memory_key_padding_mask: Optional[Tensor], tgt_is_causal: Optional[bool], memory_is_causal: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.transformer.TransformerDecoderLayer" [color="black", fontcolor="black", label=<{TransformerDecoderLayer|activation<br ALIGN="LEFT"/>dropout<br ALIGN="LEFT"/>dropout1<br ALIGN="LEFT"/>dropout2<br ALIGN="LEFT"/>dropout3<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>multihead_attn<br ALIGN="LEFT"/>norm1<br ALIGN="LEFT"/>norm2<br ALIGN="LEFT"/>norm3<br ALIGN="LEFT"/>norm_first : bool<br ALIGN="LEFT"/>self_attn<br ALIGN="LEFT"/>|forward(tgt: Tensor, memory: Tensor, tgt_mask: Optional[Tensor], memory_mask: Optional[Tensor], tgt_key_padding_mask: Optional[Tensor], memory_key_padding_mask: Optional[Tensor], tgt_is_causal: bool, memory_is_causal: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.transformer.TransformerEncoder" [color="black", fontcolor="black", label=<{TransformerEncoder|enable_nested_tensor : bool<br ALIGN="LEFT"/>layers<br ALIGN="LEFT"/>mask_check : bool<br ALIGN="LEFT"/>norm : Optional[Module]<br ALIGN="LEFT"/>num_layers : int<br ALIGN="LEFT"/>use_nested_tensor : bool<br ALIGN="LEFT"/>|forward(src: Tensor, mask: Optional[Tensor], src_key_padding_mask: Optional[Tensor], is_causal: Optional[bool]): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.transformer.TransformerEncoderLayer" [color="black", fontcolor="black", label=<{TransformerEncoderLayer|activation : Union[str, Callable[[Tensor], Tensor]]<br ALIGN="LEFT"/>activation_relu_or_gelu : int<br ALIGN="LEFT"/>dropout<br ALIGN="LEFT"/>dropout1<br ALIGN="LEFT"/>dropout2<br ALIGN="LEFT"/>linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>norm1<br ALIGN="LEFT"/>norm2<br ALIGN="LEFT"/>norm_first : bool<br ALIGN="LEFT"/>self_attn<br ALIGN="LEFT"/>|forward(src: Tensor, src_mask: Optional[Tensor], src_key_padding_mask: Optional[Tensor], is_causal: bool): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.interpreter.Transformer.__init__.TransformerTracer" [color="black", fontcolor="black", label=<{TransformerTracer|graph<br ALIGN="LEFT"/>root<br ALIGN="LEFT"/>tensor_attrs : Dict[torch.Tensor, str]<br ALIGN="LEFT"/>|is_leaf_module(_, __): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_fsdp.TransformerWithSharedParams" [color="black", fontcolor="black", label=<{TransformerWithSharedParams|bn<br ALIGN="LEFT"/>bs : int<br ALIGN="LEFT"/>embed_tokens<br ALIGN="LEFT"/>output_proj<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>transformer<br ALIGN="LEFT"/>world_size<br ALIGN="LEFT"/>|forward(src_ids, tgt_ids)<br ALIGN="LEFT"/>get_ignored_modules()<br ALIGN="LEFT"/>get_input(device)<br ALIGN="LEFT"/>get_loss(input, output)<br ALIGN="LEFT"/>init(group: dist.ProcessGroup, fsdp_init_mode: FSDPInitMode, device_init_mode: DEVICEInitMode, fsdp_kwargs: Optional[Dict[str, Any]], deterministic: bool, add_bn: bool): Union[nn.Module, FSDP]<br ALIGN="LEFT"/>run_backward(loss)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._translation_metadata.TranslationMetadata" [color="black", fontcolor="black", label=<{TranslationMetadata|download_uri : Optional[str]<br ALIGN="LEFT"/>full_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>full_name : Optional[str]<br ALIGN="LEFT"/>information_uri : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>short_description : Optional[_multiformat_message_string.MultiformatMessageString]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator.TranslationValidator" [color="black", fontcolor="black", label=<{TranslationValidator|symbols : Dict[sympy.Symbol, z3.ExprRef]<br ALIGN="LEFT"/>|add_assertion(e: Union[z3.BoolRef, sympy.Basic]): None<br ALIGN="LEFT"/>add_source_expr(e: z3.BoolRef): None<br ALIGN="LEFT"/>add_target_expr(e: 'sympy.logic.boolalg.Boolean'): None<br ALIGN="LEFT"/>add_var(symbol: sympy.Symbol, type: Type): z3.ExprRef<br ALIGN="LEFT"/>to_z3_boolean_expr(e: sympy.Basic): z3.BoolRef<br ALIGN="LEFT"/>validate(): None<br ALIGN="LEFT"/>z3var(symbol: sympy.Symbol): z3.ExprRef<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.migrate_gradual_types.constraint.Transpose" [color="black", fontcolor="black", label=<{Transpose|index1<br ALIGN="LEFT"/>index2<br ALIGN="LEFT"/>input_var<br ALIGN="LEFT"/>output<br ALIGN="LEFT"/>tensor_size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees.TreeManagerContainer" [color="black", fontcolor="black", label=<{TreeManagerContainer|device_index : int<br ALIGN="LEFT"/>graph : NoneType, Optional[torch.cuda.CUDAGraph]<br ALIGN="LEFT"/>live_cudagraphify_fns : int<br ALIGN="LEFT"/>live_storages_count : int<br ALIGN="LEFT"/>lock : lock<br ALIGN="LEFT"/>tree_manager : NoneType, Optional[CUDAGraphTreeManager]<br ALIGN="LEFT"/>|add_strong_reference(fn: Callable[..., Any]): None<br ALIGN="LEFT"/>finalize_cudagraphify_fn(): None<br ALIGN="LEFT"/>get_tree_manager(): CUDAGraphTreeManager<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._pytree.TreeSpec" [color="black", fontcolor="black", label=<{TreeSpec|children_specs : List['TreeSpec']<br ALIGN="LEFT"/>context : Any<br ALIGN="LEFT"/>num_children : int<br ALIGN="LEFT"/>num_leaves : int<br ALIGN="LEFT"/>num_nodes : int<br ALIGN="LEFT"/>type : Any<br ALIGN="LEFT"/>|flatten_up_to(tree: PyTree): List[PyTree]<br ALIGN="LEFT"/>is_leaf(): bool<br ALIGN="LEFT"/>unflatten(leaves: Iterable[Any]): PyTree<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.Trie" [color="black", fontcolor="black", label=<{Trie|root<br ALIGN="LEFT"/>|add(word)<br ALIGN="LEFT"/>dump()<br ALIGN="LEFT"/>export_to_regex()<br ALIGN="LEFT"/>pattern()<br ALIGN="LEFT"/>quote(char)<br ALIGN="LEFT"/>search(word)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.TrieNode" [color="black", fontcolor="black", label=<{TrieNode|children : dict<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.loss.TripletMarginLoss" [color="black", fontcolor="black", label=<{TripletMarginLoss|eps : float<br ALIGN="LEFT"/>margin : float<br ALIGN="LEFT"/>p : float<br ALIGN="LEFT"/>swap : bool<br ALIGN="LEFT"/>|forward(anchor: Tensor, positive: Tensor, negative: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss.TripletMarginWithDistanceLoss" [color="black", fontcolor="black", label=<{TripletMarginWithDistanceLoss|distance_function : Optional[Callable[[Tensor, Tensor], Tensor]]<br ALIGN="LEFT"/>margin : float<br ALIGN="LEFT"/>swap : bool<br ALIGN="LEFT"/>|forward(anchor: Tensor, positive: Tensor, negative: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TritonBenchmarkRequest" [color="black", fontcolor="black", label=<{TritonBenchmarkRequest|grid : List[int]<br ALIGN="LEFT"/>matrix_instr_nonkdim : int<br ALIGN="LEFT"/>module_cache_key : str<br ALIGN="LEFT"/>module_path : str<br ALIGN="LEFT"/>num_stages : int<br ALIGN="LEFT"/>num_warps : int<br ALIGN="LEFT"/>workspace_arg : Optional[WorkspaceArg]<br ALIGN="LEFT"/>|make_run_fn(): Callable[[], None]<br ALIGN="LEFT"/>precompile()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.benchmarking.TritonBenchmarker" [color="black", fontcolor="black", label=<{TritonBenchmarker|triton_do_bench<br ALIGN="LEFT"/>|benchmark_gpu(_callable: Callable[[], Any]): float<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.triton_bundler.TritonBundleEntry" [color="black", fontcolor="black", label=<{TritonBundleEntry|device : int<br ALIGN="LEFT"/>directory : str<br ALIGN="LEFT"/>kernel_hash : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.triton_bundler.TritonBundler" [color="black", fontcolor="black", label=<{TritonBundler|<br ALIGN="LEFT"/>|begin_compile(): None<br ALIGN="LEFT"/>collect(): Tuple[List[TritonKernelArtifacts], Optional[TritonBundlerMetadata]]<br ALIGN="LEFT"/>end_compile(): None<br ALIGN="LEFT"/>is_enabled(): bool<br ALIGN="LEFT"/>put(kernel_hash: str, device: int): None<br ALIGN="LEFT"/>read_and_emit(bundle: List[TritonKernelArtifacts]): Optional[TritonBundlerMetadata]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.triton_bundler.TritonBundlerMetadata" [color="black", fontcolor="black", label=<{TritonBundlerMetadata|cached_kernel_names : List[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TritonCPUBenchmarkRequest" [color="black", fontcolor="black", label=<{TritonCPUBenchmarkRequest|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonCSE" [color="black", fontcolor="black", label=<{TritonCSE|<br ALIGN="LEFT"/>|augment_key(cache_key: object): object<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonCSEVariable" [color="black", fontcolor="black", label=<{TritonCSEVariable|mask_vars<br ALIGN="LEFT"/>|update_on_args(name, args, kwargs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.TritonCodeCache" [color="black", fontcolor="black", label=<{TritonCodeCache|<br ALIGN="LEFT"/>|load(kernel_name: str, source_code: str): ModuleType<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codecache.TritonFuture" [color="black", fontcolor="black", label=<{TritonFuture|future : NoneType, Optional[Future[Any]]<br ALIGN="LEFT"/>kernel : module<br ALIGN="LEFT"/>|result(): ModuleType<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TritonGPUBenchmarkRequest" [color="black", fontcolor="black", label=<{TritonGPUBenchmarkRequest|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.TritonHOPifier" [color="black", fontcolor="black", label=<{TritonHOPifier|<br ALIGN="LEFT"/>|<I>call_HOP</I>(variable, grids, combined_args: Dict[str, Any], tx): Optional['ConstantVariable']<br ALIGN="LEFT"/>call_getitem(variable: Union['TritonKernelVariable', 'TraceableTritonKernelWrapper'], args: Sequence[Any]): Union['TritonKernelVariable', 'TraceableTritonKernelWrapper']<br ALIGN="LEFT"/><I>call_grid</I>(grid, meta, tx): Union[Tuple[Union[int, sympy.Expr, SymInt], ...], Tuple['Proxy', ...]]<br ALIGN="LEFT"/>call_run(variable: Union['TritonKernelVariable', 'TraceableTritonKernelWrapper'], args: Sequence[Any], kwargs: Dict[str, Any], tx: Optional['InstructionTranslator']): Optional['ConstantVariable']<br ALIGN="LEFT"/>call_triton_kernel(variable: Union['TritonKernelVariable', 'TraceableTritonKernelWrapper'], args: Sequence[Any], kwargs: Dict[str, Any], tx: Optional['InstructionTranslator']): Optional['ConstantVariable']<br ALIGN="LEFT"/><I>check_grid</I>(grid): Union[Tuple[Union[int, sympy.Expr, SymInt], ...], Tuple['Proxy', ...]]<br ALIGN="LEFT"/><I>get_value</I>(val: Any): Any<br ALIGN="LEFT"/>init_variable(variable: Union['TraceableTritonKernelWrapper', 'TritonKernelVariable'], kernel: 'TritonKernelType', kernel_idx: Optional[int], grid: Optional['TritonGridType']): None<br ALIGN="LEFT"/><I>is_callable</I>(maybe_callable: Any): bool<br ALIGN="LEFT"/><I>raise_unsupported</I>(msg: str): Never<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonKernel" [color="black", fontcolor="black", label=<{TritonKernel|allow_block_ptr : bool<br ALIGN="LEFT"/>assert_function<br ALIGN="LEFT"/>autotune_hints<br ALIGN="LEFT"/>block_ptr_id : count<br ALIGN="LEFT"/>cooperative_reduction_workspace_cache<br ALIGN="LEFT"/>cse<br ALIGN="LEFT"/>fixed_config : Optional[FixedTritonConfig]<br ALIGN="LEFT"/>helper_functions<br ALIGN="LEFT"/>inside_reduction : bool<br ALIGN="LEFT"/>kexpr : Callable[[sympy.Expr], str]<br ALIGN="LEFT"/>min_elem_per_thread : int<br ALIGN="LEFT"/>optimize_mask : bool<br ALIGN="LEFT"/>outside_loop_vars<br ALIGN="LEFT"/>overrides<br ALIGN="LEFT"/>post_loop_combine<br ALIGN="LEFT"/>post_loop_store<br ALIGN="LEFT"/>semaphores_name : str<br ALIGN="LEFT"/>triton_meta : Optional[Dict[str, Any]], dict<br ALIGN="LEFT"/>|add_numel_to_call_args_and_grid(name, call_args, arg_types, grid)<br ALIGN="LEFT"/>bucketize(values: CSEVariable, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: CSEVariable, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[CSEVariable]): CSEVariable<br ALIGN="LEFT"/>call_kernel(name: str, node: Optional[IRNode])<br ALIGN="LEFT"/>check_bounds(expr: sympy.Expr, size: sympy.Expr, lower: bool, upper: bool)<br ALIGN="LEFT"/>codegen_block_ptr(name: str, var: str, indexing: BlockPtrOptions, other): Tuple[str, Optional[DeferredLine], str]<br ALIGN="LEFT"/>codegen_block_ptr_store_line(name, indexing, block_ptr, value, other)<br ALIGN="LEFT"/>codegen_body()<br ALIGN="LEFT"/>codegen_cooperative_reduction_peer_combine(result_var, dtype)<br ALIGN="LEFT"/>codegen_iteration_ranges_entry(entry: IterationRangesEntry)<br ALIGN="LEFT"/>codegen_kernel(name)<br ALIGN="LEFT"/>codegen_kernel_benchmark(num_gb, grid)<br ALIGN="LEFT"/>codegen_nan_check()<br ALIGN="LEFT"/>codegen_range_tree()<br ALIGN="LEFT"/>codegen_reduction_indices(buffer): None<br ALIGN="LEFT"/>codegen_reduction_numels(buffer): None<br ALIGN="LEFT"/>codegen_static_numels(code)<br ALIGN="LEFT"/>create_cse_var()<br ALIGN="LEFT"/>dtype_to_str(dtype: torch.dtype): str<br ALIGN="LEFT"/>filter_masks(mask_vars)<br ALIGN="LEFT"/>get_load_buffer(indexing)<br ALIGN="LEFT"/>get_reduction_prefixes(): List[str]<br ALIGN="LEFT"/>guard_cooperative_store(name, buffer)<br ALIGN="LEFT"/>has_persistent_RBLOCK(rnumel)<br ALIGN="LEFT"/>imports_for_benchmark_kernel()<br ALIGN="LEFT"/>indexing(index: sympy.Expr)<br ALIGN="LEFT"/>inductor_meta_common()<br ALIGN="LEFT"/>init_cooperative_reduction()<br ALIGN="LEFT"/>iteration_ranges_codegen_header(entry, code)<br ALIGN="LEFT"/>iteration_ranges_get_pid(entry)<br ALIGN="LEFT"/>iteration_ranges_ranges_code(entry)<br ALIGN="LEFT"/>iteration_ranges_scalar_code(entry, value)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>max_block(prefix)<br ALIGN="LEFT"/>max_rsplit()<br ALIGN="LEFT"/>need_numel_args()<br ALIGN="LEFT"/>reduction(dtype: torch.dtype, src_dtype: torch.dtype, reduction_type: ReductionType, value: Union[CSEVariable, Tuple[CSEVariable, ...]]): Union[CSEVariable, Tuple[CSEVariable, ...]]<br ALIGN="LEFT"/>reduction_resize(value)<br ALIGN="LEFT"/>scan(dtypes: Tuple[torch.dtype, ...], combine_fn: Callable[[Tuple[CSEVariable, ...], Tuple[CSEVariable, ...]], Tuple[CSEVariable, ...]], values: Tuple[CSEVariable, ...]): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>should_use_cooperative_reduction(): bool<br ALIGN="LEFT"/>should_use_persistent_reduction(): bool<br ALIGN="LEFT"/>sort(dtypes: Tuple[torch.dtype, ...], values: Tuple[CSEVariable, ...], stable: bool, descending: bool): Tuple[CSEVariable, ...]<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: CSEVariable, mode: StoreMode): None<br ALIGN="LEFT"/>store_reduction(name: str, index: sympy.Expr, value: CSEVariable)<br ALIGN="LEFT"/>want_no_x_dim()<br ALIGN="LEFT"/>welford_reduce(result_var, reduction_type, value, where_cond, acc_type, dtype)<br ALIGN="LEFT"/>welford_reduce_final_reduction(buf, result_mean, result_m2, result_weight, accumulator, accumulator_m2, accumulator_weight, dim)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.triton_bundler.TritonKernelArtifact" [color="black", fontcolor="black", label=<{TritonKernelArtifact|filename : str<br ALIGN="LEFT"/>payload : bytes<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.triton_bundler.TritonKernelArtifacts" [color="black", fontcolor="black", label=<{TritonKernelArtifacts|artifacts : List[TritonKernelArtifact]<br ALIGN="LEFT"/>device : int<br ALIGN="LEFT"/>kernel_hash : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonKernelOverrides" [color="black", fontcolor="black", label=<{TritonKernelOverrides|<br ALIGN="LEFT"/>|constant(value, dtype)<br ALIGN="LEFT"/>frexp(x)<br ALIGN="LEFT"/>index_expr(expr, dtype)<br ALIGN="LEFT"/>load_seed(name, offset)<br ALIGN="LEFT"/>masked(mask, body, other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.TritonKernelVariable" [color="black", fontcolor="black", label=<{TritonKernelVariable|grid : str<br ALIGN="LEFT"/>kernel : str<br ALIGN="LEFT"/>kernel_idx : Optional[int]<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>specialize_symbolic(arg: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.TritonKernelWrapperFunctional" [color="black", fontcolor="black", label=<{TritonKernelWrapperFunctional|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.TritonKernelWrapperMutation" [color="black", fontcolor="black", label=<{TritonKernelWrapperMutation|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonOverrides" [color="black", fontcolor="black", label=<{TritonOverrides|<br ALIGN="LEFT"/>|abs(x)<br ALIGN="LEFT"/>acos(x)<br ALIGN="LEFT"/>acosh(x)<br ALIGN="LEFT"/>asin(x)<br ALIGN="LEFT"/>asinh(x)<br ALIGN="LEFT"/>atan(x)<br ALIGN="LEFT"/>atan2(x, y)<br ALIGN="LEFT"/>atanh(x)<br ALIGN="LEFT"/>bitwise_and(a, b)<br ALIGN="LEFT"/>bitwise_left_shift(a, b)<br ALIGN="LEFT"/>bitwise_not(a)<br ALIGN="LEFT"/>bitwise_or(a, b)<br ALIGN="LEFT"/>bitwise_right_shift(a, b)<br ALIGN="LEFT"/>bitwise_xor(a, b)<br ALIGN="LEFT"/>ceil(x)<br ALIGN="LEFT"/>constant(value, dtype)<br ALIGN="LEFT"/>copysign(x, y)<br ALIGN="LEFT"/>cos(x)<br ALIGN="LEFT"/>cosh(x)<br ALIGN="LEFT"/>erf(x)<br ALIGN="LEFT"/>erfc(x)<br ALIGN="LEFT"/>erfinv(x)<br ALIGN="LEFT"/>exp(x)<br ALIGN="LEFT"/>exp2(x)<br ALIGN="LEFT"/>expm1(x)<br ALIGN="LEFT"/>floor(x)<br ALIGN="LEFT"/>floordiv(a, b)<br ALIGN="LEFT"/>fmod(a, b)<br ALIGN="LEFT"/>hypot(x, y)<br ALIGN="LEFT"/><I>index_expr</I>(expr, dtype)<br ALIGN="LEFT"/>inline_asm_elementwise()<br ALIGN="LEFT"/>isinf(x)<br ALIGN="LEFT"/>isnan(x)<br ALIGN="LEFT"/>lgamma(x)<br ALIGN="LEFT"/>libdevice_abs(x)<br ALIGN="LEFT"/>libdevice_cos(x)<br ALIGN="LEFT"/>libdevice_exp(x)<br ALIGN="LEFT"/>libdevice_log(x)<br ALIGN="LEFT"/>libdevice_sin(x)<br ALIGN="LEFT"/>libdevice_sqrt(x)<br ALIGN="LEFT"/><I>load_seed</I>(name, offset)<br ALIGN="LEFT"/>log(x)<br ALIGN="LEFT"/>log10(x)<br ALIGN="LEFT"/>log1p(x)<br ALIGN="LEFT"/>log2(x)<br ALIGN="LEFT"/>logical_and(a, b)<br ALIGN="LEFT"/>logical_not(a)<br ALIGN="LEFT"/>logical_or(a, b)<br ALIGN="LEFT"/>logical_xor(a, b)<br ALIGN="LEFT"/><I>masked</I>(mask, body, other)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>minimum(a, b)<br ALIGN="LEFT"/>nextafter(x, y)<br ALIGN="LEFT"/>pow(a, b)<br ALIGN="LEFT"/>rand(seed, offset)<br ALIGN="LEFT"/>randint64(seed, offset, low, high)<br ALIGN="LEFT"/>randn(seed, offset)<br ALIGN="LEFT"/>relu(x)<br ALIGN="LEFT"/>round(x)<br ALIGN="LEFT"/>rsqrt(x)<br ALIGN="LEFT"/>sigmoid(x)<br ALIGN="LEFT"/>sign(x)<br ALIGN="LEFT"/>signbit(x)<br ALIGN="LEFT"/>sin(x)<br ALIGN="LEFT"/>sinh(x)<br ALIGN="LEFT"/>sqrt(x)<br ALIGN="LEFT"/>tan(x)<br ALIGN="LEFT"/>tanh(x)<br ALIGN="LEFT"/>to_dtype(x, dtype: torch.dtype, src_dtype: Optional[torch.dtype], use_compute_types)<br ALIGN="LEFT"/>to_dtype_bitcast(x, dtype: torch.dtype, src_dtype: torch.dtype)<br ALIGN="LEFT"/>trunc(x)<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>where(a, b, c)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonPrinter" [color="black", fontcolor="black", label=<{TritonPrinter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonScheduling" [color="black", fontcolor="black", label=<{TritonScheduling|backend_features : dict<br ALIGN="LEFT"/>kernel_type : Type[Any]<br ALIGN="LEFT"/>|add_multi_kernel_choices(kernel: SIMDKernel, kernel_args: List[Any], kernel_kwargs: Dict[str, Any]): List[SIMDKernel]<br ALIGN="LEFT"/>benchmark_combo_kernel(node_list)<br ALIGN="LEFT"/>benchmark_fused_nodes(nodes, n_spills_threshold)<br ALIGN="LEFT"/>codegen_comment(node_schedule)<br ALIGN="LEFT"/>create_kernel_choices(kernel_features, kernel_args, kernel_kwargs): List[SIMDKernel]<br ALIGN="LEFT"/>define_kernel(src_code, node_schedule, kernel)<br ALIGN="LEFT"/>get_backend_features(device: torch.device)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton_split_scan.TritonSplitScanKernel" [color="black", fontcolor="black", label=<{TritonSplitScanKernel|no_x_dim : bool<br ALIGN="LEFT"/>|initialize_range_tree(pid_cache)<br ALIGN="LEFT"/><I>reduction</I>(dtype, src_dtype, reduction_type, value)<br ALIGN="LEFT"/>scan(dtypes, combine_fn, values)<br ALIGN="LEFT"/>should_use_cooperative_reduction(): bool<br ALIGN="LEFT"/>should_use_persistent_reduction(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.triton.TritonSymbols" [color="black", fontcolor="black", label=<{TritonSymbols|block_offsets<br ALIGN="LEFT"/>block_sizes<br ALIGN="LEFT"/>block_types<br ALIGN="LEFT"/>reduction_types<br ALIGN="LEFT"/>|get_block_offset(tree: IterationRanges): sympy.Symbol<br ALIGN="LEFT"/>get_block_size(tree: IterationRanges): sympy.Symbol<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.TritonTemplate" [color="black", fontcolor="black", label=<{TritonTemplate|all_templates : Dict[str, 'TritonTemplate']<br ALIGN="LEFT"/>debug : bool<br ALIGN="LEFT"/>grid : Any<br ALIGN="LEFT"/>index_counter : count<br ALIGN="LEFT"/>template : NoneType, Template<br ALIGN="LEFT"/>|generate(input_nodes, layout, num_stages, num_warps, prefix_args, suffix_args, epilogue_fn, subgraphs, mutated_inputs, call_sizes, workspace_arg: Optional[WorkspaceArg])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.TritonTemplateBuffer" [color="black", fontcolor="black", label=<{TritonTemplateBuffer|allowed_prologue_inps<br ALIGN="LEFT"/>mutated_inputs : Optional[Iterable[IRNode]]<br ALIGN="LEFT"/>outputs : List[Buffer]<br ALIGN="LEFT"/>|get_allowed_prologue_inps(): OrderedSet[str]<br ALIGN="LEFT"/>get_outputs(): List[Buffer]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.TritonTemplateCaller" [color="black", fontcolor="black", label=<{TritonTemplateCaller|allowed_prologue_inps : NoneType<br ALIGN="LEFT"/>bmreq<br ALIGN="LEFT"/>log_info : Optional[Dict[str, Any]]<br ALIGN="LEFT"/>make_kernel_render<br ALIGN="LEFT"/>mutated_inputs : NoneType<br ALIGN="LEFT"/>workspace_arg : Optional[WorkspaceArg]<br ALIGN="LEFT"/>|autoheuristic_id()<br ALIGN="LEFT"/>benchmark()<br ALIGN="LEFT"/>call_name()<br ALIGN="LEFT"/>get_make_kernel_render()<br ALIGN="LEFT"/>hash_key()<br ALIGN="LEFT"/>info_dict(): Dict[str, Union[PrimitiveInfoType, List[PrimitiveInfoType]]]<br ALIGN="LEFT"/>output_node()<br ALIGN="LEFT"/>precompile()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.TritonTemplateCallerBase" [color="black", fontcolor="black", label=<{TritonTemplateCallerBase|<br ALIGN="LEFT"/>|<I>get_make_kernel_render</I>(): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.select_algorithm.TritonTemplateKernel" [color="black", fontcolor="black", label=<{TritonTemplateKernel|body<br ALIGN="LEFT"/>call_sizes<br ALIGN="LEFT"/>compute<br ALIGN="LEFT"/>defines<br ALIGN="LEFT"/>epilogue_fn<br ALIGN="LEFT"/>grid_fn<br ALIGN="LEFT"/>indexing_code<br ALIGN="LEFT"/>input_nodes<br ALIGN="LEFT"/>kernel_name<br ALIGN="LEFT"/>loads<br ALIGN="LEFT"/>meta<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>named_input_nodes : dict<br ALIGN="LEFT"/>num_stages<br ALIGN="LEFT"/>num_warps<br ALIGN="LEFT"/>numels<br ALIGN="LEFT"/>ops_handler : Optional[V.WrapperHandler]<br ALIGN="LEFT"/>output_node<br ALIGN="LEFT"/>prefix_args : int<br ALIGN="LEFT"/>prologue_fused_inputs : OrderedSet[str]<br ALIGN="LEFT"/>prologue_supported_inputs : OrderedSet[str]<br ALIGN="LEFT"/>range_trees : list<br ALIGN="LEFT"/>render_hooks : dict<br ALIGN="LEFT"/>stores<br ALIGN="LEFT"/>subgraph_bodies : Dict[str, SubgraphInfo]<br ALIGN="LEFT"/>subgraphs : Optional[List[ir.ComputedBuffer]]<br ALIGN="LEFT"/>suffix_args : int<br ALIGN="LEFT"/>template_indices : list<br ALIGN="LEFT"/>template_mask : NoneType, Optional[str]<br ALIGN="LEFT"/>template_out : Optional[str]<br ALIGN="LEFT"/>triton_meta : Optional[Dict[str, object]], dict<br ALIGN="LEFT"/>use_jit : bool<br ALIGN="LEFT"/>workspace_arg : Optional[WorkspaceArg]<br ALIGN="LEFT"/>|call_kernel(name: str, node: Optional[ir.IRNode])<br ALIGN="LEFT"/><I>codegen_range_tree</I>()<br ALIGN="LEFT"/>create_subgraph_body(body_name: str)<br ALIGN="LEFT"/>def_kernel()<br ALIGN="LEFT"/>estimate_kernel_num_bytes()<br ALIGN="LEFT"/>gen_argdefs()<br ALIGN="LEFT"/>gen_defines()<br ALIGN="LEFT"/>indexing(index: sympy.Expr)<br ALIGN="LEFT"/>jit_lines()<br ALIGN="LEFT"/>load_input(input_name: str, output_name: str, indices: Union[List[Any], Tuple[Any]], mask: Optional[str], other: Optional[Union[float, int]], indent_width: int)<br ALIGN="LEFT"/>make_load(name, indices, mask)<br ALIGN="LEFT"/>modification(subgraph_number: int, output_name: Optional[str], mask: Optional[str]): str<br ALIGN="LEFT"/>need_numel_args()<br ALIGN="LEFT"/>render(template, kwargs)<br ALIGN="LEFT"/>set_subgraph_body(body_name: str)<br ALIGN="LEFT"/>size(name: str, index: int)<br ALIGN="LEFT"/>store_output(indices: Union[List[Any], Tuple[Any]], val: str, mask: Optional[str], indent_width: int)<br ALIGN="LEFT"/>stride(name, index)<br ALIGN="LEFT"/>template_env()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR.TrivialLossWrapper" [color="black", fontcolor="black", label=<{TrivialLossWrapper|loss_spec : bool<br ALIGN="LEFT"/>|forward(x, targets)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.TruncToFloat" [color="black", fontcolor="black", label=<{TruncToFloat|is_real : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.TruncToInt" [color="black", fontcolor="black", label=<{TruncToInt|is_integer : bool<br ALIGN="LEFT"/>|eval(number)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TuningProcess" [color="black", fontcolor="black", label=<{TuningProcess|device : Optional[int]<br ALIGN="LEFT"/>process : Optional[BaseProcess]<br ALIGN="LEFT"/>request_queue : Optional[Queue[Any]]<br ALIGN="LEFT"/>response_queue : Optional[Queue[Any]]<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>get(result_timeout, graceful_timeout, terminate_timeout): Any<br ALIGN="LEFT"/>initialize(): None<br ALIGN="LEFT"/>kill(graceful_timeout, terminate_timeout): None<br ALIGN="LEFT"/>process_main(request_queue: Queue[Any], response_queue: Queue[Any]): None<br ALIGN="LEFT"/>put(obj: Any): None<br ALIGN="LEFT"/>terminate(): None<br ALIGN="LEFT"/>valid(): bool<br ALIGN="LEFT"/>wait(): None<br ALIGN="LEFT"/>workloop(request_queue: Queue[Any], response_queue: Queue[Any]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.autotune_process.TuningProcessPool" [color="black", fontcolor="black", label=<{TuningProcessPool|executor : Optional[ThreadPoolExecutor]<br ALIGN="LEFT"/>processes : Optional[queue.Queue[TuningProcess]]<br ALIGN="LEFT"/>|benchmark(choices: List[TritonTemplateCaller]): Dict[TritonTemplateCaller, float]<br ALIGN="LEFT"/>get_device_list(): Sequence[Optional[int]]<br ALIGN="LEFT"/>initialize(): None<br ALIGN="LEFT"/>target(choice: TritonTemplateCaller): float<br ALIGN="LEFT"/>terminate(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.TupleIteratorGetItemSource" [color="black", fontcolor="black", label=<{TupleIteratorGetItemSource|<br ALIGN="LEFT"/>|name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.TupleIteratorVariable" [color="black", fontcolor="black", label=<{TupleIteratorVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._op_schema.TupleStrategy" [color="black", fontcolor="black", label=<{TupleStrategy|childs : Sequence[StrategyType]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.lists.TupleVariable" [color="black", fontcolor="black", label=<{TupleVariable|class_type<br ALIGN="LEFT"/>has_grad_fn : bool<br ALIGN="LEFT"/>|call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: List['VariableTracker'], kwargs: Dict[str, 'VariableTracker']): 'VariableTracker'<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen: 'PyCodegen'): None<br ALIGN="LEFT"/>var_getattr(tx, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerConvModel" [color="black", fontcolor="black", label=<{TwoLayerConvModel|conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerFunctionalConvModel" [color="black", fontcolor="black", label=<{TwoLayerFunctionalConvModel|conv1<br ALIGN="LEFT"/>conv2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerFunctionalLinearModel" [color="black", fontcolor="black", label=<{TwoLayerFunctionalLinearModel|linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" [color="black", fontcolor="black", label=<{TwoLayerLinearModel|fc1<br ALIGN="LEFT"/>fc2<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>get_example_inputs(): Tuple[Any, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.TwoLinLayerNet" [color="black", fontcolor="black", label=<{TwoLinLayerNet|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.TwoLinearModule" [color="black", fontcolor="black", label=<{TwoLinearModule|linear1<br ALIGN="LEFT"/>linear2<br ALIGN="LEFT"/>|example_inputs()<br ALIGN="LEFT"/>forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.two_tensor.TwoTensor" [color="black", fontcolor="black", label=<{TwoTensor|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.two_tensor.TwoTensorMode" [color="black", fontcolor="black", label=<{TwoTensorMode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd._functions.tensor.Type" [color="black", fontcolor="black", label=<{Type|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, i, dest_type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._debug_utils.SimpleProfiler.Type" [color="black", fontcolor="black", label=<{Type|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._schemas.TypeConstraintParam" [color="black", fontcolor="black", label=<{TypeConstraintParam|allowed_types : set[ir.TypeProtocol]<br ALIGN="LEFT"/>description : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|any_tensor(name: str, description: str): TypeConstraintParam<br ALIGN="LEFT"/>any_value(name: str, description: str): TypeConstraintParam<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TypePair" [color="black", fontcolor="black", label=<{TypePair|CLS : type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.TypePromotionRule" [color="black", fontcolor="black", label=<{TypePromotionRule|namespace : str<br ALIGN="LEFT"/>op_name : str<br ALIGN="LEFT"/>|is_valid(): bool<br ALIGN="LEFT"/><I>preview_type_promotion</I>(args: tuple, kwargs: dict): TypePromotionSnapshot<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.TypePromotionSnapshot" [color="black", fontcolor="black", label=<{TypePromotionSnapshot|args_dtypes : Mapping[int, torch.dtype]<br ALIGN="LEFT"/>kwargs_dtypes : Mapping[str, torch.dtype]<br ALIGN="LEFT"/>out_dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.TypePromotionTable" [color="black", fontcolor="black", label=<{TypePromotionTable|<br ALIGN="LEFT"/>|add_rule(rule: TypePromotionRule): None<br ALIGN="LEFT"/>get_rule(py_op: torch._ops.OpOverloadPacket): TypePromotionRule \| None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.type_reflection_method.TypeReflectionMethod" [color="black", fontcolor="black", label=<{TypeReflectionMethod|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils._scrubbed_inductor_config_for_logging.TypeSafeSerializer" [color="black", fontcolor="black", label=<{TypeSafeSerializer|<br ALIGN="LEFT"/>|default(o)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.TypeSource" [color="black", fontcolor="black", label=<{TypeSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.index_propagation.TypedExpr" [color="black", fontcolor="black", label=<{TypedExpr|dtype<br ALIGN="LEFT"/>expr : Union<br ALIGN="LEFT"/>|is_constant()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.storage.TypedStorage" [color="black", fontcolor="black", label=<{TypedStorage|device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>filename<br ALIGN="LEFT"/>is_cuda<br ALIGN="LEFT"/>is_hpu<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>|bfloat16()<br ALIGN="LEFT"/>bool()<br ALIGN="LEFT"/>byte()<br ALIGN="LEFT"/>char()<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>complex_double()<br ALIGN="LEFT"/>complex_float()<br ALIGN="LEFT"/>copy_(source: T, non_blocking: _Optional[bool])<br ALIGN="LEFT"/>cpu()<br ALIGN="LEFT"/>cuda(device, non_blocking): Self<br ALIGN="LEFT"/>data_ptr()<br ALIGN="LEFT"/>double()<br ALIGN="LEFT"/>element_size()<br ALIGN="LEFT"/>fill_(value)<br ALIGN="LEFT"/>float()<br ALIGN="LEFT"/>float8_e4m3fn()<br ALIGN="LEFT"/>float8_e4m3fnuz()<br ALIGN="LEFT"/>float8_e5m2()<br ALIGN="LEFT"/>float8_e5m2fnuz()<br ALIGN="LEFT"/>from_buffer()<br ALIGN="LEFT"/>from_file(filename, shared, size)<br ALIGN="LEFT"/>get_device(): _int<br ALIGN="LEFT"/>half()<br ALIGN="LEFT"/>hpu(device, non_blocking): Self<br ALIGN="LEFT"/>int()<br ALIGN="LEFT"/>is_pinned(device: Union[str, torch.device])<br ALIGN="LEFT"/>is_shared()<br ALIGN="LEFT"/>long()<br ALIGN="LEFT"/>nbytes()<br ALIGN="LEFT"/>pickle_storage_type()<br ALIGN="LEFT"/>pin_memory(device: Union[str, torch.device])<br ALIGN="LEFT"/>resizable()<br ALIGN="LEFT"/>resize_(size)<br ALIGN="LEFT"/>share_memory_()<br ALIGN="LEFT"/>short()<br ALIGN="LEFT"/>size()<br ALIGN="LEFT"/>to(): Self<br ALIGN="LEFT"/>tolist()<br ALIGN="LEFT"/>type(dtype: _Optional[str], non_blocking: bool): Union[_StorageBase, TypedStorage, str]<br ALIGN="LEFT"/>untyped()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.TypedStoragePair" [color="black", fontcolor="black", label=<{TypedStoragePair|atol<br ALIGN="LEFT"/>rtol<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.TypingVariable" [color="black", fontcolor="black", label=<{TypingVariable|value<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._util.UFuncTypeError" [color="black", fontcolor="red", label=<{UFuncTypeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.grouping.UnBatcherIterDataPipe" [color="black", fontcolor="black", label=<{UnBatcherIterDataPipe|datapipe<br ALIGN="LEFT"/>unbatch_level : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.mkldnn_fusion.UnaryAttr" [color="black", fontcolor="black", label=<{UnaryAttr|algorithm_attr : str<br ALIGN="LEFT"/>op_name : str<br ALIGN="LEFT"/>scalars_attr : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.quantization._register_quantization_unary_fusion.UnaryAttr" [color="black", fontcolor="black", label=<{UnaryAttr|algorithm_attr : str<br ALIGN="LEFT"/>op_name : str<br ALIGN="LEFT"/>scalars_attr : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.op_fuzzers.unary.UnaryOpFuzzer" [color="black", fontcolor="black", label=<{UnaryOpFuzzer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.op_fuzzers.sparse_unary.UnaryOpSparseFuzzer" [color="black", fontcolor="black", label=<{UnaryOpSparseFuzzer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.UnaryUfuncInfo" [color="black", fontcolor="black", label=<{UnaryUfuncInfo|domain : tuple<br ALIGN="LEFT"/>handles_complex_extremal_values : bool<br ALIGN="LEFT"/>handles_large_floats : bool<br ALIGN="LEFT"/>reference_numerics_filter : NoneType<br ALIGN="LEFT"/>sample_kwargs<br ALIGN="LEFT"/>supports_complex_to_float : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.split_cat.UnbindCatRemover" [color="black", fontcolor="black", label=<{UnbindCatRemover|<br ALIGN="LEFT"/>|get_simplified_split_ranges(split_sections: List[int], next_users: List[torch.fx.Node], user_inputs_list: List[List[Union[torch.fx.Node, _Range]]]): Optional[List[_Range]]<br ALIGN="LEFT"/>get_transform_params(split_node: torch.fx.Node, next_users: List[torch.fx.Node], user_inputs_list: List[List[Union[torch.fx.Node, _Range]]]): Optional[List[List[_TransformParam]]]<br ALIGN="LEFT"/>remove_unbind(graph: torch.fx.Graph, unbind_node: torch.fx.Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.UncapturedHigherOrderOpError" [color="black", fontcolor="red", label=<{UncapturedHigherOrderOpError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.flatten.Unflatten" [color="black", fontcolor="black", label=<{Unflatten|NamedShape : Tuple<br ALIGN="LEFT"/>dim : Union[int, str]<br ALIGN="LEFT"/>unflattened_size : Union[_size, NamedShape]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.unflatten.UnflattenedModule" [color="black", fontcolor="black", label=<{UnflattenedModule|adapted : bool<br ALIGN="LEFT"/>check_input_constraints : bool<br ALIGN="LEFT"/>equality_constraints : List<br ALIGN="LEFT"/>flat_args_adapter : Optional[FlatArgsAdapter]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>graph_signature<br ALIGN="LEFT"/>input_placeholders<br ALIGN="LEFT"/>ivals<br ALIGN="LEFT"/>module_call_graph<br ALIGN="LEFT"/>range_constraints<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>print_readable(print_output, include_stride, include_device, colored)<br ALIGN="LEFT"/>process_forward_inputs()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.fold.Unfold" [color="black", fontcolor="black", label=<{Unfold|dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>stride : Union<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.uniform.Uniform" [color="black", fontcolor="black", label=<{Uniform|arg_constraints : dict<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>high<br ALIGN="LEFT"/>low<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>stddev<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|cdf(value)<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>icdf(value)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>rsample(sample_shape: _size): torch.Tensor<br ALIGN="LEFT"/>support()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer.UniformQuantizationObserverBase" [color="black", fontcolor="black", label=<{UniformQuantizationObserverBase|eps<br ALIGN="LEFT"/>has_customized_qrange<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>quant_max : int<br ALIGN="LEFT"/>quant_min : int<br ALIGN="LEFT"/>reduce_range : bool<br ALIGN="LEFT"/>|<I>reset_min_max_vals</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.joint_graph.UniformValueConstantFolder" [color="black", fontcolor="black", label=<{UniformValueConstantFolder|constant_data_ptrs : Dict[torch.fx.Node, StorageWeakRef]<br ALIGN="LEFT"/>indexing_op_packets<br ALIGN="LEFT"/>node_replacements_shapes : Dict[torch.fx.Node, List[int]]<br ALIGN="LEFT"/>node_storages_ptrs : Dict[torch.fx.Node, int]<br ALIGN="LEFT"/>symint_nodes<br ALIGN="LEFT"/>view_op_packets : list<br ALIGN="LEFT"/>|add_node_replacement(node: torch.fx.Node, tensor: torch.Tensor): None<br ALIGN="LEFT"/>insert_placerholder_values(env: Dict[torch.fx.Node, Any]): None<br ALIGN="LEFT"/>insertable_tensor_check(t: torch.Tensor): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parameter.UninitializedBuffer" [color="black", fontcolor="black", label=<{UninitializedBuffer|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parameter.UninitializedParameter" [color="black", fontcolor="black", label=<{UninitializedParameter|cls_to_become<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parameter.UninitializedTensorMixin" [color="black", fontcolor="black", label=<{UninitializedTensorMixin|data<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|materialize(shape, device, dtype)<br ALIGN="LEFT"/>share_memory_()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.optimization.UnionFind" [color="black", fontcolor="black", label=<{UnionFind|parent : List[Optional[int]]<br ALIGN="LEFT"/>size : List[int]<br ALIGN="LEFT"/>|find(v: int): int<br ALIGN="LEFT"/>join(a: int, b: int)<br ALIGN="LEFT"/>make_set(v: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.UnitModule" [color="black", fontcolor="black", label=<{UnitModule|l1<br ALIGN="LEFT"/>l2<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_dist_composable.UnitParamModule" [color="black", fontcolor="black", label=<{UnitParamModule|l<br ALIGN="LEFT"/>p<br ALIGN="LEFT"/>seq<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.UnittestPair" [color="black", fontcolor="black", label=<{UnittestPair|CLS : Union[Type, Tuple[Type, ...]]<br ALIGN="LEFT"/>TYPE_NAME : Optional[str]<br ALIGN="LEFT"/>|compare()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.UnknownVariable" [color="black", fontcolor="black", label=<{UnknownVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.forward_ad.UnpackedDualTensor" [color="black", fontcolor="black", label=<{UnpackedDualTensor|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._weights_only_unpickler.Unpickler" [color="black", fontcolor="black", label=<{Unpickler|append<br ALIGN="LEFT"/>encoding : str<br ALIGN="LEFT"/>memo : Dict[int, Any]<br ALIGN="LEFT"/>metastack : list<br ALIGN="LEFT"/>proto : int<br ALIGN="LEFT"/>read<br ALIGN="LEFT"/>readline<br ALIGN="LEFT"/>stack : List[Any], list<br ALIGN="LEFT"/>|load()<br ALIGN="LEFT"/>persistent_load(pid)<br ALIGN="LEFT"/>pop_mark()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization._legacy_load.UnpicklerWrapper" [color="black", fontcolor="black", label=<{UnpicklerWrapper|persistent_load<br ALIGN="LEFT"/>|find_class(mod_name, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization._load.UnpicklerWrapper" [color="black", fontcolor="black", label=<{UnpicklerWrapper|persistent_load<br ALIGN="LEFT"/>|find_class(mod_name, name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.UnsafeScriptObjectError" [color="black", fontcolor="red", label=<{UnsafeScriptObjectError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal._exporter_legacy.UnsatisfiedDependencyError" [color="black", fontcolor="red", label=<{UnsatisfiedDependencyError|package_name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.cudnn.rnn.Unserializable" [color="black", fontcolor="black", label=<{Unserializable|inner : NoneType<br ALIGN="LEFT"/>|get()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.eval_frame.Unset" [color="black", fontcolor="black", label=<{Unset|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel._unshard.UnshardHandle" [color="black", fontcolor="black", label=<{UnshardHandle|<br ALIGN="LEFT"/>|wait()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fully_shard.UnshardHandle" [color="black", fontcolor="black", label=<{UnshardHandle|<br ALIGN="LEFT"/>|wait(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.UnspecializeRestartAnalysis" [color="black", fontcolor="red", label=<{UnspecializeRestartAnalysis|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.UnspecializedBuiltinNNModuleSource" [color="black", fontcolor="black", label=<{UnspecializedBuiltinNNModuleSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.nn_module.UnspecializedBuiltinNNModuleVariable" [color="black", fontcolor="black", label=<{UnspecializedBuiltinNNModuleVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.UnspecializedNNModuleSource" [color="black", fontcolor="black", label=<{UnspecializedNNModuleSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.nn_module.UnspecializedNNModuleVariable" [color="black", fontcolor="black", label=<{UnspecializedNNModuleVariable|is_state_mutated : bool<br ALIGN="LEFT"/>nn_module_stack_source : NoneType<br ALIGN="LEFT"/>value_type<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>get_nn_module_stack_source()<br ALIGN="LEFT"/>getattr_helper(tx: 'InstructionTranslator', field, name_vt)<br ALIGN="LEFT"/>manually_trace_nn_module_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>set_nn_module_stack_source(source)<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.source.UnspecializedParamBufferSource" [color="black", fontcolor="black", label=<{UnspecializedParamBufferSource|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.UnspecializedPythonVariable" [color="black", fontcolor="black", label=<{UnspecializedPythonVariable|need_unwrap : bool<br ALIGN="LEFT"/>raw_value : NoneType<br ALIGN="LEFT"/>|from_tensor_variable(tensor_variable, raw_value, need_unwrap)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.exc.Unsupported" [color="black", fontcolor="red", label=<{Unsupported|case_name : Optional[str]<br ALIGN="LEFT"/>category : Optional[str]<br ALIGN="LEFT"/>msg<br ALIGN="LEFT"/>real_stack : StackSummary<br ALIGN="LEFT"/>|add_to_stats(category)<br ALIGN="LEFT"/>remove_from_stats()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.halide.Unsupported" [color="black", fontcolor="red", label=<{Unsupported|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.utils.UnsupportedAliasMutationException" [color="black", fontcolor="red", label=<{UnsupportedAliasMutationException|reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.UnsupportedFakeTensorException" [color="black", fontcolor="red", label=<{UnsupportedFakeTensorException|reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.diagnostics.UnsupportedFxNodeDiagnostic" [color="black", fontcolor="black", label=<{UnsupportedFxNodeDiagnostic|level : WARNING<br ALIGN="LEFT"/>unsupported_fx_node : torch.fx.Node \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.analysis.unsupported_nodes.UnsupportedFxNodesAnalysis" [color="black", fontcolor="black", label=<{UnsupportedFxNodesAnalysis|<br ALIGN="LEFT"/>|analyze(diagnostic_level: diagnostics.infra.Level): UnsupportedFxNodesAnalysisResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.analysis.unsupported_nodes.UnsupportedFxNodesAnalysisResult" [color="black", fontcolor="black", label=<{UnsupportedFxNodesAnalysisResult|unsupported_op_to_target_mapping : dict[str, dict[str, None]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._comparison.UnsupportedInputs" [color="black", fontcolor="red", label=<{UnsupportedInputs|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.frontend.UnsupportedNodeError" [color="black", fontcolor="red", label=<{UnsupportedNodeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.errors.UnsupportedOperatorError" [color="black", fontcolor="red", label=<{UnsupportedOperatorError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor.UnsupportedOperatorException" [color="black", fontcolor="red", label=<{UnsupportedOperatorException|func<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda._sanitizer.UnsynchronizedAccessError" [color="black", fontcolor="red", label=<{UnsynchronizedAccessError|allocation_stack_trace : Optional[traceback.StackSummary]<br ALIGN="LEFT"/>current_access<br ALIGN="LEFT"/>data_ptr : int<br ALIGN="LEFT"/>previous_access<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.storage.UntypedStorage" [color="black", fontcolor="black", label=<{UntypedStorage|filename<br ALIGN="LEFT"/>is_cuda<br ALIGN="LEFT"/>is_hpu<br ALIGN="LEFT"/>|share_memory_()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.tensor.UntypedStorageVariable" [color="black", fontcolor="black", label=<{UntypedStorageVariable|example_value<br ALIGN="LEFT"/>from_tensor<br ALIGN="LEFT"/>|call_method(tx, name, args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs.UnusedParamModule" [color="black", fontcolor="black", label=<{UnusedParamModule|t0<br ALIGN="LEFT"/>t1<br ALIGN="LEFT"/>unused_params_rank<br ALIGN="LEFT"/>|forward(x, rank)<br ALIGN="LEFT"/>task_parameters()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" [color="black", fontcolor="black", label=<{UnusedParamTwoLinLayerNet|a<br ALIGN="LEFT"/>b<br ALIGN="LEFT"/>c<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.subclass_parametrization.UnwrapTensorSubclass" [color="black", fontcolor="black", label=<{UnwrapTensorSubclass|rebuild_stack : list<br ALIGN="LEFT"/>|forward(): torch.Tensor<br ALIGN="LEFT"/>right_inverse(tensor: torch.Tensor): List[torch.Tensor]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.upsampling.Upsample" [color="black", fontcolor="black", label=<{Upsample|align_corners : Optional[bool]<br ALIGN="LEFT"/>mode : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>recompute_scale_factor : Optional[bool]<br ALIGN="LEFT"/>scale_factor : Optional[_ratio_any_t]<br ALIGN="LEFT"/>size : Optional[_size_any_t]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.decomposition_skip.UpsampleBilinear2DDecompSkip" [color="black", fontcolor="black", label=<{UpsampleBilinear2DDecompSkip|new_op_name : str<br ALIGN="LEFT"/>new_op_schema : str<br ALIGN="LEFT"/>onnxscript_function<br ALIGN="LEFT"/>op_callable<br ALIGN="LEFT"/>|abstract(input, output_size, align_corners, scale_factors)<br ALIGN="LEFT"/>register(export_options: torch.onnx.ExportOptions)<br ALIGN="LEFT"/>unregister()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.decomposition_skip.UpsampleTrilinear3DDecompSkip" [color="black", fontcolor="black", label=<{UpsampleTrilinear3DDecompSkip|new_op_name : str<br ALIGN="LEFT"/>new_op_schema : str<br ALIGN="LEFT"/>onnxscript_function<br ALIGN="LEFT"/>op_callable<br ALIGN="LEFT"/>|abstract(input, output_size, align_corners, scale_factors)<br ALIGN="LEFT"/>register(export_options: torch.onnx.ExportOptions)<br ALIGN="LEFT"/>unregister()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.upsampling.UpsamplingBilinear2d" [color="black", fontcolor="black", label=<{UpsamplingBilinear2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.upsampling.UpsamplingNearest2d" [color="black", fontcolor="black", label=<{UpsamplingNearest2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.UserDefinedClassVariable" [color="black", fontcolor="black", label=<{UserDefinedClassVariable|value<br ALIGN="LEFT"/>|as_proxy()<br ALIGN="LEFT"/>as_python_constant()<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>can_constant_fold_through()<br ALIGN="LEFT"/>const_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>has_key_in_generic_dict(tx: 'InstructionTranslator', key)<br ALIGN="LEFT"/>is_standard_new()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [color="black", fontcolor="black", label=<{UserDefinedObjectVariable|class_type<br ALIGN="LEFT"/>cls_source : NoneType<br ALIGN="LEFT"/>has_grad_fn : bool<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>value_type<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_torch_function(tx: 'InstructionTranslator', fn, types, args, kwargs)<br ALIGN="LEFT"/>get_source_by_walking_mro(name)<br ALIGN="LEFT"/>get_torch_fn(tx)<br ALIGN="LEFT"/>guard_as_python_constant()<br ALIGN="LEFT"/>has_key_in_generic_dict(tx: 'InstructionTranslator', key)<br ALIGN="LEFT"/>is_supported_random()<br ALIGN="LEFT"/>method_setattr_standard(tx: 'InstructionTranslator', name, value)<br ALIGN="LEFT"/>needs_slow_setattr()<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>odict_getitem(tx: 'InstructionTranslator', key)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>torch_function_check()<br ALIGN="LEFT"/>unpack_var_sequence(tx)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.UserDefinedTritonKernel" [color="black", fontcolor="black", label=<{UserDefinedTritonKernel|device<br ALIGN="LEFT"/>grid<br ALIGN="LEFT"/>kernel_idx<br ALIGN="LEFT"/>mutable_args<br ALIGN="LEFT"/>mutation_outputs<br ALIGN="LEFT"/>ordered_kwargs_for_cpp_kernel<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>get_device(): Optional[torch.device]<br ALIGN="LEFT"/>get_kernel_and_metadata()<br ALIGN="LEFT"/>get_outputs(): List[Buffer]<br ALIGN="LEFT"/>get_unbacked_symbol_defs(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>get_unbacked_symbol_uses(): OrderedSet[sympy.Symbol]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.user_defined.UserDefinedVariable" [color="black", fontcolor="black", label=<{UserDefinedVariable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.UserError" [color="black", fontcolor="red", label=<{UserError|error_type<br ALIGN="LEFT"/>message<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.exc.UserErrorType" [color="black", fontcolor="black", label=<{UserErrorType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.UserFunctionVariable" [color="black", fontcolor="black", label=<{UserFunctionVariable|fn : function<br ALIGN="LEFT"/>is_constant : bool<br ALIGN="LEFT"/>|as_python_constant()<br ALIGN="LEFT"/>bind_args(parent, args, kwargs): Dict[str, VariableTracker]<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>create_with_source(value, source)<br ALIGN="LEFT"/>get_code()<br ALIGN="LEFT"/>get_function()<br ALIGN="LEFT"/>get_globals()<br ALIGN="LEFT"/>has_self()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>self_args()<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.db.examples.user_input_mutation.UserInputMutation" [color="black", fontcolor="black", label=<{UserInputMutation|<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.UserInputMutationSpec" [color="black", fontcolor="black", label=<{UserInputMutationSpec|arg : Annotated[TensorArgument, 10]<br ALIGN="LEFT"/>user_input_name : Annotated[str, 20]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.schema.UserInputSpec" [color="black", fontcolor="black", label=<{UserInputSpec|arg : Annotated[Argument, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.UserMethodVariable" [color="black", fontcolor="black", label=<{UserMethodVariable|obj<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>inspect_parameter_names()<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>self_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema.UserOutputSpec" [color="black", fontcolor="black", label=<{UserOutputSpec|arg : Annotated[Argument, 10]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._VF.VFModule" [color="black", fontcolor="black", label=<{VFModule|vf : module<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator.ValidationException" [color="black", fontcolor="red", label=<{ValidationException|details : str<br ALIGN="LEFT"/>msg : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.ValueMutationExisting" [color="black", fontcolor="black", label=<{ValueMutationExisting|is_modified : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.ValueMutationNew" [color="black", fontcolor="black", label=<{ValueMutationNew|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.value_ranges.ValueRangeAnalysis" [color="black", fontcolor="black", label=<{ValueRangeAnalysis|name : str<br ALIGN="LEFT"/>|bool_handler()<br ALIGN="LEFT"/>default_handler()<br ALIGN="LEFT"/>index_expr(index, dtype)<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr)<br ALIGN="LEFT"/>neg(x)<br ALIGN="LEFT"/>reduction(name, dtype, src_dtype, reduction_type, index, value)<br ALIGN="LEFT"/>square(x)<br ALIGN="LEFT"/>store(name, index, value, mode)<br ALIGN="LEFT"/>sub(a, b)<br ALIGN="LEFT"/>to_dtype(x, dtype: torch.dtype, src_dtype: Optional[torch.dtype])<br ALIGN="LEFT"/>truncdiv(a, b)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.value_ranges.ValueRangeError" [color="black", fontcolor="red", label=<{ValueRangeError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._sympy.value_ranges.ValueRanges" [color="black", fontcolor="black", label=<{ValueRanges|AllVR : Union<br ALIGN="LEFT"/>BoolVR<br ALIGN="LEFT"/>ExprVR<br ALIGN="LEFT"/>is_bool : bool<br ALIGN="LEFT"/>is_float : bool<br ALIGN="LEFT"/>is_int : bool<br ALIGN="LEFT"/>lower : _T<br ALIGN="LEFT"/>upper : _T<br ALIGN="LEFT"/>|boolify(): ValueRanges[SympyBoolean]<br ALIGN="LEFT"/>convex_min_zero_map(x: Union[ExprIn, ExprVR], fn: ExprFn): ExprVR<br ALIGN="LEFT"/>coordinatewise_increasing_map(x: Union[ExprIn, ExprVR], y: Union[ExprIn, ExprVR], fn: ExprFn2): ExprVR<br ALIGN="LEFT"/>coordinatewise_monotone_map(x, y, fn)<br ALIGN="LEFT"/>decreasing_map(x: Union[ExprIn, ExprVR], fn: ExprFn): ExprVR<br ALIGN="LEFT"/>increasing_map(x: Union[ExprIn, ExprVR], fn: ExprFn): ExprVR<br ALIGN="LEFT"/>is_singleton(): bool<br ALIGN="LEFT"/>issubset(other)<br ALIGN="LEFT"/>monotone_map(x: Union[ExprIn, ExprVR], fn: ExprFn): ExprVR<br ALIGN="LEFT"/>tighten(other): ValueRanges<br ALIGN="LEFT"/>unknown(): ValueRanges[sympy.Expr]<br ALIGN="LEFT"/>unknown_bool(): ValueRanges[SympyBoolean]<br ALIGN="LEFT"/>unknown_int(): ValueRanges[sympy.Expr]<br ALIGN="LEFT"/>wrap(arg: Union[ExprIn, ExprVR]): ExprVR<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes.ValueRangesSLoc" [color="black", fontcolor="black", label=<{ValueRangesSLoc|lower<br ALIGN="LEFT"/>upper<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.variable.Var" [color="black", fontcolor="black", label=<{Var|token : str, tuple<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.match.VarDispatcher" [color="black", fontcolor="black", label=<{VarDispatcher|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.variable.Variable" [color="black", fontcolor="black", label=<{Variable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builder.VariableBuilder" [color="black", fontcolor="black", label=<{VariableBuilder|name<br ALIGN="LEFT"/>source<br ALIGN="LEFT"/>tx<br ALIGN="LEFT"/>|assert_not_wrapped_by_this_graph(value: torch.Tensor)<br ALIGN="LEFT"/>get_source()<br ALIGN="LEFT"/>install_guards()<br ALIGN="LEFT"/>mark_static_input(value: torch.Tensor, guard: bool)<br ALIGN="LEFT"/>wrap_jit_function(value)<br ALIGN="LEFT"/>wrap_listlike(value: Union[tuple, list, odict_values, NamedTuple])<br ALIGN="LEFT"/>wrap_literal(value)<br ALIGN="LEFT"/>wrap_module(value: torch.nn.Module)<br ALIGN="LEFT"/>wrap_numpy_ndarray(value)<br ALIGN="LEFT"/>wrap_range_iterator(value: range_iterator)<br ALIGN="LEFT"/>wrap_regex_pattern(value: re.Pattern)<br ALIGN="LEFT"/>wrap_removable_handle(value)<br ALIGN="LEFT"/>wrap_slice_range(value: Union[slice, range])<br ALIGN="LEFT"/>wrap_symfloat(value)<br ALIGN="LEFT"/>wrap_symint(value)<br ALIGN="LEFT"/>wrap_tensor(value: torch.Tensor)<br ALIGN="LEFT"/>wrap_tuple_iterator(value: tuple_iterator)<br ALIGN="LEFT"/>wrap_unspecialized_primitive(value)<br ALIGN="LEFT"/>wrap_user_defined(value: Any)<br ALIGN="LEFT"/>wrap_weakref(value: weakref.ReferenceType)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.variable.VariableMeta" [color="black", fontcolor="black", label=<{VariableMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.VariableTracker" [color="black", fontcolor="black", label=<{VariableTracker|mutation_type : NoneType<br ALIGN="LEFT"/>source : NoneType<br ALIGN="LEFT"/>|<I>as_proxy</I>()<br ALIGN="LEFT"/><I>as_python_constant</I>()<br ALIGN="LEFT"/>build(tx: 'InstructionTranslatorBase', value: Any, source: Optional[Source]): Any<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>call_hasattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>call_method(tx, name, args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/><I>const_getattr</I>(tx: 'InstructionTranslator', name: str): Any<br ALIGN="LEFT"/>debug_repr()<br ALIGN="LEFT"/>force_unpack_var_sequence(tx): List['VariableTracker']<br ALIGN="LEFT"/>guard_as_python_constant()<br ALIGN="LEFT"/>has_force_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>has_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>inspect_parameter_names(): List[str]<br ALIGN="LEFT"/>is_immutable()<br ALIGN="LEFT"/>is_mutable()<br ALIGN="LEFT"/>is_proxy()<br ALIGN="LEFT"/>is_python_constant()<br ALIGN="LEFT"/>is_realized()<br ALIGN="LEFT"/>is_strict_mode(tx)<br ALIGN="LEFT"/>make_guard(fn)<br ALIGN="LEFT"/>maybe_fx_node()<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>realize(): 'VariableTracker'<br ALIGN="LEFT"/><I>reconstruct</I>(codegen)<br ALIGN="LEFT"/><I>set_name_hint</I>(name)<br ALIGN="LEFT"/><I>unpack_var_sequence</I>(tx): List['VariableTracker']<br ALIGN="LEFT"/>unwrap(): 'VariableTracker'<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): 'VariableTracker'<br ALIGN="LEFT"/>visit(fn: Callable[['VariableTracker'], None], value: Any, cache: Optional[Dict[int, Any]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.VariableTrackerCache" [color="black", fontcolor="black", label=<{VariableTrackerCache|cache : dict<br ALIGN="LEFT"/>|add(value, source, vt)<br ALIGN="LEFT"/>clear()<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>lookup(value, source)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.VariableTrackerCacheKey" [color="black", fontcolor="black", label=<{VariableTrackerCacheKey|source<br ALIGN="LEFT"/>vt_id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.base.VariableTrackerMeta" [color="black", fontcolor="black", label=<{VariableTrackerMeta|all_subclasses : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.variadic.Variadic" [color="black", fontcolor="black", label=<{Variadic|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.variadic.VariadicSignatureMeta" [color="black", fontcolor="black", label=<{VariadicSignatureMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.unification.multipledispatch.variadic.VariadicSignatureType" [color="black", fontcolor="black", label=<{VariadicSignatureType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecAMX" [color="black", fontcolor="black", label=<{VecAMX|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecAVX2" [color="black", fontcolor="black", label=<{VecAVX2|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecAVX512" [color="black", fontcolor="black", label=<{VecAVX512|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecISA" [color="black", fontcolor="black", label=<{VecISA|<br ALIGN="LEFT"/>|bit_width(): int<br ALIGN="LEFT"/>build_arch_flags(): str<br ALIGN="LEFT"/>build_macro(): List[str]<br ALIGN="LEFT"/>check_build(code: str): bool<br ALIGN="LEFT"/>nelements(dtype: torch.dtype): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecNEON" [color="black", fontcolor="black", label=<{VecNEON|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecSVE" [color="black", fontcolor="black", label=<{VecSVE|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecVSX" [color="black", fontcolor="black", label=<{VecVSX|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cpu_vec_isa.VecZVECTOR" [color="black", fontcolor="black", label=<{VecZVECTOR|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._verification.VerificationInfo" [color="black", fontcolor="black", label=<{VerificationInfo|abs_diff_hist : tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>actual_dtype<br ALIGN="LEFT"/>expected_dtype<br ALIGN="LEFT"/>max_abs_diff : float<br ALIGN="LEFT"/>max_rel_diff : float<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>rel_diff_hist : tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.verification.VerificationOptions" [color="black", fontcolor="black", label=<{VerificationOptions|acceptable_error_percentage : float \| None<br ALIGN="LEFT"/>atol : float<br ALIGN="LEFT"/>backend<br ALIGN="LEFT"/>check_dtype : bool<br ALIGN="LEFT"/>check_shape : bool<br ALIGN="LEFT"/>flatten : bool<br ALIGN="LEFT"/>ignore_none : bool<br ALIGN="LEFT"/>remained_onnx_input_idx : Sequence[int] \| None<br ALIGN="LEFT"/>rtol : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.verifier.Verifier" [color="black", fontcolor="black", label=<{Verifier|dialect : str<br ALIGN="LEFT"/>|allowed_builtin_ops(): List<br ALIGN="LEFT"/>allowed_getattr_types(): Tuple[Type[Any], ...]<br ALIGN="LEFT"/>allowed_op_types(): Tuple[Type[Any], ...]<br ALIGN="LEFT"/>check(ep: 'ExportedProgram'): None<br ALIGN="LEFT"/><I>check_additional</I>(gm: GraphModule): None<br ALIGN="LEFT"/><I>check_valid_op</I>(op)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.common_state_dict.VerifyStateDictMixin" [color="black", fontcolor="black", label=<{VerifyStateDictMixin|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._vendor.packaging.version.Version" [color="black", fontcolor="black", label=<{Version|base_version<br ALIGN="LEFT"/>dev<br ALIGN="LEFT"/>epoch<br ALIGN="LEFT"/>is_devrelease<br ALIGN="LEFT"/>is_postrelease<br ALIGN="LEFT"/>is_prerelease<br ALIGN="LEFT"/>local<br ALIGN="LEFT"/>major<br ALIGN="LEFT"/>micro<br ALIGN="LEFT"/>minor<br ALIGN="LEFT"/>post<br ALIGN="LEFT"/>pre<br ALIGN="LEFT"/>public<br ALIGN="LEFT"/>release<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._version_control_details.VersionControlDetails" [color="black", fontcolor="black", label=<{VersionControlDetails|as_of_time_utc : Optional[str]<br ALIGN="LEFT"/>branch : Optional[str]<br ALIGN="LEFT"/>mapped_to : Optional[_artifact_location.ArtifactLocation]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>repository_uri : str<br ALIGN="LEFT"/>revision_id : Optional[str]<br ALIGN="LEFT"/>revision_tag : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.View" [color="black", fontcolor="black", label=<{View|<br ALIGN="LEFT"/>|create(x, new_size)<br ALIGN="LEFT"/>dynamic_reshape_indexer(old_size, new_size)<br ALIGN="LEFT"/>handle_negative_index(idx, size)<br ALIGN="LEFT"/>resolve_negative_size(old_size, new_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch._aot_autograd.schemas.ViewAndMutationMeta" [color="black", fontcolor="black", label=<{ViewAndMutationMeta|aliased_out_indices<br ALIGN="LEFT"/>bw_donated_idxs : Optional[List[int]]<br ALIGN="LEFT"/>deterministic : Optional[bool]<br ALIGN="LEFT"/>dynamic_outputs<br ALIGN="LEFT"/>grad_enabled_mutation : Optional[bool]<br ALIGN="LEFT"/>indices_of_inputs_that_requires_grad_with_mutations_in_bw : List[int]<br ALIGN="LEFT"/>input_info : List[InputAliasInfo]<br ALIGN="LEFT"/>is_rng_op_functionalized : bool<br ALIGN="LEFT"/>is_train : bool<br ALIGN="LEFT"/>keep_input_mutations : bool<br ALIGN="LEFT"/>mutated_graph_handled_indices<br ALIGN="LEFT"/>mutated_graph_handled_indices_seen_by_autograd<br ALIGN="LEFT"/>mutated_inp_runtime_indices<br ALIGN="LEFT"/>num_backward_tokens : int<br ALIGN="LEFT"/>num_forward<br ALIGN="LEFT"/>num_forward_returns<br ALIGN="LEFT"/>num_intermediate_bases : int<br ALIGN="LEFT"/>num_mutated_graph_handled_indices<br ALIGN="LEFT"/>num_mutated_graph_handled_indices_seen_by_autograd<br ALIGN="LEFT"/>num_mutated_inp_runtime_indices<br ALIGN="LEFT"/>num_outputs<br ALIGN="LEFT"/>num_outputs_aliased<br ALIGN="LEFT"/>num_outputs_aliased_to_inputs<br ALIGN="LEFT"/>num_outputs_aliased_to_intermediates<br ALIGN="LEFT"/>num_outputs_non_aliased<br ALIGN="LEFT"/>num_outputs_rng_offset : int<br ALIGN="LEFT"/>num_symints_saved_for_bw : Optional[int]<br ALIGN="LEFT"/>num_unsafe_view_outputs<br ALIGN="LEFT"/>output_info : List[OutputAliasInfo]<br ALIGN="LEFT"/>output_types<br ALIGN="LEFT"/>static_input_indices : List[int]<br ALIGN="LEFT"/>subclass_fw_graph_out_meta : List[Union[PlainTensorMeta, SubclassCreationMeta]]<br ALIGN="LEFT"/>subclass_inp_meta : List[Union[PlainTensorMeta, SubclassCreationMeta]]<br ALIGN="LEFT"/>subclass_tangent_meta : List[Union[PlainTensorMeta, SubclassCreationMeta]]<br ALIGN="LEFT"/>symints_saved_for_backwards_slice<br ALIGN="LEFT"/>tensors_saved_for_backwards_slice<br ALIGN="LEFT"/>tokens : Dict[Any, torch.Tensor]<br ALIGN="LEFT"/>traced_tangent_metas : Optional[List[Any]]<br ALIGN="LEFT"/>traced_tangents : List[Any]<br ALIGN="LEFT"/>unsafe_view_out_indices<br ALIGN="LEFT"/>|make_runtime_safe()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nested._internal.nested_tensor.ViewBufferFromNested" [color="black", fontcolor="black", label=<{ViewBufferFromNested|<br ALIGN="LEFT"/>|backward(ctx, gO: torch.Tensor)<br ALIGN="LEFT"/>forward(ctx, x: NestedTensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.meta_utils.ViewFunc" [color="black", fontcolor="black", label=<{ViewFunc|<br ALIGN="LEFT"/>|<I>apply</I>(t: _TensorT, new_base: _TensorT, symint_visitor_fn: Optional[Callable[[int], int]], tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]]): _TensorT<br ALIGN="LEFT"/>from_tensor(t: torch.Tensor): ViewFunc<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.auto_functionalize.ViewInfo" [color="black", fontcolor="black", label=<{ViewInfo|base_index : int<br ALIGN="LEFT"/>|<I>regenerate_view</I>(bases_list: List[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nested._internal.nested_tensor.ViewNestedFromBuffer" [color="black", fontcolor="black", label=<{ViewNestedFromBuffer|<br ALIGN="LEFT"/>|backward(ctx, gO: NestedTensor)<br ALIGN="LEFT"/>forward(ctx, values: torch.Tensor, offsets: torch.Tensor, metadata_cache: Optional[Dict[str, Any]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.reinplace.ViewOp" [color="black", fontcolor="black", label=<{ViewOp|args : Tuple[Any, ...]<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.virtualized.Virtualized" [color="black", fontcolor="black", label=<{Virtualized|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.VmapIncrementNestingCtxManagerVariable" [color="black", fontcolor="black", label=<{VmapIncrementNestingCtxManagerVariable|<br ALIGN="LEFT"/>|create(tx: 'InstructionTranslator', target_values)<br ALIGN="LEFT"/>enter(tx)<br ALIGN="LEFT"/>exit(tx: 'InstructionTranslator')<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.autograd_function.VmapInfo" [color="black", fontcolor="black", label=<{VmapInfo|batch_size : int<br ALIGN="LEFT"/>randomness : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._functorch.pyfunctorch.VmapInterpreter" [color="black", fontcolor="black", label=<{VmapInterpreter|<br ALIGN="LEFT"/>|batch_size()<br ALIGN="LEFT"/>get_state()<br ALIGN="LEFT"/>process(op, args, kwargs)<br ALIGN="LEFT"/>randomness()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.von_mises.VonMises" [color="black", fontcolor="black", label=<{VonMises|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>loc<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>|expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>sample(sample_shape)<br ALIGN="LEFT"/>variance()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.backcompat.Warning" [color="black", fontcolor="black", label=<{Warning|enabled<br ALIGN="LEFT"/>getter<br ALIGN="LEFT"/>setter<br ALIGN="LEFT"/>|get_enabled()<br ALIGN="LEFT"/>set_enabled(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies.WeakDep" [color="black", fontcolor="black", label=<{WeakDep|index<br ALIGN="LEFT"/>mutating_buf : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|get_numel(): sympy.Expr<br ALIGN="LEFT"/>has_unbacked_symbols()<br ALIGN="LEFT"/>is_contiguous(): bool<br ALIGN="LEFT"/>numbytes_hint()<br ALIGN="LEFT"/>rename(renames: Dict[str, str]): 'WeakDep'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" [color="black", fontcolor="black", label=<{WeakIdKeyDictionary|data : dict<br ALIGN="LEFT"/>ref_type<br ALIGN="LEFT"/>|copy()<br ALIGN="LEFT"/>get(key, default)<br ALIGN="LEFT"/>items()<br ALIGN="LEFT"/>keyrefs()<br ALIGN="LEFT"/>keys()<br ALIGN="LEFT"/>pop(key)<br ALIGN="LEFT"/>popitem()<br ALIGN="LEFT"/>setdefault(key, default)<br ALIGN="LEFT"/>update(dict)<br ALIGN="LEFT"/>values()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.weak.WeakIdRef" [color="black", fontcolor="black", label=<{WeakIdRef|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.source.WeakRefCallSource" [color="black", fontcolor="black", label=<{WeakRefCallSource|<br ALIGN="LEFT"/>|guard_source()<br ALIGN="LEFT"/>name()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.misc.WeakRefVariable" [color="black", fontcolor="black", label=<{WeakRefVariable|referent_vt<br ALIGN="LEFT"/>|build(tx, weakref_value)<br ALIGN="LEFT"/>call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._web_request.WebRequest" [color="black", fontcolor="black", label=<{WebRequest|body : Optional[_artifact_content.ArtifactContent]<br ALIGN="LEFT"/>headers : Optional[Any]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>method : Optional[str]<br ALIGN="LEFT"/>parameters : Optional[Any]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>protocol : Optional[str]<br ALIGN="LEFT"/>target : Optional[str]<br ALIGN="LEFT"/>version : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._web_response.WebResponse" [color="black", fontcolor="black", label=<{WebResponse|body : Optional[_artifact_content.ArtifactContent]<br ALIGN="LEFT"/>headers : Optional[Any]<br ALIGN="LEFT"/>index : int<br ALIGN="LEFT"/>no_response_received : Optional[bool]<br ALIGN="LEFT"/>properties : Optional[_property_bag.PropertyBag]<br ALIGN="LEFT"/>protocol : Optional[str]<br ALIGN="LEFT"/>reason_phrase : Optional[str]<br ALIGN="LEFT"/>status_code : Optional[int]<br ALIGN="LEFT"/>version : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.weibull.Weibull" [color="black", fontcolor="black", label=<{Weibull|arg_constraints : dict<br ALIGN="LEFT"/>concentration<br ALIGN="LEFT"/>concentration_reciprocal<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.weight_norm.WeightNorm" [color="black", fontcolor="black", label=<{WeightNorm|dim : int<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|apply(module, name: str, dim: int): 'WeightNorm'<br ALIGN="LEFT"/>compute_weight(module: Module): Any<br ALIGN="LEFT"/>remove(module: Module): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.pruning.sparsifier.weight_norm_sparsifier.WeightNormSparsifier" [color="black", fontcolor="black", label=<{WeightNormSparsifier|norm_fn : NoneType, int<br ALIGN="LEFT"/>|update_mask(module, tensor_name, sparsity_level, sparse_block_shape, zeros_per_block)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule" [color="black", fontcolor="black", label=<{WeightedQuantizedModule|<br ALIGN="LEFT"/>|<I>from_reference</I>(ref_module, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.sampler.WeightedRandomSampler" [color="black", fontcolor="black", label=<{WeightedRandomSampler|generator : NoneType<br ALIGN="LEFT"/>num_samples : int<br ALIGN="LEFT"/>replacement : bool<br ALIGN="LEFT"/>weights<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir.WelfordReduction" [color="black", fontcolor="black", label=<{WelfordReduction|output_index : int<br ALIGN="LEFT"/>|create(device: torch.device, dtype: torch.dtype, inner_fns: Sequence[Callable[..., Any]], ranges: List[Integer], reduction_ranges: List[Integer], reduction_type: str, reduction_hint: ReductionHint): Sequence[TensorBox]<br ALIGN="LEFT"/>create_multilayer(device: torch.device, dtype: torch.dtype, inner_fns: Sequence[Callable[..., Any]], ranges: List[Integer], reduction_ranges: List[Integer], reduction_type: str, split: _IntLike, reduction_hint: ReductionHint): Sequence[TensorBox]<br ALIGN="LEFT"/>default_value(reduction_type: str, dtype: torch.dtype): Union[_NumLike, Sequence[_NumLike]]<br ALIGN="LEFT"/>store_reduction(output_name: Optional[str], indexer: Callable[[Sequence[Expr]], Never], vars: Sequence[Expr], reduction_vars: Sequence[Symbol]): OpsValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._sympy.functions.Where" [color="black", fontcolor="black", label=<{Where|nargs : Tuple[int, ...]<br ALIGN="LEFT"/>precedence : int<br ALIGN="LEFT"/>|eval(c: sympy.Basic, p: sympy.Basic, q: sympy.Basic): Optional[sympy.Basic]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.ir.WhileLoop" [color="black", fontcolor="black", label=<{WhileLoop|additional_inputs : Optional[List[TensorBox]]<br ALIGN="LEFT"/>body_subgraph : Optional[Subgraph]<br ALIGN="LEFT"/>carried_inputs : Optional[List[TensorBox]]<br ALIGN="LEFT"/>cond_subgraph : Optional[Subgraph]<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>outputs : Optional[List[MultiOutput]]<br ALIGN="LEFT"/>|codegen(wrapper): None<br ALIGN="LEFT"/>create(cond_fn: Subgraph, body_fn: Subgraph, carried_inputs: List[TensorBox], additional_inputs: List[TensorBox])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.WhileLoopHigherOrderVariable" [color="black", fontcolor="black", label=<{WhileLoopHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: List[VariableTracker], kwargs: Dict[str, VariableTracker]): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.while_loop.WhileLoopOp" [color="black", fontcolor="black", label=<{WhileLoopOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.scheduler.WhyNoFuse" [color="black", fontcolor="black", label=<{WhyNoFuse|args : Tuple[Any, ...]<br ALIGN="LEFT"/>node1<br ALIGN="LEFT"/>node2<br ALIGN="LEFT"/>reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.wishart.Wishart" [color="black", fontcolor="black", label=<{Wishart|arg_constraints : dict<br ALIGN="LEFT"/>covariance_matrix<br ALIGN="LEFT"/>df<br ALIGN="LEFT"/>has_rsample : bool<br ALIGN="LEFT"/>mean<br ALIGN="LEFT"/>mode<br ALIGN="LEFT"/>precision_matrix<br ALIGN="LEFT"/>scale_tril<br ALIGN="LEFT"/>support<br ALIGN="LEFT"/>variance<br ALIGN="LEFT"/>|covariance_matrix()<br ALIGN="LEFT"/>entropy()<br ALIGN="LEFT"/>expand(batch_shape, _instance)<br ALIGN="LEFT"/>log_prob(value)<br ALIGN="LEFT"/>precision_matrix()<br ALIGN="LEFT"/>rsample(sample_shape: _size, max_try_correction): torch.Tensor<br ALIGN="LEFT"/>scale_tril()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.effects.WithEffects" [color="black", fontcolor="black", label=<{WithEffects|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.ctx_manager.WithExitFunctionVariable" [color="black", fontcolor="black", label=<{WithExitFunctionVariable|ctx : Union[ContextWrappingVariable, GenericContextWrappingVariable]<br ALIGN="LEFT"/>target<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit.frontend.WithItemBuilder" [color="black", fontcolor="black", label=<{WithItemBuilder|<br ALIGN="LEFT"/>|build_withitem(ctx, item)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._symmetric_memory.Work" [color="black", fontcolor="black", label=<{Work|event<br ALIGN="LEFT"/>|wait(timeout: timedelta): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.cpp.WorkSharing" [color="black", fontcolor="black", label=<{WorkSharing|code<br ALIGN="LEFT"/>in_parallel : bool<br ALIGN="LEFT"/>num_threads : NoneType<br ALIGN="LEFT"/>stack : ExitStack<br ALIGN="LEFT"/>|close()<br ALIGN="LEFT"/>parallel(threads)<br ALIGN="LEFT"/>single()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceInterface.Worker" [color="black", fontcolor="black", label=<{Worker|<br ALIGN="LEFT"/>|<I>current_device</I>(): int<br ALIGN="LEFT"/><I>get_device_properties</I>(device: _device_t)<br ALIGN="LEFT"/><I>set_device</I>(device: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CudaInterface.Worker" [color="black", fontcolor="black", label=<{Worker|<br ALIGN="LEFT"/>|current_device(): int<br ALIGN="LEFT"/>get_device_properties(device: _device_t)<br ALIGN="LEFT"/>set_device(device: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.XpuInterface.Worker" [color="black", fontcolor="black", label=<{Worker|<br ALIGN="LEFT"/>|current_device(): int<br ALIGN="LEFT"/>get_device_properties(device: _device_t)<br ALIGN="LEFT"/>set_device(device: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.CpuInterface.Worker" [color="black", fontcolor="black", label=<{Worker|<br ALIGN="LEFT"/>|get_device_properties(device: _device_t)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.Worker" [color="black", fontcolor="black", label=<{Worker|global_rank : int<br ALIGN="LEFT"/>id : Optional[Any]<br ALIGN="LEFT"/>local_rank : int<br ALIGN="LEFT"/>role_rank : int<br ALIGN="LEFT"/>role_world_size : int<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerGroup" [color="black", fontcolor="black", label=<{WorkerGroup|group_rank : NoneType<br ALIGN="LEFT"/>group_world_size : NoneType<br ALIGN="LEFT"/>master_addr : NoneType<br ALIGN="LEFT"/>master_port : NoneType<br ALIGN="LEFT"/>spec<br ALIGN="LEFT"/>state : FAILED, INIT<br ALIGN="LEFT"/>store : NoneType<br ALIGN="LEFT"/>workers<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.worker.WorkerInfo" [color="black", fontcolor="black", label=<{WorkerInfo|dataset : str<br ALIGN="LEFT"/>id : int<br ALIGN="LEFT"/>num_workers : int<br ALIGN="LEFT"/>seed : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerSpec" [color="black", fontcolor="black", label=<{WorkerSpec|args : Tuple<br ALIGN="LEFT"/>entrypoint : Optional[Union[Callable, str, None]]<br ALIGN="LEFT"/>fn : Optional[Callable]<br ALIGN="LEFT"/>local_addr : Optional[str]<br ALIGN="LEFT"/>local_world_size : int<br ALIGN="LEFT"/>master_addr : Optional[str]<br ALIGN="LEFT"/>master_port : Optional[int]<br ALIGN="LEFT"/>max_restarts : int<br ALIGN="LEFT"/>monitor_interval : float<br ALIGN="LEFT"/>rdzv_handler<br ALIGN="LEFT"/>role : str<br ALIGN="LEFT"/>|get_entrypoint_name()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerState" [color="black", fontcolor="black", label=<{WorkerState|name<br ALIGN="LEFT"/>|is_running(state: 'WorkerState'): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.WorkspaceArg" [color="black", fontcolor="black", label=<{WorkspaceArg|count : Expr<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>get_device_or_error<br ALIGN="LEFT"/>get_output_spec<br ALIGN="LEFT"/>inner_name : str<br ALIGN="LEFT"/>layout<br ALIGN="LEFT"/>maybe_get_layout<br ALIGN="LEFT"/>maybe_get_output_spec<br ALIGN="LEFT"/>outer_name : str<br ALIGN="LEFT"/>zero_mode<br ALIGN="LEFT"/>|can_join(a, b): bool<br ALIGN="LEFT"/>get_device()<br ALIGN="LEFT"/>get_dtype()<br ALIGN="LEFT"/>get_inputs_that_alias_output()<br ALIGN="LEFT"/>get_layout()<br ALIGN="LEFT"/>get_name()<br ALIGN="LEFT"/>get_size()<br ALIGN="LEFT"/>get_stride()<br ALIGN="LEFT"/>join(a, b)<br ALIGN="LEFT"/>maximum(a, b)<br ALIGN="LEFT"/>unique_name(prefix)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.common.WorkspaceZeroMode" [color="black", fontcolor="black", label=<{WorkspaceZeroMode|name<br ALIGN="LEFT"/>|combine(a, b)<br ALIGN="LEFT"/>from_bool(zero_fill)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.multi_threaded_pg.WorldData" [color="black", fontcolor="black", label=<{WorldData|default_pg<br ALIGN="LEFT"/>group_count : int<br ALIGN="LEFT"/>pg_backend_config : Dict[dist.ProcessGroup, str]<br ALIGN="LEFT"/>pg_coalesce_state : Dict[dist.ProcessGroup, List[Union[_CollOp, P2POp]]]<br ALIGN="LEFT"/>pg_group_ranks : Dict[dist.ProcessGroup, Dict[int, int]]<br ALIGN="LEFT"/>pg_map : Dict[dist.ProcessGroup, Tuple[str, Optional[Store]]]<br ALIGN="LEFT"/>pg_names : Dict[dist.ProcessGroup, str]<br ALIGN="LEFT"/>pg_to_tag : Dict[dist.ProcessGroup, str]<br ALIGN="LEFT"/>tags_to_pg : Dict[str, List[dist.ProcessGroup]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.distributed.WorldMetaClassVariable" [color="black", fontcolor="black", label=<{WorldMetaClassVariable|<br ALIGN="LEFT"/>|is_group_member_type(value)<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name: str): VariableTracker<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.wrap.Wrap" [color="black", fontcolor="black", label=<{Wrap|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.wrap.WrapActivationCheckpoint" [color="black", fontcolor="black", label=<{WrapActivationCheckpoint|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.repro.after_dynamo.WrapBackendDebug" [color="black", fontcolor="black", label=<{WrapBackendDebug|get_compiler_config<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.WrapHigherOrderVariable" [color="black", fontcolor="black", label=<{WrapHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>create_wrapped_node(tx: 'InstructionTranslator', fn_vt, fn_args_vt, kwargs, description, under_activation_checkpoint)<br ALIGN="LEFT"/>install_subgraph_in_output_graph(tx, fn_vt, fn_args_vt, kwargs, body_gmod, attr_name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.wrap.WrapWithAutocast" [color="black", fontcolor="black", label=<{WrapWithAutocast|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.WrapWithAutocastHigherOrderVariable" [color="black", fontcolor="black", label=<{WrapWithAutocastHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._higher_order_ops.wrap.WrapWithSetGradEnabled" [color="black", fontcolor="black", label=<{WrapWithSetGradEnabled|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.higher_order_ops.WrapWithSetGradEnabledHigherOrderVariable" [color="black", fontcolor="black", label=<{WrapWithSetGradEnabledHigherOrderVariable|<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._functorch.autograd_function.WrappedCtx" [color="black", fontcolor="black", label=<{WrappedCtx|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.cudagraph_utils.WrappedFunction" [color="black", fontcolor="black", label=<{WrappedFunction|constants : Tuple[torch.Tensor, ...]<br ALIGN="LEFT"/>id<br ALIGN="LEFT"/>model : Callable[..., Any]<br ALIGN="LEFT"/>mutated_input_idxs : Sequence[int]<br ALIGN="LEFT"/>placeholders : Sequence[PlaceholderInfo]<br ALIGN="LEFT"/>static_input_idxs : Sequence[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._capture_strategies.JitTraceConvertStrategy._capture.WrappedModel" [color="black", fontcolor="black", label=<{WrappedModel|model<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.WrappedUserFunctionVariable" [color="black", fontcolor="black", label=<{WrappedUserFunctionVariable|context<br ALIGN="LEFT"/>wrapped<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.WrappedUserMethodVariable" [color="black", fontcolor="black", label=<{WrappedUserMethodVariable|context<br ALIGN="LEFT"/>wrapped<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._trace._non_strict_export._tuplify_outputs._aot_export_non_strict.Wrapper" [color="black", fontcolor="black", label=<{Wrapper|<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.output_graph.WrapperBackend" [color="black", fontcolor="black", label=<{WrapperBackend|backend : Callable<br ALIGN="LEFT"/>candidate<br ALIGN="LEFT"/>gm<br ALIGN="LEFT"/>restore<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ops_handler.WrapperHandler" [color="black", fontcolor="black", label=<{WrapperHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.codegen.wrapper.WrapperLine" [color="black", fontcolor="black", label=<{WrapperLine|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.backends.distributed.SubmodCompiler.compile_submod.WrapperModule" [color="black", fontcolor="black", label=<{WrapperModule|submod<br ALIGN="LEFT"/>unwrap_singleton_tuple<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.WrapperModule" [color="black", fontcolor="black", label=<{WrapperModule|model<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>gradients(ctx_id)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.subclasses.WrapperSubclass" [color="black", fontcolor="black", label=<{WrapperSubclass|a<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.WrapperTensor" [color="black", fontcolor="black", label=<{WrapperTensor|<br ALIGN="LEFT"/>|<I>get_wrapper_properties</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.WrapperTensorWithCustomSizes" [color="black", fontcolor="black", label=<{WrapperTensorWithCustomSizes|t<br ALIGN="LEFT"/>|get_wrapper_properties(t, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_subclass.WrapperTensorWithCustomStrides" [color="black", fontcolor="black", label=<{WrapperTensorWithCustomStrides|t<br ALIGN="LEFT"/>|get_wrapper_properties(t, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.functions.WrapperUserFunctionVariable" [color="black", fontcolor="black", label=<{WrapperUserFunctionVariable|attr_to_trace<br ALIGN="LEFT"/>wrapper_obj<br ALIGN="LEFT"/>|call_function(tx: 'InstructionTranslator', args: 'List[VariableTracker]', kwargs: 'Dict[str, VariableTracker]'): 'VariableTracker'<br ALIGN="LEFT"/>var_getattr(tx: 'InstructionTranslator', name)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.WriteItem" [color="black", fontcolor="black", label=<{WriteItem|index<br ALIGN="LEFT"/>tensor_data : Optional[TensorWriteData]<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|tensor_storage_size(): Optional[int]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.planner.WriteItemType" [color="black", fontcolor="black", label=<{WriteItemType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.storage.WriteResult" [color="black", fontcolor="black", label=<{WriteResult|index<br ALIGN="LEFT"/>size_in_bytes : int<br ALIGN="LEFT"/>storage_data : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.repro.after_aot.repro_analyze.WriterInterp" [color="black", fontcolor="black", label=<{WriterInterp|subdir<br ALIGN="LEFT"/>|run_node(n)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.x86_inductor_quantizer.X86InductorQuantizer" [color="black", fontcolor="black", label=<{X86InductorQuantizer|global_config : Optional[QuantizationConfig]<br ALIGN="LEFT"/>module_function_to_aten_operator_type : dict<br ALIGN="LEFT"/>module_name_qconfig : Dict[str, Optional[QuantizationConfig]]<br ALIGN="LEFT"/>operator_type_qconfig : Dict[torch._ops.OpOverloadPacket, Optional[QuantizationConfig]]<br ALIGN="LEFT"/>|annotate(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/>get_global_quantization_config()<br ALIGN="LEFT"/>set_function_type_qconfig(function_type: Callable, quantization_config: Optional[QuantizationConfig]): 'X86InductorQuantizer'<br ALIGN="LEFT"/>set_global(quantization_config: QuantizationConfig)<br ALIGN="LEFT"/>set_module_name_qconfig(module_name: str, quantization_config: Optional[QuantizationConfig])<br ALIGN="LEFT"/>set_module_type_qconfig(module_type: torch.nn.Module, quantization_config: Optional[QuantizationConfig]): 'X86InductorQuantizer'<br ALIGN="LEFT"/><I>validate</I>(model: torch.fx.GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.XFailRule" [color="black", fontcolor="black", label=<{XFailRule|error_msg : str<br ALIGN="LEFT"/>error_type : TypeVar<br ALIGN="LEFT"/>type<br ALIGN="LEFT"/>|get_context(test_case)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.run_tests.XMLTestResultVerbose" [color="black", fontcolor="black", label=<{XMLTestResultVerbose|<br ALIGN="LEFT"/>|addSkip(test, reason)<br ALIGN="LEFT"/>printErrors(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.xnnpack.XNNPACKEngine" [color="black", fontcolor="black", label=<{XNNPACKEngine|enabled<br ALIGN="LEFT"/>m<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer.XNNPACKQuantizer" [color="black", fontcolor="black", label=<{XNNPACKQuantizer|DYNAMIC_OPS : list<br ALIGN="LEFT"/>STATIC_OPS : list<br ALIGN="LEFT"/>STATIC_QAT_ONLY_OPS : list<br ALIGN="LEFT"/>global_config : Optional[QuantizationConfig]<br ALIGN="LEFT"/>module_name_config : Dict[str, Optional[QuantizationConfig]]<br ALIGN="LEFT"/>module_type_config : Dict[Callable, Optional[QuantizationConfig]]<br ALIGN="LEFT"/>operator_type_config : Dict[torch._ops.OpOverloadPacket, Optional[QuantizationConfig]]<br ALIGN="LEFT"/>supported_config_and_operators : list<br ALIGN="LEFT"/>|annotate(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/>get_supported_operator_for_quantization_config(quantization_config: Optional[QuantizationConfig]): List[OperatorPatternType]<br ALIGN="LEFT"/>get_supported_operators(): List[OperatorConfig]<br ALIGN="LEFT"/>get_supported_quantization_configs(): List[QuantizationConfig]<br ALIGN="LEFT"/>set_global(quantization_config: QuantizationConfig): XNNPACKQuantizer<br ALIGN="LEFT"/>set_module_name(module_name: str, quantization_config: Optional[QuantizationConfig])<br ALIGN="LEFT"/>set_module_type(module_type: Callable, quantization_config: QuantizationConfig)<br ALIGN="LEFT"/>set_operator_type(operator_type: torch._ops.OpOverloadPacket, quantization_config: QuantizationConfig): XNNPACKQuantizer<br ALIGN="LEFT"/>transform_for_annotation(model: torch.fx.GraphModule): torch.fx.GraphModule<br ALIGN="LEFT"/><I>validate</I>(model: torch.fx.GraphModule): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.codegen.xpu.device_op_overrides.XPUDeviceOpOverrides" [color="black", fontcolor="black", label=<{XPUDeviceOpOverrides|<br ALIGN="LEFT"/>|abi_compatible_header()<br ALIGN="LEFT"/>aoti_get_stream()<br ALIGN="LEFT"/>cpp_aoti_device_guard()<br ALIGN="LEFT"/>cpp_aoti_stream_guard()<br ALIGN="LEFT"/>cpp_device_guard()<br ALIGN="LEFT"/>cpp_device_ptr()<br ALIGN="LEFT"/>cpp_getStreamFromExternal()<br ALIGN="LEFT"/>cpp_kernel_type()<br ALIGN="LEFT"/>cpp_stream_guard()<br ALIGN="LEFT"/>cpp_stream_type()<br ALIGN="LEFT"/>device_guard(device_idx)<br ALIGN="LEFT"/>import_get_raw_stream_as(name)<br ALIGN="LEFT"/>kernel_driver()<br ALIGN="LEFT"/>kernel_header()<br ALIGN="LEFT"/>set_device(device_idx)<br ALIGN="LEFT"/>synchronize()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.xpu_inductor_quantizer.XPUInductorQuantizer" [color="black", fontcolor="black", label=<{XPUInductorQuantizer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.XPUTestBase" [color="black", fontcolor="black", label=<{XPUTestBase|device_type : str<br ALIGN="LEFT"/>primary_device : ClassVar[str]<br ALIGN="LEFT"/>|get_all_devices()<br ALIGN="LEFT"/>get_primary_device()<br ALIGN="LEFT"/>setUpClass()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.device_interface.XpuInterface" [color="black", fontcolor="black", label=<{XpuInterface|Event<br ALIGN="LEFT"/>Stream<br ALIGN="LEFT"/>current_device : staticmethod<br ALIGN="LEFT"/>current_stream : staticmethod<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>device_count : staticmethod<br ALIGN="LEFT"/>exchange_device : staticmethod<br ALIGN="LEFT"/>get_device_properties : staticmethod<br ALIGN="LEFT"/>get_raw_stream : staticmethod<br ALIGN="LEFT"/>maybe_exchange_device : staticmethod<br ALIGN="LEFT"/>memory_allocated : staticmethod<br ALIGN="LEFT"/>set_device : staticmethod<br ALIGN="LEFT"/>set_stream : staticmethod<br ALIGN="LEFT"/>stream : staticmethod<br ALIGN="LEFT"/>synchronize : staticmethod<br ALIGN="LEFT"/>|get_compute_capability(device: _device_t)<br ALIGN="LEFT"/>is_available(): bool<br ALIGN="LEFT"/>is_bf16_supported(including_emulation: bool): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.autograd_function_db.ZeroGradientsGenVmap" [color="black", fontcolor="black", label=<{ZeroGradientsGenVmap|generate_vmap_rule : bool<br ALIGN="LEFT"/>|backward(ctx, gx, gy)<br ALIGN="LEFT"/>forward(x, y)<br ALIGN="LEFT"/>jvp(ctx, gx, gy)<br ALIGN="LEFT"/><I>setup_context</I>(ctx, inputs, outputs)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding.ZeroPad1d" [color="black", fontcolor="black", label=<{ZeroPad1d|padding : Tuple[int, int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding.ZeroPad2d" [color="black", fontcolor="black", label=<{ZeroPad2d|padding : Tuple[int, int, int, int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding.ZeroPad3d" [color="black", fontcolor="black", label=<{ZeroPad3d|padding : Tuple[int, int, int, int, int, int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer.ZeroRedundancyOptimizer" [color="black", fontcolor="black", label=<{ZeroRedundancyOptimizer|functional_optim_map : Any<br ALIGN="LEFT"/>global_rank : int<br ALIGN="LEFT"/>initialized : bool<br ALIGN="LEFT"/>join_device<br ALIGN="LEFT"/>optim : Any<br ALIGN="LEFT"/>parameters_as_bucket_view : bool<br ALIGN="LEFT"/>process_group : Any<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|add_param_group(param_group: dict[str, Any]): None<br ALIGN="LEFT"/>consolidate_state_dict(to: int): None<br ALIGN="LEFT"/>join_hook()<br ALIGN="LEFT"/>join_process_group(): Any<br ALIGN="LEFT"/>load_state_dict(state_dict: dict[str, Any]): None<br ALIGN="LEFT"/>state_dict(): dict[str, Any]<br ALIGN="LEFT"/>step(closure: None): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.iter.ZipVariable" [color="black", fontcolor="black", label=<{ZipVariable|index : int<br ALIGN="LEFT"/>iterables : List[Union[List[VariableTracker], VariableTracker]]<br ALIGN="LEFT"/>strict : bool<br ALIGN="LEFT"/>|has_unpack_var_sequence(tx): bool<br ALIGN="LEFT"/>next_variable(tx)<br ALIGN="LEFT"/>python_type()<br ALIGN="LEFT"/>reconstruct(codegen)<br ALIGN="LEFT"/>reconstruct_items(codegen)<br ALIGN="LEFT"/>unpack_var_sequence(tx): List['VariableTracker']<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining.ZipperIterDataPipe" [color="black", fontcolor="black", label=<{ZipperIterDataPipe|datapipes : Tuple[IterDataPipe]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.map.combining.ZipperMapDataPipe" [color="black", fontcolor="black", label=<{ZipperMapDataPipe|datapipes : Tuple[MapDataPipe[_T_co], ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._Action" [color="black", fontcolor="black", label=<{_Action|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules._Action" [color="black", fontcolor="black", label=<{_Action|computation_type<br ALIGN="LEFT"/>microbatch_index : Optional[int]<br ALIGN="LEFT"/>stage_index : int<br ALIGN="LEFT"/>|from_str(action_string: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._AdaptiveAvgPoolNd" [color="black", fontcolor="black", label=<{_AdaptiveAvgPoolNd|output_size : Union<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._AdaptiveMaxPoolNd" [color="black", fontcolor="black", label=<{_AdaptiveMaxPoolNd|output_size : Union<br ALIGN="LEFT"/>return_indices : bool<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.passes.add_runtime_assertions_for_constraints_pass._AddRuntimeAssertionsForInlineConstraintsPass" [color="black", fontcolor="black", label=<{_AddRuntimeAssertionsForInlineConstraintsPass|counter : int<br ALIGN="LEFT"/>existing_inline_assertions : dict<br ALIGN="LEFT"/>range_constraints : Dict[sympy.Symbol, ValueRanges]<br ALIGN="LEFT"/>|call(graph_module): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._AllGather" [color="black", fontcolor="black", label=<{_AllGather|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._AllGatherBase" [color="black", fontcolor="black", label=<{_AllGatherBase|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, output_tensor, input_tensor, group)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.micro_pipeline_tp._AllGatherMatch" [color="black", fontcolor="black", label=<{_AllGatherMatch|ag_node<br ALIGN="LEFT"/>gather_dim : int<br ALIGN="LEFT"/>group_name : str<br ALIGN="LEFT"/>match<br ALIGN="LEFT"/>res_node<br ALIGN="LEFT"/>shard_node<br ALIGN="LEFT"/>|erase(): None<br ALIGN="LEFT"/>replace_with(new_node: torch.fx.Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._AllGatherRotater" [color="black", fontcolor="black", label=<{_AllGatherRotater|<br ALIGN="LEFT"/>|exchange_buffers(curr_buffer: torch.Tensor): None<br ALIGN="LEFT"/>next_buffer(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._AllReduce" [color="black", fontcolor="black", label=<{_AllReduce|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, op, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._AllToAllRotater" [color="black", fontcolor="black", label=<{_AllToAllRotater|<br ALIGN="LEFT"/>|exchange_buffers(curr_buffer: torch.Tensor): None<br ALIGN="LEFT"/>next_buffer(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph._AllowMutationOnSavedContext" [color="black", fontcolor="black", label=<{_AllowMutationOnSavedContext|cloned : MutableMapping[_Handle, torch.Tensor]<br ALIGN="LEFT"/>original : MutableMapping[_Handle, torch.Tensor]<br ALIGN="LEFT"/>sid_to_tid : Dict[_SID, Set[_TID]]<br ALIGN="LEFT"/>tid_to_weakhandle : MutableMapping[_TID, _Handle]<br ALIGN="LEFT"/>|clear(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.mixed_precision_hooks._AllreduceUpcastHookState" [color="black", fontcolor="black", label=<{_AllreduceUpcastHookState|ddp_weakref : Any<br ALIGN="LEFT"/>upcast_stream<br ALIGN="LEFT"/>wait_for_stream_enqueued : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.nn.functional._AlltoAll" [color="black", fontcolor="black", label=<{_AlltoAll|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, group, out_tensor_list)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._AlltoAllSingle" [color="black", fontcolor="black", label=<{_AlltoAllSingle|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, group, output, output_split_sizes, input_split_sizes, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.utils._Anchors" [color="black", fontcolor="black", label=<{_Anchors|left_end_lineno : int<br ALIGN="LEFT"/>left_end_offset : int<br ALIGN="LEFT"/>right_start_lineno : int<br ALIGN="LEFT"/>right_start_offset : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils._AssertRaisesRegexWithHighlightContext" [color="black", fontcolor="black", label=<{_AssertRaisesRegexWithHighlightContext|exception_type<br ALIGN="LEFT"/>highlight<br ALIGN="LEFT"/>regex<br ALIGN="LEFT"/>test_case<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.polyfills.pytree._Asterisk" [color="black", fontcolor="black", label=<{_Asterisk|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._AttentionContextParallel" [color="black", fontcolor="black", label=<{_AttentionContextParallel|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._AttentionOp" [color="black", fontcolor="black", label=<{_AttentionOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.unflatten._AttrKind" [color="black", fontcolor="black", label=<{_AttrKind|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._AttrProxy" [color="black", fontcolor="black", label=<{_AttrProxy|<br ALIGN="LEFT"/>|<I>reset_proxy_mapping</I>(base: Module, path: str): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.autotune_cache._AutotuneCacheBundlerImpl" [color="black", fontcolor="black", label=<{_AutotuneCacheBundlerImpl|<br ALIGN="LEFT"/>|end_compile(): None<br ALIGN="LEFT"/>put(basename: str, data: JsonDataTy): None<br ALIGN="LEFT"/><I>sync</I>(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._AvgPoolNd" [color="black", fontcolor="black", label=<{_AvgPoolNd|<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._awaits._Await" [color="black", fontcolor="black", label=<{_Await|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" [color="black", fontcolor="black", label=<{_BackendRendezvousStateHolder|state<br ALIGN="LEFT"/>|mark_dirty(): None<br ALIGN="LEFT"/>sync(): Optional[bool]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataloader._BaseDataLoaderIter" [color="black", fontcolor="black", label=<{_BaseDataLoaderIter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.fetch._BaseDatasetFetcher" [color="black", fontcolor="black", label=<{_BaseDatasetFetcher|auto_collation<br ALIGN="LEFT"/>collate_fn<br ALIGN="LEFT"/>dataset<br ALIGN="LEFT"/>drop_last<br ALIGN="LEFT"/>|<I>fetch</I>(possibly_batched_index)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._vendor.packaging.version._BaseVersion" [color="black", fontcolor="black", label=<{_BaseVersion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.batchnorm._BatchNorm" [color="black", fontcolor="black", label=<{_BatchNorm|bias<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|from_float(cls, mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(bn, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm._BatchNorm" [color="black", fontcolor="black", label=<{_BatchNorm|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Boolean" [color="black", fontcolor="black", label=<{_Boolean|is_discrete : bool<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._Broadcast" [color="black", fontcolor="black", label=<{_Broadcast|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, src, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel.distributed._BufferCommHook" [color="black", fontcolor="black", label=<{_BufferCommHook|buffer_comm_hook : Callable<br ALIGN="LEFT"/>buffer_comm_hook_location<br ALIGN="LEFT"/>buffer_comm_hook_state : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parallel.distributed._BufferCommHookLocation" [color="black", fontcolor="black", label=<{_BufferCommHookLocation|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parameter._BufferMeta" [color="black", fontcolor="black", label=<{_BufferMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor._BypassDispatchCache" [color="black", fontcolor="red", label=<{_BypassDispatchCache|reason : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.xeon.run_cpu._CPUinfo" [color="black", fontcolor="black", label=<{_CPUinfo|cpuinfo : list<br ALIGN="LEFT"/>logical_core_node_map : dict<br ALIGN="LEFT"/>node_logical_cores : List[List[int]]<br ALIGN="LEFT"/>node_nums<br ALIGN="LEFT"/>node_physical_cores : List[List[int]]<br ALIGN="LEFT"/>physical_core_node_map : dict<br ALIGN="LEFT"/>|get_all_logical_cores()<br ALIGN="LEFT"/>get_all_physical_cores()<br ALIGN="LEFT"/>get_node_logical_cores(node_id)<br ALIGN="LEFT"/>get_node_physical_cores(node_id)<br ALIGN="LEFT"/>numa_aware_check(core_list)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.memory._CUDAAllocator" [color="black", fontcolor="black", label=<{_CUDAAllocator|<br ALIGN="LEFT"/>|allocator()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._CacheKeyState" [color="black", fontcolor="black", label=<{_CacheKeyState|shape_env : Optional[ShapeEnv]<br ALIGN="LEFT"/>sym_node_lookup : Dict[int, int]<br ALIGN="LEFT"/>|cache_on_shape_env(): bool<br ALIGN="LEFT"/>convert_output(arg: _MetadataIntLike): _MetadataIntLike<br ALIGN="LEFT"/>convert_sym_int(result: List[object], arg: SymInt): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.remote_cache._CacheStat" [color="black", fontcolor="black", label=<{_CacheStat|exception : int<br ALIGN="LEFT"/>hit : int<br ALIGN="LEFT"/>miss : int<br ALIGN="LEFT"/>put : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.remote_cache._CacheStats" [color="black", fontcolor="black", label=<{_CacheStats|<br ALIGN="LEFT"/>|exception(name: str, count: int): None<br ALIGN="LEFT"/>get(name: str, value: Optional[object]): None<br ALIGN="LEFT"/>hit(name: str, count: int): None<br ALIGN="LEFT"/>miss(name: str, count: int): None<br ALIGN="LEFT"/>put(name: str, count: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script._CachedForward" [color="black", fontcolor="black", label=<{_CachedForward|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._CachedTorchDispatchMode" [color="black", fontcolor="black", label=<{_CachedTorchDispatchMode|allow_cache_entry_mutation<br ALIGN="LEFT"/>policy_fn<br ALIGN="LEFT"/>storage<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._CachingTorchDispatchMode" [color="black", fontcolor="black", label=<{_CachingTorchDispatchMode|policy_fn<br ALIGN="LEFT"/>storage<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._refs.fft._CanonicalizeC2rReturn" [color="black", fontcolor="black", label=<{_CanonicalizeC2rReturn|dim : Tuple[int, ...]<br ALIGN="LEFT"/>last_dim_size : int<br ALIGN="LEFT"/>shape : Tuple[int, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._Cat" [color="black", fontcolor="black", label=<{_Cat|cseq : list<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>event_dim<br ALIGN="LEFT"/>is_discrete<br ALIGN="LEFT"/>lengths : list<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._CausalBehavior" [color="black", fontcolor="black", label=<{_CausalBehavior|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._CheckpointFrame" [color="black", fontcolor="black", label=<{_CheckpointFrame|early_stop<br ALIGN="LEFT"/>forward_completed : bool<br ALIGN="LEFT"/>ignore_saved_mismatch : bool<br ALIGN="LEFT"/>input_saver : NoneType<br ALIGN="LEFT"/>is_recomputed : DefaultDict[int, bool]<br ALIGN="LEFT"/>metadata_fn<br ALIGN="LEFT"/>recomp_counter : DefaultDict[int, int]<br ALIGN="LEFT"/>recompute_fn<br ALIGN="LEFT"/>recomputed : DefaultDict[int, weakref.WeakKeyDictionary[_Handle, torch.Tensor]]<br ALIGN="LEFT"/>unpack_error_cb<br ALIGN="LEFT"/>weak_holders : List[ReferenceType]<br ALIGN="LEFT"/>x_metadatas : list<br ALIGN="LEFT"/>|check_recomputed_tensors_match(gid)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._checkpointable._Checkpointable" [color="black", fontcolor="black", label=<{_Checkpointable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint._checkpointer._Checkpointer" [color="black", fontcolor="black", label=<{_Checkpointer|coordinator_rank : int<br ALIGN="LEFT"/>load_planner : NoneType<br ALIGN="LEFT"/>no_dist : bool<br ALIGN="LEFT"/>process_group : NoneType<br ALIGN="LEFT"/>save_planner : NoneType<br ALIGN="LEFT"/>storage_reader<br ALIGN="LEFT"/>storage_writer<br ALIGN="LEFT"/>|async_save(state_dict: STATE_DICT_TYPE): Future<br ALIGN="LEFT"/>load(state_dict: Dict[str, Any]): None<br ALIGN="LEFT"/>save(state_dict: STATE_DICT_TYPE): Metadata<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining._ChildDataPipe" [color="black", fontcolor="black", label=<{_ChildDataPipe|instance_id : int<br ALIGN="LEFT"/>main_datapipe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding._CircularPadNd" [color="black", fontcolor="black", label=<{_CircularPadNd|padding : Sequence[int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._classes._ClassNamespace" [color="black", fontcolor="black", label=<{_ClassNamespace|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._utils._ClassPropertyDescriptor" [color="black", fontcolor="black", label=<{_ClassPropertyDescriptor|fget<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._classes._Classes" [color="black", fontcolor="black", label=<{_Classes|loaded_libraries<br ALIGN="LEFT"/>|load_library(path)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph._CloneArgBeforeMutateMode" [color="black", fontcolor="black", label=<{_CloneArgBeforeMutateMode|ctx : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._CoalescingManager" [color="black", fontcolor="black", label=<{_CoalescingManager|works : List[Work]<br ALIGN="LEFT"/>|append(work: Work)<br ALIGN="LEFT"/>wait()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph_module._CodeOnlyModule" [color="black", fontcolor="black", label=<{_CodeOnlyModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.jiterator._CodeParser" [color="black", fontcolor="black", label=<{_CodeParser|function_body<br ALIGN="LEFT"/>function_name<br ALIGN="LEFT"/>function_params<br ALIGN="LEFT"/>return_type<br ALIGN="LEFT"/>template_params<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._CollOp" [color="black", fontcolor="black", label=<{_CollOp|dst_tensor : Optional[torch.Tensor]<br ALIGN="LEFT"/>op : Callable<br ALIGN="LEFT"/>redop : Optional[ReduceOp]<br ALIGN="LEFT"/>root : Optional[int]<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir._CollectiveKernel" [color="black", fontcolor="black", label=<{_CollectiveKernel|cpp_kernel_name<br ALIGN="LEFT"/>ordered_kwargs_for_cpp_kernel<br ALIGN="LEFT"/>outputs : list<br ALIGN="LEFT"/>|create_inplace(kernel, inputs: Union[TensorBox, List[TensorBox]]): None<br ALIGN="LEFT"/>create_out_of_place(kernel, inputs: Union[TensorBox, List[TensorBox]])<br ALIGN="LEFT"/>has_side_effects(): bool<br ALIGN="LEFT"/>set_cpp_kernel_name(cpp_kernel_name: Optional[str]): None<br ALIGN="LEFT"/>should_allocate(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.compare._Column" [color="black", fontcolor="black", label=<{_Column|<br ALIGN="LEFT"/>|get_results_for(group)<br ALIGN="LEFT"/>num_to_str(value: Optional[float], estimated_sigfigs: int, spread: Optional[float])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" [color="black", fontcolor="black", label=<{_CommModeModuleTracker|activation_checkpointing : bool<br ALIGN="LEFT"/>module_helper_dict : dict<br ALIGN="LEFT"/>module_parameters_dict : dict<br ALIGN="LEFT"/>module_parents_dict : dict<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>parent_dict : dict<br ALIGN="LEFT"/>parent_list : list<br ALIGN="LEFT"/>register_forward_hook_handles : dict<br ALIGN="LEFT"/>sharding_dict : dict<br ALIGN="LEFT"/>|print_paramater_info()<br ALIGN="LEFT"/>print_sharding_info()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.schema_check._Commit" [color="black", fontcolor="black", label=<{_Commit|additions : Dict[str, Any]<br ALIGN="LEFT"/>base : Dict[str, Any]<br ALIGN="LEFT"/>checksum_head : Optional[str]<br ALIGN="LEFT"/>checksum_next : str<br ALIGN="LEFT"/>cpp_header : str<br ALIGN="LEFT"/>cpp_header_path : str<br ALIGN="LEFT"/>result : Dict[str, Any]<br ALIGN="LEFT"/>subtractions : Dict[str, Any]<br ALIGN="LEFT"/>thrift_checksum_head : Optional[str]<br ALIGN="LEFT"/>thrift_checksum_next : str<br ALIGN="LEFT"/>thrift_checksum_real : Optional[str]<br ALIGN="LEFT"/>thrift_schema : str<br ALIGN="LEFT"/>thrift_schema_path : str<br ALIGN="LEFT"/>yaml_path : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compile_fx._CompileFxCallable" [color="black", fontcolor="black", label=<{_CompileFxCallable|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compile_fx._CompileFxKwargs" [color="black", fontcolor="black", label=<{_CompileFxKwargs|aot_mode : bool<br ALIGN="LEFT"/>boxed_forward_device_index : Optional[BoxedDeviceIndex]<br ALIGN="LEFT"/>cpp_wrapper : bool<br ALIGN="LEFT"/>cudagraphs : Optional[BoxedBool]<br ALIGN="LEFT"/>extern_node_serializer : Optional[Callable[[List[ExternKernelNode]], Any]]<br ALIGN="LEFT"/>graph_id : Optional[int]<br ALIGN="LEFT"/>is_backward : bool<br ALIGN="LEFT"/>is_inference : bool<br ALIGN="LEFT"/>layout_opt : Optional[bool]<br ALIGN="LEFT"/>static_input_idxs : Sequence[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.comptime._Comptime" [color="black", fontcolor="black", label=<{_Comptime|<br ALIGN="LEFT"/>|assert_static(val)<br ALIGN="LEFT"/>breakpoint()<br ALIGN="LEFT"/>force_static(val)<br ALIGN="LEFT"/>graph_break()<br ALIGN="LEFT"/>print(e)<br ALIGN="LEFT"/>print_bt()<br ALIGN="LEFT"/>print_disas()<br ALIGN="LEFT"/>print_graph()<br ALIGN="LEFT"/>print_guards()<br ALIGN="LEFT"/>print_locals()<br ALIGN="LEFT"/>print_value_stack()<br ALIGN="LEFT"/>print_value_stack_and_return(e)<br ALIGN="LEFT"/>sleep(sec)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules._ComputationType" [color="black", fontcolor="black", label=<{_ComputationType|name<br ALIGN="LEFT"/>|from_str(action)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.wrap._ConfigAutoWrap" [color="black", fontcolor="black", label=<{_ConfigAutoWrap|in_autowrap_context : bool<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>wrapper_cls : Optional[Callable]<br ALIGN="LEFT"/>|disable_autowrap_context(): None<br ALIGN="LEFT"/>enable_autowrap_context(kwargs: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._config_module._ConfigEntry" [color="black", fontcolor="black", label=<{_ConfigEntry|default : Any<br ALIGN="LEFT"/>env_value_default : Any<br ALIGN="LEFT"/>env_value_force : Any<br ALIGN="LEFT"/>hide : bool<br ALIGN="LEFT"/>justknob : Optional[str]<br ALIGN="LEFT"/>user_override : Any<br ALIGN="LEFT"/>value_type : type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._optim_utils._ConsolidatedOptimState" [color="black", fontcolor="black", label=<{_ConsolidatedOptimState|non_tensor_state : Dict[str, Any]<br ALIGN="LEFT"/>tensor_state : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>zero_dim_tensor_state : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding._ConstantPadNd" [color="black", fontcolor="black", label=<{_ConstantPadNd|padding : Sequence[int]<br ALIGN="LEFT"/>value : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._Constraint" [color="black", fontcolor="black", label=<{_Constraint|constraint_range : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>serializable_spec<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._ConstraintTarget" [color="black", fontcolor="black", label=<{_ConstraintTarget|dim : int<br ALIGN="LEFT"/>t_id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier._Container" [color="black", fontcolor="black", label=<{_Container|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining._ContainerTemplate" [color="black", fontcolor="black", label=<{_ContainerTemplate|<br ALIGN="LEFT"/>|<I>get_length_by_instance</I>(instance_id: int)<br ALIGN="LEFT"/><I>get_next_element_by_instance</I>(instance_id: int)<br ALIGN="LEFT"/><I>is_every_instance_exhausted</I>(): bool<br ALIGN="LEFT"/><I>reset</I>(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.utils._PeriodicTimer._Context" [color="black", fontcolor="black", label=<{_Context|args : Tuple[Any, ...]<br ALIGN="LEFT"/>function : Callable[..., None]<br ALIGN="LEFT"/>interval : float<br ALIGN="LEFT"/>kwargs : Dict[str, Any]<br ALIGN="LEFT"/>stop_event : Event<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._ContextParallelOptions" [color="black", fontcolor="black", label=<{_ContextParallelOptions|convert_to_f32 : bool<br ALIGN="LEFT"/>enable_load_balance : bool<br ALIGN="LEFT"/>rotate_method<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [color="black", fontcolor="black", label=<{_ConvBnNd|bias<br ALIGN="LEFT"/>bn<br ALIGN="LEFT"/>freeze_bn : bool<br ALIGN="LEFT"/>qconfig : NoneType<br ALIGN="LEFT"/>training : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>forward(input)<br ALIGN="LEFT"/>freeze_bn_stats()<br ALIGN="LEFT"/>from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>reset_bn_parameters()<br ALIGN="LEFT"/>reset_parameters()<br ALIGN="LEFT"/>reset_running_stats()<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>train(mode)<br ALIGN="LEFT"/>update_bn_stats()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv._ConvNd" [color="black", fontcolor="black", label=<{_ConvNd|<br ALIGN="LEFT"/>|from_float(cls, float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv._ConvNd" [color="black", fontcolor="black", label=<{_ConvNd|dilation<br ALIGN="LEFT"/>groups<br ALIGN="LEFT"/>in_channels<br ALIGN="LEFT"/>kernel_size<br ALIGN="LEFT"/>out_channels<br ALIGN="LEFT"/>output_padding<br ALIGN="LEFT"/>padding<br ALIGN="LEFT"/>padding_mode : str<br ALIGN="LEFT"/>scale : float<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>training<br ALIGN="LEFT"/>transposed<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|<I>bias</I>()<br ALIGN="LEFT"/>extra_repr()<br ALIGN="LEFT"/>from_float(cls, mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(ref_qconv, output_scale, output_zero_point)<br ALIGN="LEFT"/>get_qconv(mod, activation_post_process, weight_post_process)<br ALIGN="LEFT"/><I>set_weight_bias</I>(qweight, bias_float)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.qat.modules.conv._ConvNd" [color="black", fontcolor="black", label=<{_ConvNd|qconfig : NoneType<br ALIGN="LEFT"/>weight_fake_quant<br ALIGN="LEFT"/>|forward(input)<br ALIGN="LEFT"/>from_float(cls, mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>to_float()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv._ConvNd" [color="black", fontcolor="black", label=<{_ConvNd|bias : Optional[Tensor]<br ALIGN="LEFT"/>dilation : Tuple[int, ...]<br ALIGN="LEFT"/>groups : int<br ALIGN="LEFT"/>in_channels : int<br ALIGN="LEFT"/>kernel_size : Tuple[int, ...]<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>output_padding : Tuple[int, ...]<br ALIGN="LEFT"/>padding : Union[str, Tuple[int, ...]]<br ALIGN="LEFT"/>padding_mode : str<br ALIGN="LEFT"/>stride : Tuple[int, ...]<br ALIGN="LEFT"/>transposed : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv._ConvTransposeMixin" [color="black", fontcolor="black", label=<{_ConvTransposeMixin|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" [color="black", fontcolor="black", label=<{_ConvTransposeNd|<br ALIGN="LEFT"/>|from_float(cls, float_conv, weight_qparams)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantized.modules.conv._ConvTransposeNd" [color="black", fontcolor="black", label=<{_ConvTransposeNd|scale : float<br ALIGN="LEFT"/>zero_point : int<br ALIGN="LEFT"/>|from_float(mod, use_precomputed_fake_quant)<br ALIGN="LEFT"/>from_reference(cls, ref_qconvt, output_scale, output_zero_point)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv._ConvTransposeNd" [color="black", fontcolor="black", label=<{_ConvTransposeNd|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._CorrCholesky" [color="black", fontcolor="black", label=<{_CorrCholesky|event_dim : int<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaBase" [color="black", fontcolor="black", label=<{_CudaBase|is_cuda : bool<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>|type()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [color="black", fontcolor="black", label=<{_CudaLegacyStorage|<br ALIGN="LEFT"/>|from_buffer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.x86_inductor_quantizer._CurrentQuantizationMode" [color="black", fontcolor="black", label=<{_CurrentQuantizationMode|dynamic_state : Optional[bool]<br ALIGN="LEFT"/>qat_state : Optional[bool]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph._CustomBuiltin" [color="black", fontcolor="black", label=<{_CustomBuiltin|import_str : str<br ALIGN="LEFT"/>obj : Any<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.microbatch._CustomReducer" [color="black", fontcolor="black", label=<{_CustomReducer|init_value<br ALIGN="LEFT"/>reduce_fn<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.meta_utils._CustomViewFunc" [color="black", fontcolor="black", label=<{_CustomViewFunc|func : Callable[[torch.Tensor, Optional[Callable[[int], int]], Optional[Callable[[torch.Tensor], _TensorT]]], _TensorT]<br ALIGN="LEFT"/>|apply(t: torch.Tensor, new_base: torch.Tensor, symint_visitor_fn: Optional[Callable[[int], int]], tensor_visitor_fn: Optional[Callable[[torch.Tensor], _TensorT]]): _TensorT<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer._DDPBucketAssignment" [color="black", fontcolor="black", label=<{_DDPBucketAssignment|bucket_index : int<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>offset : int<br ALIGN="LEFT"/>parameters : list[torch.Tensor]<br ALIGN="LEFT"/>tensor : torch.Tensor \| None<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parallel.distributed._DDPJoinHook" [color="black", fontcolor="black", label=<{_DDPJoinHook|ddp<br ALIGN="LEFT"/>|main_hook()<br ALIGN="LEFT"/>post_hook(is_last_joiner: bool)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel.distributed._DDPSink" [color="black", fontcolor="black", label=<{_DDPSink|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, ddp_weakref)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing._DataPipeMeta" [color="black", fontcolor="black", label=<{_DataPipeMeta|type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe._DataPipeSerializationWrapper" [color="black", fontcolor="black", label=<{_DataPipeSerializationWrapper|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing._DataPipeType" [color="black", fontcolor="black", label=<{_DataPipeType|param<br ALIGN="LEFT"/>|issubtype(other)<br ALIGN="LEFT"/>issubtype_of_instance(other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataloader._DatasetKind" [color="black", fontcolor="black", label=<{_DatasetKind|Iterable : int<br ALIGN="LEFT"/>Map : int<br ALIGN="LEFT"/>|create_fetcher(kind, dataset, auto_collation, collate_fn, drop_last)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._DeconstructedSymNode" [color="black", fontcolor="black", label=<{_DeconstructedSymNode|constant : Optional[Union[int, float, bool]]<br ALIGN="LEFT"/>fx_node<br ALIGN="LEFT"/>pytype : type<br ALIGN="LEFT"/>|extract(shape_env: ShapeEnv): SymNode<br ALIGN="LEFT"/>from_node(node: SymNode): _DeconstructedSymNode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._DeconstructedSymType" [color="black", fontcolor="black", label=<{_DeconstructedSymType|node<br ALIGN="LEFT"/>ty : Type[PySymType]<br ALIGN="LEFT"/>|extract(shape_env: ShapeEnv): PySymType<br ALIGN="LEFT"/>from_sym_type(value: PySymType): _DeconstructedSymType<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._contextlib._DecoratorContextManager" [color="black", fontcolor="black", label=<{_DecoratorContextManager|<br ALIGN="LEFT"/>|clone()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining._DemultiplexerIterDataPipe" [color="black", fontcolor="black", label=<{_DemultiplexerIterDataPipe|buffer_size : int<br ALIGN="LEFT"/>child_buffers : List[Deque[_T_co]]<br ALIGN="LEFT"/>classifier_fn : Callable[[_T_co], Optional[int]]<br ALIGN="LEFT"/>current_buffer_usage : int<br ALIGN="LEFT"/>drop_none : bool<br ALIGN="LEFT"/>main_datapipe : IterDataPipe[_T_co]<br ALIGN="LEFT"/>main_datapipe_exhausted : bool<br ALIGN="LEFT"/>num_instances : int<br ALIGN="LEFT"/>|get_length_by_instance(instance_id: int): int<br ALIGN="LEFT"/>get_next_element_by_instance(instance_id: int)<br ALIGN="LEFT"/>is_every_instance_exhausted(): bool<br ALIGN="LEFT"/>reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.infra.partitioner._DependencyViewer" [color="black", fontcolor="black", label=<{_DependencyViewer|downstreams : defaultdict<br ALIGN="LEFT"/>upstreams : defaultdict<br ALIGN="LEFT"/>|downstreams_of(node: Node): Set[Node]<br ALIGN="LEFT"/>upstreams_of(node: Node): Set[Node]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Dependent" [color="black", fontcolor="black", label=<{_Dependent|event_dim<br ALIGN="LEFT"/>is_discrete<br ALIGN="LEFT"/>|check(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._DependentProperty" [color="black", fontcolor="black", label=<{_DependentProperty|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._DerivedConstraint" [color="black", fontcolor="black", label=<{_DerivedConstraint|constraint_range : str<br ALIGN="LEFT"/>fn : Callable<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>root : Union[_ConstraintTarget, _PhantomRoot]<br ALIGN="LEFT"/>serializable_spec<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._DerivedDim" [color="black", fontcolor="black", label=<{_DerivedDim|max<br ALIGN="LEFT"/>min<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization._DerivedObserverOrFakeQuantize" [color="black", fontcolor="black", label=<{_DerivedObserverOrFakeQuantize|ch_axis : Optional[int]<br ALIGN="LEFT"/>derive_qparams_fn : Callable[[List[ObserverOrFakeQuantize]], Tuple[Tensor, Tensor]]<br ALIGN="LEFT"/>obs_or_fqs : List[ObserverOrFakeQuantize]<br ALIGN="LEFT"/>qscheme : Optional[torch.qscheme]<br ALIGN="LEFT"/>quant_max : Optional[int]<br ALIGN="LEFT"/>quant_min : Optional[int]<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>forward(x: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.deterministic._Deterministic" [color="black", fontcolor="black", label=<{_Deterministic|fill_uninitialized_memory<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.xpu._DeviceGuard" [color="black", fontcolor="black", label=<{_DeviceGuard|idx : int<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda._DeviceGuard" [color="black", fontcolor="black", label=<{_DeviceGuard|idx : int<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.device_mesh._DeviceMeshStub" [color="black", fontcolor="black", label=<{_DeviceMeshStub|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.converter.ExplainTS2FXGraphConverter._DictMock" [color="black", fontcolor="black", label=<{_DictMock|mock_value<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._Dim" [color="black", fontcolor="black", label=<{_Dim|<br ALIGN="LEFT"/>|readable(name, min_, max_)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._DimHint" [color="black", fontcolor="black", label=<{_DimHint|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.decorators._DimRange" [color="black", fontcolor="black", label=<{_DimRange|dim : int<br ALIGN="LEFT"/>max : int<br ALIGN="LEFT"/>min : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.dirichlet._Dirichlet" [color="black", fontcolor="black", label=<{_Dirichlet|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, concentration)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor._DispatchCacheEntry" [color="black", fontcolor="black", label=<{_DispatchCacheEntry|is_output_tuple : bool<br ALIGN="LEFT"/>output_infos : Tuple[_DispatchCacheEntryOutputInfo]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor._DispatchCacheEntryOutputInfo" [color="black", fontcolor="black", label=<{_DispatchCacheEntryOutputInfo|inplace_idx : Optional[int]<br ALIGN="LEFT"/>metadata : Optional[TensorMetadata]<br ALIGN="LEFT"/>view_idx : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor._DispatchCacheKey" [color="black", fontcolor="black", label=<{_DispatchCacheKey|hashvalue : int<br ALIGN="LEFT"/>key : Tuple[object, ...]<br ALIGN="LEFT"/>|strip_shape_env(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase" [color="black", fontcolor="black", label=<{_DistTestBase|<br ALIGN="LEFT"/>|call_dist_op(profiling_title_postfix, is_async, op)<br ALIGN="LEFT"/>test_1_level_hierarchical_model_averager_equivalent_to_periodic_model_averager()<br ALIGN="LEFT"/>test_3_level_hierarchical_model_averager()<br ALIGN="LEFT"/>test_Backend_enum_class()<br ALIGN="LEFT"/>test_DistributedDataParallel()<br ALIGN="LEFT"/>test_DistributedDataParallelCPU()<br ALIGN="LEFT"/>test_DistributedDataParallelCPU_grad_is_view()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_2D_Input()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_Channels_Last()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_Running_Value()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_gradient()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_No_Affine()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_Single_Input_Per_Process()<br ALIGN="LEFT"/>test_DistributedDataParallel_SyncBatchNorm_half()<br ALIGN="LEFT"/>test_DistributedDataParallel_non_default_stream()<br ALIGN="LEFT"/>test_DistributedDataParallel_requires_grad()<br ALIGN="LEFT"/>test_DistributedDataParallel_with_amp_and_grad_is_view()<br ALIGN="LEFT"/>test_DistributedSampler_padding()<br ALIGN="LEFT"/>test_SyncBatchNorm_process_group()<br ALIGN="LEFT"/>test_accumulate_gradients_no_sync()<br ALIGN="LEFT"/>test_accumulate_gradients_no_sync_allreduce_hook()<br ALIGN="LEFT"/>test_accumulate_gradients_no_sync_allreduce_with_then_hook()<br ALIGN="LEFT"/>test_accumulate_gradients_no_sync_grad_is_view()<br ALIGN="LEFT"/>test_all_gather()<br ALIGN="LEFT"/>test_all_gather_coalesced_complex()<br ALIGN="LEFT"/>test_all_gather_coalesced_full_group()<br ALIGN="LEFT"/>test_all_gather_coalesced_group()<br ALIGN="LEFT"/>test_all_gather_coalesced_simple()<br ALIGN="LEFT"/>test_all_gather_coalesced_with_empty()<br ALIGN="LEFT"/>test_all_gather_complex()<br ALIGN="LEFT"/>test_all_gather_cuda()<br ALIGN="LEFT"/>test_all_gather_cuda_complex()<br ALIGN="LEFT"/>test_all_gather_full_group()<br ALIGN="LEFT"/>test_all_gather_group()<br ALIGN="LEFT"/>test_all_gather_into_cat_tensor_cuda()<br ALIGN="LEFT"/>test_all_gather_into_stack_tensor_cuda()<br ALIGN="LEFT"/>test_all_gather_object_default_pg()<br ALIGN="LEFT"/>test_all_gather_object_subgroup()<br ALIGN="LEFT"/>test_all_gather_v_cuda()<br ALIGN="LEFT"/>test_all_reduce_coalesced_full_group_max()<br ALIGN="LEFT"/>test_all_reduce_coalesced_full_group_min()<br ALIGN="LEFT"/>test_all_reduce_coalesced_full_group_product()<br ALIGN="LEFT"/>test_all_reduce_coalesced_full_group_sum()<br ALIGN="LEFT"/>test_all_reduce_coalesced_group_max()<br ALIGN="LEFT"/>test_all_reduce_coalesced_group_min()<br ALIGN="LEFT"/>test_all_reduce_coalesced_group_product()<br ALIGN="LEFT"/>test_all_reduce_coalesced_group_sum()<br ALIGN="LEFT"/>test_all_reduce_coalesced_max()<br ALIGN="LEFT"/>test_all_reduce_coalesced_max_complex_unsupported()<br ALIGN="LEFT"/>test_all_reduce_coalesced_min()<br ALIGN="LEFT"/>test_all_reduce_coalesced_product()<br ALIGN="LEFT"/>test_all_reduce_coalesced_sum()<br ALIGN="LEFT"/>test_all_reduce_complex_unsupported_ops()<br ALIGN="LEFT"/>test_all_reduce_full_group_max()<br ALIGN="LEFT"/>test_all_reduce_full_group_min()<br ALIGN="LEFT"/>test_all_reduce_full_group_product()<br ALIGN="LEFT"/>test_all_reduce_full_group_sum()<br ALIGN="LEFT"/>test_all_reduce_group_max()<br ALIGN="LEFT"/>test_all_reduce_group_min()<br ALIGN="LEFT"/>test_all_reduce_group_product()<br ALIGN="LEFT"/>test_all_reduce_group_sum()<br ALIGN="LEFT"/>test_all_reduce_max()<br ALIGN="LEFT"/>test_all_reduce_min()<br ALIGN="LEFT"/>test_all_reduce_product()<br ALIGN="LEFT"/>test_all_reduce_sum()<br ALIGN="LEFT"/>test_all_reduce_sum_async()<br ALIGN="LEFT"/>test_all_reduce_sum_complex()<br ALIGN="LEFT"/>test_all_reduce_sum_cuda()<br ALIGN="LEFT"/>test_all_reduce_sum_cuda_async()<br ALIGN="LEFT"/>test_all_reduce_sum_cuda_complex()<br ALIGN="LEFT"/>test_all_to_all()<br ALIGN="LEFT"/>test_all_to_all_complex()<br ALIGN="LEFT"/>test_all_to_all_cuda()<br ALIGN="LEFT"/>test_all_to_all_cuda_complex()<br ALIGN="LEFT"/>test_all_to_all_full_group()<br ALIGN="LEFT"/>test_all_to_all_full_group_cuda()<br ALIGN="LEFT"/>test_all_to_all_group()<br ALIGN="LEFT"/>test_all_to_all_group_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_complex()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_cuda_complex()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_full_group()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_full_group_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_group()<br ALIGN="LEFT"/>test_all_to_all_single_equal_split_group_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_complex()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_cuda_complex()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_full_group()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_full_group_cuda()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_group()<br ALIGN="LEFT"/>test_all_to_all_single_unequal_split_group_cuda()<br ALIGN="LEFT"/>test_average_parameters()<br ALIGN="LEFT"/>test_barrier()<br ALIGN="LEFT"/>test_barrier_cuda()<br ALIGN="LEFT"/>test_barrier_full_group()<br ALIGN="LEFT"/>test_barrier_full_group_cuda()<br ALIGN="LEFT"/>test_barrier_group()<br ALIGN="LEFT"/>test_barrier_group_cuda()<br ALIGN="LEFT"/>test_barrier_timeout_full_group()<br ALIGN="LEFT"/>test_barrier_timeout_global()<br ALIGN="LEFT"/>test_barrier_timeout_group()<br ALIGN="LEFT"/>test_batch_isend_irecv_gloo()<br ALIGN="LEFT"/>test_batch_isend_irecv_gloo_tags()<br ALIGN="LEFT"/>test_batch_isend_irecv_mixed_backend_err()<br ALIGN="LEFT"/>test_batch_isend_irecv_nccl()<br ALIGN="LEFT"/>test_batch_isend_irecv_no_rank_zero_nccl()<br ALIGN="LEFT"/>test_batch_isend_irecv_op_err()<br ALIGN="LEFT"/>test_batch_isend_irecv_op_list_err()<br ALIGN="LEFT"/>test_batch_isend_irecv_ring_exchange_nccl()<br ALIGN="LEFT"/>test_batch_isend_irecv_self_nccl()<br ALIGN="LEFT"/>test_broadcast()<br ALIGN="LEFT"/>test_broadcast_cuda()<br ALIGN="LEFT"/>test_broadcast_full_group()<br ALIGN="LEFT"/>test_broadcast_group()<br ALIGN="LEFT"/>test_broadcast_object_list()<br ALIGN="LEFT"/>test_coalescing_manager()<br ALIGN="LEFT"/>test_coalescing_manager_async()<br ALIGN="LEFT"/>test_compute_bucket_assignment_by_size_sparse_error_with_logger()<br ALIGN="LEFT"/>test_compute_bucket_assignment_by_size_sparse_error_without_logger()<br ALIGN="LEFT"/>test_ddp_apply_optim_in_backward()<br ALIGN="LEFT"/>test_ddp_apply_optim_in_backward_grad_as_bucket_view_false()<br ALIGN="LEFT"/>test_ddp_apply_optim_in_backward_ignored_params()<br ALIGN="LEFT"/>test_ddp_broadcast_buffer()<br ALIGN="LEFT"/>test_ddp_broadcast_buffer_via_hook()<br ALIGN="LEFT"/>test_ddp_buffer_hook_allreduce()<br ALIGN="LEFT"/>test_ddp_buffer_hook_allreduce_return_future()<br ALIGN="LEFT"/>test_ddp_build_debug_param_to_name_mapping()<br ALIGN="LEFT"/>test_ddp_build_debug_param_to_name_mapping_requires_grad()<br ALIGN="LEFT"/>test_ddp_comm_hook_logging()<br ALIGN="LEFT"/>test_ddp_compile_static_graph()<br ALIGN="LEFT"/>test_ddp_control_flow_different_across_ranks()<br ALIGN="LEFT"/>test_ddp_control_flow_same_across_ranks()<br ALIGN="LEFT"/>test_ddp_create_graph()<br ALIGN="LEFT"/>test_ddp_device()<br ALIGN="LEFT"/>test_ddp_device_mesh_initialization()<br ALIGN="LEFT"/>test_ddp_forward_backward_hook()<br ALIGN="LEFT"/>test_ddp_grad_div_uneven_inputs()<br ALIGN="LEFT"/>test_ddp_has_finalized()<br ALIGN="LEFT"/>test_ddp_hook_parity_allreduce()<br ALIGN="LEFT"/>test_ddp_hook_parity_allreduce_process_group()<br ALIGN="LEFT"/>test_ddp_hook_parity_post_localSGD()<br ALIGN="LEFT"/>test_ddp_hook_parity_powerSGD()<br ALIGN="LEFT"/>test_ddp_hook_pickling_powerSGD()<br ALIGN="LEFT"/>test_ddp_ignore_params_arg()<br ALIGN="LEFT"/>test_ddp_inference()<br ALIGN="LEFT"/>test_ddp_join_model_equivalence()<br ALIGN="LEFT"/>test_ddp_logging_data_cpu()<br ALIGN="LEFT"/>test_ddp_logging_data_gpu()<br ALIGN="LEFT"/>test_ddp_model_diff_num_params_across_ranks()<br ALIGN="LEFT"/>test_ddp_model_diff_shape_across_ranks()<br ALIGN="LEFT"/>test_ddp_multiple_nested_unused_params_err_ignore_params()<br ALIGN="LEFT"/>test_ddp_multiple_nested_unused_params_error()<br ALIGN="LEFT"/>test_ddp_namedtuple()<br ALIGN="LEFT"/>test_ddp_native_mixed_precision_grad_as_bucket_view_no_set_grad_none()<br ALIGN="LEFT"/>test_ddp_native_mixed_precision_grad_as_bucket_view_set_grad_to_none()<br ALIGN="LEFT"/>test_ddp_native_mixed_precision_ignored_params()<br ALIGN="LEFT"/>test_ddp_native_mixed_precision_no_grad_as_bucket_view_no_set_grad_none()<br ALIGN="LEFT"/>test_ddp_native_mixed_precision_no_grad_as_bucket_view_set_grad_to_none()<br ALIGN="LEFT"/>test_ddp_new_tensor_in_fwd()<br ALIGN="LEFT"/>test_ddp_new_tensor_in_fwd_static_graph()<br ALIGN="LEFT"/>test_ddp_profiling_autograd_profiler()<br ALIGN="LEFT"/>test_ddp_profiling_execution_trace()<br ALIGN="LEFT"/>test_ddp_profiling_torch_profiler()<br ALIGN="LEFT"/>test_ddp_python_error_logged()<br ALIGN="LEFT"/>test_ddp_remove_autograd_hooks()<br ALIGN="LEFT"/>test_ddp_returns_tensor_with_no_grad()<br ALIGN="LEFT"/>test_ddp_shared_grad_acc_unused_params()<br ALIGN="LEFT"/>test_ddp_sink_noclone()<br ALIGN="LEFT"/>test_ddp_static_graph_nested_types()<br ALIGN="LEFT"/>test_ddp_sync_bn_training_vs_eval()<br ALIGN="LEFT"/>test_ddp_sync_module_states()<br ALIGN="LEFT"/>test_ddp_uneven_input_exception()<br ALIGN="LEFT"/>test_ddp_uneven_input_join_disable()<br ALIGN="LEFT"/>test_ddp_uneven_inputs()<br ALIGN="LEFT"/>test_ddp_uneven_inputs_stop_iteration_sync_bn()<br ALIGN="LEFT"/>test_ddp_unused_params_rebuild_buckets_exception()<br ALIGN="LEFT"/>test_ddp_zero_output_features()<br ALIGN="LEFT"/>test_destroy_full_group()<br ALIGN="LEFT"/>test_destroy_group()<br ALIGN="LEFT"/>test_detect_ddp_is_actually_static()<br ALIGN="LEFT"/>test_different_graph_across_ranks()<br ALIGN="LEFT"/>test_dump_DDP_relevant_env_vars()<br ALIGN="LEFT"/>test_gather()<br ALIGN="LEFT"/>test_gather_checks()<br ALIGN="LEFT"/>test_gather_cuda()<br ALIGN="LEFT"/>test_gather_full_group()<br ALIGN="LEFT"/>test_gather_group()<br ALIGN="LEFT"/>test_gather_object()<br ALIGN="LEFT"/>test_gather_object_subgroup()<br ALIGN="LEFT"/>test_get_backend()<br ALIGN="LEFT"/>test_get_data_parallel_params()<br ALIGN="LEFT"/>test_get_future()<br ALIGN="LEFT"/>test_get_rank()<br ALIGN="LEFT"/>test_get_rank_size_full_group()<br ALIGN="LEFT"/>test_get_rank_size_group()<br ALIGN="LEFT"/>test_grads_same_across_ranks_with_no_sync()<br ALIGN="LEFT"/>test_invalid_static_graph()<br ALIGN="LEFT"/>test_irecv()<br ALIGN="LEFT"/>test_isend()<br ALIGN="LEFT"/>test_isend_autograd_profiler()<br ALIGN="LEFT"/>test_isend_torch_profiler()<br ALIGN="LEFT"/>test_monitored_barrier_allreduce_hang()<br ALIGN="LEFT"/>test_monitored_barrier_allreduce_hang_wait_all_ranks()<br ALIGN="LEFT"/>test_monitored_barrier_failure_order()<br ALIGN="LEFT"/>test_monitored_barrier_gloo()<br ALIGN="LEFT"/>test_monitored_barrier_gloo_rank_0_timeout()<br ALIGN="LEFT"/>test_monitored_barrier_gloo_subgroup()<br ALIGN="LEFT"/>test_monitored_barrier_wait_all_ranks()<br ALIGN="LEFT"/>test_nccl_backend_bool_allgather()<br ALIGN="LEFT"/>test_nccl_backend_bool_allreduce()<br ALIGN="LEFT"/>test_nccl_backend_bool_broadcast()<br ALIGN="LEFT"/>test_nccl_backend_bool_reduce()<br ALIGN="LEFT"/>test_nccl_high_priority_stream()<br ALIGN="LEFT"/>test_new_subgroups()<br ALIGN="LEFT"/>test_new_subgroups_by_enumeration()<br ALIGN="LEFT"/>test_new_subgroups_by_enumeration_input_rank_exceeds_world_size()<br ALIGN="LEFT"/>test_new_subgroups_by_enumeration_negative_input_rank()<br ALIGN="LEFT"/>test_new_subgroups_group_size_exceeds_world_size()<br ALIGN="LEFT"/>test_new_subgroups_overlap_not_allowed()<br ALIGN="LEFT"/>test_new_subgroups_world_size_not_divisible_by_group_size()<br ALIGN="LEFT"/>test_output_unused_in_loss_dict_module()<br ALIGN="LEFT"/>test_output_unused_in_loss_tuple_module()<br ALIGN="LEFT"/>test_periodic_model_averager()<br ALIGN="LEFT"/>test_periodic_model_averager_param_group()<br ALIGN="LEFT"/>test_post_localSGD_optimizer_parity()<br ALIGN="LEFT"/>test_post_localSGD_optimizer_parity_grad_is_view()<br ALIGN="LEFT"/>test_post_localSGD_optimizer_parity_with_hierarchical_sgd()<br ALIGN="LEFT"/>test_post_localSGD_optimizer_parity_with_hierarchical_sgd_grad_is_view()<br ALIGN="LEFT"/>test_post_localSGD_optimizer_step_reload()<br ALIGN="LEFT"/>test_reduce_full_group_max()<br ALIGN="LEFT"/>test_reduce_full_group_min()<br ALIGN="LEFT"/>test_reduce_full_group_product()<br ALIGN="LEFT"/>test_reduce_full_group_sum()<br ALIGN="LEFT"/>test_reduce_group_max()<br ALIGN="LEFT"/>test_reduce_group_min()<br ALIGN="LEFT"/>test_reduce_group_product()<br ALIGN="LEFT"/>test_reduce_group_sum()<br ALIGN="LEFT"/>test_reduce_max()<br ALIGN="LEFT"/>test_reduce_min()<br ALIGN="LEFT"/>test_reduce_product()<br ALIGN="LEFT"/>test_reduce_scatter_tensor_cuda()<br ALIGN="LEFT"/>test_reduce_scatter_v_cuda()<br ALIGN="LEFT"/>test_reduce_sum()<br ALIGN="LEFT"/>test_reduce_sum_cuda()<br ALIGN="LEFT"/>test_reduce_sum_cuda_twice()<br ALIGN="LEFT"/>test_reduce_sum_twice()<br ALIGN="LEFT"/>test_scatter()<br ALIGN="LEFT"/>test_scatter_checks()<br ALIGN="LEFT"/>test_scatter_complex()<br ALIGN="LEFT"/>test_scatter_cuda()<br ALIGN="LEFT"/>test_scatter_cuda_complex()<br ALIGN="LEFT"/>test_scatter_full_group()<br ALIGN="LEFT"/>test_scatter_group()<br ALIGN="LEFT"/>test_scatter_object_list()<br ALIGN="LEFT"/>test_send_recv()<br ALIGN="LEFT"/>test_send_recv_any_source()<br ALIGN="LEFT"/>test_send_recv_any_source_autograd_profiler()<br ALIGN="LEFT"/>test_send_recv_any_source_torch_profiler()<br ALIGN="LEFT"/>test_send_recv_autograd_profiler()<br ALIGN="LEFT"/>test_send_recv_nccl()<br ALIGN="LEFT"/>test_send_recv_nccl_autograd_profiler()<br ALIGN="LEFT"/>test_send_recv_nccl_torch_profiler()<br ALIGN="LEFT"/>test_send_recv_torch_profiler()<br ALIGN="LEFT"/>test_send_recv_with_tag()<br ALIGN="LEFT"/>test_send_recv_with_tag_autograd_profiler()<br ALIGN="LEFT"/>test_send_recv_with_tag_torch_profiler()<br ALIGN="LEFT"/>test_sparse_all_reduce_sum()<br ALIGN="LEFT"/>test_sparse_all_reduce_sum_cuda()<br ALIGN="LEFT"/>test_stateless_api_with_ddp()<br ALIGN="LEFT"/>test_static_graph_api_cpu()<br ALIGN="LEFT"/>test_static_graph_multi_forward()<br ALIGN="LEFT"/>test_sync_bn_logged()<br ALIGN="LEFT"/>test_undefined_grad_parity_unused_parameters()<br ALIGN="LEFT"/>test_verify_model_across_rank_with_logger()<br ALIGN="LEFT"/>test_verify_model_across_rank_without_logger()<br ALIGN="LEFT"/>validate_net_equivalence(net)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.utils._DistWrapper" [color="black", fontcolor="black", label=<{_DistWrapper|coordinator_rank : int<br ALIGN="LEFT"/>group : Optional[dist.ProcessGroup]<br ALIGN="LEFT"/>is_coordinator : bool<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>use_dist : bool<br ALIGN="LEFT"/>|all_gather(step: str, map_fun: Callable[[], T]): List[T]<br ALIGN="LEFT"/>all_gather_object(object: T): List[T]<br ALIGN="LEFT"/>all_reduce(step: str, map_fun: Callable[[], T], reduce_fun: Callable[[List[T]], R]): R<br ALIGN="LEFT"/>broadcast(step: str, map_fun: Callable[[], T]): T<br ALIGN="LEFT"/>broadcast_object(object: Optional[T]): T<br ALIGN="LEFT"/>gather_object(object: T): Optional[List[T]]<br ALIGN="LEFT"/>get_rank(): int<br ALIGN="LEFT"/>get_world_size(): int<br ALIGN="LEFT"/>reduce_scatter(step: str, map_fun: Callable[[], T], reduce_fun: Callable[[List[T]], List[R]]): R<br ALIGN="LEFT"/>scatter_object(object_list: Optional[List[T]]): T<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._DistributedPdb" [color="black", fontcolor="black", label=<{_DistributedPdb|<br ALIGN="LEFT"/>|interaction()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" [color="black", fontcolor="black", label=<{_DistributedRendezvousOpExecutor|<br ALIGN="LEFT"/>|run(state_handler: Callable[[_RendezvousContext, float], _Action], deadline: float, update_deadline: Optional[Callable[[timedelta], float]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.dropout._DropoutNd" [color="black", fontcolor="black", label=<{_DropoutNd|inplace : bool<br ALIGN="LEFT"/>p : float<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy.testing.utils._Dummy" [color="black", fontcolor="black", label=<{_Dummy|<br ALIGN="LEFT"/>|<I>nop</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._cxx_pytree._DummyLeaf" [color="black", fontcolor="black", label=<{_DummyLeaf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree._DummyLeaf" [color="black", fontcolor="black", label=<{_DummyLeaf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.io_adapter._DummyLeaf" [color="black", fontcolor="black", label=<{_DummyLeaf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.tensor_type._DynType" [color="black", fontcolor="black", label=<{_DynType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.state_dict._EXTRA_STATE" [color="black", fontcolor="black", label=<{_EXTRA_STATE|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._higher_order_ops.effects._EffectType" [color="black", fontcolor="black", label=<{_EffectType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.exporter._schemas._Empty" [color="black", fontcolor="black", label=<{_Empty|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.default_planner._EmptyStateDictLoadPlanner" [color="black", fontcolor="black", label=<{_EmptyStateDictLoadPlanner|keys : NoneType<br ALIGN="LEFT"/>|set_up_planner(state_dict: STATE_DICT_TYPE, metadata: Optional[Metadata], is_coordinator: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph_module._EvalCacheLoader" [color="black", fontcolor="black", label=<{_EvalCacheLoader|eval_cache : dict<br ALIGN="LEFT"/>next_id : int<br ALIGN="LEFT"/>|cache(src: str, globals: Dict[str, Any], co_fields)<br ALIGN="LEFT"/>get_source(module_name): Optional[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._streambase._EventBase" [color="black", fontcolor="black", label=<{_EventBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._exec_order_utils._ExecOrderData" [color="black", fontcolor="black", label=<{_ExecOrderData|all_handles : List[FlatParamHandle]<br ALIGN="LEFT"/>current_order_index : int<br ALIGN="LEFT"/>handles_post_forward_order : List[Optional[FlatParamHandle]]<br ALIGN="LEFT"/>handles_pre_forward_order : List[FlatParamHandle]<br ALIGN="LEFT"/>is_first_iter<br ALIGN="LEFT"/>param_to_fqn : Dict[nn.Parameter, List[str]]<br ALIGN="LEFT"/>process_group : Optional[dist.ProcessGroup]<br ALIGN="LEFT"/>rank<br ALIGN="LEFT"/>warn_status : NONE, WARNED, WARNING<br ALIGN="LEFT"/>world_size : Optional[int]<br ALIGN="LEFT"/>|get_handle_to_backward_prefetch(current_handle: FlatParamHandle): Optional[FlatParamHandle]<br ALIGN="LEFT"/>get_handle_to_forward_prefetch(current_handle: FlatParamHandle): Optional[FlatParamHandle]<br ALIGN="LEFT"/>init(state: _FSDPState, root_module: nn.Module, process_group: dist.ProcessGroup): None<br ALIGN="LEFT"/>next_iter()<br ALIGN="LEFT"/>record_post_forward(handle: Optional[FlatParamHandle]): None<br ALIGN="LEFT"/>record_pre_forward(handle: Optional[FlatParamHandle], is_training: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._trace_utils._ExecOrderTracer" [color="black", fontcolor="black", label=<{_ExecOrderTracer|exec_info : Optional[_ExecutionInfo]<br ALIGN="LEFT"/>|patch_tracer(tracer: torch.fx.Tracer, root_module: nn.Module)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._exec_order_utils._ExecOrderWarnStatus" [color="black", fontcolor="black", label=<{_ExecOrderWarnStatus|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._trace_utils._ExecutionInfo" [color="black", fontcolor="black", label=<{_ExecutionInfo|curr_module<br ALIGN="LEFT"/>module_forward_order : List[nn.Module]<br ALIGN="LEFT"/>module_to_param_usage_infos : Dict[nn.Module, List[_ParamUsageInfo]]<br ALIGN="LEFT"/>param_forward_order : List[nn.Parameter]<br ALIGN="LEFT"/>visited_params : Set[nn.Parameter]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._trace._ExportOutcome" [color="black", fontcolor="black", label=<{_ExportOutcome|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [color="black", fontcolor="black", label=<{_ExportPassBaseDeprecatedDoNotUse|fake_tensor_mode : NoneType, Optional[FakeTensorMode]<br ALIGN="LEFT"/>interpreter<br ALIGN="LEFT"/>node_debug_str : Optional[typing.Optional[str]]<br ALIGN="LEFT"/>tracer<br ALIGN="LEFT"/>|call(graph_module: fx.GraphModule): PassResult<br ALIGN="LEFT"/>call_cond(pred: ProxyValue, true_fn: torch.fx.GraphModule, false_fn: torch.fx.GraphModule, inputs: List[Argument], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>call_getitem(value: ProxyValue, key: int, meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>call_map(f: torch.fx.GraphModule, mapped_args: List[ProxyValue], operands: List[ProxyValue], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>call_operator(op, args: Tuple[Argument, ...], kwargs: Dict[str, Argument], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>call_submodule(graph_module: fx.GraphModule, inputs: Tuple[Argument, ...]): PassResult<br ALIGN="LEFT"/>call_sym(target: Fn, args: Tuple[Argument, ...], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>inputs(graph_module: torch.fx.GraphModule): List[Argument]<br ALIGN="LEFT"/><I>on_attr</I>(attr: ProxyValue): None<br ALIGN="LEFT"/>output(results: List[Argument], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>placeholder(name: str, arg: Argument, meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._trace._ExportType" [color="black", fontcolor="black", label=<{_ExportType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_importer._ExternNode" [color="black", fontcolor="black", label=<{_ExternNode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.find_file_dependencies._ExtractModuleReferences" [color="black", fontcolor="black", label=<{_ExtractModuleReferences|package<br ALIGN="LEFT"/>references : dict<br ALIGN="LEFT"/>|run(src: str, package: str): List[Tuple[str, Optional[str]]]<br ALIGN="LEFT"/>visit_Call(node)<br ALIGN="LEFT"/>visit_Import(node)<br ALIGN="LEFT"/>visit_ImportFrom(node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.distributed.distributed_test._FC2" [color="black", fontcolor="black", label=<{_FC2|fc<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._common_utils._FSDPDeviceHandle" [color="black", fontcolor="black", label=<{_FSDPDeviceHandle|<br ALIGN="LEFT"/>|from_device(device: torch.device): '_FSDPDeviceHandle'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker._FSDPModMemStats" [color="black", fontcolor="black", label=<{_FSDPModMemStats|local_peak : Dict[torch.device, int]<br ALIGN="LEFT"/>mod_fqn : str<br ALIGN="LEFT"/>snapshots : Dict[_FSDPModState, List[Dict[torch.device, Dict[str, int]]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker._FSDPModState" [color="black", fontcolor="black", label=<{_FSDPModState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker._FSDPRefType" [color="black", fontcolor="black", label=<{_FSDPRefType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._common_utils._FSDPState" [color="black", fontcolor="black", label=<{_FSDPState|compute_device : Optional[torch.device]<br ALIGN="LEFT"/>process_group : Optional[dist.ProcessGroup]<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>sharding_strategy : FULL_SHARD<br ALIGN="LEFT"/>training_state : IDLE<br ALIGN="LEFT"/>world_size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.operator_schemas._FakeGlobalNamespace" [color="black", fontcolor="black", label=<{_FakeGlobalNamespace|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.meta_utils._FakeTensorViewFunc" [color="black", fontcolor="black", label=<{_FakeTensorViewFunc|<br ALIGN="LEFT"/>|apply(t: torch.Tensor, new_base: torch.Tensor, symint_visitor_fn: Optional[Callable[[int], int]], tensor_visitor_fn: Optional[Callable[[torch.Tensor], FakeTensor]]): FakeTensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.hub._Faketqdm" [color="black", fontcolor="black", label=<{_Faketqdm|disable : bool<br ALIGN="LEFT"/>n : int<br ALIGN="LEFT"/>total : NoneType<br ALIGN="LEFT"/>|close()<br ALIGN="LEFT"/><I>set_description</I>()<br ALIGN="LEFT"/>update(n)<br ALIGN="LEFT"/>write(s)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._FileSystemWriter" [color="black", fontcolor="black", label=<{_FileSystemWriter|checkpoint_id<br ALIGN="LEFT"/>fs<br ALIGN="LEFT"/>metadata_path<br ALIGN="LEFT"/>overwrite : bool<br ALIGN="LEFT"/>path : NoneType, Path<br ALIGN="LEFT"/>per_thread_copy_ahead : int<br ALIGN="LEFT"/>save_id : str<br ALIGN="LEFT"/>single_file_per_rank : bool<br ALIGN="LEFT"/>sync_files : bool<br ALIGN="LEFT"/>thread_count : int<br ALIGN="LEFT"/>|finish(metadata: Metadata, results: List[List[WriteResult]]): None<br ALIGN="LEFT"/>prepare_global_plan(plans: List[SavePlan]): List[SavePlan]<br ALIGN="LEFT"/>prepare_local_plan(plan: SavePlan): SavePlan<br ALIGN="LEFT"/>reset(checkpoint_id: Union[str, os.PathLike, None]): None<br ALIGN="LEFT"/><I>set_up_storage_writer</I>(is_coordinator: bool): None<br ALIGN="LEFT"/>storage_meta(): Optional[StorageMeta]<br ALIGN="LEFT"/>validate_checkpoint_id(checkpoint_id: Union[str, os.PathLike]): bool<br ALIGN="LEFT"/>write_data(plan: SavePlan, planner: SavePlanner): Future[List[WriteResult]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph._FindNodesLookupTable" [color="black", fontcolor="black", label=<{_FindNodesLookupTable|table : Dict[Tuple[str, Optional[Target]], Dict[Node, None]]<br ALIGN="LEFT"/>|find_nodes()<br ALIGN="LEFT"/>insert(node: Node): None<br ALIGN="LEFT"/>remove(node: Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FindOperatorOverloadsInOnnxRegistry" [color="black", fontcolor="black", label=<{_FindOperatorOverloadsInOnnxRegistry|<br ALIGN="LEFT"/>|format(level: infra.Level, node): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(node): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FindOpschemaMatchedSymbolicFunction" [color="black", fontcolor="black", label=<{_FindOpschemaMatchedSymbolicFunction|<br ALIGN="LEFT"/>|format(level: infra.Level, symbolic_fn, node): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(symbolic_fn, node): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param._FlatParameterMeta" [color="black", fontcolor="black", label=<{_FlatParameterMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.flop_counter._FlopCounterMode" [color="black", fontcolor="black", label=<{_FlopCounterMode|counter<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.combining._ForkerIterDataPipe" [color="black", fontcolor="black", label=<{_ForkerIterDataPipe|buffer : Deque, deque<br ALIGN="LEFT"/>buffer_size : int<br ALIGN="LEFT"/>child_pointers : List[int]<br ALIGN="LEFT"/>copy_fn<br ALIGN="LEFT"/>end_ptr : NoneType, Optional[int]<br ALIGN="LEFT"/>leading_ptr : int<br ALIGN="LEFT"/>main_datapipe<br ALIGN="LEFT"/>num_instances : int<br ALIGN="LEFT"/>slowest_ptr : int<br ALIGN="LEFT"/>|get_length_by_instance(instance_id: int): int<br ALIGN="LEFT"/>get_next_element_by_instance(instance_id: int)<br ALIGN="LEFT"/>is_every_instance_exhausted(): bool<br ALIGN="LEFT"/>reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._tensor_str._Formatter" [color="black", fontcolor="black", label=<{_Formatter|floating_dtype<br ALIGN="LEFT"/>int_mode : bool<br ALIGN="LEFT"/>max_width : int<br ALIGN="LEFT"/>sci_mode : bool<br ALIGN="LEFT"/>|format(value)<br ALIGN="LEFT"/>width()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._limiter_utils._FreeEventQueue" [color="black", fontcolor="black", label=<{_FreeEventQueue|<br ALIGN="LEFT"/>|dequeue_if_needed(): Optional[torch.Event]<br ALIGN="LEFT"/>enqueue(free_event: torch.Event): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._functional_collectives._FromTorchTensor" [color="black", fontcolor="black", label=<{_FromTorchTensor|<br ALIGN="LEFT"/>|backward(ctx, grad_output: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>forward(ctx, input: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._api._FromTorchTensor" [color="black", fontcolor="black", label=<{_FromTorchTensor|<br ALIGN="LEFT"/>|backward(ctx, grad_output: 'DTensor')<br ALIGN="LEFT"/>forward(ctx, input: torch.Tensor, device_mesh: DeviceMesh, placements: Tuple[Placement, ...], run_check: bool, shape: Optional[torch.Size], stride: Optional[Tuple[int, ...]]): 'DTensor'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_adadelta._FunctionalAdadelta" [color="black", fontcolor="black", label=<{_FunctionalAdadelta|defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_adagrad._FunctionalAdagrad" [color="black", fontcolor="black", label=<{_FunctionalAdagrad|coalesce_grad : bool<br ALIGN="LEFT"/>defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>fused : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_adam._FunctionalAdam" [color="black", fontcolor="black", label=<{_FunctionalAdam|amsgrad : bool<br ALIGN="LEFT"/>defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>fused : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>step_param(param: Tensor, grad: Optional[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_adamw._FunctionalAdamW" [color="black", fontcolor="black", label=<{_FunctionalAdamW|amsgrad : bool<br ALIGN="LEFT"/>defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>fused : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>step_param(param: Tensor, grad: Optional[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_adamax._FunctionalAdamax" [color="black", fontcolor="black", label=<{_FunctionalAdamax|defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_rmsprop._FunctionalRMSprop" [color="black", fontcolor="black", label=<{_FunctionalRMSprop|centered : bool<br ALIGN="LEFT"/>defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_rprop._FunctionalRprop" [color="black", fontcolor="black", label=<{_FunctionalRprop|defaults : dict<br ALIGN="LEFT"/>etas : Tuple[float, float]<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>step_sizes : Tuple[float, float]<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.functional_sgd._FunctionalSGD" [color="black", fontcolor="black", label=<{_FunctionalSGD|defaults : dict<br ALIGN="LEFT"/>foreach : bool<br ALIGN="LEFT"/>fused : bool<br ALIGN="LEFT"/>maximize : bool<br ALIGN="LEFT"/>nesterov : bool<br ALIGN="LEFT"/>param_group : dict<br ALIGN="LEFT"/>state : dict<br ALIGN="LEFT"/>|step(gradients: List[Optional[Tensor]])<br ALIGN="LEFT"/>step_param(param: Tensor, grad: Optional[Tensor])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.reinplace._FunctionalizationMetadataProp" [color="black", fontcolor="black", label=<{_FunctionalizationMetadataProp|multi_output_view_nodes : dict<br ALIGN="LEFT"/>node_counter : int<br ALIGN="LEFT"/>|propagate()<br ALIGN="LEFT"/>run_node(node: Node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.passes.functionalize_side_effectful_ops_pass._FunctionalizeSideEffectfulOpsPass" [color="black", fontcolor="black", label=<{_FunctionalizeSideEffectfulOpsPass|<br ALIGN="LEFT"/>|call(graph_module: torch.fx.GraphModule): PassResult<br ALIGN="LEFT"/>call_operator(op: OpOverload, args: Tuple[Argument, ...], kwargs: Dict[str, Argument], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>output(results: List[Argument], meta: NodeMetadata): ProxyValue<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.intrinsic.modules.fused._FusedModule" [color="black", fontcolor="black", label=<{_FusedModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxGraphToOnnx" [color="black", fontcolor="black", label=<{_FxGraphToOnnx|<br ALIGN="LEFT"/>|format(level: infra.Level, graph_name): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(graph_name): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxNodeInsertTypePromotion" [color="black", fontcolor="black", label=<{_FxNodeInsertTypePromotion|<br ALIGN="LEFT"/>|format(level: infra.Level, target): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(target): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxNodeToOnnx" [color="black", fontcolor="black", label=<{_FxNodeToOnnx|<br ALIGN="LEFT"/>|format(level: infra.Level, node_repr): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(node_repr): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxPass" [color="black", fontcolor="black", label=<{_FxPass|<br ALIGN="LEFT"/>|format(level: infra.Level, pass_name): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(pass_name): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._Gather" [color="black", fontcolor="black", label=<{_Gather|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward(ctx, dst, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda.gds._GdsFile" [color="black", fontcolor="black", label=<{_GdsFile|fd<br ALIGN="LEFT"/>filename : str<br ALIGN="LEFT"/>flags : int<br ALIGN="LEFT"/>handle : NoneType, Optional[int]<br ALIGN="LEFT"/>|deregister_handle(): None<br ALIGN="LEFT"/>load_storage(storage: Storage, offset: int): None<br ALIGN="LEFT"/>register_handle(): None<br ALIGN="LEFT"/>save_storage(storage: Storage, offset: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.sharded_grad_scaler._GeneralMultiDeviceReplicator" [color="black", fontcolor="black", label=<{_GeneralMultiDeviceReplicator|master<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" [color="black", fontcolor="black", label=<{_GlobalItemStats|cache : Dict[str, object]<br ALIGN="LEFT"/>|reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.mock_cache._GlobalStats" [color="black", fontcolor="black", label=<{_GlobalStats|aot_autograd<br ALIGN="LEFT"/>autotune_local<br ALIGN="LEFT"/>autotune_remote<br ALIGN="LEFT"/>bundled_autotune<br ALIGN="LEFT"/>dynamo_pgo<br ALIGN="LEFT"/>fx_graph<br ALIGN="LEFT"/>triton<br ALIGN="LEFT"/>|get_stat(name: str): _GlobalItemStats<br ALIGN="LEFT"/>report()<br ALIGN="LEFT"/>reset(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._GraphAppendingTracerEx" [color="black", fontcolor="black", label=<{_GraphAppendingTracerEx|enable_thunkify : bool<br ALIGN="LEFT"/>script_object_tracker : MutableMapping[_AnyScriptObjectType, Proxy]<br ALIGN="LEFT"/>symnode_tracker : MutableMapping[PySymType, _PySymProxyType]<br ALIGN="LEFT"/>sympy_expr_tracker : Dict[sympy.Symbol, object]<br ALIGN="LEFT"/>tensor_tracker : MutableMapping[Tensor, _ProxyTensor]<br ALIGN="LEFT"/>torch_fn_counts : Dict[OpOverload, int]<br ALIGN="LEFT"/>torch_fn_metadata : Optional[OpOverload]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx.verification._GraphDiff" [color="black", fontcolor="black", label=<{_GraphDiff|graph_a<br ALIGN="LEFT"/>graph_b<br ALIGN="LEFT"/>|diff_report(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._GreaterThan" [color="black", fontcolor="black", label=<{_GreaterThan|lower_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._GreaterThanEq" [color="black", fontcolor="black", label=<{_GreaterThanEq|lower_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._HalfOpenInterval" [color="black", fontcolor="black", label=<{_HalfOpenInterval|lower_bound<br ALIGN="LEFT"/>upper_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph._Handle" [color="black", fontcolor="black", label=<{_Handle|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._Handle" [color="black", fontcolor="black", label=<{_Handle|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._HasMeta" [color="black", fontcolor="black", label=<{_HasMeta|meta : Dict[str, PySymType]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package._directory_reader._HasStorage" [color="black", fontcolor="black", label=<{_HasStorage|<br ALIGN="LEFT"/>|storage()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.variables.dicts.ConstDictVariable._HashableTracker" [color="black", fontcolor="black", label=<{_HashableTracker|underlying_value<br ALIGN="LEFT"/>vt<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._Holder" [color="black", fontcolor="black", label=<{_Holder|handles : Dict[int, Optional[_Handle]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.function._HookMixin" [color="black", fontcolor="black", label=<{_HookMixin|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.polyfills.functools._INITIAL_MISSING" [color="black", fontcolor="black", label=<{_INITIAL_MISSING|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization._IRNode" [color="black", fontcolor="black", label=<{_IRNode|stack_meta<br ALIGN="LEFT"/>stack_trace<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler.itt._ITTStub" [color="black", fontcolor="black", label=<{_ITTStub|mark<br ALIGN="LEFT"/>rangePop<br ALIGN="LEFT"/>rangePush<br ALIGN="LEFT"/>|is_available()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler.profiler._ITraceObserver" [color="black", fontcolor="black", label=<{_ITraceObserver|<br ALIGN="LEFT"/>|<I>cleanup</I>()<br ALIGN="LEFT"/><I>start</I>()<br ALIGN="LEFT"/><I>stop</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.unflatten._IVals" [color="black", fontcolor="black", label=<{_IVals|fqns : defaultdict<br ALIGN="LEFT"/>storage : dict<br ALIGN="LEFT"/>|create(partitions, root_module)<br ALIGN="LEFT"/>read(fqn, graph, node)<br ALIGN="LEFT"/>update(fqn, graph, node)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._jit_internal._IgnoreContextManager" [color="black", fontcolor="black", label=<{_IgnoreContextManager|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._IllegalWork" [color="black", fontcolor="black", label=<{_IllegalWork|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compile_fx._InProcessFxCompile" [color="black", fontcolor="black", label=<{_InProcessFxCompile|<br ALIGN="LEFT"/>|codegen_and_compile(gm: GraphModule, example_inputs: Sequence[InputType], inputs_to_check: Sequence[int], graph_kwargs: _CompileFxKwargs): OutputCode<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.module._IncompatibleKeys" [color="black", fontcolor="black", label=<{_IncompatibleKeys|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._IndependentConstraint" [color="black", fontcolor="black", label=<{_IndependentConstraint|base_constraint<br ALIGN="LEFT"/>event_dim<br ALIGN="LEFT"/>is_discrete<br ALIGN="LEFT"/>reinterpreted_batch_ndims<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataloader._InfiniteConstantSampler" [color="black", fontcolor="black", label=<{_InfiniteConstantSampler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._InputBackref" [color="black", fontcolor="black", label=<{_InputBackref|value : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.fx._equalize._InputEqualizationObserver" [color="black", fontcolor="black", label=<{_InputEqualizationObserver|dtype<br ALIGN="LEFT"/>equalization_scale<br ALIGN="LEFT"/>equalization_shape : List[int]<br ALIGN="LEFT"/>input_obs<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>with_args : classmethod<br ALIGN="LEFT"/>|calculate_scaled_minmax()<br ALIGN="LEFT"/>forward(x_orig)<br ALIGN="LEFT"/>get_input_minmax()<br ALIGN="LEFT"/>set_equalization_scale(equalization_scale)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph._InsertPoint" [color="black", fontcolor="black", label=<{_InsertPoint|graph<br ALIGN="LEFT"/>orig_insert<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit._ir_utils._InsertPoint" [color="black", fontcolor="black", label=<{_InsertPoint|g<br ALIGN="LEFT"/>guard : NoneType<br ALIGN="LEFT"/>insert_point : Union[torch._C.Node, torch._C.Block]<br ALIGN="LEFT"/>prev_insert_point<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.instancenorm._InstanceNorm" [color="black", fontcolor="black", label=<{_InstanceNorm|<br ALIGN="LEFT"/>|forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._IntegerGreaterThan" [color="black", fontcolor="black", label=<{_IntegerGreaterThan|is_discrete : bool<br ALIGN="LEFT"/>lower_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._IntegerInterval" [color="black", fontcolor="black", label=<{_IntegerInterval|is_discrete : bool<br ALIGN="LEFT"/>lower_bound<br ALIGN="LEFT"/>upper_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._IntegerLessThan" [color="black", fontcolor="black", label=<{_IntegerLessThan|is_discrete : bool<br ALIGN="LEFT"/>upper_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._globals._InternalGlobals" [color="black", fontcolor="black", label=<{_InternalGlobals|autograd_inlining<br ALIGN="LEFT"/>export_onnx_opset_version<br ALIGN="LEFT"/>export_training : bool<br ALIGN="LEFT"/>in_onnx_export<br ALIGN="LEFT"/>onnx_shape_inference : bool<br ALIGN="LEFT"/>operator_export_type<br ALIGN="LEFT"/>training_mode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.rpc.internal._InternalRPCPickler" [color="black", fontcolor="black", label=<{_InternalRPCPickler|<br ALIGN="LEFT"/>|deserialize(binary_data, tensor_table)<br ALIGN="LEFT"/>serialize(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Interval" [color="black", fontcolor="black", label=<{_Interval|lower_bound<br ALIGN="LEFT"/>upper_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.transforms._InverseTransform" [color="black", fontcolor="black", label=<{_InverseTransform|bijective<br ALIGN="LEFT"/>inv<br ALIGN="LEFT"/>sign<br ALIGN="LEFT"/>|codomain()<br ALIGN="LEFT"/>domain()<br ALIGN="LEFT"/>forward_shape(shape)<br ALIGN="LEFT"/>inverse_shape(shape)<br ALIGN="LEFT"/>log_abs_det_jacobian(x, y)<br ALIGN="LEFT"/>with_cache(cache_size)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._typing._IterDataPipeMeta" [color="black", fontcolor="black", label=<{_IterDataPipeMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe._IterDataPipeSerializationWrapper" [color="black", fontcolor="black", label=<{_IterDataPipeSerializationWrapper|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.fetch._IterableDatasetFetcher" [color="black", fontcolor="black", label=<{_IterableDatasetFetcher|dataset_iter<br ALIGN="LEFT"/>ended : bool<br ALIGN="LEFT"/>|fetch(possibly_batched_index)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data._utils.worker._IterableDatasetStopIteration" [color="black", fontcolor="black", label=<{_IterableDatasetStopIteration|worker_id : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.jiterator._JittedFunction" [color="black", fontcolor="black", label=<{_JittedFunction|code_string : str<br ALIGN="LEFT"/>is_cuda_available : bool<br ALIGN="LEFT"/>kernel_name<br ALIGN="LEFT"/>kwargs_dict : dict<br ALIGN="LEFT"/>num_outputs : int<br ALIGN="LEFT"/>return_by_ref : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms.join._JoinConfig" [color="black", fontcolor="black", label=<{_JoinConfig|enable : bool<br ALIGN="LEFT"/>is_first_joinable : bool<br ALIGN="LEFT"/>throw_on_early_termination : bool<br ALIGN="LEFT"/>|construct_disabled_join_config()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler.profiler._KinetoProfile" [color="black", fontcolor="black", label=<{_KinetoProfile|acc_events : bool<br ALIGN="LEFT"/>activities<br ALIGN="LEFT"/>custom_trace_id_callback : NoneType<br ALIGN="LEFT"/>execution_trace_observer : NoneType<br ALIGN="LEFT"/>experimental_config : NoneType<br ALIGN="LEFT"/>mem_tl : Optional[MemoryProfileTimeline]<br ALIGN="LEFT"/>preset_metadata : Dict[str, str]<br ALIGN="LEFT"/>profile_memory : bool<br ALIGN="LEFT"/>profiler : Optional[prof.profile]<br ALIGN="LEFT"/>record_shapes : bool<br ALIGN="LEFT"/>use_device : NoneType, str<br ALIGN="LEFT"/>with_flops : bool<br ALIGN="LEFT"/>with_modules : bool<br ALIGN="LEFT"/>with_stack : bool<br ALIGN="LEFT"/>|add_metadata(key: str, value: str)<br ALIGN="LEFT"/>add_metadata_json(key: str, value: str)<br ALIGN="LEFT"/>events()<br ALIGN="LEFT"/>export_chrome_trace(path: str)<br ALIGN="LEFT"/>export_memory_timeline(path: str, device: Optional[str]): None<br ALIGN="LEFT"/>export_stacks(path: str, metric: str)<br ALIGN="LEFT"/>key_averages(group_by_input_shape: bool, group_by_stack_n: int)<br ALIGN="LEFT"/>prepare_trace()<br ALIGN="LEFT"/>preset_metadata_json(key: str, value: str)<br ALIGN="LEFT"/>start()<br ALIGN="LEFT"/>start_trace()<br ALIGN="LEFT"/>stop()<br ALIGN="LEFT"/>stop_trace()<br ALIGN="LEFT"/>toggle_collection_dynamic(enable: bool, activities: Iterable[ProfilerActivity])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._LPPoolNd" [color="black", fontcolor="black", label=<{_LPPoolNd|ceil_mode : bool<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>norm_type : float<br ALIGN="LEFT"/>stride : Optional[_size_any_t]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.lr_scheduler._LRScheduler" [color="black", fontcolor="black", label=<{_LRScheduler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMLayer" [color="black", fontcolor="black", label=<{_LSTMLayer|batch_first : bool<br ALIGN="LEFT"/>bidirectional : bool<br ALIGN="LEFT"/>layer_bw<br ALIGN="LEFT"/>layer_fw<br ALIGN="LEFT"/>qconfig<br ALIGN="LEFT"/>|forward(x: Tensor, hidden: Optional[Tuple[Tensor, Tensor]])<br ALIGN="LEFT"/>from_float(other, layer_idx, qconfig)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" [color="black", fontcolor="black", label=<{_LSTMSingleLayer|cell<br ALIGN="LEFT"/>|forward(x: Tensor, hidden: Optional[Tuple[Tensor, Tensor]])<br ALIGN="LEFT"/>from_params()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.xeon.run_cpu._Launcher" [color="black", fontcolor="black", label=<{_Launcher|cpuinfo<br ALIGN="LEFT"/>msg_lib_notfound : str<br ALIGN="LEFT"/>|add_lib_preload(lib_type)<br ALIGN="LEFT"/>is_numactl_available()<br ALIGN="LEFT"/>launch(args)<br ALIGN="LEFT"/>log_env_var(env_var_name)<br ALIGN="LEFT"/>set_env(env_name, env_value)<br ALIGN="LEFT"/>set_memory_allocator(enable_tcmalloc, enable_jemalloc, use_default_allocator)<br ALIGN="LEFT"/>set_multi_thread_and_allocator(ncores_per_instance, disable_iomp, set_kmp_affinity, enable_tcmalloc, enable_jemalloc, use_default_allocator)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.conv._LazyConvXdMixin" [color="black", fontcolor="black", label=<{_LazyConvXdMixin|bias<br ALIGN="LEFT"/>groups : int<br ALIGN="LEFT"/>in_channels : int<br ALIGN="LEFT"/>kernel_size : Tuple[int, ...]<br ALIGN="LEFT"/>out_channels : int<br ALIGN="LEFT"/>transposed : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|initialize_parameters(input: Tensor): None<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._lazy_graph_module._LazyGraphModule" [color="black", fontcolor="black", label=<{_LazyGraphModule|code<br ALIGN="LEFT"/>forward<br ALIGN="LEFT"/>|force_recompile(gm)<br ALIGN="LEFT"/>from_graphmodule(gm: GraphModule)<br ALIGN="LEFT"/>real_recompile()<br ALIGN="LEFT"/>recompile()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal._lazy_import._LazyModule" [color="black", fontcolor="black", label=<{_LazyModule|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm._LazyNormBase" [color="black", fontcolor="black", label=<{_LazyNormBase|affine : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>num_batches_tracked<br ALIGN="LEFT"/>num_features<br ALIGN="LEFT"/>running_mean<br ALIGN="LEFT"/>running_var<br ALIGN="LEFT"/>track_running_stats : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|initialize_parameters(input): None<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.lazy._LazyProtocol" [color="black", fontcolor="black", label=<{_LazyProtocol|<br ALIGN="LEFT"/>|register_forward_pre_hook(hook)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._utils._LazySeedTracker" [color="black", fontcolor="black", label=<{_LazySeedTracker|call_order : list<br ALIGN="LEFT"/>manual_seed_all_cb : NoneType, tuple<br ALIGN="LEFT"/>manual_seed_cb : NoneType, tuple<br ALIGN="LEFT"/>|get_calls(): List<br ALIGN="LEFT"/>queue_seed(cb, traceback)<br ALIGN="LEFT"/>queue_seed_all(cb, traceback)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization._LeafNode" [color="black", fontcolor="black", label=<{_LeafNode|fx_node<br ALIGN="LEFT"/>fx_op<br ALIGN="LEFT"/>stack_meta<br ALIGN="LEFT"/>stack_trace<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" [color="black", fontcolor="black", label=<{_LearnableFakeQuantize|activation_post_process<br ALIGN="LEFT"/>bitwidth : int<br ALIGN="LEFT"/>ch_axis : int<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>quant_max : int<br ALIGN="LEFT"/>quant_min : int<br ALIGN="LEFT"/>scale<br ALIGN="LEFT"/>use_grad_scaling : bool<br ALIGN="LEFT"/>zero_point<br ALIGN="LEFT"/>|calculate_qparams()<br ALIGN="LEFT"/>enable_observer(enabled)<br ALIGN="LEFT"/>enable_param_learning()<br ALIGN="LEFT"/>enable_static_estimate()<br ALIGN="LEFT"/>enable_static_observation()<br ALIGN="LEFT"/>forward(X)<br ALIGN="LEFT"/>observe_quant_params()<br ALIGN="LEFT"/>toggle_fake_quant(enabled)<br ALIGN="LEFT"/>toggle_observer_update(enabled)<br ALIGN="LEFT"/>toggle_qparam_learning(enabled)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.storage._LegacyStorage" [color="black", fontcolor="black", label=<{_LegacyStorage|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.storage._LegacyStorageMeta" [color="black", fontcolor="black", label=<{_LegacyStorageMeta|dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._LessThan" [color="black", fontcolor="black", label=<{_LessThan|upper_bound<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR._LinearNodeList" [color="black", fontcolor="black", label=<{_LinearNodeList|serialize_node_list : list<br ALIGN="LEFT"/>|to_graph()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._LoadBalancer" [color="black", fontcolor="black", label=<{_LoadBalancer|<br ALIGN="LEFT"/>|<I>shard</I>(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/><I>unshard</I>(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.runtime.autotune_cache._LocalAutotuneCacheBackend" [color="black", fontcolor="black", label=<{_LocalAutotuneCacheBackend|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.optim.optimizer._LocalOptimizer" [color="black", fontcolor="black", label=<{_LocalOptimizer|global_lock : lock<br ALIGN="LEFT"/>optim<br ALIGN="LEFT"/>|step(autograd_ctx_id)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss._Loss" [color="black", fontcolor="black", label=<{_Loss|reduction : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.microbatch._LossReducer" [color="black", fontcolor="black", label=<{_LossReducer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._LowerCholesky" [color="black", fontcolor="black", label=<{_LowerCholesky|event_dim : int<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._LowerTriangular" [color="black", fontcolor="black", label=<{_LowerTriangular|event_dim : int<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.metadata._MEM_FORMAT_ENCODING" [color="black", fontcolor="black", label=<{_MEM_FORMAT_ENCODING|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._MakefxTracer" [color="black", fontcolor="black", label=<{_MakefxTracer|decomposition_table : Dict[OpOverload, Callable]<br ALIGN="LEFT"/>fake_tensor_mode : NoneType, Optional[FakeTensorMode]<br ALIGN="LEFT"/>fx_tracer : Optional[PythonKeyTracer]<br ALIGN="LEFT"/>pre_dispatch : bool<br ALIGN="LEFT"/>proxy_function_mode : Union[nullcontext, PreDispatchTorchFunctionMode]<br ALIGN="LEFT"/>proxy_mode : Union[nullcontext, ProxyTorchDispatchMode]<br ALIGN="LEFT"/>python_dispatcher_mode : Union[nullcontext, Any]<br ALIGN="LEFT"/>record_module_stack : bool<br ALIGN="LEFT"/>torch_fn_metadata_mode : Union[nullcontext, TorchFunctionMetadataMode]<br ALIGN="LEFT"/>tracing_mode : str<br ALIGN="LEFT"/>|trace(f: Callable): fx.GraphModule<br ALIGN="LEFT"/>trace_subgraph(f: Callable): GraphModule<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes.datapipe._MapDataPipeSerializationWrapper" [color="black", fontcolor="black", label=<{_MapDataPipeSerializationWrapper|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.fetch._MapDatasetFetcher" [color="black", fontcolor="black", label=<{_MapDatasetFetcher|<br ALIGN="LEFT"/>|fetch(possibly_batched_index)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._embedding_ops._MaskPartial" [color="black", fontcolor="black", label=<{_MaskPartial|mask_buffer<br ALIGN="LEFT"/>offset_dim : int<br ALIGN="LEFT"/>offset_shape : Optional[torch.Size]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.masked.maskedtensor._ops_refs._MaskedContiguous" [color="black", fontcolor="black", label=<{_MaskedContiguous|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor._ops_refs._MaskedToDense" [color="black", fontcolor="black", label=<{_MaskedToDense|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor._ops_refs._MaskedToSparse" [color="black", fontcolor="black", label=<{_MaskedToSparse|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor._ops_refs._MaskedToSparseCsr" [color="black", fontcolor="black", label=<{_MaskedToSparseCsr|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, input)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.masked.maskedtensor._ops_refs._MaskedWhere" [color="black", fontcolor="black", label=<{_MaskedWhere|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, cond, self, other)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.kl._Match" [color="black", fontcolor="black", label=<{_Match|types : tuple<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.micro_pipeline_tp._Matmul" [color="black", fontcolor="black", label=<{_Matmul|A_node<br ALIGN="LEFT"/>B_node<br ALIGN="LEFT"/>arg_ancestor_nodes : OrderedSet[torch.fx.Node]<br ALIGN="LEFT"/>nodes : List[torch.fx.Node]<br ALIGN="LEFT"/>|erase(): None<br ALIGN="LEFT"/>from_match(match: List[torch.fx.Node]): '_Matmul'<br ALIGN="LEFT"/>replace_with(new_node: torch.fx.Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._MaxPoolNd" [color="black", fontcolor="black", label=<{_MaxPoolNd|ceil_mode : bool<br ALIGN="LEFT"/>dilation : Union<br ALIGN="LEFT"/>kernel_size : Union<br ALIGN="LEFT"/>padding : Union<br ALIGN="LEFT"/>return_indices : bool<br ALIGN="LEFT"/>stride : NoneType<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.pooling._MaxUnpoolNd" [color="black", fontcolor="black", label=<{_MaxUnpoolNd|<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._MemRefType" [color="black", fontcolor="black", label=<{_MemRefType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.device_mesh._MeshEnv" [color="black", fontcolor="black", label=<{_MeshEnv|child_to_root_mapping : Dict[DeviceMesh, DeviceMesh]<br ALIGN="LEFT"/>flatten_name_to_root_dims : Dict[DeviceMesh, Dict[str, Tuple[int, ...]]]<br ALIGN="LEFT"/>mesh_dim_group_options : Dict[int, Tuple[str, Optional[C10dBackend.Options]]]<br ALIGN="LEFT"/>mesh_stack : List[DeviceMesh]<br ALIGN="LEFT"/>root_to_flatten_mapping : Dict[DeviceMesh, Dict[str, DeviceMesh]]<br ALIGN="LEFT"/>|create_flatten_mesh(device_mesh: 'DeviceMesh', mesh_dim_name: Optional[str]): 'DeviceMesh'<br ALIGN="LEFT"/>create_sub_mesh(device_mesh: 'DeviceMesh', submesh_dim_names: Tuple[str, ...], submesh_dims: List[Tuple[int, ...]]): 'DeviceMesh'<br ALIGN="LEFT"/>get_current_mesh(): 'DeviceMesh'<br ALIGN="LEFT"/>get_mesh_dim_by_name(device_mesh: 'DeviceMesh', mesh_dim_name: str): int<br ALIGN="LEFT"/>get_root_mesh(device_mesh: 'DeviceMesh'): 'DeviceMesh'<br ALIGN="LEFT"/>get_root_mesh_dim(device_mesh: 'DeviceMesh'): Optional[int]<br ALIGN="LEFT"/>num_devices_per_host(device_type: str): int<br ALIGN="LEFT"/>num_hosts(device_type: str): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses.meta_utils._MetaTensorCallback" [color="black", fontcolor="black", label=<{_MetaTensorCallback|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.meta_utils._MetaTensorCallbackKwargs" [color="black", fontcolor="black", label=<{_MetaTensorCallbackKwargs|device : Union[torch.device, str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.net_min_base._MinimizerBase" [color="black", fontcolor="black", label=<{_MinimizerBase|a_outputs : Dict[str, Any]<br ALIGN="LEFT"/>b_outputs : Dict[str, Any]<br ALIGN="LEFT"/>compare_fn : Callable[[TensorOrTensors, TensorOrTensors, Names], Tuple[float, bool]]<br ALIGN="LEFT"/>exclusion_fn : Optional[Callable[[NodeList, int, int], None]]<br ALIGN="LEFT"/>fusions : dict<br ALIGN="LEFT"/>iteration : int<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>module_exporter : Optional[Callable[[Tensors, torch.fx.GraphModule, str], None]]<br ALIGN="LEFT"/>reports : List[List[str]]<br ALIGN="LEFT"/>results : Dict[Any, Any]<br ALIGN="LEFT"/>sample_input : Union<br ALIGN="LEFT"/>settings<br ALIGN="LEFT"/>|minimize(start: Optional[str], end: Optional[str], skip_nodes: Optional[List], find_last_node: Optional[bool]): NodeSet<br ALIGN="LEFT"/>print_report(report: List[str])<br ALIGN="LEFT"/>print_reports()<br ALIGN="LEFT"/>run_a(mod: torch.fx.GraphModule, inputs: Tensors, report_idx: int): TensorOrTensors<br ALIGN="LEFT"/>run_b(mod: torch.fx.GraphModule, inputs: Tensors, report_idx: int): TensorOrTensors<br ALIGN="LEFT"/>run_nodes(start: Optional[str], end: Optional[str])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.net_min_base._MinimizerSettingBase" [color="black", fontcolor="black", label=<{_MinimizerSettingBase|accumulate_error : bool<br ALIGN="LEFT"/>all_outputs : bool<br ALIGN="LEFT"/>find_all : bool<br ALIGN="LEFT"/>return_intermediate : bool<br ALIGN="LEFT"/>traverse_method : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._MissingCustomSymbolicFunction" [color="black", fontcolor="black", label=<{_MissingCustomSymbolicFunction|<br ALIGN="LEFT"/>|format(level: infra.Level, op_name): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(op_name): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._MissingStandardSymbolicFunction" [color="black", fontcolor="black", label=<{_MissingStandardSymbolicFunction|<br ALIGN="LEFT"/>|format(level: infra.Level, op_name, opset_version, issue_url): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(op_name, opset_version, issue_url): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.parallel.distributed._MixedPrecision" [color="black", fontcolor="black", label=<{_MixedPrecision|buffer_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>param_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>reduce_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.mkldnn._MkldnnConvNd" [color="black", fontcolor="black", label=<{_MkldnnConvNd|dilation<br ALIGN="LEFT"/>groups<br ALIGN="LEFT"/>padding<br ALIGN="LEFT"/>stride<br ALIGN="LEFT"/>|forward(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._ModMemStats" [color="black", fontcolor="black", label=<{_ModMemStats|buffer_mem : int<br ALIGN="LEFT"/>input_mem : int<br ALIGN="LEFT"/>local_peak : Dict[torch.device, int]<br ALIGN="LEFT"/>mod_fqn : str<br ALIGN="LEFT"/>output_mem : int<br ALIGN="LEFT"/>parameter_mem : int<br ALIGN="LEFT"/>snapshots : Dict[_ModState, List[Dict[torch.device, Dict[str, int]]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._ModState" [color="black", fontcolor="black", label=<{_ModState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._ops._ModeStackStateForPreDispatch" [color="black", fontcolor="black", label=<{_ModeStackStateForPreDispatch|<br ALIGN="LEFT"/>|count()<br ALIGN="LEFT"/>get(index)<br ALIGN="LEFT"/>set(index, mode)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.attention.flex_attention._ModificationType" [color="black", fontcolor="black", label=<{_ModificationType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.unflatten._ModuleFrame" [color="black", fontcolor="black", label=<{_ModuleFrame|child_fqn : str<br ALIGN="LEFT"/>created_modules<br ALIGN="LEFT"/>flat_graph<br ALIGN="LEFT"/>fqn<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>ivals : dict<br ALIGN="LEFT"/>module : Union[torch.fx.GraphModule, UnflattenedModule, InterpreterModule]<br ALIGN="LEFT"/>module_call_graph : Dict[str, ModuleCallSignature]<br ALIGN="LEFT"/>module_id<br ALIGN="LEFT"/>module_stack : List[Tuple[str, int]]<br ALIGN="LEFT"/>node_map : Dict[torch.fx.Node, torch.fx.Node]<br ALIGN="LEFT"/>node_to_placeholder : dict<br ALIGN="LEFT"/>nodes : Tuple[torch.fx.Node, ...]<br ALIGN="LEFT"/>parent<br ALIGN="LEFT"/>parent_call_module : Optional[torch.fx.Node]<br ALIGN="LEFT"/>seen_attrs<br ALIGN="LEFT"/>seen_modules<br ALIGN="LEFT"/>seen_nodes<br ALIGN="LEFT"/>verbose : bool<br ALIGN="LEFT"/>|add_placeholder(x)<br ALIGN="LEFT"/>copy_node(node)<br ALIGN="LEFT"/>copy_sym_call_function(x)<br ALIGN="LEFT"/>finalize_outputs()<br ALIGN="LEFT"/>print()<br ALIGN="LEFT"/>remap_input(x)<br ALIGN="LEFT"/>run_from(node_idx)<br ALIGN="LEFT"/>run_outer()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization._ModuleMeta" [color="black", fontcolor="black", label=<{_ModuleMeta|module_class_name<br ALIGN="LEFT"/>module_display_name<br ALIGN="LEFT"/>module_name<br ALIGN="LEFT"/>qualified_module_class_name<br ALIGN="LEFT"/>raw_meta<br ALIGN="LEFT"/>|create_root(): _ModuleMeta<br ALIGN="LEFT"/>from_dynamo_produced_raw_meta(raw_meta: _DYNAMO_NN_MODULE_META_TYPE): _ModuleMeta<br ALIGN="LEFT"/>from_fx_tracer_produced_raw_meta(raw_meta: _FX_TRACER_NN_MODULE_META_TYPE): _ModuleMeta<br ALIGN="LEFT"/>from_raw_meta(raw_meta: _FX_TRACER_NN_MODULE_META_TYPE \| _DYNAMO_NN_MODULE_META_TYPE): _ModuleMeta<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization._ModuleNode" [color="black", fontcolor="black", label=<{_ModuleNode|stack_meta<br ALIGN="LEFT"/>stack_trace<br ALIGN="LEFT"/>|add_leaf_node(leaf_node: _LeafNode): None<br ALIGN="LEFT"/>build_module(module_names: dict[str, int]): torch.fx.GraphModule<br ALIGN="LEFT"/>fx_nodes(): Generator[torch.fx.Node, None, None]<br ALIGN="LEFT"/>is_parent_module_of(node: _IRNode): bool<br ALIGN="LEFT"/>is_same_module_as(node: _IRNode): bool<br ALIGN="LEFT"/>module_inputs(): Sequence[torch.fx.Node]<br ALIGN="LEFT"/>module_outputs(): Sequence[torch.fx.Node]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.package_importer._ModuleNode" [color="black", fontcolor="black", label=<{_ModuleNode|source_file : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleNotInstalledAsSubmoduleError" [color="black", fontcolor="red", label=<{_ModuleNotInstalledAsSubmoduleError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_exporter._ModuleProviderAction" [color="black", fontcolor="black", label=<{_ModuleProviderAction|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.modularization._ModuleStackMeta" [color="black", fontcolor="black", label=<{_ModuleStackMeta|module_class<br ALIGN="LEFT"/>module_display_name<br ALIGN="LEFT"/>qualified_module_class_name<br ALIGN="LEFT"/>raw_meta<br ALIGN="LEFT"/>|is_empty_or_root(): bool<br ALIGN="LEFT"/>is_superset_of(module_stack: _ModuleStackMeta): bool<br ALIGN="LEFT"/>push(module_meta: _ModuleMeta): None<br ALIGN="LEFT"/>top(): _ModuleMeta<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer" [color="black", fontcolor="black", label=<{_ModuleStackTracer|attr_proxy_map : WeakKeyDictionary[Module, _AttrProxy]<br ALIGN="LEFT"/>counter : int<br ALIGN="LEFT"/>enable_attr_proxy : bool<br ALIGN="LEFT"/>module_id_cache : defaultdict<br ALIGN="LEFT"/>proxy_modules : WeakKeyDictionary[_AttrProxy, Module]<br ALIGN="LEFT"/>proxy_paths : WeakKeyDictionary[_AttrProxy, str]<br ALIGN="LEFT"/>proxy_type<br ALIGN="LEFT"/>scope_root<br ALIGN="LEFT"/>submodule_paths : dict<br ALIGN="LEFT"/>|call_module(m: Module, forward: Callable, args: Tuple[object, ...], kwargs: Dict[str, object]): None<br ALIGN="LEFT"/>create_node(): fx.node.Node<br ALIGN="LEFT"/>getattr(attr: str, attr_val: object, parameter_proxy_cache: Dict[str, Proxy]): object<br ALIGN="LEFT"/>is_leaf_module(m: Module, module_qualified_name: str): bool<br ALIGN="LEFT"/>path_of_module(mod: Module): str<br ALIGN="LEFT"/>trace(root: Union[Module, Callable], concrete_args: Optional[Dict[str, object]]): fx.Graph<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.amp.grad_scaler._MultiDeviceReplicator" [color="black", fontcolor="black", label=<{_MultiDeviceReplicator|master<br ALIGN="LEFT"/>|get(device: torch.device): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.graph._MultiHandle" [color="black", fontcolor="black", label=<{_MultiHandle|handles : Tuple[RemovableHandle, ...]<br ALIGN="LEFT"/>|remove(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataloader._MultiProcessingDataLoaderIter" [color="black", fontcolor="black", label=<{_MultiProcessingDataLoaderIter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._Multinomial" [color="black", fontcolor="black", label=<{_Multinomial|event_dim : int<br ALIGN="LEFT"/>is_discrete : bool<br ALIGN="LEFT"/>upper_bound<br ALIGN="LEFT"/>|check(x)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.ns.fx.graph_matcher._NSGraphMatchableSubgraphsIterator" [color="black", fontcolor="black", label=<{_NSGraphMatchableSubgraphsIterator|gm<br ALIGN="LEFT"/>non_matchable_functions : Set[NSNodeTargetType]<br ALIGN="LEFT"/>non_matchable_methods : Set[NSNodeTargetType]<br ALIGN="LEFT"/>non_matchable_modules : Set[NSNodeTargetType]<br ALIGN="LEFT"/>seen_nodes : Set[Node]<br ALIGN="LEFT"/>stack : List[Node]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.nvtx._NVTXStub" [color="black", fontcolor="black", label=<{_NVTXStub|markA<br ALIGN="LEFT"/>rangePop<br ALIGN="LEFT"/>rangePushA<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.optim.named_optimizer._NamedOptimizer" [color="black", fontcolor="black", label=<{_NamedOptimizer|module : Optional[nn.Module]<br ALIGN="LEFT"/>named_parameters : dict<br ALIGN="LEFT"/>ordered_param_keys : list<br ALIGN="LEFT"/>param_groups : Optional[Collection[Mapping[str, Any]]]<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|add_param_group(param_group: Mapping[str, Any]): None<br ALIGN="LEFT"/>init_state(): None<br ALIGN="LEFT"/>load_state_dict(state_dict: Mapping[str, Any]): None<br ALIGN="LEFT"/>state_dict(): Dict[str, Any]<br ALIGN="LEFT"/>step(closure: None): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph._Namespace" [color="black", fontcolor="black", label=<{_Namespace|<br ALIGN="LEFT"/>|associate_name_with_obj(name: str, obj: Any)<br ALIGN="LEFT"/>create_name(candidate: str, obj: Optional[Any]): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends._nnapi.serializer._NnapiSerializer" [color="black", fontcolor="black", label=<{_NnapiSerializer|ADDER_MAP : dict<br ALIGN="LEFT"/>cached_immediates : dict<br ALIGN="LEFT"/>constants : dict<br ALIGN="LEFT"/>flexible_shape_computation_lines : list<br ALIGN="LEFT"/>inputs : list<br ALIGN="LEFT"/>jitval_operand_map : dict<br ALIGN="LEFT"/>modules : dict<br ALIGN="LEFT"/>operands : list<br ALIGN="LEFT"/>operation_args : list<br ALIGN="LEFT"/>operations : list<br ALIGN="LEFT"/>outputs : list<br ALIGN="LEFT"/>tensor_sequences : dict<br ALIGN="LEFT"/>use_int16_for_qint16 : bool<br ALIGN="LEFT"/>used_weights : list<br ALIGN="LEFT"/>value_data : list<br ALIGN="LEFT"/>values : list<br ALIGN="LEFT"/>weight_offset : int<br ALIGN="LEFT"/>|add_adaptive_avg_pool2d(node)<br ALIGN="LEFT"/>add_add_sub_op(node, opcode, fuse_code)<br ALIGN="LEFT"/>add_addmm(node)<br ALIGN="LEFT"/>add_addmm_or_linear(node, transpose_weight, jit_input, jit_weight, jit_bias)<br ALIGN="LEFT"/>add_anonymous_tensor_operand(oper)<br ALIGN="LEFT"/>add_avg_pool2d(node)<br ALIGN="LEFT"/>add_cat(node)<br ALIGN="LEFT"/>add_constant_node(node)<br ALIGN="LEFT"/>add_constant_value(jitval, ctype, value)<br ALIGN="LEFT"/>add_conv2d(node)<br ALIGN="LEFT"/>add_conv2d_common(jit_out, out_scale, out_zero_point, jit_image, weight_tensor, bias_id, args, transpose, fuse_code)<br ALIGN="LEFT"/>add_conv_underscore(node)<br ALIGN="LEFT"/>add_dequantize(node)<br ALIGN="LEFT"/>add_flatten(node)<br ALIGN="LEFT"/>add_getattr(node)<br ALIGN="LEFT"/>add_hardtanh(node)<br ALIGN="LEFT"/>add_immediate_bool_scalar(value)<br ALIGN="LEFT"/>add_immediate_float_scalar(value)<br ALIGN="LEFT"/>add_immediate_int_scalar(value)<br ALIGN="LEFT"/>add_immediate_int_vector(value)<br ALIGN="LEFT"/>add_immediate_operand(code, value, dims)<br ALIGN="LEFT"/>add_linear(node)<br ALIGN="LEFT"/>add_list_construct(node)<br ALIGN="LEFT"/>add_log_softmax(node)<br ALIGN="LEFT"/>add_mean(node)<br ALIGN="LEFT"/>add_node(node)<br ALIGN="LEFT"/>add_operation(opcode, inputs, outputs)<br ALIGN="LEFT"/>add_pointwise_simple_binary_broadcast_op(node, opcode, fuse_code)<br ALIGN="LEFT"/>add_pointwise_simple_unary_op(node, opcode)<br ALIGN="LEFT"/>add_pool2d_node(node, opcode)<br ALIGN="LEFT"/>add_prelu_op(node)<br ALIGN="LEFT"/>add_qadd(node, opcode, fuse_code)<br ALIGN="LEFT"/>add_qconv2d(node, fuse_code, transpose)<br ALIGN="LEFT"/>add_qlinear(node)<br ALIGN="LEFT"/>add_quantize(node)<br ALIGN="LEFT"/>add_reshape(node)<br ALIGN="LEFT"/>add_size(node)<br ALIGN="LEFT"/>add_slice(node)<br ALIGN="LEFT"/>add_softmax(node)<br ALIGN="LEFT"/>add_tensor_operand(jitval, oper)<br ALIGN="LEFT"/>add_tensor_operand_for_input(arg_idx, jitval, tensor)<br ALIGN="LEFT"/>add_tensor_operand_for_weight(tensor, dim_order)<br ALIGN="LEFT"/>add_tensor_sequence(jitval, values)<br ALIGN="LEFT"/>add_to(node)<br ALIGN="LEFT"/>add_tuple_construct(node)<br ALIGN="LEFT"/>add_unsqueeze(node)<br ALIGN="LEFT"/>add_upsample_nearest2d(node)<br ALIGN="LEFT"/>compute_operand_shape(op_id, dim, expr)<br ALIGN="LEFT"/>forward_operand_shape(out_op_id, out_dim, in_op_id, in_dim)<br ALIGN="LEFT"/>get_constant_value(jitval, typekind)<br ALIGN="LEFT"/>get_conv_pool_args_2d_common(kernel_size, strides, paddings, dilations, group_num)<br ALIGN="LEFT"/>get_conv_pool_args_2d_from_jit(kernel_size, stride, padding, dilation, group)<br ALIGN="LEFT"/>get_conv_pool_args_2d_from_pack(kernel_size, packed_config)<br ALIGN="LEFT"/>get_next_operand_id()<br ALIGN="LEFT"/>get_optional_bias(jit_bias, weight_tensor, transpose)<br ALIGN="LEFT"/>get_size_arg(jitval)<br ALIGN="LEFT"/>get_tensor_operand_by_jitval(jitval)<br ALIGN="LEFT"/>get_tensor_operand_by_jitval_fixed_size(jitval)<br ALIGN="LEFT"/>get_tensor_operand_for_weight(jitval)<br ALIGN="LEFT"/>get_tensor_operand_or_constant(jitval, dim_order)<br ALIGN="LEFT"/>has_operand_for_jitval(jitval)<br ALIGN="LEFT"/>operand_to_template_torchscript(op_id, oper, shape)<br ALIGN="LEFT"/>serialize_ints(ints)<br ALIGN="LEFT"/>serialize_model(model, inputs, return_shapes)<br ALIGN="LEFT"/>serialize_values()<br ALIGN="LEFT"/>torch_tensor_to_operand(tensor, dim_order)<br ALIGN="LEFT"/>transpose_for_broadcast(in0_id, in0_oper, in1_id, in1_oper)<br ALIGN="LEFT"/>transpose_to_nhwc(in_id, oper)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._NoDefault" [color="black", fontcolor="black", label=<{_NoDefault|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._contextlib._NoParamDecoratorContextManager" [color="black", fontcolor="black", label=<{_NoParamDecoratorContextManager|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._NoSymbolicFunctionForCallFunction" [color="black", fontcolor="black", label=<{_NoSymbolicFunctionForCallFunction|<br ALIGN="LEFT"/>|format(level: infra.Level, target): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(target): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDesc" [color="black", fontcolor="black", label=<{_NodeDesc|addr : str<br ALIGN="LEFT"/>local_id : int<br ALIGN="LEFT"/>pid : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDescGenerator" [color="black", fontcolor="black", label=<{_NodeDescGenerator|<br ALIGN="LEFT"/>|generate(local_addr: Optional[str]): _NodeDesc<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._NodeMissingOnnxShapeInference" [color="black", fontcolor="black", label=<{_NodeMissingOnnxShapeInference|<br ALIGN="LEFT"/>|format(level: infra.Level, op_name): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(op_name): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining._IR._NodeReference" [color="black", fontcolor="black", label=<{_NodeReference|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.non_strict_utils._NonStrictTorchFunctionHandler" [color="black", fontcolor="black", label=<{_NonStrictTorchFunctionHandler|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._NoopSaveInputs" [color="black", fontcolor="black", label=<{_NoopSaveInputs|<br ALIGN="LEFT"/>|backward(ctx)<br ALIGN="LEFT"/>forward()<br ALIGN="LEFT"/>setup_context(ctx: Any, inputs: Tuple[Any, ...], output: Any): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.batchnorm._NormBase" [color="black", fontcolor="black", label=<{_NormBase|affine : bool<br ALIGN="LEFT"/>bias<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>momentum : Optional[float]<br ALIGN="LEFT"/>num_batches_tracked : Optional[Tensor]<br ALIGN="LEFT"/>num_features : int<br ALIGN="LEFT"/>running_mean : Optional[Tensor]<br ALIGN="LEFT"/>running_var : Optional[Tensor]<br ALIGN="LEFT"/>track_running_stats : bool<br ALIGN="LEFT"/>weight<br ALIGN="LEFT"/>|extra_repr()<br ALIGN="LEFT"/>reset_parameters(): None<br ALIGN="LEFT"/>reset_running_stats(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._ops._math_ops._NormPartial" [color="black", fontcolor="black", label=<{_NormPartial|norm_type : Union[int, float, str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.bytecode_transformation._NotProvided" [color="black", fontcolor="black", label=<{_NotProvided|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.eval_frame._NullDecorator" [color="black", fontcolor="black", label=<{_NullDecorator|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler.profiler._NumpyEncoder" [color="black", fontcolor="black", label=<{_NumpyEncoder|<br ALIGN="LEFT"/>|default(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._OneHot" [color="black", fontcolor="black", label=<{_OneHot|event_dim : int<br ALIGN="LEFT"/>is_discrete : bool<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.onnxfunction_dispatcher._OnnxSchemaChecker" [color="black", fontcolor="black", label=<{_OnnxSchemaChecker|attributes<br ALIGN="LEFT"/>match_score<br ALIGN="LEFT"/>onnxfunction : onnxscript.OnnxFunction \| onnxscript.TracedOnnxFunction<br ALIGN="LEFT"/>op_schema<br ALIGN="LEFT"/>param_schema<br ALIGN="LEFT"/>type_constraints<br ALIGN="LEFT"/>|perfect_match_inputs(diagnostic: diagnostics.Diagnostic, args: Sequence[fx_type_utils.TensorLike \| str \| int \| float \| bool \| list \| complex \| None], kwargs: dict[str, fx_type_utils.Argument]): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._OpLevelDebugging" [color="black", fontcolor="black", label=<{_OpLevelDebugging|<br ALIGN="LEFT"/>|format(level: infra.Level, node, symbolic_fn): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(node, symbolic_fn): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops._OpNamespace" [color="black", fontcolor="black", label=<{_OpNamespace|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion._OpTraceDispatchMode" [color="black", fontcolor="black", label=<{_OpTraceDispatchMode|traced_ops : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._OperatorSupportedInNewerOpsetVersion" [color="black", fontcolor="black", label=<{_OperatorSupportedInNewerOpsetVersion|<br ALIGN="LEFT"/>|format(level: infra.Level, op_name, opset_version, supported_opset_version): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(op_name, opset_version, supported_opset_version): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._ops._Ops" [color="black", fontcolor="black", label=<{_Ops|loaded_libraries : set<br ALIGN="LEFT"/>|import_module(module)<br ALIGN="LEFT"/>load_library(path)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks._OptimInBackwardHookState" [color="black", fontcolor="black", label=<{_OptimInBackwardHookState|optim_stream<br ALIGN="LEFT"/>wait_for_optim_stream_enqueued : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._optim_utils._OptimStateKey" [color="black", fontcolor="black", label=<{_OptimStateKey|is_fsdp_managed : bool<br ALIGN="LEFT"/>unflat_param_names : Tuple[str, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks._OptimizerHookState" [color="black", fontcolor="black", label=<{_OptimizerHookState|functional_optimizer<br ALIGN="LEFT"/>params_to_optimize : set<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.group_batch_fusion._OrderedSet" [color="black", fontcolor="black", label=<{_OrderedSet|rep : OrderedDict<br ALIGN="LEFT"/>|append(o)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.parametrizations._OrthMaps" [color="black", fontcolor="black", label=<{_OrthMaps|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.parametrizations._Orthogonal" [color="black", fontcolor="black", label=<{_Orthogonal|base<br ALIGN="LEFT"/>orthogonal_map<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|forward(X: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>right_inverse(Q: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer._OverlapInfo" [color="black", fontcolor="black", label=<{_OverlapInfo|assigned_ranks_per_bucket : list[set[int]]<br ALIGN="LEFT"/>broadcast_handles : Any<br ALIGN="LEFT"/>bucket_index_to_bucket : Any<br ALIGN="LEFT"/>bucket_index_to_future : Any<br ALIGN="LEFT"/>bucket_indices_seen : Any<br ALIGN="LEFT"/>offsets : Any<br ALIGN="LEFT"/>params_per_bucket : Any<br ALIGN="LEFT"/>params_per_rank : Any<br ALIGN="LEFT"/>shard_buckets : bool<br ALIGN="LEFT"/>status : Any<br ALIGN="LEFT"/>total_size : int<br ALIGN="LEFT"/>|clear_per_iter_info(): None<br ALIGN="LEFT"/>wait_for_broadcasts(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer._OverlapStatus" [color="black", fontcolor="black", label=<{_OverlapStatus|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.algorithms._optimizer_overlap.optimizer_overlap._OverlappedStandardOptimizer" [color="black", fontcolor="black", label=<{_OverlappedStandardOptimizer|<br ALIGN="LEFT"/>|register_ddp(ddp_inst: DistributedDataParallel)<br ALIGN="LEFT"/><I>register_fsdp</I>(fsdp: FullyShardedDataParallel): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._OverlappingCpuLoader" [color="black", fontcolor="black", label=<{_OverlappingCpuLoader|current_items : deque<br ALIGN="LEFT"/>device_module<br ALIGN="LEFT"/>device_type : NoneType, str<br ALIGN="LEFT"/>idx : int<br ALIGN="LEFT"/>in_flight_data : int<br ALIGN="LEFT"/>inflight_threshhold : int<br ALIGN="LEFT"/>items : List[Tuple[int, object]]<br ALIGN="LEFT"/>resolve_fun : Callable<br ALIGN="LEFT"/>started : bool<br ALIGN="LEFT"/>stream<br ALIGN="LEFT"/>|add(size: int, obj: object): None<br ALIGN="LEFT"/>start_loading(): None<br ALIGN="LEFT"/>values(): Iterator[Tuple[torch.Tensor, object]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._POERules" [color="black", fontcolor="black", label=<{_POERules|find_operator_overloads_in_onnx_registry<br ALIGN="LEFT"/>find_opschema_matched_symbolic_function<br ALIGN="LEFT"/>fx_graph_to_onnx<br ALIGN="LEFT"/>fx_node_insert_type_promotion<br ALIGN="LEFT"/>fx_node_to_onnx<br ALIGN="LEFT"/>fx_pass<br ALIGN="LEFT"/>missing_custom_symbolic_function<br ALIGN="LEFT"/>missing_standard_symbolic_function<br ALIGN="LEFT"/>no_symbolic_function_for_call_function<br ALIGN="LEFT"/>node_missing_onnx_shape_inference<br ALIGN="LEFT"/>op_level_debugging<br ALIGN="LEFT"/>operator_supported_in_newer_opset_version<br ALIGN="LEFT"/>unsupported_fx_node_analysis<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_importer._PackageNode" [color="black", fontcolor="black", label=<{_PackageNode|children : Dict[str, _PathNode]<br ALIGN="LEFT"/>source_file : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_importer._PackageResourceReader" [color="black", fontcolor="black", label=<{_PackageResourceReader|fullname<br ALIGN="LEFT"/>importer<br ALIGN="LEFT"/>|contents()<br ALIGN="LEFT"/>is_resource(name)<br ALIGN="LEFT"/>open_resource(resource)<br ALIGN="LEFT"/>resource_path(resource)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._trace_utils._ParamUsageInfo" [color="black", fontcolor="black", label=<{_ParamUsageInfo|module<br ALIGN="LEFT"/>named_params : List[Tuple[str, nn.Parameter]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.parameter._ParameterMeta" [color="black", fontcolor="black", label=<{_ParameterMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph._ParsedStackTrace" [color="black", fontcolor="black", label=<{_ParsedStackTrace|code : str<br ALIGN="LEFT"/>file : str<br ALIGN="LEFT"/>lineno : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|get_summary_str()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.observer._PartialWrapper" [color="black", fontcolor="black", label=<{_PartialWrapper|callable_args : dict<br ALIGN="LEFT"/>p<br ALIGN="LEFT"/>|with_args()<br ALIGN="LEFT"/>with_callable_args()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher._PassDictsType" [color="black", fontcolor="black", label=<{_PassDictsType|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx._symbolic_trace._PatchedFn" [color="black", fontcolor="black", label=<{_PatchedFn|fn_name : str<br ALIGN="LEFT"/>frame_dict : Any<br ALIGN="LEFT"/>new_fn : Any<br ALIGN="LEFT"/>orig_fn : Any<br ALIGN="LEFT"/>|<I>patch</I>()<br ALIGN="LEFT"/><I>revert</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace._PatchedFnDel" [color="black", fontcolor="black", label=<{_PatchedFnDel|<br ALIGN="LEFT"/>|patch()<br ALIGN="LEFT"/>revert()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace._PatchedFnSetAttr" [color="black", fontcolor="black", label=<{_PatchedFnSetAttr|<br ALIGN="LEFT"/>|patch()<br ALIGN="LEFT"/>revert()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace._PatchedFnSetItem" [color="black", fontcolor="black", label=<{_PatchedFnSetItem|<br ALIGN="LEFT"/>|patch()<br ALIGN="LEFT"/>revert()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx._symbolic_trace._Patcher" [color="black", fontcolor="black", label=<{_Patcher|patches_made : List[_PatchedFn]<br ALIGN="LEFT"/>visited : Set[int]<br ALIGN="LEFT"/>|patch(frame_dict: Dict[str, Any], name: str, new_fn: Callable, deduplicate: bool)<br ALIGN="LEFT"/>patch_method(cls: type, name: str, new_fn: Callable, deduplicate: bool)<br ALIGN="LEFT"/>reapply_all_patches()<br ALIGN="LEFT"/>revert_all_patches()<br ALIGN="LEFT"/>visit_once(thing: Any)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.package_importer._PathNode" [color="black", fontcolor="black", label=<{_PathNode|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.package.package_exporter._PatternInfo" [color="black", fontcolor="black", label=<{_PatternInfo|action<br ALIGN="LEFT"/>allow_empty : bool<br ALIGN="LEFT"/>was_matched : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.utils._PeriodicTimer" [color="black", fontcolor="black", label=<{_PeriodicTimer|name<br ALIGN="LEFT"/>|cancel(): None<br ALIGN="LEFT"/>set_name(name: str): None<br ALIGN="LEFT"/>start(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._PhantomRoot" [color="black", fontcolor="black", label=<{_PhantomRoot|constraint_range : str<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>val : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules._PipelineSchedule" [color="black", fontcolor="black", label=<{_PipelineSchedule|<br ALIGN="LEFT"/>|<I>step</I>()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules._PipelineScheduleRuntime" [color="black", fontcolor="black", label=<{_PipelineScheduleRuntime|pipeline_order_with_comms : Dict[int, List[_Action]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.stage._PipelineStage" [color="black", fontcolor="black", label=<{_PipelineStage|act_send_info : dict<br ALIGN="LEFT"/>name<br ALIGN="LEFT"/>node<br ALIGN="LEFT"/>pipe_info<br ALIGN="LEFT"/>submod_to_stage_index : Dict[str, int]<br ALIGN="LEFT"/>|find_dst_rank(user: fx.Node): Optional[int]<br ALIGN="LEFT"/>get_stage_index_of_submod(submod_name: str)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.stage._PipelineStageBase" [color="black", fontcolor="black", label=<{_PipelineStageBase|act_send_info : Dict[int, List]<br ALIGN="LEFT"/>args_recv_info : Dict[int, Tuple[InputInfo, ...]]<br ALIGN="LEFT"/>backward_state : Dict[int, Tuple[Any, ...]]<br ALIGN="LEFT"/>bwd_cache : Dict[int, Tuple[Optional[torch.Tensor], ...]]<br ALIGN="LEFT"/>chunks : Optional[int]<br ALIGN="LEFT"/>device<br ALIGN="LEFT"/>dw_builder : Optional[Callable[[], Callable[..., None]]]<br ALIGN="LEFT"/>dw_runner : Dict[int, Callable[..., None]]<br ALIGN="LEFT"/>fwd_cache : Dict[int, Tuple[Any, List[torch.Tensor]]]<br ALIGN="LEFT"/>grad_recv_info : Dict<br ALIGN="LEFT"/>grad_send_info : Optional[List], list<br ALIGN="LEFT"/>group : Optional[dist.ProcessGroup]<br ALIGN="LEFT"/>group_rank : int<br ALIGN="LEFT"/>group_size : int<br ALIGN="LEFT"/>has_backward<br ALIGN="LEFT"/>is_first<br ALIGN="LEFT"/>is_last<br ALIGN="LEFT"/>log_prefix : str<br ALIGN="LEFT"/>num_stages : int<br ALIGN="LEFT"/>output_chunks : List[Any]<br ALIGN="LEFT"/>stage_index : int<br ALIGN="LEFT"/>stage_index_to_group_rank : Dict[int, int]<br ALIGN="LEFT"/>submod<br ALIGN="LEFT"/>|backward_maybe_with_nosync(backward_type, bwd_kwargs: Dict, last_backward): Tuple[Tuple[Optional[torch.Tensor], ...], Optional[List[Dict[str, Any]]]]<br ALIGN="LEFT"/>backward_one_chunk(bwd_chunk_id: int, loss, full_backward: bool, last_backward)<br ALIGN="LEFT"/>backward_weight_one_chunk(bwd_chunk_id: int, last_backward)<br ALIGN="LEFT"/>clear_runtime_states(): None<br ALIGN="LEFT"/>forward_maybe_with_nosync()<br ALIGN="LEFT"/>forward_one_chunk(fwd_chunk_id: int, args: Tuple[Any, ...], kwargs: Optional[Dict[str, Any]])<br ALIGN="LEFT"/>get_bwd_recv_ops(bwd_chunk_id: int): List[dist.P2POp]<br ALIGN="LEFT"/>get_bwd_send_ops(bwd_chunk_id: int): List[dist.P2POp]<br ALIGN="LEFT"/>get_fwd_recv_ops(fwd_chunk_id: int): List[dist.P2POp]<br ALIGN="LEFT"/>get_fwd_send_ops(fwd_chunk_id: int): List[dist.P2POp]<br ALIGN="LEFT"/>get_local_bwd_output(mb_index)<br ALIGN="LEFT"/>get_outputs_meta(): Tuple[torch.Tensor, ...]<br ALIGN="LEFT"/>set_local_bwd_input(next_stage_bwd_outputs: Tuple[Optional[torch.Tensor], ...], mb_index: int): None<br ALIGN="LEFT"/>set_local_fwd_input(prev_stage_outputs: Any, mb_index: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp.wrap._Policy" [color="black", fontcolor="black", label=<{_Policy|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._optim_utils._PosDimTensorInfo" [color="black", fontcolor="black", label=<{_PosDimTensorInfo|dtype<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._PositiveDefinite" [color="black", fontcolor="black", label=<{_PositiveDefinite|<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._PositiveSemidefinite" [color="black", fontcolor="black", label=<{_PositiveSemidefinite|<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._runtime_utils._PrefetchMode" [color="black", fontcolor="black", label=<{_PrefetchMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._ProcessGroupStub" [color="black", fontcolor="black", label=<{_ProcessGroupStub|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler._ProfilerStats" [color="black", fontcolor="black", label=<{_ProfilerStats|function_events_build_tree_call_duration_us : int<br ALIGN="LEFT"/>number_of_events : int<br ALIGN="LEFT"/>parse_kineto_call_duration_us : int<br ALIGN="LEFT"/>profiler_disable_call_duration_us : int<br ALIGN="LEFT"/>profiler_enable_call_duration_us : int<br ALIGN="LEFT"/>profiler_prepare_call_duration_us : int<br ALIGN="LEFT"/>profiling_window_duration_sec : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree._ProtocolFn" [color="black", fontcolor="black", label=<{_ProtocolFn|json_to_treespec : Callable[[DumpableContext], TreeSpec]<br ALIGN="LEFT"/>treespec_to_json : Callable[[TreeSpec], DumpableContext]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._ProxyTensor" [color="black", fontcolor="black", label=<{_ProxyTensor|constant : Optional[Tensor]<br ALIGN="LEFT"/>proxy<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._awaits._PyAwaitMeta" [color="black", fontcolor="black", label=<{_PyAwaitMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.futures._PyFutureMeta" [color="black", fontcolor="black", label=<{_PyFutureMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._ops._PyOpNamespace" [color="black", fontcolor="black", label=<{_PyOpNamespace|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._PySymInputStub" [color="black", fontcolor="black", label=<{_PySymInputStub|value : Union[PySymType, _DeconstructedSymType, _InputBackref]<br ALIGN="LEFT"/>|extract(shape_env: ShapeEnv): PySymType<br ALIGN="LEFT"/>strip_shape_env(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package._package_pickler._PyTorchLegacyPickler" [color="black", fontcolor="black", label=<{_PyTorchLegacyPickler|persistent_id<br ALIGN="LEFT"/>|persistent_id(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph._PyTreeCodeGen" [color="black", fontcolor="black", label=<{_PyTreeCodeGen|pytree_info : _PyTreeInfo<br ALIGN="LEFT"/>|gen_fn_def(free_vars, maybe_return_annotation)<br ALIGN="LEFT"/>generate_output(output_args)<br ALIGN="LEFT"/>process_inputs(): Any<br ALIGN="LEFT"/>process_outputs(out: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.dynamo_graph_extractor._PyTreeExtensionContext" [color="black", fontcolor="black", label=<{_PyTreeExtensionContext|<br ALIGN="LEFT"/>|register_pytree_node(class_type: type, flatten_func: pytree.FlattenFunc, unflatten_func: pytree.UnflattenFunc)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.graph._PyTreeInfo" [color="black", fontcolor="black", label=<{_PyTreeInfo|in_spec<br ALIGN="LEFT"/>orig_args : List[str]<br ALIGN="LEFT"/>out_spec : Optional[pytree.TreeSpec]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes._PythonMsgPrinter" [color="black", fontcolor="black", label=<{_PythonMsgPrinter|src_map : Dict[str, List[str]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.quantized._QEngineProp" [color="black", fontcolor="black", label=<{_QEngineProp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor._random._RNGStateTracker" [color="black", fontcolor="black", label=<{_RNGStateTracker|distribute_region_enabled<br ALIGN="LEFT"/>rng_states<br ALIGN="LEFT"/>|get_seed(name: str): int<br ALIGN="LEFT"/>rng_state_is_sync(name): bool<br ALIGN="LEFT"/>set_seed(name: str, seed: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.utils._ReaderView" [color="black", fontcolor="black", label=<{_ReaderView|base_stream : IOBase<br ALIGN="LEFT"/>len : int<br ALIGN="LEFT"/>offset : int<br ALIGN="LEFT"/>|read(size)<br ALIGN="LEFT"/>readable(): bool<br ALIGN="LEFT"/>readinto(b)<br ALIGN="LEFT"/>seek(__offset: int, __whence: int): int<br ALIGN="LEFT"/>seekable(): bool<br ALIGN="LEFT"/>tell(): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.optimizer._ReaderWithOffset" [color="black", fontcolor="black", label=<{_ReaderWithOffset|fqn_to_offset : Dict[str, Sequence[int]]<br ALIGN="LEFT"/>metadata<br ALIGN="LEFT"/>state_dict : Dict<br ALIGN="LEFT"/>translation : Dict[MetadataIndex, MetadataIndex]<br ALIGN="LEFT"/>|create_local_plan(): LoadPlan<br ALIGN="LEFT"/>lookup_tensor(index: MetadataIndex): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Real" [color="black", fontcolor="black", label=<{_Real|<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.dependencies._RecordLoadStoreInner" [color="black", fontcolor="black", label=<{_RecordLoadStoreInner|<br ALIGN="LEFT"/>|bucketize(values: T, boundaries: Tuple[str, sympy.Expr, sympy.Expr, sympy.Expr], boundary_indices: T, indexing_dtype: torch.dtype, right: bool, sorter: Optional[Tuple[str, sympy.Expr]], sorter_indices: Optional[T]): None<br ALIGN="LEFT"/>canonicalize(index: sympy.Expr): Tuple[sympy.Expr, Tuple[sympy.Symbol, ...], Tuple[sympy.Expr, ...]]<br ALIGN="LEFT"/>drop_unused_symbols(index, var_names, sizes)<br ALIGN="LEFT"/>index_expr(index: sympy.Expr, dtype): str<br ALIGN="LEFT"/>load(name: str, index: sympy.Expr): str<br ALIGN="LEFT"/>load_seed(name: str, index: int)<br ALIGN="LEFT"/>store(name: str, index: sympy.Expr, value: str, mode): str<br ALIGN="LEFT"/>store_reduction(name: str, index, value): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.stage._RecvInfo" [color="black", fontcolor="black", label=<{_RecvInfo|buffer<br ALIGN="LEFT"/>input_name : str<br ALIGN="LEFT"/>source : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.nn.functional._Reduce" [color="black", fontcolor="black", label=<{_Reduce|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, src, op, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.fx_passes.micro_pipeline_tp._ReduceScatterMatch" [color="black", fontcolor="black", label=<{_ReduceScatterMatch|group_name : str<br ALIGN="LEFT"/>input_node<br ALIGN="LEFT"/>match<br ALIGN="LEFT"/>reduce_op : str<br ALIGN="LEFT"/>res_node<br ALIGN="LEFT"/>rs_node<br ALIGN="LEFT"/>scatter_dim : int<br ALIGN="LEFT"/>|erase(): None<br ALIGN="LEFT"/>replace_with(new_node: torch.fx.Node): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._Reduce_Scatter" [color="black", fontcolor="black", label=<{_Reduce_Scatter|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, op, group, tensor)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._RefType" [color="black", fontcolor="black", label=<{_RefType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.padding._ReflectionPadNd" [color="black", fontcolor="black", label=<{_ReflectionPadNd|padding : Sequence[int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._RelaxedConstraint" [color="black", fontcolor="black", label=<{_RelaxedConstraint|serializable_spec<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.nn.api.remote_module._RemoteModule" [color="black", fontcolor="black", label=<{_RemoteModule|device : str<br ALIGN="LEFT"/>generated_methods<br ALIGN="LEFT"/>is_device_map_set<br ALIGN="LEFT"/>is_scriptable : bool<br ALIGN="LEFT"/>module_rref<br ALIGN="LEFT"/>on : NoneType, int<br ALIGN="LEFT"/>|add_module(name: str, module: Optional[Module]): None<br ALIGN="LEFT"/>apply(fn: Callable[[Module], None]): T<br ALIGN="LEFT"/>bfloat16(): T<br ALIGN="LEFT"/>buffers(recurse: bool): Iterator[Tensor]<br ALIGN="LEFT"/>children(): Iterator[Module]<br ALIGN="LEFT"/>cpu(): T<br ALIGN="LEFT"/>cuda(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>double(): T<br ALIGN="LEFT"/>eval(): T<br ALIGN="LEFT"/>extra_repr(): str<br ALIGN="LEFT"/>float(): T<br ALIGN="LEFT"/>get_module_rref(): rpc.RRef[nn.Module]<br ALIGN="LEFT"/>half(): T<br ALIGN="LEFT"/>init_from_module_rref(remote_device: str, module_rref: rpc.RRef[nn.Module], _module_interface_cls: Any)<br ALIGN="LEFT"/>ipu(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>load_state_dict(state_dict: Mapping[str, Any], strict: bool, assign: bool)<br ALIGN="LEFT"/>modules(): Iterator[Module]<br ALIGN="LEFT"/>named_buffers(prefix: str, recurse: bool, remove_duplicate: bool): Iterator[Tuple[str, Tensor]]<br ALIGN="LEFT"/>named_children(): Iterator[Tuple[str, Module]]<br ALIGN="LEFT"/>named_modules(memo: Optional[Set[Module]], prefix: str, remove_duplicate: bool)<br ALIGN="LEFT"/>named_parameters(prefix: str, recurse: bool, remove_duplicate: bool): Iterator[Tuple[str, Parameter]]<br ALIGN="LEFT"/>parameters(recurse: bool): Iterator[Parameter]<br ALIGN="LEFT"/>register_backward_hook(hook: Callable[[Module, _grad_t, _grad_t], Union[None, _grad_t]]): RemovableHandle<br ALIGN="LEFT"/>register_buffer(name: str, tensor: Optional[Tensor], persistent: bool): None<br ALIGN="LEFT"/>register_forward_hook(hook: Union[Callable[[T, Tuple[Any, ...], Any], Optional[Any]], Callable[[T, Tuple[Any, ...], Dict[str, Any], Any], Optional[Any]]], prepend: bool, with_kwargs: bool): RemovableHandle<br ALIGN="LEFT"/>register_forward_pre_hook(hook: Union[Callable[[T, Tuple[Any, ...]], Optional[Any]], Callable[[T, Tuple[Any, ...], Dict[str, Any]], Optional[Tuple[Any, Dict[str, Any]]]]], prepend: bool, with_kwargs: bool): RemovableHandle<br ALIGN="LEFT"/>register_parameter(name: str, param: Optional[Parameter]): None<br ALIGN="LEFT"/>remote_parameters(recurse: bool): List[rpc.RRef[Parameter]]<br ALIGN="LEFT"/>requires_grad_(requires_grad: bool): T<br ALIGN="LEFT"/>share_memory(): T<br ALIGN="LEFT"/>state_dict()<br ALIGN="LEFT"/>to(): T<br ALIGN="LEFT"/>train(mode: bool): T<br ALIGN="LEFT"/>type(dst_type: Union[dtype, str]): T<br ALIGN="LEFT"/>xpu(device: Optional[Union[int, device]]): T<br ALIGN="LEFT"/>zero_grad(set_to_none: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.passes.remove_runtime_assertions._RemoveRuntimeAssertionsPass" [color="black", fontcolor="black", label=<{_RemoveRuntimeAssertionsPass|<br ALIGN="LEFT"/>|call(graph_module): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousCloseOp" [color="black", fontcolor="black", label=<{_RendezvousCloseOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousContext" [color="black", fontcolor="black", label=<{_RendezvousContext|node<br ALIGN="LEFT"/>settings<br ALIGN="LEFT"/>state<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousExitOp" [color="black", fontcolor="black", label=<{_RendezvousExitOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousJoinOp" [color="black", fontcolor="black", label=<{_RendezvousJoinOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousKeepAliveOp" [color="black", fontcolor="black", label=<{_RendezvousKeepAliveOp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousOpExecutor" [color="black", fontcolor="black", label=<{_RendezvousOpExecutor|<br ALIGN="LEFT"/>|<I>run</I>(state_handler: Callable[[_RendezvousContext, float], _Action], deadline: float, update_deadline: Optional[Callable[[timedelta], float]]): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousState" [color="black", fontcolor="black", label=<{_RendezvousState|closed : bool<br ALIGN="LEFT"/>complete : bool<br ALIGN="LEFT"/>deadline : Optional[datetime]<br ALIGN="LEFT"/>last_heartbeats : Dict[_NodeDesc, datetime]<br ALIGN="LEFT"/>participants : Dict[_NodeDesc, int]<br ALIGN="LEFT"/>redundancy_list : Set[_NodeDesc]<br ALIGN="LEFT"/>round : int<br ALIGN="LEFT"/>wait_list : Set[_NodeDesc]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousStateHolder" [color="black", fontcolor="black", label=<{_RendezvousStateHolder|state<br ALIGN="LEFT"/>|<I>mark_dirty</I>(): None<br ALIGN="LEFT"/><I>sync</I>(): Optional[bool]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.stateless._ReparametrizeModule" [color="black", fontcolor="black", label=<{_ReparametrizeModule|accessor<br ALIGN="LEFT"/>orig_parameters_and_buffers : dict<br ALIGN="LEFT"/>parameters_and_buffers : Dict[str, Tensor]<br ALIGN="LEFT"/>stack_weights : bool<br ALIGN="LEFT"/>untied_parameters_and_buffers<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.pipelining.microbatch._Replicate" [color="black", fontcolor="black", label=<{_Replicate|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._composable.replicate._ReplicateState" [color="black", fontcolor="black", label=<{_ReplicateState|has_initialized : bool<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>|forward_post_hook(module: nn.Module, input: Tuple[torch.Tensor], output: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>forward_pre_hook(module: nn.Module, args: Tuple[Any, ...], kwargs: Dict[str, Any]): Any<br ALIGN="LEFT"/>init(module: nn.Module, ignored_modules: Set[nn.Module]): None<br ALIGN="LEFT"/>lazy_init(): None<br ALIGN="LEFT"/>record_init_args(): None<br ALIGN="LEFT"/>register_comm_hook(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.padding._ReplicationPadNd" [color="black", fontcolor="black", label=<{_ReplicationPadNd|padding : Sequence[int]<br ALIGN="LEFT"/>|extra_repr(): str<br ALIGN="LEFT"/>forward(input: Tensor): Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.optim.optimizer._RequiredParameter" [color="black", fontcolor="black", label=<{_RequiredParameter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data._utils.worker._ResumeIteration" [color="black", fontcolor="black", label=<{_ResumeIteration|seed : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e.representation.rewrite._RewriteInfo" [color="black", fontcolor="black", label=<{_RewriteInfo|example_inputs : Tuple[Any, ...]<br ALIGN="LEFT"/>pattern : Callable<br ALIGN="LEFT"/>pattern_post_trans : Optional[Callable[[GraphModule], GraphModule]]<br ALIGN="LEFT"/>replacement : Callable<br ALIGN="LEFT"/>replacement_post_trans : Optional[Callable[[GraphModule], GraphModule]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._RingRotater" [color="black", fontcolor="black", label=<{_RingRotater|<br ALIGN="LEFT"/>|<I>exchange_buffers</I>(curr_buffer: torch.Tensor): None<br ALIGN="LEFT"/><I>next_buffer</I>(): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.elastic.agent.server.api._RoleInstanceInfo" [color="black", fontcolor="black", label=<{_RoleInstanceInfo|local_world_size : int<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>role : str<br ALIGN="LEFT"/>|compare(obj1, obj2): int<br ALIGN="LEFT"/>deserialize(data: bytes)<br ALIGN="LEFT"/>find_role_boundaries(roles_infos: List, role: str): Tuple[int, int]<br ALIGN="LEFT"/>serialize(): bytes<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.stage._RootArgPlaceholder" [color="black", fontcolor="black", label=<{_RootArgPlaceholder|meta<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._RotateMethod" [color="black", fontcolor="black", label=<{_RotateMethod|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._RoundRobinLoadBalancer" [color="black", fontcolor="black", label=<{_RoundRobinLoadBalancer|ROUND_ROBIN_CYCLE : int<br ALIGN="LEFT"/>|shard(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/>unshard(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.compare._Row" [color="black", fontcolor="black", label=<{_Row|<br ALIGN="LEFT"/>|as_column_strings()<br ALIGN="LEFT"/>color_segment(segment, value, best_value)<br ALIGN="LEFT"/>finalize_column_strings(column_strings, col_widths)<br ALIGN="LEFT"/>register_columns(columns: Tuple[_Column, ...])<br ALIGN="LEFT"/>row_separator(overall_width)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator._SACMetadata" [color="black", fontcolor="black", label=<{_SACMetadata|curr_idx : int<br ALIGN="LEFT"/>func : Any<br ALIGN="LEFT"/>inplace_info : Tuple[int, ...]<br ALIGN="LEFT"/>is_rand_op : bool<br ALIGN="LEFT"/>is_view_like : bool<br ALIGN="LEFT"/>memory_used : float<br ALIGN="LEFT"/>output_ids : Tuple[int, ...]<br ALIGN="LEFT"/>time_taken : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.sac_estimator._SACModMetadata" [color="black", fontcolor="black", label=<{_SACModMetadata|force_store_random : bool<br ALIGN="LEFT"/>sac_metadata : List[_SACMetadata]<br ALIGN="LEFT"/>start_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._SDPAMerger" [color="black", fontcolor="black", label=<{_SDPAMerger|<br ALIGN="LEFT"/>|results(): Tuple[torch.Tensor, torch.Tensor]<br ALIGN="LEFT"/>step(out: torch.Tensor, lse: torch.Tensor, partial: bool): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker._SavedCollectives" [color="black", fontcolor="black", label=<{_SavedCollectives|all_gather_into_tensor : Callable<br ALIGN="LEFT"/>all_reduce : Callable<br ALIGN="LEFT"/>barrier : Callable<br ALIGN="LEFT"/>reduce_scatter_tensor : Callable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.fsdp2_mem_tracker._SavedFSDPMethods" [color="black", fontcolor="black", label=<{_SavedFSDPMethods|post_backward : Callable<br ALIGN="LEFT"/>pre_backward : Callable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._symmetric_memory._ScaleMode" [color="black", fontcolor="black", label=<{_ScaleMode|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.micro_pipeline_tp._ScaledMatmul" [color="black", fontcolor="black", label=<{_ScaledMatmul|A_node<br ALIGN="LEFT"/>A_scale_node<br ALIGN="LEFT"/>B_scale_node<br ALIGN="LEFT"/>arg_ancestor_nodes<br ALIGN="LEFT"/>bias_node : Optional[torch.fx.Node]<br ALIGN="LEFT"/>out_dtype : Optional[torch.dtype]<br ALIGN="LEFT"/>result_scale_node : Optional[torch.fx.Node]<br ALIGN="LEFT"/>use_fast_accum : bool<br ALIGN="LEFT"/>|from_match(match: List[torch.fx.Node]): '_ScaledMatmul'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.nn.functional._Scatter" [color="black", fontcolor="black", label=<{_Scatter|<br ALIGN="LEFT"/>|backward(ctx, grad_output)<br ALIGN="LEFT"/>forward(ctx, src, group)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.pipelining.schedules._ScheduleForwardOnly" [color="black", fontcolor="black", label=<{_ScheduleForwardOnly|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.lr_scheduler._SchedulePhase" [color="black", fontcolor="black", label=<{_SchedulePhase|end_lr : str<br ALIGN="LEFT"/>end_momentum : str<br ALIGN="LEFT"/>end_step : float<br ALIGN="LEFT"/>start_lr : str<br ALIGN="LEFT"/>start_momentum : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.optim.optimizer._ScriptLocalOptimizer" [color="black", fontcolor="black", label=<{_ScriptLocalOptimizer|compile_lock : lock<br ALIGN="LEFT"/>optim<br ALIGN="LEFT"/>|step(autograd_ctx_id: int)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.optimizer._ScriptLocalOptimizerInterface" [color="black", fontcolor="black", label=<{_ScriptLocalOptimizerInterface|<br ALIGN="LEFT"/>|<I>step</I>(autograd_ctx_id: int): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script._ScriptProfile" [color="black", fontcolor="black", label=<{_ScriptProfile|profile<br ALIGN="LEFT"/>|disable()<br ALIGN="LEFT"/>dump()<br ALIGN="LEFT"/>dump_string(): str<br ALIGN="LEFT"/>enable()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script._ScriptProfileColumn" [color="black", fontcolor="black", label=<{_ScriptProfileColumn|alignment : int<br ALIGN="LEFT"/>header : str<br ALIGN="LEFT"/>offset : int<br ALIGN="LEFT"/>rows : Dict[int, Any]<br ALIGN="LEFT"/>|add_row(lineno: int, value: Any)<br ALIGN="LEFT"/>materialize()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.jit._script._ScriptProfileTable" [color="black", fontcolor="black", label=<{_ScriptProfileTable|cols : List[_ScriptProfileColumn]<br ALIGN="LEFT"/>source_range : List[int]<br ALIGN="LEFT"/>|dump_string()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._attention._SequentialSharder" [color="black", fontcolor="black", label=<{_SequentialSharder|<br ALIGN="LEFT"/>|shard(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/>unshard(buffer: torch.Tensor, mesh: DeviceMesh, seq_dim: int): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._SerialCpuLoader" [color="black", fontcolor="black", label=<{_SerialCpuLoader|items : List[Tuple[int, object]]<br ALIGN="LEFT"/>resolve_fun : Callable<br ALIGN="LEFT"/>|add(size: int, obj: object): None<br ALIGN="LEFT"/><I>start_loading</I>(): None<br ALIGN="LEFT"/>values(): Iterator[Tuple[torch.Tensor, object]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.serialization._SerializationLocal" [color="black", fontcolor="black", label=<{_SerializationLocal|map_location : NoneType, Optional[MAP_LOCATION]<br ALIGN="LEFT"/>materialize_fake_tensors : bool<br ALIGN="LEFT"/>skip_data : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree._SerializeNodeDef" [color="black", fontcolor="black", label=<{_SerializeNodeDef|from_dumpable_context : Optional[FromDumpableContextFn]<br ALIGN="LEFT"/>serialized_type_name : str<br ALIGN="LEFT"/>to_dumpable_context : Optional[ToDumpableContextFn]<br ALIGN="LEFT"/>typ : Type[Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.serialize._SerializedProgram" [color="black", fontcolor="black", label=<{_SerializedProgram|constants : bytes<br ALIGN="LEFT"/>example_inputs : bytes<br ALIGN="LEFT"/>exported_program<br ALIGN="LEFT"/>state_dict : bytes<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._refs.fft._ShapeAndDims" [color="black", fontcolor="black", label=<{_ShapeAndDims|dims : Tuple[int, ...]<br ALIGN="LEFT"/>shape : Tuple[int, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.symbolic_shapes._ShapeGuardPrinter" [color="black", fontcolor="black", label=<{_ShapeGuardPrinter|source_ref : Callable[[Source], str]<br ALIGN="LEFT"/>symbol_to_source : Mapping[sympy.Symbol, List[Source]]<br ALIGN="LEFT"/>var_to_sources : Mapping[sympy.Symbol, List[Source]]<br ALIGN="LEFT"/>|<I>print_source</I>(source: Source): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._flat_param._ShardParamInfo" [color="black", fontcolor="black", label=<{_ShardParamInfo|in_shard : bool<br ALIGN="LEFT"/>intra_param_end_idx : Optional[int]<br ALIGN="LEFT"/>intra_param_start_idx : Optional[int]<br ALIGN="LEFT"/>numel_in_shard : Optional[int]<br ALIGN="LEFT"/>offset_in_shard : Optional[int]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes.iter.sharding._ShardingIterDataPipe" [color="black", fontcolor="black", label=<{_ShardingIterDataPipe|<br ALIGN="LEFT"/>|<I>apply_sharding</I>(num_of_instances: int, instance_id: int, sharding_group: SHARDING_PRIORITIES)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Simplex" [color="black", fontcolor="black", label=<{_Simplex|event_dim : int<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.function._SingleLevelFunction" [color="black", fontcolor="black", label=<{_SingleLevelFunction|vjp<br ALIGN="LEFT"/>|<I>backward</I>(ctx: Any): Any<br ALIGN="LEFT"/><I>forward</I>(): Any<br ALIGN="LEFT"/><I>jvp</I>(ctx: Any): Any<br ALIGN="LEFT"/><I>setup_context</I>(ctx: Any, inputs: Tuple[Any, ...], output: Any): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.dataloader._SingleProcessDataLoaderIter" [color="black", fontcolor="black", label=<{_SingleProcessDataLoaderIter|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes._hook_iterator._SnapshotState" [color="black", fontcolor="black", label=<{_SnapshotState|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.utils.parametrizations._SpectralNorm" [color="black", fontcolor="black", label=<{_SpectralNorm|dim : int<br ALIGN="LEFT"/>eps : float<br ALIGN="LEFT"/>n_power_iterations : int<br ALIGN="LEFT"/>|forward(weight: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>right_inverse(value: torch.Tensor): torch.Tensor<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base._SplitterBase" [color="black", fontcolor="black", label=<{_SplitterBase|PCIe_BW : int<br ALIGN="LEFT"/>acc_nodes : set<br ALIGN="LEFT"/>deps : defaultdict<br ALIGN="LEFT"/>fusions : dict<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>non_acc_submodule_name : str<br ALIGN="LEFT"/>operator_support<br ALIGN="LEFT"/>sample_input : Sequence[Any]<br ALIGN="LEFT"/>settings<br ALIGN="LEFT"/>tags : List[str], list<br ALIGN="LEFT"/>|extend_acc_subgraph(tag: str)<br ALIGN="LEFT"/>find_deps(): Dict[torch.fx.Node, NodeSet]<br ALIGN="LEFT"/>find_parent_nodes_of_subgraph(tag: str): NodeSet<br ALIGN="LEFT"/>find_reverse_deps(tag_id: Optional[int]): Dict[torch.fx.Node, NodeSet]<br ALIGN="LEFT"/>generate_split_results(): SplitResult<br ALIGN="LEFT"/>get_node_submodule_map(): Dict[str, str]<br ALIGN="LEFT"/>node_support_preview(dump_graph: bool)<br ALIGN="LEFT"/>put_nodes_into_subgraphs(): List[Subgraph]<br ALIGN="LEFT"/>remove_small_acc_subgraphs(subgraphs: List[Subgraph]): List[Subgraph]<br ALIGN="LEFT"/>split(remove_tag: bool): torch.fx.GraphModule<br ALIGN="LEFT"/>split_preview(dump_graph: bool)<br ALIGN="LEFT"/>starter_nodes(): Tuple[NodeSet, NodeSet]<br ALIGN="LEFT"/>tag(subgraphs: List[Subgraph])<br ALIGN="LEFT"/>update_deps_for_fusions()<br ALIGN="LEFT"/>update_reverse_deps_for_fusions(deps: Dict[torch.fx.Node, NodeSet])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.splitter_base._SplitterSettingBase" [color="black", fontcolor="black", label=<{_SplitterSettingBase|allow_non_tensor : bool<br ALIGN="LEFT"/>max_acc_splits : int<br ALIGN="LEFT"/>min_acc_module_size : int<br ALIGN="LEFT"/>skip_fusion : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.constraints._Square" [color="black", fontcolor="black", label=<{_Square|event_dim : int<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Stack" [color="black", fontcolor="black", label=<{_Stack|cseq : list<br ALIGN="LEFT"/>dim : int<br ALIGN="LEFT"/>event_dim<br ALIGN="LEFT"/>is_discrete<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._composable_state._State" [color="black", fontcolor="black", label=<{_State|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._State" [color="black", fontcolor="black", label=<{_State|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.state_dict._StateDictInfo" [color="black", fontcolor="black", label=<{_StateDictInfo|fqn_param_mapping : Dict[Union[str, torch.Tensor], Union[FQNS_T, torch.Tensor]]<br ALIGN="LEFT"/>fsdp_context : Callable<br ALIGN="LEFT"/>fsdp_modules : List[nn.Module]<br ALIGN="LEFT"/>handle_model : bool<br ALIGN="LEFT"/>handle_optim : bool<br ALIGN="LEFT"/>shared_params_mapping : Dict[Union[str, torch.Tensor], Union[FQNS_T, torch.Tensor]]<br ALIGN="LEFT"/>submodule_prefixes : Set[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._unlift._StatefulGraphModule" [color="black", fontcolor="black", label=<{_StatefulGraphModule|range_constraints : list<br ALIGN="LEFT"/>validate_inputs : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export._unlift._StatefulGraphModuleFactory" [color="black", fontcolor="black", label=<{_StatefulGraphModuleFactory|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.dynamic_shapes._StaticDim" [color="black", fontcolor="black", label=<{_StaticDim|max<br ALIGN="LEFT"/>min<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._StopRecomputationError" [color="black", fontcolor="red", label=<{_StopRecomputationError|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.profiler._memory_profiler._Storage" [color="black", fontcolor="black", label=<{_Storage|allocation_id : int<br ALIGN="LEFT"/>ptr : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.storage._StorageBase" [color="black", fontcolor="black", label=<{_StorageBase|device<br ALIGN="LEFT"/>is_cuda<br ALIGN="LEFT"/>is_hpu<br ALIGN="LEFT"/>is_sparse : bool<br ALIGN="LEFT"/>is_sparse_csr : bool<br ALIGN="LEFT"/>|bfloat16()<br ALIGN="LEFT"/>bool()<br ALIGN="LEFT"/>byte()<br ALIGN="LEFT"/>byteswap(dtype)<br ALIGN="LEFT"/>char()<br ALIGN="LEFT"/>clone()<br ALIGN="LEFT"/>complex_double()<br ALIGN="LEFT"/>complex_float()<br ALIGN="LEFT"/><I>copy_</I>(source: T, non_blocking: _Optional[_bool]): T<br ALIGN="LEFT"/>cpu()<br ALIGN="LEFT"/>cuda(device, non_blocking): Union[_StorageBase, TypedStorage]<br ALIGN="LEFT"/><I>data_ptr</I>(): _int<br ALIGN="LEFT"/>double()<br ALIGN="LEFT"/><I>element_size</I>(): _int<br ALIGN="LEFT"/>float()<br ALIGN="LEFT"/>float8_e4m3fn()<br ALIGN="LEFT"/>float8_e4m3fnuz()<br ALIGN="LEFT"/>float8_e5m2()<br ALIGN="LEFT"/>float8_e5m2fnuz()<br ALIGN="LEFT"/><I>from_buffer</I>(): T<br ALIGN="LEFT"/><I>from_file</I>(filename, shared, nbytes): Union[_StorageBase, TypedStorage]<br ALIGN="LEFT"/>get_device(): _int<br ALIGN="LEFT"/>half()<br ALIGN="LEFT"/>hpu(device, non_blocking): Union[_StorageBase, TypedStorage]<br ALIGN="LEFT"/>int()<br ALIGN="LEFT"/>is_pinned(device: Union[str, torch.device])<br ALIGN="LEFT"/><I>is_shared</I>(): _bool<br ALIGN="LEFT"/>long()<br ALIGN="LEFT"/>mps()<br ALIGN="LEFT"/><I>nbytes</I>(): _int<br ALIGN="LEFT"/><I>new</I>(): Union[_StorageBase, TypedStorage]<br ALIGN="LEFT"/>pin_memory(device: Union[str, torch.device])<br ALIGN="LEFT"/><I>resizable</I>(): _bool<br ALIGN="LEFT"/><I>resize_</I>(size: _int)<br ALIGN="LEFT"/>share_memory_()<br ALIGN="LEFT"/>short()<br ALIGN="LEFT"/>size(): _int<br ALIGN="LEFT"/>to()<br ALIGN="LEFT"/>tolist()<br ALIGN="LEFT"/>type(dtype: _Optional[str], non_blocking: _bool): Union[_StorageBase, TypedStorage]<br ALIGN="LEFT"/>untyped()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._StorageInfo" [color="black", fontcolor="black", label=<{_StorageInfo|length : int<br ALIGN="LEFT"/>offset : int<br ALIGN="LEFT"/>relative_path : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._StoragePrefix" [color="black", fontcolor="black", label=<{_StoragePrefix|prefix : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._streambase._StreamBase" [color="black", fontcolor="black", label=<{_StreamBase|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.tensor.placement_types._StridedShard" [color="black", fontcolor="black", label=<{_StridedShard|split_factor : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.export.unflatten._SubmoduleEntry" [color="black", fontcolor="black", label=<{_SubmoduleEntry|call_idx : int<br ALIGN="LEFT"/>fqn : str<br ALIGN="LEFT"/>module<br ALIGN="LEFT"/>parent_call_module<br ALIGN="LEFT"/>parent_fqn : str<br ALIGN="LEFT"/>parent_module<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.compile_worker.subproc_pool._SubprocExceptionInfo" [color="black", fontcolor="black", label=<{_SubprocExceptionInfo|details : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.quantized._SupportedQEnginesProp" [color="black", fontcolor="black", label=<{_SupportedQEnginesProp|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.dedupe_symint_uses._SymExprHash" [color="black", fontcolor="black", label=<{_SymExprHash|sym_obj : Union[SymInt, SymFloat, SymBool]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.fx_passes.dedupe_symint_uses._SymHashingDict" [color="black", fontcolor="black", label=<{_SymHashingDict|sym_hash_dict : dict<br ALIGN="LEFT"/>|get(key, default)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._subclasses._fake_tensor_utils._SymIntOutputStub" [color="black", fontcolor="black", label=<{_SymIntOutputStub|value : Union[int, _DeconstructedSymNode]<br ALIGN="LEFT"/>|extract(key: _DispatchCacheKey, shape_env: ShapeEnv): SymInt<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.experimental.proxy_tensor._SymNodeDict" [color="black", fontcolor="black", label=<{_SymNodeDict|sym_node_dict : Dict[PySymType, _PySymProxyType]<br ALIGN="LEFT"/>|get(key: PySymType, default: Optional[_PySymProxyType]): _PySymProxyType<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.registration._SymbolicFunctionGroup" [color="black", fontcolor="black", label=<{_SymbolicFunctionGroup|<br ALIGN="LEFT"/>|add(func: Callable, opset: OpsetVersion): None<br ALIGN="LEFT"/>add_custom(func: Callable, opset: OpsetVersion): None<br ALIGN="LEFT"/>get(opset: OpsetVersion): Optional[Callable]<br ALIGN="LEFT"/>get_min_supported(): OpsetVersion<br ALIGN="LEFT"/>remove_custom(opset: OpsetVersion): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.constraints._Symmetric" [color="black", fontcolor="black", label=<{_Symmetric|<br ALIGN="LEFT"/>|check(value)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.package.importer._SysImporter" [color="black", fontcolor="black", label=<{_SysImporter|<br ALIGN="LEFT"/>|import_module(module_name: str)<br ALIGN="LEFT"/>whichmodule(obj: Any, name: str): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher._TargetArgsExpr" [color="black", fontcolor="black", label=<{_TargetArgsExpr|args : tuple<br ALIGN="LEFT"/>flat_args_kwargs : tuple<br ALIGN="LEFT"/>flatten<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|find_anchor_nodes(ctx: MatchContext, searched: OrderedSet[torch.fx.Node]): Generator[Optional[torch.fx.Node], None, None]<br ALIGN="LEFT"/>pattern_eq(other: Any): bool<br ALIGN="LEFT"/>pretty_print(pp: PatternPrettyPrinter): str<br ALIGN="LEFT"/>pytree_flatten(args: Sequence[Any], kwargs: Mapping[Any, Any]): Tuple[Sequence[Any], Union[_SimpleSpec, pytree.TreeSpec]]<br ALIGN="LEFT"/>simple_flatten(args: Sequence[Any], kwargs: Mapping[Any, Any]): Tuple[Sequence[Any], Union[_SimpleSpec, pytree.TreeSpec]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher._TargetExpr" [color="black", fontcolor="black", label=<{_TargetExpr|fns : List[FnsType]<br ALIGN="LEFT"/>fns_set : OrderedSet[FnsType]<br ALIGN="LEFT"/>op<br ALIGN="LEFT"/>users : Union[Multiple, int]<br ALIGN="LEFT"/>|<I>find_anchor_nodes</I>(ctx: MatchContext, searched: OrderedSet[torch.fx.Node]): Generator[Optional[torch.fx.Node], None, None]<br ALIGN="LEFT"/>fns_repr(): str<br ALIGN="LEFT"/>has_multiple_users(): bool<br ALIGN="LEFT"/>pattern_eq(other: Any): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.pattern_matcher._TargetExprVarArgs" [color="black", fontcolor="black", label=<{_TargetExprVarArgs|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._jit_internal._TensorExtractor" [color="black", fontcolor="black", label=<{_TensorExtractor|tensors<br ALIGN="LEFT"/>|persistent_id(obj)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._state_dict_utils._TensorInfo" [color="black", fontcolor="black", label=<{_TensorInfo|dtype<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.checkpoint.filesystem._TensorLoader" [color="black", fontcolor="black", label=<{_TensorLoader|<br ALIGN="LEFT"/>|<I>add</I>(size: int, obj: object): None<br ALIGN="LEFT"/><I>start_loading</I>(): None<br ALIGN="LEFT"/><I>values</I>(): Iterator[Tuple[torch.Tensor, object]]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor.experimental._tp_transform._TensorParallelTransformPass" [color="black", fontcolor="black", label=<{_TensorParallelTransformPass|graph_signature<br ALIGN="LEFT"/>mesh<br ALIGN="LEFT"/>parallel_strategies : Dict[str, ParallelStyle]<br ALIGN="LEFT"/>rank : int<br ALIGN="LEFT"/>state_dict : Dict[str, torch.Tensor]<br ALIGN="LEFT"/>|call(graph_module): PassResult<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.cuda._sanitizer._TensorsAccessed" [color="black", fontcolor="black", label=<{_TensorsAccessed|accesses : Dict[DataPtr, TensorInfo]<br ALIGN="LEFT"/>|add_read(data_ptr: DataPtr, access: Access): None<br ALIGN="LEFT"/>create_tensor(data_ptr: DataPtr, stack_trace: Optional[traceback.StackSummary]): None<br ALIGN="LEFT"/>delete_tensor(data_ptr: DataPtr): None<br ALIGN="LEFT"/>ensure_tensor_does_not_exist(data_ptr: DataPtr): None<br ALIGN="LEFT"/>ensure_tensor_exists(data_ptr: DataPtr): None<br ALIGN="LEFT"/>get_allocation_stack_trace(data_ptr: DataPtr): Optional[traceback.StackSummary]<br ALIGN="LEFT"/>get_reads(data_ptr: DataPtr): List[Access]<br ALIGN="LEFT"/>get_write(data_ptr: DataPtr): Optional[Access]<br ALIGN="LEFT"/>set_write(data_ptr: DataPtr, access: Access): None<br ALIGN="LEFT"/>were_there_reads_since_last_write(data_ptr: DataPtr): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils._config_module.ContextDecorator.__call__._TestCase" [color="black", fontcolor="black", label=<{_TestCase|<br ALIGN="LEFT"/>|setUpClass(): None<br ALIGN="LEFT"/>tearDownClass(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils._TestParametrizer" [color="black", fontcolor="black", label=<{_TestParametrizer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool1d" [color="black", fontcolor="black", label=<{_TestParamsMaxPool1d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool2d" [color="black", fontcolor="black", label=<{_TestParamsMaxPool2d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool3d" [color="black", fontcolor="black", label=<{_TestParamsMaxPool3d|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPoolBase" [color="black", fontcolor="black", label=<{_TestParamsMaxPoolBase|kwargs : dict<br ALIGN="LEFT"/>shapes : list<br ALIGN="LEFT"/>|gen_input_params()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._api._ToTorchTensor" [color="black", fontcolor="black", label=<{_ToTorchTensor|<br ALIGN="LEFT"/>|backward(ctx, grad_output: torch.Tensor)<br ALIGN="LEFT"/>forward(ctx, input: 'DTensor', grad_placements: Optional[Sequence[Placement]])<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._TorchCompileInductorWrapper" [color="black", fontcolor="black", label=<{_TorchCompileInductorWrapper|compiler_name : str<br ALIGN="LEFT"/>config : _Dict[str, _Any]<br ALIGN="LEFT"/>dynamic<br ALIGN="LEFT"/>|apply_mode(mode: _Optional[str])<br ALIGN="LEFT"/>apply_options(options: _Optional[_Dict[str, _Any]])<br ALIGN="LEFT"/>get_compiler_config()<br ALIGN="LEFT"/>reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._TorchCompileWrapper" [color="black", fontcolor="black", label=<{_TorchCompileWrapper|compiler_fn<br ALIGN="LEFT"/>compiler_name : str<br ALIGN="LEFT"/>dynamic<br ALIGN="LEFT"/>kwargs : dict<br ALIGN="LEFT"/>|reset()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.eval_frame._TorchDynamoContext" [color="black", fontcolor="black", label=<{_TorchDynamoContext|callback : Union<br ALIGN="LEFT"/>cleanup_fns : List[Callable[[], Any]]<br ALIGN="LEFT"/>compiler_config : NoneType<br ALIGN="LEFT"/>enter_exit_hooks : list<br ALIGN="LEFT"/>export : bool<br ALIGN="LEFT"/>first_ctx : bool<br ALIGN="LEFT"/>prior : NoneType, Union[Unset, DynamoCallback], bool, token<br ALIGN="LEFT"/>prior_skip_guard_eval_unsafe<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._onnx_supported_ops._TorchSchema" [color="black", fontcolor="black", label=<{_TorchSchema|arguments : List[str], list<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>opsets : List[int], list<br ALIGN="LEFT"/>optional_arguments : List[str], list<br ALIGN="LEFT"/>overload_name : str<br ALIGN="LEFT"/>returns : List[str], list<br ALIGN="LEFT"/>|is_aten(): bool<br ALIGN="LEFT"/>is_backward(): bool<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.tensor._redistribute._TransformInfo" [color="black", fontcolor="black", label=<{_TransformInfo|logical_shape : List[int]<br ALIGN="LEFT"/>mesh_dim : int<br ALIGN="LEFT"/>src_dst_placements : Tuple[Placement, Placement]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils._pytree._TreeSpecSchema" [color="black", fontcolor="black", label=<{_TreeSpecSchema|children_spec : List['_TreeSpecSchema']<br ALIGN="LEFT"/>context : Any<br ALIGN="LEFT"/>type : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._TritonLibrary" [color="black", fontcolor="black", label=<{_TritonLibrary|lib<br ALIGN="LEFT"/>ops_table : _Dict[_Tuple[str, str], _Callable]<br ALIGN="LEFT"/>|registerOp(op_key, full_schema, op_impl, dispatch_key)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter" [color="black", fontcolor="black", label=<{_TypePromotionInterpreter|diagnostic_context<br ALIGN="LEFT"/>type_promotion_table<br ALIGN="LEFT"/>|run_node(node: torch.fx.Node): Any<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.cudagraph_trees._UnaliasedStorage" [color="black", fontcolor="black", label=<{_UnaliasedStorage|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._subclasses.fake_tensor._Unassigned" [color="black", fontcolor="black", label=<{_Unassigned|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.fsdp._common_utils._UninitializedDeviceHandle" [color="black", fontcolor="black", label=<{_UninitializedDeviceHandle|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._export.serde.union._Union" [color="black", fontcolor="black", label=<{_Union|type<br ALIGN="LEFT"/>value<br ALIGN="LEFT"/>|create()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.serde.union._UnionTag" [color="black", fontcolor="black", label=<{_UnionTag|<br ALIGN="LEFT"/>|create(t, cls)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.fsdp._fully_shard._fully_shard._UnshardHandleImpl" [color="black", fontcolor="black", label=<{_UnshardHandleImpl|<br ALIGN="LEFT"/>|wait()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._ndarray._Unspecified" [color="black", fontcolor="black", label=<{_Unspecified|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.onnx._internal.diagnostics._rules._UnsupportedFxNodeAnalysis" [color="black", fontcolor="black", label=<{_UnsupportedFxNodeAnalysis|<br ALIGN="LEFT"/>|format(level: infra.Level, node_op_to_target_mapping): Tuple[infra.Rule, infra.Level, str]<br ALIGN="LEFT"/>format_message(node_op_to_target_mapping): str<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._UpdateType" [color="black", fontcolor="black", label=<{_UpdateType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.virtualized._V" [color="black", fontcolor="black", label=<{_V|KernelFormatterHandler<br ALIGN="LEFT"/>MockHandler<br ALIGN="LEFT"/>WrapperHandler<br ALIGN="LEFT"/>aot_compilation<br ALIGN="LEFT"/>choices<br ALIGN="LEFT"/>current_node<br ALIGN="LEFT"/>debug<br ALIGN="LEFT"/>fake_mode<br ALIGN="LEFT"/>get_aot_compilation : Callable[[], Any]<br ALIGN="LEFT"/>get_current_node : Callable[[], Any]<br ALIGN="LEFT"/>get_fake_mode : Callable[[], Any]<br ALIGN="LEFT"/>get_local_buffer_context : Callable[[], Any]<br ALIGN="LEFT"/>get_ops_handler : Callable[[], Any]<br ALIGN="LEFT"/>get_real_inputs : Callable[[], Any]<br ALIGN="LEFT"/>graph<br ALIGN="LEFT"/>interpreter<br ALIGN="LEFT"/>kernel<br ALIGN="LEFT"/>local_buffer_context<br ALIGN="LEFT"/>ops<br ALIGN="LEFT"/>real_inputs<br ALIGN="LEFT"/>set_aot_compilation : Callable[[bool], Any]<br ALIGN="LEFT"/>set_choices_handler : Callable[[Any], Any]<br ALIGN="LEFT"/>set_current_node : Callable[[Any], Any]<br ALIGN="LEFT"/>set_debug_handler : Callable[[Any], Any]<br ALIGN="LEFT"/>set_fake_mode : Callable[[Any], Any]<br ALIGN="LEFT"/>set_graph_handler : Callable[[GraphLowering], Any]<br ALIGN="LEFT"/>set_interpreter_handler : Callable[[Any], Any]<br ALIGN="LEFT"/>set_kernel_handler : Callable[[Any], Any]<br ALIGN="LEFT"/>set_local_buffer_context : Callable[[Any], Any]<br ALIGN="LEFT"/>set_ops_handler : Callable[[Any], Any]<br ALIGN="LEFT"/>set_real_inputs : Callable[[Any], Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper" [color="black", fontcolor="black", label=<{_ValgrindWrapper|<br ALIGN="LEFT"/>|collect_callgrind(task_spec: common.TaskSpec, globals: Dict[str, Any]): Tuple[CallgrindStats, ...]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._export.verifier._VerifierMeta" [color="black", fontcolor="black", label=<{_VerifierMeta|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._vendor.packaging.version._Version" [color="black", fontcolor="black", label=<{_Version|dev : Optional[Tuple[str, int]]<br ALIGN="LEFT"/>epoch : int<br ALIGN="LEFT"/>local : Optional[LocalType]<br ALIGN="LEFT"/>post : Optional[Tuple[str, int]]<br ALIGN="LEFT"/>pre : Optional[Tuple[str, int]]<br ALIGN="LEFT"/>release : Tuple[int, ...]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._VersionWrapper" [color="black", fontcolor="black", label=<{_VersionWrapper|val : Union[torch.Tensor, Any]<br ALIGN="LEFT"/>version : Optional[int]<br ALIGN="LEFT"/>|get_val(allow_cache_entry_mutation)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.fx.passes.reinplace._ViewType" [color="black", fontcolor="black", label=<{_ViewType|name<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.ir._WaitKernel" [color="black", fontcolor="black", label=<{_WaitKernel|<br ALIGN="LEFT"/>|create_wait(kernel, inp: TensorBox): None<br ALIGN="LEFT"/>get_read_writes(): dependencies.ReadWrites<br ALIGN="LEFT"/>get_volatile_reads()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.weak._WeakHashRef" [color="black", fontcolor="black", label=<{_WeakHashRef|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed._tools.mem_tracker._WeakRefInfo" [color="black", fontcolor="black", label=<{_WeakRefInfo|device<br ALIGN="LEFT"/>element_size : int<br ALIGN="LEFT"/>mem_consumed<br ALIGN="LEFT"/>reftype<br ALIGN="LEFT"/>size : int<br ALIGN="LEFT"/>|create_winfo(st: torch.UntypedStorage, device: torch.device, reftype: _RefType, callback: Optional[Callable[[Self, weakref.ref], Any]]): Tuple[Self, weakref.ref]<br ALIGN="LEFT"/>get_untyped_storages(t: torch.Tensor): Set[torch.UntypedStorage]<br ALIGN="LEFT"/>update_mem_consumed(st: torch.UntypedStorage): int<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.fx._equalize._WeightEqualizationObserver" [color="black", fontcolor="black", label=<{_WeightEqualizationObserver|ch_axis : int<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>equalization_scale<br ALIGN="LEFT"/>qscheme<br ALIGN="LEFT"/>weight_col_obs<br ALIGN="LEFT"/>with_args : classmethod<br ALIGN="LEFT"/>|forward(w_orig)<br ALIGN="LEFT"/>get_weight_col_minmax()<br ALIGN="LEFT"/>set_equalization_scale(equalization_scale)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.utils.parametrizations._WeightNorm" [color="black", fontcolor="black", label=<{_WeightNorm|dim : Optional[int]<br ALIGN="LEFT"/>|forward(weight_g, weight_v)<br ALIGN="LEFT"/>right_inverse(weight)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.nn.modules.loss._WeightedLoss" [color="black", fontcolor="black", label=<{_WeightedLoss|weight : Optional[Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims_common._WorksWithInt" [color="black", fontcolor="black", label=<{_WorksWithInt|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._World" [color="black", fontcolor="black", label=<{_World|default_pg<br ALIGN="LEFT"/>group_count<br ALIGN="LEFT"/>pg_backend_config<br ALIGN="LEFT"/>pg_coalesce_state<br ALIGN="LEFT"/>pg_config_info<br ALIGN="LEFT"/>pg_group_ranks<br ALIGN="LEFT"/>pg_map<br ALIGN="LEFT"/>pg_names<br ALIGN="LEFT"/>pg_to_tag<br ALIGN="LEFT"/>tags_to_pg<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._WorldMeta" [color="black", fontcolor="black", label=<{_WorldMeta|WORLD<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph_module._WrappedCall" [color="black", fontcolor="black", label=<{_WrappedCall|cls<br ALIGN="LEFT"/>cls_call<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.nn.modules.module._WrappedHook" [color="black", fontcolor="black", label=<{_WrappedHook|hook : Callable<br ALIGN="LEFT"/>module : weakref.ReferenceType[Module]<br ALIGN="LEFT"/>with_module : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda._WrappedTritonKernel" [color="black", fontcolor="black", label=<{_WrappedTritonKernel|kernel<br ALIGN="LEFT"/>kernel_invoked : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.quantization.pt2e.export_utils._WrapperModule" [color="black", fontcolor="black", label=<{_WrapperModule|fn<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.export._trace._WrapperModule" [color="black", fontcolor="black", label=<{_WrapperModule|f<br ALIGN="LEFT"/>|forward()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.ao.quantization.quantizer.x86_inductor_quantizer._X86InductorQuantizationAnnotation" [color="black", fontcolor="black", label=<{_X86InductorQuantizationAnnotation|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.xnnpack._XNNPACKEnabled" [color="black", fontcolor="black", label=<{_XNNPACKEnabled|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.experimental.validator._Z3Ops" [color="black", fontcolor="black", label=<{_Z3Ops|bitwise_and<br ALIGN="LEFT"/>bitwise_or<br ALIGN="LEFT"/>lshift<br ALIGN="LEFT"/>rshift<br ALIGN="LEFT"/>validator : str<br ALIGN="LEFT"/>|abs(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>ceil(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>div(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>floor(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>floordiv(numerator: z3.ArithRef, denominator: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>max(a: z3.ArithRef, b: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>min(a: z3.ArithRef, b: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>mod(p: z3.ArithRef, q: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>pow(base: z3.ArithRef, exp: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>round_to_int(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>sqrt(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>sym_sum(args: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>to_int(x: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>to_real(x: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>trunc(number: z3.ArithRef): z3.ArithRef<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer._ZeROJoinHook" [color="black", fontcolor="black", label=<{_ZeROJoinHook|zero : Any<br ALIGN="LEFT"/>|main_hook(): None<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._tensor_str.__PrinterOptions" [color="black", fontcolor="black", label=<{__PrinterOptions|edgeitems : int<br ALIGN="LEFT"/>linewidth : int<br ALIGN="LEFT"/>precision : int<br ALIGN="LEFT"/>sci_mode : Optional[bool]<br ALIGN="LEFT"/>threshold : float<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._checkpoint_hook" [color="black", fontcolor="black", label=<{_checkpoint_hook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config._collective" [color="black", fontcolor="black", label=<{_collective|auto_select : bool<br ALIGN="LEFT"/>one_shot_all_reduce_threshold_bytes : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_dtype._dispatch_dtypes" [color="black", fontcolor="black", label=<{_dispatch_dtypes|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.utils._dynamic_dispatch_dtypes" [color="black", fontcolor="black", label=<{_dynamic_dispatch_dtypes|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.optim.lr_scheduler._enable_get_lr_call" [color="black", fontcolor="black", label=<{_enable_get_lr_call|o<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.pruning.scheduler.base_scheduler.BaseScheduler.step._enable_get_sl_call" [color="black", fontcolor="black", label=<{_enable_get_sl_call|o<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.ao.pruning._experimental.data_scheduler.base_data_scheduler.BaseDataScheduler.step._enable_get_sp_call" [color="black", fontcolor="black", label=<{_enable_get_sp_call|o<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode._force_original_view_tracking" [color="black", fontcolor="black", label=<{_force_original_view_tracking|mode : bool<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>|clone()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.distributions.utils._lazy_property_and_property" [color="black", fontcolor="black", label=<{_lazy_property_and_property|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.variables.builder._missing" [color="black", fontcolor="black", label=<{_missing|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.graph._node_list" [color="black", fontcolor="black", label=<{_node_list|direction : str<br ALIGN="LEFT"/>graph : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_buffer_reader" [color="black", fontcolor="black", label=<{_open_buffer_reader|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_buffer_writer" [color="black", fontcolor="black", label=<{_open_buffer_writer|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_file" [color="black", fontcolor="black", label=<{_open_file|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_zipfile_reader" [color="black", fontcolor="black", label=<{_open_zipfile_reader|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_zipfile_writer_buffer" [color="black", fontcolor="black", label=<{_open_zipfile_writer_buffer|buffer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._open_zipfile_writer_file" [color="black", fontcolor="black", label=<{_open_zipfile_writer_file|file_stream : FileIO, NoneType<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization._opener" [color="black", fontcolor="black", label=<{_opener|file_like<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.checkpoint._recomputation_hook" [color="black", fontcolor="black", label=<{_recomputation_hook|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d._reduce_op" [color="black", fontcolor="black", label=<{_reduce_op|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.remote_device._remote_device" [color="black", fontcolor="black", label=<{_remote_device|<br ALIGN="LEFT"/>|device(): torch.device<br ALIGN="LEFT"/>rank(): Optional[int]<br ALIGN="LEFT"/>worker_name(): Optional[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._weights_only_unpickler._safe_globals" [color="black", fontcolor="black", label=<{_safe_globals|safe_globals : List[Union[Callable, Tuple[Callable, str]]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.rpc.server_process_global_profiler._server_process_global_profile" [color="black", fontcolor="black", label=<{_server_process_global_profile|entered : bool<br ALIGN="LEFT"/>function_events<br ALIGN="LEFT"/>process_global_function_events : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.forward_ad._set_fwd_grad_enabled" [color="black", fontcolor="black", label=<{_set_fwd_grad_enabled|prev<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph._swap_with_cloned" [color="black", fontcolor="black", label=<{_swap_with_cloned|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode._unsafe_preserve_version_counter" [color="black", fontcolor="black", label=<{_unsafe_preserve_version_counter|prev_version<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.utils.align" [color="black", fontcolor="black", label=<{align|is_integer : bool<br ALIGN="LEFT"/>nargs : tuple<br ALIGN="LEFT"/>|eval(value: sympy.Expr): Optional[sympy.Expr]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._inductor.config.aot_inductor" [color="black", fontcolor="black", label=<{aot_inductor|allow_stack_allocation : bool<br ALIGN="LEFT"/>debug_compile<br ALIGN="LEFT"/>debug_intermediate_value_printer : str<br ALIGN="LEFT"/>dump_aoti_minifier : bool<br ALIGN="LEFT"/>filtered_kernel_names : NoneType<br ALIGN="LEFT"/>force_mmap_weights : bool<br ALIGN="LEFT"/>metadata : Dict[str, str]<br ALIGN="LEFT"/>output_path : str<br ALIGN="LEFT"/>package : bool<br ALIGN="LEFT"/>package_constants_in_so : bool<br ALIGN="LEFT"/>package_cpp_only : bool<br ALIGN="LEFT"/>presets : Dict[str, Any]<br ALIGN="LEFT"/>raise_error_on_ignored_optimization : bool<br ALIGN="LEFT"/>serialized_in_spec : str<br ALIGN="LEFT"/>serialized_out_spec : str<br ALIGN="LEFT"/>use_minimal_arrayref_interface : bool<br ALIGN="LEFT"/>use_runtime_constant_folding : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.optests.aot_autograd.assert_raises_regex" [color="black", fontcolor="black", label=<{assert_raises_regex|exception_cls<br ALIGN="LEFT"/>regex<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cpu.amp.autocast_mode.autocast" [color="black", fontcolor="black", label=<{autocast|device : str<br ALIGN="LEFT"/>fast_dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.amp.autocast_mode.autocast" [color="black", fontcolor="black", label=<{autocast|device : str<br ALIGN="LEFT"/>fast_dtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.amp.autocast_mode.autocast" [color="black", fontcolor="black", label=<{autocast|custom_backend_name<br ALIGN="LEFT"/>custom_device_mod<br ALIGN="LEFT"/>device : str<br ALIGN="LEFT"/>fast_dtype : NoneType<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>prev_cache_enabled<br ALIGN="LEFT"/>prev_fastdtype<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.hipify.hipify_python.bcolors" [color="black", fontcolor="black", label=<{bcolors|BOLD : str<br ALIGN="LEFT"/>ENDC : str<br ALIGN="LEFT"/>FAIL : str<br ALIGN="LEFT"/>HEADER : str<br ALIGN="LEFT"/>OKBLUE : str<br ALIGN="LEFT"/>OKGREEN : str<br ALIGN="LEFT"/>UNDERLINE : str<br ALIGN="LEFT"/>WARNING : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.bool_" [color="black", fontcolor="black", label=<{bool_|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils.JitTestCase.capture_stderr" [color="black", fontcolor="black", label=<{capture_stderr|stringio : StringIO<br ALIGN="LEFT"/>sys_stderr : NoneType, StringIO, TextIOWrapper<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_utils.JitTestCase.capture_stdout" [color="black", fontcolor="black", label=<{capture_stdout|stringio : StringIO<br ALIGN="LEFT"/>sys_stdout : StringIO, TextIOWrapper<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.argparse_util.check_env" [color="black", fontcolor="black", label=<{check_env|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.sparse.check_sparse_tensor_invariants" [color="black", fontcolor="black", label=<{check_sparse_tensor_invariants|saved_state : NoneType, Optional[bool]<br ALIGN="LEFT"/>state : bool<br ALIGN="LEFT"/>|disable()<br ALIGN="LEFT"/>enable()<br ALIGN="LEFT"/>is_enabled()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy.testing.utils.clear_and_catch_warnings" [color="black", fontcolor="black", label=<{clear_and_catch_warnings|class_modules : tuple<br ALIGN="LEFT"/>modules<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._jit_internal.createResolutionCallbackFromClosure.closure_lookup" [color="black", fontcolor="black", label=<{closure_lookup|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.cpp_extension.BuildExtension.with_options.cls_with_options" [color="black", fontcolor="black", label=<{cls_with_options|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.complex128" [color="black", fontcolor="black", label=<{complex128|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.complex64" [color="black", fontcolor="black", label=<{complex64|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.complexfloating" [color="black", fontcolor="black", label=<{complexfloating|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.autograd.context" [color="black", fontcolor="black", label=<{context|autograd_context<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.cpp" [color="black", fontcolor="black", label=<{cpp|cxx : tuple<br ALIGN="LEFT"/>descriptive_names : str<br ALIGN="LEFT"/>dynamic_threads<br ALIGN="LEFT"/>enable_concat_linear : bool<br ALIGN="LEFT"/>enable_floating_point_contract_flag<br ALIGN="LEFT"/>enable_kernel_profile<br ALIGN="LEFT"/>enable_loop_tail_vec : bool<br ALIGN="LEFT"/>enable_tiling_heuristics<br ALIGN="LEFT"/>enable_unsafe_math_opt_flag<br ALIGN="LEFT"/>fallback_scatter_reduce_sum<br ALIGN="LEFT"/>gemm_cache_blocking : NoneType<br ALIGN="LEFT"/>gemm_max_k_slices : int<br ALIGN="LEFT"/>gemm_thread_factors : NoneType<br ALIGN="LEFT"/>inject_log1p_bug_TESTING_ONLY : Optional[str]<br ALIGN="LEFT"/>inject_relu_bug_TESTING_ONLY : Optional[str]<br ALIGN="LEFT"/>max_horizontal_fusion_size : int<br ALIGN="LEFT"/>min_chunk_size : int<br ALIGN="LEFT"/>no_redundant_loops<br ALIGN="LEFT"/>simdlen : Optional[int]<br ALIGN="LEFT"/>threads : int<br ALIGN="LEFT"/>vec_isa_ok : Optional[bool]<br ALIGN="LEFT"/>weight_prepack<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.cuda.cuBLASModule" [color="black", fontcolor="black", label=<{cuBLASModule|allow_tf32 : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.cuda.cuFFTPlanCache" [color="black", fontcolor="black", label=<{cuFFTPlanCache|device_index<br ALIGN="LEFT"/>max_size<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>|clear()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.backends.cuda.cuFFTPlanCacheAttrContextProp" [color="black", fontcolor="black", label=<{cuFFTPlanCacheAttrContextProp|getter<br ALIGN="LEFT"/>setter<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.cuda.cuFFTPlanCacheManager" [color="black", fontcolor="black", label=<{cuFFTPlanCacheManager|caches : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.cuda" [color="black", fontcolor="black", label=<{cuda|arch : Optional[str]<br ALIGN="LEFT"/>compile_opt_level : str<br ALIGN="LEFT"/>cuda_cxx : Optional[str]<br ALIGN="LEFT"/>cutlass_backend_min_gemm_size : int<br ALIGN="LEFT"/>cutlass_dir<br ALIGN="LEFT"/>cutlass_max_profiling_configs : Optional[int]<br ALIGN="LEFT"/>cutlass_op_allowlist_regex : Optional[str]<br ALIGN="LEFT"/>cutlass_op_denylist_regex : Optional[str]<br ALIGN="LEFT"/>enable_cuda_lto : bool<br ALIGN="LEFT"/>enable_debug_info : bool<br ALIGN="LEFT"/>enable_ptxas_info : bool<br ALIGN="LEFT"/>generate_test_runner : bool<br ALIGN="LEFT"/>use_fast_math : bool<br ALIGN="LEFT"/>version : Optional[str]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.cudaStatus" [color="black", fontcolor="black", label=<{cudaStatus|ERROR_NOT_READY : int<br ALIGN="LEFT"/>SUCCESS : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.decorateIf" [color="black", fontcolor="black", label=<{decorateIf|decorator<br ALIGN="LEFT"/>predicate_fn<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.anomaly_mode.detect_anomaly" [color="black", fontcolor="black", label=<{detect_anomaly|check_nan : bool<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>prev_check_nan<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.xpu.device" [color="black", fontcolor="black", label=<{device|idx : NoneType, int<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.device_interface.DeviceInterface.device" [color="black", fontcolor="black", label=<{device|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.device" [color="black", fontcolor="black", label=<{device|idx<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.mtia.device" [color="black", fontcolor="black", label=<{device|idx : NoneType, int<br ALIGN="LEFT"/>prev_idx : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.deviceCountAtLeast" [color="black", fontcolor="black", label=<{deviceCountAtLeast|num_required_devices<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.xpu.device_of" [color="black", fontcolor="black", label=<{device_of|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.device_of" [color="black", fontcolor="black", label=<{device_of|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.jit_metaprogramming_utils.dont_convert" [color="black", fontcolor="black", label=<{dont_convert|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypes" [color="black", fontcolor="black", label=<{dtypes|args : tuple<br ALIGN="LEFT"/>device_type : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypesIfCPU" [color="black", fontcolor="black", label=<{dtypesIfCPU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypesIfCUDA" [color="black", fontcolor="black", label=<{dtypesIfCUDA|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypesIfHPU" [color="black", fontcolor="black", label=<{dtypesIfHPU|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypesIfMPS" [color="black", fontcolor="black", label=<{dtypesIfMPS|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.dtypesIfPRIVATEUSE1" [color="black", fontcolor="black", label=<{dtypesIfPRIVATEUSE1|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.forward_ad.dual_level" [color="black", fontcolor="black", label=<{dual_level|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.launcher.api.elastic_launch" [color="black", fontcolor="black", label=<{elastic_launch|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._prims_common.wrappers.elementwise_type_promotion_wrapper" [color="black", fontcolor="black", label=<{elementwise_type_promotion_wrapper|type_promoting_arg_names : NoneType<br ALIGN="LEFT"/>type_promotion_kind<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler.emit_itt" [color="black", fontcolor="black", label=<{emit_itt|enabled : bool<br ALIGN="LEFT"/>entered : bool<br ALIGN="LEFT"/>record_shapes : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler.emit_nvtx" [color="black", fontcolor="black", label=<{emit_nvtx|enabled : bool<br ALIGN="LEFT"/>entered : bool<br ALIGN="LEFT"/>record_shapes : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode.enable_grad" [color="black", fontcolor="black", label=<{enable_grad|prev<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._jit_internal.createResolutionCallbackFromFrame.env" [color="black", fontcolor="black", label=<{env|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.argparse_util.env" [color="black", fontcolor="black", label=<{env|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.expectedFailure" [color="black", fontcolor="black", label=<{expectedFailure|device_type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.float16" [color="black", fontcolor="black", label=<{float16|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.float32" [color="black", fontcolor="black", label=<{float32|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.float64" [color="black", fontcolor="black", label=<{float64|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.floating" [color="black", fontcolor="black", label=<{floating|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.foreach_inputs_sample_func" [color="black", fontcolor="black", label=<{foreach_inputs_sample_func|arity : int<br ALIGN="LEFT"/>|sample_zero_size_tensor_inputs(opinfo, device, dtype, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.foreach_max_sample_func" [color="black", fontcolor="black", label=<{foreach_max_sample_func|<br ALIGN="LEFT"/>|sample_zero_size_tensor_inputs(opinfo, device, dtype, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.foreach_norm_sample_func" [color="black", fontcolor="black", label=<{foreach_norm_sample_func|<br ALIGN="LEFT"/>|sample_zero_size_tensor_inputs(opinfo, device, dtype, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_methods_invocations.foreach_pointwise_sample_func" [color="black", fontcolor="black", label=<{foreach_pointwise_sample_func|<br ALIGN="LEFT"/>|sample_zero_size_tensor_inputs(opinfo, device, dtype, requires_grad)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.utils.data.datapipes._decorator.functional_datapipe" [color="black", fontcolor="black", label=<{functional_datapipe|enable_df_api_tracing : bool<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.generic" [color="black", fontcolor="black", label=<{generic|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.cuda.graphs.graph" [color="black", fontcolor="black", label=<{graph|capture_error_mode : str<br ALIGN="LEFT"/>capture_stream : NoneType<br ALIGN="LEFT"/>cuda_graph<br ALIGN="LEFT"/>default_capture_stream : Optional[typing.Optional['torch.cuda.Stream']]<br ALIGN="LEFT"/>pool : tuple<br ALIGN="LEFT"/>stream_ctx<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.distributed_c10d.group" [color="black", fontcolor="black", label=<{group|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes._decorator.guaranteed_datapipes_determinism" [color="black", fontcolor="black", label=<{guaranteed_datapipes_determinism|prev : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.halide" [color="black", fontcolor="black", label=<{halide|asserts : bool<br ALIGN="LEFT"/>cpu_target : str<br ALIGN="LEFT"/>debug : bool<br ALIGN="LEFT"/>gpu_target : str<br ALIGN="LEFT"/>scan_kernels : bool<br ALIGN="LEFT"/>scheduler_cpu : str<br ALIGN="LEFT"/>scheduler_cuda : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.inexact" [color="black", fontcolor="black", label=<{inexact|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode.inference_mode" [color="black", fontcolor="black", label=<{inference_mode|mode : bool<br ALIGN="LEFT"/>|clone(): 'inference_mode'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._dtypes.int16" [color="black", fontcolor="black", label=<{int16|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.int32" [color="black", fontcolor="black", label=<{int32|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.int64" [color="black", fontcolor="black", label=<{int64|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.int8" [color="black", fontcolor="black", label=<{int8|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.integer" [color="black", fontcolor="black", label=<{integer|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributions.utils.lazy_property" [color="black", fontcolor="black", label=<{lazy_property|wrapped<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.distributed.elastic.utils.api.macros" [color="black", fontcolor="black", label=<{macros|local_rank : str<br ALIGN="LEFT"/>|substitute(args: List[Any], local_rank: str): List[str]<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_modules.modules" [color="black", fontcolor="black", label=<{modules|allowed_dtypes : NoneType, set<br ALIGN="LEFT"/>module_info_list : list<br ALIGN="LEFT"/>skip_if_dynamo : bool<br ALIGN="LEFT"/>train_eval_mode<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._ndarray.ndarray" [color="black", fontcolor="black", label=<{ndarray|T<br ALIGN="LEFT"/>conj<br ALIGN="LEFT"/>conjugate<br ALIGN="LEFT"/>data<br ALIGN="LEFT"/>dtype<br ALIGN="LEFT"/>flags<br ALIGN="LEFT"/>fn<br ALIGN="LEFT"/>imag<br ALIGN="LEFT"/>itemsize<br ALIGN="LEFT"/>ivar : str<br ALIGN="LEFT"/>method : str<br ALIGN="LEFT"/>name : NoneType<br ALIGN="LEFT"/>nbytes<br ALIGN="LEFT"/>ndim<br ALIGN="LEFT"/>plain : str<br ALIGN="LEFT"/>put<br ALIGN="LEFT"/>real<br ALIGN="LEFT"/>rvar : str<br ALIGN="LEFT"/>shape<br ALIGN="LEFT"/>size<br ALIGN="LEFT"/>strides<br ALIGN="LEFT"/>take<br ALIGN="LEFT"/>tensor<br ALIGN="LEFT"/>|astype(dtype, order, casting, subok, copy)<br ALIGN="LEFT"/>copy(order: NotImplementedType)<br ALIGN="LEFT"/>fill(value: ArrayLike)<br ALIGN="LEFT"/>flatten(order: NotImplementedType)<br ALIGN="LEFT"/>is_integer()<br ALIGN="LEFT"/>item()<br ALIGN="LEFT"/>reshape()<br ALIGN="LEFT"/>resize()<br ALIGN="LEFT"/>sort(axis, kind, order)<br ALIGN="LEFT"/>tolist()<br ALIGN="LEFT"/>transpose()<br ALIGN="LEFT"/>view(dtype, type)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.fake_config_module.nested" [color="black", fontcolor="black", label=<{nested|e_bool : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode.no_grad" [color="black", fontcolor="black", label=<{no_grad|prev : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes._decorator.non_deterministic" [color="black", fontcolor="black", label=<{non_deterministic|cls : Optional[Type[IterDataPipe]]<br ALIGN="LEFT"/>deterministic_fn : Callable[[], bool]<br ALIGN="LEFT"/>|deterministic_wrapper_fn(): IterDataPipe<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._dtypes.number" [color="black", fontcolor="black", label=<{number|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.numpy_method_wrapper" [color="black", fontcolor="black", label=<{numpy_method_wrapper|method : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.numpy_operator_wrapper" [color="black", fontcolor="black", label=<{numpy_operator_wrapper|op : Callable[..., Any]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._dynamo.utils.numpy_to_tensor_wrapper" [color="black", fontcolor="black", label=<{numpy_to_tensor_wrapper|f<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.onlyOn" [color="black", fontcolor="black", label=<{onlyOn|device_type<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.ops" [color="black", fontcolor="black", label=<{ops|allowed_dtypes : NoneType, set<br ALIGN="LEFT"/>op_list : list<br ALIGN="LEFT"/>opinfo_dtypes : supported<br ALIGN="LEFT"/>skip_if_dynamo : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_optimizers.optims" [color="black", fontcolor="black", label=<{optims|dtypes : NoneType, list<br ALIGN="LEFT"/>optim_info_list : list<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.parametrize" [color="black", fontcolor="black", label=<{parametrize|arg_names : List[str]<br ALIGN="LEFT"/>arg_values<br ALIGN="LEFT"/>name_fn : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.precisionOverride" [color="black", fontcolor="black", label=<{precisionOverride|d<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.profiler_legacy.profile" [color="black", fontcolor="black", label=<{profile|enabled : bool<br ALIGN="LEFT"/>entered : bool<br ALIGN="LEFT"/>function_events : NoneType<br ALIGN="LEFT"/>profile_memory : bool<br ALIGN="LEFT"/>profiler_kind<br ALIGN="LEFT"/>record_shapes : bool<br ALIGN="LEFT"/>self_cpu_time_total<br ALIGN="LEFT"/>use_cuda : bool<br ALIGN="LEFT"/>with_flops : bool<br ALIGN="LEFT"/>with_modules : bool<br ALIGN="LEFT"/>with_stack : bool<br ALIGN="LEFT"/>|config()<br ALIGN="LEFT"/>export_chrome_trace(path)<br ALIGN="LEFT"/>export_stacks(path: str, metric: str)<br ALIGN="LEFT"/>key_averages(group_by_input_shape, group_by_stack_n)<br ALIGN="LEFT"/>table(sort_by, row_limit, max_src_column_width, max_name_column_width, max_shapes_column_width, header, top_level_events_only)<br ALIGN="LEFT"/>total_average()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler.profile" [color="black", fontcolor="black", label=<{profile|acc_events : bool<br ALIGN="LEFT"/>custom_trace_id_callback : NoneType<br ALIGN="LEFT"/>enabled : bool<br ALIGN="LEFT"/>entered : bool<br ALIGN="LEFT"/>experimental_config : NoneType<br ALIGN="LEFT"/>function_events<br ALIGN="LEFT"/>kineto_activities : set<br ALIGN="LEFT"/>kineto_results : Optional[_ProfilerResult]<br ALIGN="LEFT"/>profile_memory : bool<br ALIGN="LEFT"/>profiler_kind<br ALIGN="LEFT"/>profiling_end_time_ns : int<br ALIGN="LEFT"/>profiling_start_time_ns : int<br ALIGN="LEFT"/>record_shapes : bool<br ALIGN="LEFT"/>self_cpu_time_total<br ALIGN="LEFT"/>trace_id : str<br ALIGN="LEFT"/>use_cpu : bool<br ALIGN="LEFT"/>use_cuda : bool<br ALIGN="LEFT"/>use_device : NoneType, Optional[str]<br ALIGN="LEFT"/>with_flops : bool<br ALIGN="LEFT"/>with_modules : bool<br ALIGN="LEFT"/>with_stack : bool<br ALIGN="LEFT"/>|config(create_trace_id)<br ALIGN="LEFT"/>create_trace_id()<br ALIGN="LEFT"/>default_trace_id()<br ALIGN="LEFT"/>export_chrome_trace(path)<br ALIGN="LEFT"/>export_stacks(path: str, metric: str)<br ALIGN="LEFT"/>key_averages(group_by_input_shape, group_by_stack_n)<br ALIGN="LEFT"/>table(sort_by, row_limit, max_src_column_width, max_name_column_width, max_shapes_column_width, header, top_level_events_only)<br ALIGN="LEFT"/>toggle_collection_dynamic(enabled: bool, activities: Iterable[ProfilerActivity])<br ALIGN="LEFT"/>total_average()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.profiler.profiler.profile" [color="black", fontcolor="black", label=<{profile|action_map : Dict[Tuple[ProfilerAction, Optional[ProfilerAction]], List[Any]]<br ALIGN="LEFT"/>current_action : RECORD<br ALIGN="LEFT"/>custom_trace_id_callback<br ALIGN="LEFT"/>on_trace_ready : NoneType<br ALIGN="LEFT"/>record_steps : bool<br ALIGN="LEFT"/>schedule : NoneType<br ALIGN="LEFT"/>step_num : int<br ALIGN="LEFT"/>step_rec_fn : Optional[prof.record_function]<br ALIGN="LEFT"/>|get_trace_id()<br ALIGN="LEFT"/>set_custom_trace_id_callback(callback)<br ALIGN="LEFT"/>start()<br ALIGN="LEFT"/>step()<br ALIGN="LEFT"/>stop()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.profiler.record_function" [color="black", fontcolor="black", label=<{record_function|args : Optional[str]<br ALIGN="LEFT"/>name : str<br ALIGN="LEFT"/>record : NoneType<br ALIGN="LEFT"/>run_callbacks_on_exit : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.reparametrize" [color="black", fontcolor="black", label=<{reparametrize|adapter_fn<br ALIGN="LEFT"/>parametrizer<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.rocm" [color="black", fontcolor="black", label=<{rocm|arch : List[str]<br ALIGN="LEFT"/>ck_dir : NoneType<br ALIGN="LEFT"/>ck_supported_arch : List[str]<br ALIGN="LEFT"/>compile_opt_level : str<br ALIGN="LEFT"/>flush_denormals : bool<br ALIGN="LEFT"/>generate_test_runner : bool<br ALIGN="LEFT"/>is_debug : bool<br ALIGN="LEFT"/>n_max_profiling_configs : Optional[int]<br ALIGN="LEFT"/>print_kernel_resource_usage : bool<br ALIGN="LEFT"/>rocm_home : Optional[str]<br ALIGN="LEFT"/>save_temps : bool<br ALIGN="LEFT"/>use_fast_math : bool<br ALIGN="LEFT"/>use_preselected_instances : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.utils.data.datapipes._decorator.runtime_validation_disabled" [color="black", fontcolor="black", label=<{runtime_validation_disabled|prev : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization.safe_globals" [color="black", fontcolor="black", label=<{safe_globals|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.opinfo.core.sample_skips_and_xfails" [color="black", fontcolor="black", label=<{sample_skips_and_xfails|rules<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.save_on_cpu" [color="black", fontcolor="black", label=<{save_on_cpu|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.graph.saved_tensors_hooks" [color="black", fontcolor="black", label=<{saved_tensors_hooks|pack_hook : Callable[[torch.Tensor], Any]<br ALIGN="LEFT"/>unpack_hook : Callable[[Any], torch.Tensor]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization.set_default_mmap_options" [color="black", fontcolor="black", label=<{set_default_mmap_options|prev<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.anomaly_mode.set_detect_anomaly" [color="black", fontcolor="black", label=<{set_detect_anomaly|prev<br ALIGN="LEFT"/>prev_check_nan<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.autograd.grad_mode.set_grad_enabled" [color="black", fontcolor="black", label=<{set_grad_enabled|mode : bool<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>|clone(): 'set_grad_enabled'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.autograd.grad_mode.set_multithreading_enabled" [color="black", fontcolor="black", label=<{set_multithreading_enabled|mode : bool<br ALIGN="LEFT"/>prev<br ALIGN="LEFT"/>|clone(): 'set_multithreading_enabled'<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._dynamo.decorators.set_stance" [color="black", fontcolor="black", label=<{set_stance|prev<br ALIGN="LEFT"/>stance<br ALIGN="LEFT"/>|clone()<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch._numpy._dtypes.signedinteger" [color="black", fontcolor="black", label=<{signedinteger|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.fx.passes.graph_manipulation.size_bytes" [color="black", fontcolor="black", label=<{size_bytes|output_size : int<br ALIGN="LEFT"/>total_size : int<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipCPUIf" [color="black", fontcolor="black", label=<{skipCPUIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipCUDAIf" [color="black", fontcolor="black", label=<{skipCUDAIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipGPUIf" [color="black", fontcolor="black", label=<{skipGPUIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipHPUIf" [color="black", fontcolor="black", label=<{skipHPUIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipIf" [color="black", fontcolor="black", label=<{skipIf|dep<br ALIGN="LEFT"/>device_type : NoneType<br ALIGN="LEFT"/>reason<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipLazyIf" [color="black", fontcolor="black", label=<{skipLazyIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipMPSIf" [color="black", fontcolor="black", label=<{skipMPSIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipMetaIf" [color="black", fontcolor="black", label=<{skipMetaIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipPRIVATEUSE1If" [color="black", fontcolor="black", label=<{skipPRIVATEUSE1If|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipXLAIf" [color="black", fontcolor="black", label=<{skipXLAIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.skipXPUIf" [color="black", fontcolor="black", label=<{skipXPUIf|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.serialization.skip_data" [color="black", fontcolor="black", label=<{skip_data|materialize_fake_tensors : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.jit.strict_fusion" [color="black", fontcolor="black", label=<{strict_fusion|<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.subtest" [color="black", fontcolor="black", label=<{subtest|arg_values<br ALIGN="LEFT"/>decorators : list<br ALIGN="LEFT"/>name : NoneType<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy.testing.utils.suppress_warnings" [color="black", fontcolor="black", label=<{suppress_warnings|log : list<br ALIGN="LEFT"/>|filter(category, message, module)<br ALIGN="LEFT"/>record(category, message, module)<br ALIGN="LEFT"/>}>, shape="record", style="solid"];
"torch.testing._internal.common_utils.swap" [color="black", fontcolor="black", label=<{swap|swap_values<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.test_configs" [color="black", fontcolor="black", label=<{test_configs|force_extern_kernel_in_multi_template : bool<br ALIGN="LEFT"/>max_mm_configs : Optional[int]<br ALIGN="LEFT"/>runtime_triton_dtype_assert : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.testing._internal.common_device_type.toleranceOverride" [color="black", fontcolor="black", label=<{toleranceOverride|d<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.trace" [color="black", fontcolor="black", label=<{trace|compile_profile : bool<br ALIGN="LEFT"/>debug_dir : Optional[str]<br ALIGN="LEFT"/>debug_log : bool<br ALIGN="LEFT"/>dot_graph_shape : NoneType<br ALIGN="LEFT"/>draw_orig_fx_graph<br ALIGN="LEFT"/>enabled<br ALIGN="LEFT"/>fx_graph : bool<br ALIGN="LEFT"/>fx_graph_transformed : bool<br ALIGN="LEFT"/>graph_diagram<br ALIGN="LEFT"/>info_log : bool<br ALIGN="LEFT"/>ir_post_fusion : bool<br ALIGN="LEFT"/>ir_pre_fusion : bool<br ALIGN="LEFT"/>log_autotuning_results : bool<br ALIGN="LEFT"/>log_url_for_graph_xform : NoneType<br ALIGN="LEFT"/>output_code : bool<br ALIGN="LEFT"/>save_real_tensors<br ALIGN="LEFT"/>upload_tar : Optional[Callable[[str], None]]<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._inductor.config.triton" [color="black", fontcolor="black", label=<{triton|autotune_at_compile_time : Optional[bool]<br ALIGN="LEFT"/>autotune_cublasLt : bool<br ALIGN="LEFT"/>autotune_pointwise : bool<br ALIGN="LEFT"/>codegen_upcast_to_fp32 : bool<br ALIGN="LEFT"/>cooperative_reductions<br ALIGN="LEFT"/>cudagraph_dynamic_shape_warn_limit : Optional[int]<br ALIGN="LEFT"/>cudagraph_skip_dynamic_graphs : bool<br ALIGN="LEFT"/>cudagraph_support_input_mutation : bool<br ALIGN="LEFT"/>cudagraph_trees : bool<br ALIGN="LEFT"/>cudagraph_trees_history_recording : bool<br ALIGN="LEFT"/>cudagraph_unexpected_rerecord_limit : int<br ALIGN="LEFT"/>cudagraphs<br ALIGN="LEFT"/>debug_sync_graph : bool<br ALIGN="LEFT"/>debug_sync_kernel : bool<br ALIGN="LEFT"/>dense_indexing : bool<br ALIGN="LEFT"/>descriptive_names : str<br ALIGN="LEFT"/>divisible_by_16 : bool<br ALIGN="LEFT"/>enable_persistent_tma_matmul<br ALIGN="LEFT"/>fast_path_cudagraph_asserts : bool<br ALIGN="LEFT"/>force_cooperative_reductions : bool<br ALIGN="LEFT"/>force_cudagraph_sync : bool<br ALIGN="LEFT"/>force_cudagraphs_warmup : bool<br ALIGN="LEFT"/>inject_relu_bug_TESTING_ONLY : Optional[str]<br ALIGN="LEFT"/>max_tiles : int<br ALIGN="LEFT"/>min_split_scan_rblock : int<br ALIGN="LEFT"/>multi_kernel : int<br ALIGN="LEFT"/>persistent_reductions<br ALIGN="LEFT"/>prefer_nd_tiling : bool<br ALIGN="LEFT"/>skip_cudagraph_warmup : bool<br ALIGN="LEFT"/>slow_path_cudagraph_asserts : bool<br ALIGN="LEFT"/>spill_threshold : int<br ALIGN="LEFT"/>store_cubin : bool<br ALIGN="LEFT"/>tiling_prevents_pointwise_fusion : bool<br ALIGN="LEFT"/>tiling_prevents_reduction_fusion : bool<br ALIGN="LEFT"/>unique_kernel_names<br ALIGN="LEFT"/>use_block_ptr : bool<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.uint16" [color="black", fontcolor="black", label=<{uint16|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.uint32" [color="black", fontcolor="black", label=<{uint32|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.uint64" [color="black", fontcolor="black", label=<{uint64|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.uint8" [color="black", fontcolor="black", label=<{uint8|name : str<br ALIGN="LEFT"/>torch_dtype<br ALIGN="LEFT"/>typecode : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch._numpy._dtypes.unsignedinteger" [color="black", fontcolor="black", label=<{unsignedinteger|name : str<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.mkl.verbose" [color="black", fontcolor="black", label=<{verbose|enable<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.backends.mkldnn.verbose" [color="black", fontcolor="black", label=<{verbose|level<br ALIGN="LEFT"/>|}>, shape="record", style="solid"];
"torch.BFloat16Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.BoolStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.ByteStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.CharStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.ComplexDoubleStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.ComplexFloatStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.DoubleStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.FloatStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.HalfStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.IntStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.LongStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.QInt32Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.QInt8Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.QUInt2x4Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.QUInt4x2Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.QUInt8Storage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.ShortStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch._dynamo._trace_wrapped_higher_order_op.ModIndex" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._dynamo._trace_wrapped_higher_order_op.TraceWrapped" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._dynamo._trace_wrapped_higher_order_op.TransformGetItemToIndex" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.backends.distributed.SubmodCompiler" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.backends.distributed.SubmodCompiler.compile_submod.WrapperModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.create_parameter_op.TracableCreateParameter" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.decorators.set_stance" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.device_interface.CpuInterface" -> "torch._dynamo.device_interface.DeviceInterface" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.device_interface.CudaInterface" -> "torch._dynamo.device_interface.DeviceInterface" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.device_interface.XpuInterface" -> "torch._dynamo.device_interface.DeviceInterface" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.eval_frame.DisableContext" -> "torch._dynamo.eval_frame._TorchDynamoContext" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.eval_frame.FlattenInputOutputSignature" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.eval_frame.OptimizeContext" -> "torch._dynamo.eval_frame._TorchDynamoContext" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.eval_frame.OptimizedModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.eval_frame.RunOnlyContext" -> "torch._dynamo.eval_frame._TorchDynamoContext" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ArgsMismatchError" -> "torch._dynamo.exc.Unsupported" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.AttributeMutationError" -> "torch._dynamo.exc.Unsupported" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.BackendCompilerFailed" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.CompileCollectiveRestartAnalysis" -> "torch._dynamo.exc.RestartAnalysis" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.CondOpArgsMismatchError" -> "torch._dynamo.exc.ArgsMismatchError" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.InternalTorchDynamoError" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.InvalidBackend" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ObservedAttributeError" -> "torch._dynamo.exc.ObservedException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ObservedException" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ObservedKeyError" -> "torch._dynamo.exc.ObservedException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ObservedUserStopIteration" -> "torch._dynamo.exc.ObservedException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.RecompileError" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.RecompileLimitExceeded" -> "torch._dynamo.exc.Unsupported" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.ResetRequired" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.RestartAnalysis" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.SkipCodeRecursiveException" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.SkipFrame" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.SpeculationRestartAnalysis" -> "torch._dynamo.exc.RestartAnalysis" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.TensorifyScalarRestartAnalysis" -> "torch._dynamo.exc.RestartAnalysis" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.TorchRuntimeError" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.UncapturedHigherOrderOpError" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.UnsafeScriptObjectError" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.UnspecializeRestartAnalysis" -> "torch._dynamo.exc.RestartAnalysis" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.Unsupported" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.exc.UserError" -> "torch._dynamo.exc.Unsupported" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.guards.DeletedGuardManagerWrapper" -> "torch._dynamo.guards.GuardManagerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.guards.GuardBuilder" -> "torch._guards.GuardBuilderBase" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.guards.GuardManagerWrapper.__str__.IndentedBufferWithPrefix" -> "torch._inductor.utils.IndentedBuffer" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.output_graph.FakeRootModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.output_graph.SubgraphTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.polyfills.NoEnterTorchFunctionMode" -> "torch.overrides.BaseTorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.repro.after_aot.repro_analyze.ExactReaderInterp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.repro.after_aot.repro_analyze.ReaderInterp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.repro.after_aot.repro_analyze.WriterInterp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.AttrProxySource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.AttrSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.BackwardStateSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.CallFunctionNoArgsSource" -> "torch._dynamo.source.WeakRefCallSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.CallMethodItemSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ConstDictKeySource" -> "torch._dynamo.source.GetItemSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ConstantSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ConvertIntSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.DefaultsSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.EphemeralSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.FSDPNNModuleSource" -> "torch._dynamo.source.NNModuleSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.FlattenScriptObjectSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.FloatTensorSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.GetItemSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.GlobalSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.GlobalStateSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.GlobalWeakRefSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.GradSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.LocalCellSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.LocalSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.NNModuleSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.NegateSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.NumpyTensorSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ODictGetItemSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.OptimizerSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ParamBufferSource" -> "torch._dynamo.source.AttrSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.RandomValueSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ScriptObjectQualifiedNameSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.ShapeEnvSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.SubclassAttrListSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.SyntheticLocalSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.TensorPropertySource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.TorchFunctionModeStackSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.TupleIteratorGetItemSource" -> "torch._dynamo.source.GetItemSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.TypeSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.UnspecializedBuiltinNNModuleSource" -> "torch._dynamo.source.UnspecializedNNModuleSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.UnspecializedNNModuleSource" -> "torch._dynamo.source.NNModuleSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.UnspecializedParamBufferSource" -> "torch._dynamo.source.AttrSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.source.WeakRefCallSource" -> "torch._guards.ChainedSource" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.symbolic_convert.InliningGeneratorInstructionTranslator" -> "torch._dynamo.symbolic_convert.InliningInstructionTranslator" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.symbolic_convert.InliningInstructionTranslator" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.symbolic_convert.InstructionTranslator" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.test_case.TestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.test_minifier_common.MinifierTestBase" -> "torch._dynamo.test_case.TestCase" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.utils.CleanupManager" -> "torch._dynamo.utils.ExactWeakKeyDictionary" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.utils.GmWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.base.AttributeMutation" -> "torch._dynamo.variables.base.MutationType" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.base.AttributeMutationExisting" -> "torch._dynamo.variables.base.AttributeMutation" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.base.AttributeMutationNew" -> "torch._dynamo.variables.base.AttributeMutation" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.base.ValueMutationExisting" -> "torch._dynamo.variables.base.MutationType" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.base.ValueMutationNew" -> "torch._dynamo.variables.base.MutationType" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.builder.BackwardStateGraphArg" -> "torch._dynamo.variables.builder.GraphArg" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.builtin.BuiltinVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.constant.EnumVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.AutocastModeVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.CUDADeviceVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.CatchWarningsCtxManagerVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.ContextWrappingVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.DeterministicAlgorithmsVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.DisabledSavedTensorsHooksVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.DualLevelContextManager" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.EventVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.FSDPParamGroupUseTrainingStateVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.GenericContextWrappingVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.GradIncrementNestingCtxManagerVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.GradInplaceRequiresGradCtxManagerVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.GradModeVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.InferenceModeVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.JvpIncrementNestingCtxManagerVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.NullContextVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.PreserveVersionContextVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.SDPAKernelVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.SetFwdGradEnabledContextManager" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.StreamContextVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.StreamVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.TorchFunctionDisableVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.VmapIncrementNestingCtxManagerVariable" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.ctx_manager.WithExitFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.ConstDictVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.CustomizedDictVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.DefaultDictVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.DictKeys" -> "torch._dynamo.variables.dicts.DictView" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.DictValues" -> "torch._dynamo.variables.dicts.DictView" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.DictView" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.variables.dicts.SetVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.HFPretrainedConfigVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.PythonSysModulesVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.BackwardHookVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.DeviceMeshVariable" -> "torch._dynamo.variables.distributed.DistributedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.DistributedVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.PlacementClassVariable" -> "torch._dynamo.variables.distributed.DistributedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.PlacementVariable" -> "torch._dynamo.variables.distributed.DistributedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.ProcessGroupVariable" -> "torch._dynamo.variables.distributed.DistributedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.distributed.WorldMetaClassVariable" -> "torch._dynamo.variables.distributed.DistributedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.BaseUserFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.CollectiveFunctionRewriteVariable" -> "torch._dynamo.variables.functions.UserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.CreateTMADescriptorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.DynamoTritonHOPifier" -> "torch._higher_order_ops.triton_kernel_wrap.TritonHOPifier" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.FunctoolsPartialVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.NestedUserFunctionVariable" -> "torch._dynamo.variables.functions.BaseUserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.PolyfilledFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.SkipFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.TMADescriptorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.TritonKernelVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.UserFunctionVariable" -> "torch._dynamo.variables.functions.BaseUserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.UserMethodVariable" -> "torch._dynamo.variables.functions.UserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.WrappedUserFunctionVariable" -> "torch._dynamo.variables.functions.UserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.WrappedUserMethodVariable" -> "torch._dynamo.variables.functions.UserMethodVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.functions.WrapperUserFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.AssociativeScanHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.AutoFunctionalizeHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.AutogradFunctionApplyVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.CallTorchbindHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.CheckpointHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.WrapHigherOrderVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.CondHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.ExecutorchCallDelegateHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.ExportTracepointHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.FlexAttentionHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.FunctionalCallVariable" -> "torch._dynamo.variables.higher_order_ops.FunctorchHigherOrderVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.FunctorchHigherOrderVariable" -> "torch._dynamo.variables.functions.UserFunctionVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.HintsWrapperHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.InvokeSubgraphHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.WrapHigherOrderVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.MapHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.OutDtypeHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.PrimHOPBaseVariable" -> "torch._dynamo.variables.higher_order_ops.WrapHigherOrderVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.RunWithRNGStateHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.ScanHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.StrictModeHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.TraceWrappedHigherOrderOperatorVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.WhileLoopHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.WrapHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.WrapWithAutocastHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.higher_order_ops.WrapWithSetGradEnabledHigherOrderVariable" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.CountIteratorVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.CycleIteratorVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.FilterVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.IteratorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.ItertoolsVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.MapVariable" -> "torch._dynamo.variables.iter.ZipVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.RepeatIteratorVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.iter.ZipVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lazy.LazyVariableTracker" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.BaseListVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.CommonListMethodsVariable" -> "torch._dynamo.variables.lists.BaseListVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.DequeVariable" -> "torch._dynamo.variables.lists.CommonListMethodsVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.ListIteratorVariable" -> "torch._dynamo.variables.iter.IteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.ListVariable" -> "torch._dynamo.variables.lists.CommonListMethodsVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.NamedTupleVariable" -> "torch._dynamo.variables.lists.TupleVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.RangeVariable" -> "torch._dynamo.variables.lists.BaseListVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.RestrictedListSubclassVariable" -> "torch._dynamo.variables.lists.ListVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.SizeVariable" -> "torch._dynamo.variables.lists.TupleVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.SliceVariable" -> "torch._dynamo.variables.lists.BaseListVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.TupleIteratorVariable" -> "torch._dynamo.variables.lists.ListIteratorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.lists.TupleVariable" -> "torch._dynamo.variables.lists.BaseListVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.AutogradEngineVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.AutogradFunctionContextVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.AutogradFunctionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.CellVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.ComptimeVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.ConstantLikeVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.ConstantRegexMatchVariable" -> "torch._dynamo.variables.misc.ConstantLikeVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.DebuggingVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.DelayGraphBreakVariable" -> "torch._dynamo.variables.misc.UnknownVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.DeletedVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.ExceptionVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.GetAttrVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.GetSetDescriptorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.InspectBoundArgumentsVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.InspectParameterVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.InspectSignatureVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.LambdaVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.LoggingLoggerVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.MethodWrapperVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.NewGlobalVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.NullVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.NumpyDTypeVariable" -> "torch._dynamo.variables.misc.ConstantLikeVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.NumpyTypeInfoVariable" -> "torch._dynamo.variables.misc.ConstantLikeVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.NumpyVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.PythonModuleVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.RandomClassVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.RandomVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.RegexPatternVariable" -> "torch._dynamo.variables.misc.ConstantLikeVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.StringFormatVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.SuperVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.TorchVersionVariable" -> "torch._dynamo.variables.misc.ConstantLikeVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.TypingVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.UnknownVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.misc.WeakRefVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.nn_module.FSDPManagedNNModuleVariable" -> "torch._dynamo.variables.nn_module.UnspecializedNNModuleVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.nn_module.NNModuleVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.nn_module.UnspecializedBuiltinNNModuleVariable" -> "torch._dynamo.variables.nn_module.UnspecializedNNModuleVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.nn_module.UnspecializedNNModuleVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.optimizer.OptimizerVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.script_object.TorchScriptObjectVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.sdpa.SDPAParamsVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.DataPtrVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.FakeItemVariable" -> "torch._dynamo.variables.tensor.TensorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.NumpyNdarrayVariable" -> "torch._dynamo.variables.tensor.TensorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.SymNodeVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.TensorSubclassVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.TensorVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.UnspecializedPythonVariable" -> "torch._dynamo.variables.tensor.TensorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.tensor.UntypedStorageVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch.BaseTorchVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch.TorchCtxManagerClassVariable" -> "torch._dynamo.variables.torch.BaseTorchVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch.TorchInGraphFunctionVariable" -> "torch._dynamo.variables.torch.BaseTorchVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch_function.TensorWithTFOverrideVariable" -> "torch._dynamo.variables.tensor.TensorVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch_function.TorchFunctionModeStackVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch_function.TorchFunctionModeVariable" -> "torch._dynamo.variables.ctx_manager.GenericContextWrappingVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.torch_function.populate_builtin_to_tensor_fn_map.GetMethodMode" -> "torch.overrides.BaseTorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.FrozenDataClassVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.KeyedJaggedTensorVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.MutableMappingVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.RandomVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.RemovableHandleVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.SourcelessGraphModuleVariable" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.UserDefinedClassVariable" -> "torch._dynamo.variables.user_defined.UserDefinedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.UserDefinedObjectVariable" -> "torch._dynamo.variables.user_defined.UserDefinedVariable" [arrowhead="empty", arrowtail="none"];
"torch._dynamo.variables.user_defined.UserDefinedVariable" -> "torch._dynamo.variables.base.VariableTracker" [arrowhead="empty", arrowtail="none"];
"torch._export.converter.ExplainTS2FXGraphConverter" -> "torch._export.converter.TS2FXGraphConverter" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.assume_constant_result.AssumeConstantResult" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.autograd_function.AutogradFunction" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.autograd_function.MyAutogradFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.class_method.ClassMethod" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_branch_class_method.CondBranchClassMethod" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_branch_class_method.MySubModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_branch_nested_function.CondBranchNestedFunction" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_branch_nonlocal_variables.CondBranchNonlocalVariables" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_closed_over_variable.CondClosedOverVariable" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_operands.CondOperands" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.cond_predicate.CondPredicate" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.constrain_as_size_example.ConstrainAsSizeExample" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.constrain_as_value_example.ConstrainAsValueExample" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.decorator.Decorator" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dictionary.Dictionary" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_assert.DynamicShapeAssert" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_constructor.DynamicShapeConstructor" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_if_guard.DynamicShapeIfGuard" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_map.DynamicShapeMap" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_round.DynamicShapeRound" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_slicing.DynamicShapeSlicing" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.dynamic_shape_view.DynamicShapeView" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.fn_with_kwargs.FnWithKwargs" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.list_contains.ListContains" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.list_unpack.ListUnpack" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.model_attr_mutation.ModelAttrMutation" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.nested_function.NestedFunction" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.null_context_manager.NullContextManager" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.optional_input.OptionalInput" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.pytree_flatten.PytreeFlatten" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.scalar_output.ScalarOutput" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.specialized_attribute.SpecializedAttribute" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.static_for_loop.StaticForLoop" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.static_if.StaticIf" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.tensor_setattr.TensorSetattr" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.type_reflection_method.TypeReflectionMethod" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.unsupported_operator.TorchSymMin" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.db.examples.user_input_mutation.UserInputMutation" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._export.non_strict_utils._NonStrictTorchFunctionHandler" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportInterpreter" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.add_runtime_assertions_for_constraints_pass._AddRuntimeAssertionsForInlineConstraintsPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.collect_tracepoints_pass.CollectTracepointsPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.constant_folding.ConstantFolder" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.functionalize_side_effectful_ops_pass._FunctionalizeSideEffectfulOpsPass" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.remove_runtime_assertions._RemoveRuntimeAssertionsPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch._export.passes.replace_view_ops_with_view_copy_ops_pass.ReplaceViewOpsWithViewCopyOpsPass" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.Argument" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.ConstantValue" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.InputSpec" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.OptionalTensorArgument" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.OutputSpec" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymBool" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymBoolArgument" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymExprHint" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymFloat" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymFloatArgument" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymInt" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.serde.schema.SymIntArgument" -> "torch._export.serde.union._Union" [arrowhead="empty", arrowtail="none"];
"torch._export.verifier.TrainingIRVerifier" -> "torch._export.verifier.Verifier" [arrowhead="empty", arrowtail="none"];
"torch._export.wrappers.ExportTracepoint" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheDetails" -> "torch._inductor.codecache.FxGraphHashDetails" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.autograd_cache.AOTAutogradCachePickler" -> "torch._inductor.codecache.FxGraphCachePickler" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.autograd_cache.CompiledBackward" -> "torch._functorch._aot_autograd.autograd_cache.FXGraphCacheLoadable" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.autograd_cache.CompiledForward" -> "torch._functorch._aot_autograd.autograd_cache.FXGraphCacheLoadable" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.autograd_cache.FXGraphCacheMiss" -> "torch._functorch._aot_autograd.autograd_cache.BypassAOTAutogradCache" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDedupeWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd.post_compile.CompiledFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd.post_compile.CompiledFunction._double_backward.CompiledFunctionBackward" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchSubclassWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.AOTSyntheticBaseWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.DebugAssertWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.EffectTokensWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.FakifiedOutWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.FunctionalizedRngRuntimeWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.runtime_wrappers.RuntimeWrapper" -> "torch._functorch._aot_autograd.runtime_wrappers.CompilerWrapper" [arrowhead="empty", arrowtail="none"];
"torch._functorch._aot_autograd.subclass_parametrization.UnwrapTensorSubclass" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._functorch.aot_autograd.SerializableAOTDispatchCompiler" -> "torch._functorch.aot_autograd.AOTDispatchCompiler" [arrowhead="empty", arrowtail="none"];
"torch._functorch.aot_autograd.aot_module.AOTModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._functorch.autograd_function.AutogradFunctionApply" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._functorch.autograd_function.AutogradFunctionApply.__call__.ApplyTemplate" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._functorch.autograd_function.CtxCustomSave" -> "torch._functorch.autograd_function.WrappedCtx" [arrowhead="empty", arrowtail="none"];
"torch._functorch.autograd_function.CtxWithSavedTensors" -> "torch._functorch.autograd_function.WrappedCtx" [arrowhead="empty", arrowtail="none"];
"torch._functorch.autograd_function.CustomFunctionHigherOrderOperator" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._functorch.compilers.DebugInterpreter" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._functorch.fx_minifier.ConcreteProp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._functorch.make_functional.FunctionalModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._functorch.make_functional.FunctionalModuleWithBuffers" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch._functorch.pyfunctorch.FunctionalizeInterpreter" -> "torch._functorch.pyfunctorch.FuncTorchInterpreter" [arrowhead="empty", arrowtail="none"];
"torch._functorch.pyfunctorch.GradInterpreter" -> "torch._functorch.pyfunctorch.FuncTorchInterpreter" [arrowhead="empty", arrowtail="none"];
"torch._functorch.pyfunctorch.JvpInterpreter" -> "torch._functorch.pyfunctorch.FuncTorchInterpreter" [arrowhead="empty", arrowtail="none"];
"torch._functorch.pyfunctorch.VmapInterpreter" -> "torch._functorch.pyfunctorch.FuncTorchInterpreter" [arrowhead="empty", arrowtail="none"];
"torch._guards.ChainedSource" -> "torch._guards.Source" [arrowhead="empty", arrowtail="none"];
"torch._guards.DuplicateInputs" -> "torch._guards.GuardEnvExpr" [arrowhead="empty", arrowtail="none"];
"torch._guards.GlobalContext" -> "torch._guards.Checkpointable" [arrowhead="empty", arrowtail="none"];
"torch._guards.GuardsContext" -> "torch._guards.Checkpointable" [arrowhead="empty", arrowtail="none"];
"torch._guards.InvokeSubgraphCache" -> "torch._guards.HopSubgraphCache" [arrowhead="empty", arrowtail="none"];
"torch._guards.ModuleContext" -> "torch._guards.Checkpointable" [arrowhead="empty", arrowtail="none"];
"torch._guards.StorageOverlap" -> "torch._guards.GuardEnvExpr" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.associative_scan.AssociativeScanOp" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.AliasViewInfo" -> "torch._higher_order_ops.auto_functionalize.ViewInfo" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.AsStridedViewInfo" -> "torch._higher_order_ops.auto_functionalize.ViewInfo" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.AutoFunctionalized" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.AutoFunctionalizedV2" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.NotView" -> "torch._higher_order_ops.auto_functionalize.ViewInfo" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.auto_functionalize.SliceViewInfo" -> "torch._higher_order_ops.auto_functionalize.ViewInfo" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.cond.CondAutogradOp" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.cond.CondOp" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.effects.WithEffects" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.executorch_call_delegate.ExecutorchCallDelegate" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.flex_attention.FlexAttentionAutogradOp" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.flex_attention.FlexAttentionBackwardHOP" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.flex_attention.FlexAttentionHOP" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.foreach_map.ForeachMap" -> "torch._higher_order_ops.prim_hop_base.PrimHOPBase" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.hints_wrap.HintsWrapper" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.invoke_subgraph.InvokeSubgraphAutogradOp" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.invoke_subgraph.InvokeSubgraphHOP" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.map.MapAutogradOp" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.map.MapImpl" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.map.MapWrapper" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.out_dtype.OutDtypeOperator" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.prim_hop_base.PrimHOPBase" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.prim_hop_base.PrimHOPBaseFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.run_const_graph.RunConstGraph" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.scan.ScanOp" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.strict_mode.StrictMode" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.torchbind.CallTorchBind" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.triton_kernel_wrap.TracingTritonHOPifier" -> "torch._higher_order_ops.triton_kernel_wrap.TritonHOPifier" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.triton_kernel_wrap.TritonKernelWrapperFunctional" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.triton_kernel_wrap.TritonKernelWrapperMutation" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.while_loop.WhileLoopOp" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.wrap.TagActivationCheckpoint" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.wrap.Wrap" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.wrap.WrapActivationCheckpoint" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.wrap.WrapWithAutocast" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._higher_order_ops.wrap.WrapWithSetGradEnabled" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.artifacts._MMRankingA100.MMRankingA100" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.artifacts._MMRankingH100.MMRankingH100" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.artifacts._MixedMMA100.MixedMMA100" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.artifacts._MixedMMH100.MixedMMH100" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.artifacts._PadMMA100.PadMMA100" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicRegression" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.autoheuristic.AutoHeuristicSelectAlgorithm" -> "torch._inductor.autoheuristic.autoheuristic.AutoHeuristic" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicDecision" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristic" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristicRegression" -> "torch._inductor.autoheuristic.learnedheuristic_interface.LearnedHeuristic" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.CUDABenchmarkRequest" -> "torch._inductor.autotune_process.BenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.CUDABenchmarkRequest" -> "torch._inductor.autotune_process.GPUDeviceBenchmarkMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.CppBenchmarkRequest" -> "torch._inductor.autotune_process.BenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.CppBenchmarkRequest" -> "torch._inductor.autotune_process.CPUDeviceBenchmarkMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TestBenchmarkRequest" -> "torch._inductor.autotune_process.BenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TritonBenchmarkRequest" -> "torch._inductor.autotune_process.BenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TritonCPUBenchmarkRequest" -> "torch._inductor.autotune_process.CPUDeviceBenchmarkMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TritonCPUBenchmarkRequest" -> "torch._inductor.autotune_process.TritonBenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TritonGPUBenchmarkRequest" -> "torch._inductor.autotune_process.GPUDeviceBenchmarkMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.autotune_process.TritonGPUBenchmarkRequest" -> "torch._inductor.autotune_process.TritonBenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.CppPythonBindingsCodeCache" -> "torch._inductor.codecache.CppCodeCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.CppWrapperCodeCache" -> "torch._inductor.codecache.CppPythonBindingsCodeCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.HalideCodeCache" -> "torch._inductor.codecache.CppPythonBindingsCodeCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.LambdaFuture" -> "torch._inductor.codecache.CodeCacheFuture" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.LocalCache" -> "torch._inductor.codecache.CacheBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.PersistentCache" -> "torch._inductor.codecache.CacheBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codecache.TritonFuture" -> "torch._inductor.codecache.CodeCacheFuture" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.BracesBuffer" -> "torch._inductor.utils.IndentedBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.CppWrapperKernelArgs" -> "torch._inductor.codegen.common.KernelArgs" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.DeferredLine" -> "torch._inductor.utils.DeferredLineBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.Kernel" -> "torch._inductor.codegen.common.CodeGen" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.OpOverrides" -> "torch._inductor.codegen.common.OpDecompositions" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.common.PythonPrinter" -> "torch.utils._sympy.printers.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppKernel" -> "torch._inductor.codegen.common.Kernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppKernelProxy" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppOverrides" -> "torch._inductor.codegen.common.OpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppScheduling" -> "torch._inductor.scheduler.BaseScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppTile2DKernel" -> "torch._inductor.codegen.cpp.CppVecKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppTile2DOverrides" -> "torch._inductor.codegen.cpp.CppVecOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppVecKernel" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppVecOverrides" -> "torch._inductor.codegen.cpp.CppOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.CppWrapperKernelGroup" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.OuterLoopFusedKernel" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp.OuterLoopFusedSchedulerNode" -> "torch._inductor.scheduler.FusedSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_bmm_template.CppBmmTemplate" -> "torch._inductor.codegen.cpp_gemm_template.CppGemmTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_flex_attention_template.CppFlexAttentionTemplate" -> "torch._inductor.codegen.cpp_template.CppTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_gemm_template.CppGemmTemplate" -> "torch._inductor.codegen.cpp_template.CppTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroBrgemm" -> "torch._inductor.codegen.cpp_micro_gemm.CppMicroGemm" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmAMX" -> "torch._inductor.codegen.cpp_micro_gemm.CppMicroGemm" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmFP32Vec" -> "torch._inductor.codegen.cpp_micro_gemm.CppMicroGemm" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_micro_gemm.CppMicroGemmRef" -> "torch._inductor.codegen.cpp_micro_gemm.CppMicroGemm" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_template.CppTemplate" -> "torch._inductor.codegen.common.KernelTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_template_kernel.CppTemplateCaller" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_template_kernel.CppTemplateKernel" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_utils.CppCSEVariable" -> "torch._inductor.codegen.common.CSEVariable" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_utils.CppPrinter" -> "torch.utils._sympy.printers.CppPrinter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_utils.LocalizeBufferHandler" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_wrapper_cpu_array_ref.CppWrapperCpuArrayRef" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_wrapper_gpu.CppWrapperGpu" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_wrapper_gpu.DeferredGpuGridLine" -> "torch._inductor.utils.DeferredLineBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpp_wrapper_gpu.DeferredGpuKernelLine" -> "torch._inductor.utils.DeferredLineBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cpu_device_op_overrides.CpuDeviceOpOverrides" -> "torch._inductor.codegen.common.DeviceOpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_cpp_scheduling.CUDACPPScheduling" -> "torch._inductor.scheduler.BaseScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDAKernel" -> "torch._inductor.codegen.common.Kernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDATemplateCaller" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_kernel.CUDATemplateKernel" -> "torch._inductor.codegen.cuda.cuda_kernel.CUDAKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_template.CUDATemplate" -> "torch._inductor.codegen.common.KernelTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.cuda_template.CUTLASSTemplate" -> "torch._inductor.codegen.cuda.cuda_template.CUDATemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.device_op_overrides.CUDADeviceOpOverrides" -> "torch._inductor.codegen.common.DeviceOpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASS2xGemmTemplate" -> "torch._inductor.codegen.cuda.gemm_template.CUTLASSGemmTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASS3xGemmTemplate" -> "torch._inductor.codegen.cuda.gemm_template.CUTLASSGemmTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda.gemm_template.CUTLASSGemmTemplate" -> "torch._inductor.codegen.cuda.cuda_template.CUTLASSTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" -> "torch._inductor.scheduler.BaseScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.halide.HalideCSEVariable" -> "torch._inductor.codegen.common.CSEVariable" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.halide.HalideKernel" -> "torch._inductor.codegen.simd.SIMDKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.halide.HalideOverrides" -> "torch._inductor.codegen.common.OpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.halide.HalidePrinter" -> "torch._inductor.codegen.common.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.halide.HalideScheduling" -> "torch._inductor.codegen.simd.SIMDScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.AllocFromPoolLine" -> "torch._inductor.codegen.memory_planning.PoolMemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.Allocation" -> "torch._inductor.codegen.memory_planning.AllocationTreeNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.ClearCacheOnAllocateMixin" -> "torch._inductor.codegen.memory_planning.MemorySplitProtocol" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.DeallocFromPoolLine" -> "torch._inductor.codegen.memory_planning.PoolMemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.Empty" -> "torch._inductor.codegen.memory_planning.AllocationTreeNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.PoolMemoryPlanningLine" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.SpatialSplit" -> "torch._inductor.codegen.memory_planning.AllocationTreeNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.SpatialSplit" -> "torch._inductor.codegen.memory_planning.ClearCacheOnAllocateMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.TemporalSplit" -> "torch._inductor.codegen.memory_planning.AllocationTreeNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.memory_planning.TemporalSplit" -> "torch._inductor.codegen.memory_planning.ClearCacheOnAllocateMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.ck_conv_template.CKGroupedConvFwdTemplate" -> "torch._inductor.codegen.rocm.ck_template.CKTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.ck_template.CKTemplate" -> "torch._inductor.codegen.rocm.rocm_template.ROCmTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.ck_universal_gemm_template.CKGemmTemplate" -> "torch._inductor.codegen.rocm.ck_template.CKTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_benchmark_request.ROCmBenchmarkRequest" -> "torch._inductor.autotune_process.BenchmarkRequest" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_benchmark_request.ROCmBenchmarkRequest" -> "torch._inductor.autotune_process.GPUDeviceBenchmarkMixin" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_cpp_scheduling.ROCmCPPScheduling" -> "torch._inductor.scheduler.BaseScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmKernel" -> "torch._inductor.codegen.common.Kernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmTemplateCaller" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_kernel.ROCmTemplateKernel" -> "torch._inductor.codegen.rocm.rocm_kernel.ROCmKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_template.ROCmTemplate" -> "torch._inductor.codegen.common.KernelTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.rocm.rocm_template_buffer.ROCmTemplateBuffer" -> "torch._inductor.ir.TemplateBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd.IterationRangesEntry" -> "torch._inductor.codegen.simd.IterationRanges" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd.IterationRangesRoot" -> "torch._inductor.codegen.simd.IterationRanges" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd.SIMDKernel" -> "torch._inductor.codegen.common.Kernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd.SIMDScheduling" -> "torch._inductor.scheduler.BaseScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd_kernel_features.DisableReduction" -> "torch._inductor.codegen.simd_kernel_features.NodeScheduleMarker" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.simd_kernel_features.EnableReduction" -> "torch._inductor.codegen.simd_kernel_features.NodeScheduleMarker" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonCSE" -> "torch._inductor.codegen.common.CSE" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonCSEVariable" -> "torch._inductor.codegen.common.CSEVariable" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonKernel" -> "torch._inductor.codegen.simd.SIMDKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonKernelOverrides" -> "torch._inductor.codegen.triton.TritonOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonOverrides" -> "torch._inductor.codegen.common.OpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonPrinter" -> "torch._inductor.codegen.common.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton.TritonScheduling" -> "torch._inductor.codegen.simd.SIMDScheduling" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel" -> "torch._inductor.codegen.common.Kernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.triton_split_scan.TritonSplitScanKernel" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.AllocateLine" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.CommBufferAllocateLine" -> "torch._inductor.codegen.wrapper.CommBufferLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.CommBufferFreeLine" -> "torch._inductor.codegen.wrapper.CommBufferLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.CommBufferLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.EnterDeviceContextManagerLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.EnterSubgraphLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.ExitDeviceContextManagerLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.ExitSubgraphLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.FreeIfNotReusedLine" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.MemoryPlanningLine" -> "torch._inductor.codegen.wrapper.WrapperLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.NullLine" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" -> "torch._inductor.codegen.common.CodeGen" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.ReuseLine" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.wrapper.SubgraphPythonWrapperCodegen" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="empty", arrowtail="none"];
"torch._inductor.codegen.xpu.device_op_overrides.XPUDeviceOpOverrides" -> "torch._inductor.codegen.common.DeviceOpOverrides" [arrowhead="empty", arrowtail="none"];
"torch._inductor.compile_fx._InProcessFxCompile" -> "torch._inductor.compile_fx.FxCompile" [arrowhead="empty", arrowtail="none"];
"torch._inductor.compiler_bisector.BinarySubsystem" -> "torch._inductor.compiler_bisector.Subsystem" [arrowhead="empty", arrowtail="none"];
"torch._inductor.compiler_bisector.BisectSubsystem" -> "torch._inductor.compiler_bisector.Subsystem" [arrowhead="empty", arrowtail="none"];
"torch._inductor.compiler_bisector.ConfigChange" -> "torch._inductor.compiler_bisector.BinarySubsystem" [arrowhead="empty", arrowtail="none"];
"torch._inductor.constant_folding.ConstantFolder" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpp_builder.CppOptions" -> "torch._inductor.cpp_builder.BuildOptionsBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpp_builder.CppTorchDeviceOptions" -> "torch._inductor.cpp_builder.CppTorchOptions" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpp_builder.CppTorchOptions" -> "torch._inductor.cpp_builder.CppOptions" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.InvalidVecISA" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecAMX" -> "torch._inductor.cpu_vec_isa.VecAVX512" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecAVX2" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecAVX512" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecNEON" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecSVE" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecVSX" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cpu_vec_isa.VecZVECTOR" -> "torch._inductor.cpu_vec_isa.VecISA" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cudagraph_trees.AliasesNewOutput" -> "torch._inductor.cudagraph_trees.OutputAliasInfo" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cudagraph_trees.AliasesPriorGraphOutput" -> "torch._inductor.cudagraph_trees.OutputAliasInfo" [arrowhead="empty", arrowtail="none"];
"torch._inductor.cudagraph_trees._UnaliasedStorage" -> "torch._inductor.cudagraph_trees.OutputAliasInfo" [arrowhead="empty", arrowtail="none"];
"torch._inductor.dependencies.MemoryDep" -> "torch._inductor.dependencies.Dep" [arrowhead="empty", arrowtail="none"];
"torch._inductor.dependencies.RecordLoadStore" -> "torch._inductor.ops_handler.KernelFormatterHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.dependencies.StarDep" -> "torch._inductor.dependencies.Dep" [arrowhead="empty", arrowtail="none"];
"torch._inductor.dependencies.WeakDep" -> "torch._inductor.dependencies.Dep" [arrowhead="empty", arrowtail="none"];
"torch._inductor.dependencies._RecordLoadStoreInner" -> "torch._inductor.ops_handler.MockHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.exc.CUDACompileError" -> "torch._inductor.exc.CppCompileError" [arrowhead="empty", arrowtail="none"];
"torch._inductor.exc.LoweringException" -> "torch._inductor.exc.OperatorIssue" [arrowhead="empty", arrowtail="none"];
"torch._inductor.exc.MissingOperatorWithDecomp" -> "torch._inductor.exc.OperatorIssue" [arrowhead="empty", arrowtail="none"];
"torch._inductor.exc.MissingOperatorWithoutDecomp" -> "torch._inductor.exc.OperatorIssue" [arrowhead="empty", arrowtail="none"];
"torch._inductor.freezing.ErasedTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchAddPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchClampPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchMathOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchDetachPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchMathOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchDivPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchFusion" -> "torch._inductor.fx_passes.group_batch_fusion.GroupBatchFusionBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchLayernormFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchLinearLHSFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchMathOpsPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchMulPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchNanToNumPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchMathOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" -> "torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsFusionFactory" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchReLuPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchReLuPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSigmoidPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSigmoidPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchSubPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseMathOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchTanhPostGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPostGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.BatchTanhPreGradFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchPointwiseOpsPreGradFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.GroupFusion" -> "torch._inductor.fx_passes.group_batch_fusion.GroupBatchFusionBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.GroupLinearFusion" -> "torch._inductor.fx_passes.group_batch_fusion.GroupFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.PostGradBatchLinearFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.group_batch_fusion.PreGradBatchLinearFusion" -> "torch._inductor.fx_passes.group_batch_fusion.BatchFusion" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.joint_graph.UniformValueConstantFolder" -> "torch._inductor.constant_folding.ConstantFolder" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.micro_pipeline_tp._ScaledMatmul" -> "torch._inductor.fx_passes.micro_pipeline_tp._Matmul" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.pre_grad.remove_identity.IdentityRemover" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.split_cat.GetItem" -> "torch._inductor.pattern_matcher.CallFunction" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.split_cat.TorchSplit" -> "torch._inductor.pattern_matcher.CallFunction" [arrowhead="empty", arrowtail="none"];
"torch._inductor.fx_passes.split_cat.UnbindCatRemover" -> "torch._inductor.fx_passes.split_cat.SplitCatSimplifier" [arrowhead="empty", arrowtail="none"];
"torch._inductor.graph.GraphLowering" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.graph.SubgraphLowering" -> "torch._inductor.graph.GraphLowering" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.AssertScalar" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.BaseConstant" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.BaseView" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Buffer" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.CUDATemplateBuffer" -> "torch._inductor.ir.TemplateBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.CommBufferLayout" -> "torch._inductor.ir.FixedLayout" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ComplexView" -> "torch._inductor.ir.FallbackKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ComputedBuffer" -> "torch._inductor.ir.OperationBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ConcatKernel" -> "torch._inductor.ir.NopKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Conditional" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Constant" -> "torch._inductor.ir.BaseConstant" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ConstantBuffer" -> "torch._inductor.ir.InputBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.CppTemplateBuffer" -> "torch._inductor.ir.TemplateBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.DeviceCopy" -> "torch._inductor.ir.ExternKernelOut" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.DonatedBuffer" -> "torch._inductor.ir.InputBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.DtypeView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.DynamicScalar" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.EffectfulKernel" -> "torch._inductor.ir.FallbackKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ExpandView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ExternKernel" -> "torch._inductor.ir.InputsKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ExternKernelAlloc" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ExternKernelOut" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.FallbackKernel" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.FixedLayout" -> "torch._inductor.ir.Layout" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.FlexibleLayout" -> "torch._inductor.ir.Layout" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.GenericView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.IndexPutFallback" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.IndexingConstant" -> "torch._inductor.ir.BaseConstant" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.InplaceBernoulliFallback" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.InplaceCopyFallback" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.InputBuffer" -> "torch._inductor.ir.Buffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.InputsKernel" -> "torch._inductor.ir.OperationBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.InvokeSubgraph" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Layout" -> "torch._inductor.ir.OutputSpec" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Loops" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MultiOutput" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MultiOutputLayout" -> "torch._inductor.ir.OutputSpec" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MultiTemplateBuffer" -> "torch._inductor.ir.TritonTemplateBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MutableBox" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MutatingFirstArgExternKernel" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MutationLayoutSHOULDREMOVE" -> "torch._inductor.ir.Layout" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.MutationOutput" -> "torch._inductor.ir.Buffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.NonOwningLayout" -> "torch._inductor.ir.Layout" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.NoneAsConstantBuffer" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.NoneLayout" -> "torch._inductor.ir.OutputSpec" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.NopKernel" -> "torch._inductor.ir.InputsKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.OperationBuffer" -> "torch._inductor.ir.Buffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.OperationBuffer" -> "torch._inductor.ir.Operation" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.PermuteView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Pointwise" -> "torch._inductor.ir.Loops" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.RandomSeeds" -> "torch._inductor.ir.ExternKernelOut" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Reduction" -> "torch._inductor.ir.Loops" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ReinterpretView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ResizeStorageBytes" -> "torch._inductor.ir.MutatingFirstArgExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Scan" -> "torch._inductor.ir.Loops" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Scatter" -> "torch._inductor.ir.Pointwise" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ScatterFallback" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.SetSourceTensorKernel" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.ShapeAsConstantBuffer" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.SliceView" -> "torch._inductor.ir.View" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Sort" -> "torch._inductor.ir.Loops" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.SplitScan" -> "torch._inductor.ir.Scan" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.SqueezeView" -> "torch._inductor.ir.BaseView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.StorageBox" -> "torch._inductor.ir.MutableBox" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TMADescriptor" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TemplateBuffer" -> "torch._inductor.ir.OperationBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TensorBox" -> "torch._inductor.ir.MutableBox" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TorchBindObject" -> "torch._inductor.ir.IRNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TritonTemplateBuffer" -> "torch._inductor.ir.TemplateBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.TritonTemplateCallerBase" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.UserDefinedTritonKernel" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.View" -> "torch._inductor.ir.GenericView" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.WelfordReduction" -> "torch._inductor.ir.Reduction" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir.WhileLoop" -> "torch._inductor.ir.ExternKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir._CollectiveKernel" -> "torch._inductor.ir.FallbackKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ir._WaitKernel" -> "torch._inductor.ir._CollectiveKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.loop_body.InterpreterShim" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.loop_body.LightTracer" -> "torch.fx.proxy.TracerBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.loop_body.LoopBodyBlock.__init__.CaptureIndexing" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.ConvolutionBinary" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.ConvolutionBinaryInplace" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.ConvolutionTransposeUnary" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.ConvolutionUnary" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.LinearBinary" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.LinearUnary" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.MKLPackedLinear" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.MkldnnRnnLayer" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.QConvPointWiseBinaryPT2E" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.QConvPointWisePT2E" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.QLinearPointwiseBinaryPT2E" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mkldnn_ir.QLinearPointwisePT2E" -> "torch._inductor.ir.ExternKernelAlloc" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mock_cache.MockBackend" -> "torch._inductor.remote_cache.RemoteCacheBackend" [arrowhead="empty", arrowtail="none"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache.Stats" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ops_handler.AddParenHandler" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ops_handler.ExtractConstantsHandler" -> "torch._inductor.ops_handler.NoopHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.ops_handler.SimpleCSEHandler" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.output_code.CompiledAOTI" -> "torch._inductor.output_code.OutputCode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.output_code.CompiledFxGraph" -> "torch._inductor.output_code.OutputCode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.output_code.CompiledFxGraphConstantsWithGm" -> "torch._inductor.output_code.CompiledFxGraphConstants" [arrowhead="empty", arrowtail="none"];
"torch._inductor.output_code.MockFXGraphCacheOutput" -> "torch._inductor.output_code.OutputCode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.Arg" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallFunction" -> "torch._inductor.pattern_matcher._TargetArgsExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallFunctionVarArgs" -> "torch._inductor.pattern_matcher._TargetExprVarArgs" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallMethod" -> "torch._inductor.pattern_matcher._TargetArgsExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallMethodVarArgs" -> "torch._inductor.pattern_matcher._TargetExprVarArgs" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallModule" -> "torch._inductor.pattern_matcher._TargetArgsExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.CallModuleVarArgs" -> "torch._inductor.pattern_matcher._TargetExprVarArgs" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.ExclusiveKeywordArg" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.GraphPatternEntry" -> "torch._inductor.pattern_matcher.PatternEntry" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.Ignored" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.KeywordArg" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.ListOf" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.LoweringPatternEntry" -> "torch._inductor.pattern_matcher.PatternEntry" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.MultiOutputPattern" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.RepeatedExpr" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.ReplacementPatternEntry" -> "torch._inductor.pattern_matcher.PatternEntry" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.ReplacementPatternEntry.replace_with_graph.Replacer" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher._TargetArgsExpr" -> "torch._inductor.pattern_matcher._TargetExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher._TargetExpr" -> "torch._inductor.pattern_matcher.PatternExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher._TargetExprVarArgs" -> "torch._inductor.pattern_matcher._TargetExpr" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.clone_graph.CopyGraph" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.pattern_matcher.fx_to_pattern.Converter" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RedisRemoteCache" -> "torch._inductor.remote_cache.RemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RedisRemoteCacheBackend" -> "torch._inductor.remote_cache.RemoteCacheBackend" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteAOTAutogradCache" -> "torch._inductor.remote_cache.RedisRemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteAutotuneCache" -> "torch._inductor.remote_cache.RedisRemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteBundledAutotuneCache" -> "torch._inductor.remote_cache.RedisRemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteCacheJsonSerde" -> "torch._inductor.remote_cache.RemoteCacheSerde" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteCachePassthroughSerde" -> "torch._inductor.remote_cache.RemoteCacheSerde" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteDynamoPGOCache" -> "torch._inductor.remote_cache.RedisRemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.remote_cache.RemoteFxGraphCache" -> "torch._inductor.remote_cache.RedisRemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.runtime.autotune_cache.LocalAutotuneCache" -> "torch._inductor.remote_cache.RemoteCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.runtime.autotune_cache._LocalAutotuneCacheBackend" -> "torch._inductor.remote_cache.RemoteCacheBackend" [arrowhead="empty", arrowtail="none"];
"torch._inductor.runtime.benchmarking.TritonBenchmarker" -> "torch._inductor.runtime.benchmarking.Benchmarker" [arrowhead="empty", arrowtail="none"];
"torch._inductor.runtime.triton_heuristics.DebugAutotuner" -> "torch._inductor.runtime.triton_heuristics.CachingAutotuner" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.ExternKernelSchedulerNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.ForeachKernelSchedulerNode" -> "torch._inductor.scheduler.FusedSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.FusedSchedulerNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.GroupedSchedulerNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.NopKernelSchedulerNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.SchedulerDonatedBuffer" -> "torch._inductor.scheduler.SchedulerBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.scheduler.SchedulerNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.AlgorithmSelectorCache" -> "torch._inductor.codecache.PersistentCache" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.ExternKernelCaller" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.ModificationWrapper" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.TritonTemplate" -> "torch._inductor.codegen.common.KernelTemplate" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.TritonTemplateCaller" -> "torch._inductor.ir.TritonTemplateCallerBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.TritonTemplateKernel" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="empty", arrowtail="none"];
"torch._inductor.select_algorithm.TritonTemplateKernel.load_input.StoreOutputSubstitution" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.sizevars.SimplifyIndexing" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.subgraph_lowering.PointwiseSubgraphLowering" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch._inductor.subgraph_lowering.TracingOpsHandler" -> "torch._inductor.ops_handler.WrapperHandler" [arrowhead="empty", arrowtail="none"];
"torch._inductor.test_case.TestCase" -> "torch._dynamo.test_case.TestCase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.test_operators.Realize" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._inductor.utils.DelayReplaceLine" -> "torch._inductor.utils.DeferredLineBase" [arrowhead="empty", arrowtail="none"];
"torch._inductor.utils.FakeIndentedBuffer" -> "torch._inductor.utils.IndentedBuffer" [arrowhead="empty", arrowtail="none"];
"torch._inductor.virtualized.NullKernelHandler" -> "torch._inductor.virtualized.NullHandler" [arrowhead="empty", arrowtail="none"];
"torch._lazy.closure.AsyncClosureHandler" -> "torch._lazy.closure.ClosureHandler" [arrowhead="empty", arrowtail="none"];
"torch._lobpcg.LOBPCGAutogradFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.bool_" -> "torch._numpy._dtypes.generic" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.complex128" -> "torch._numpy._dtypes.complexfloating" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.complex64" -> "torch._numpy._dtypes.complexfloating" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.complexfloating" -> "torch._numpy._dtypes.inexact" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.float16" -> "torch._numpy._dtypes.floating" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.float32" -> "torch._numpy._dtypes.floating" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.float64" -> "torch._numpy._dtypes.floating" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.floating" -> "torch._numpy._dtypes.inexact" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.inexact" -> "torch._numpy._dtypes.number" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.int16" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.int32" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.int64" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.int8" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.integer" -> "torch._numpy._dtypes.number" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.number" -> "torch._numpy._dtypes.generic" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.signedinteger" -> "torch._numpy._dtypes.integer" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.uint16" -> "torch._numpy._dtypes.unsignedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.uint32" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.uint64" -> "torch._numpy._dtypes.signedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.uint8" -> "torch._numpy._dtypes.unsignedinteger" [arrowhead="empty", arrowtail="none"];
"torch._numpy._dtypes.unsignedinteger" -> "torch._numpy._dtypes.integer" [arrowhead="empty", arrowtail="none"];
"torch._ops.HigherOrderOperator" -> "torch._ops.OperatorBase" [arrowhead="empty", arrowtail="none"];
"torch._ops.OpOverload" -> "torch._ops.OperatorBase" [arrowhead="empty", arrowtail="none"];
"torch._ops.TorchBindOpOverload" -> "torch._ops.OpOverload" [arrowhead="empty", arrowtail="none"];
"torch._ops._PyOpNamespace" -> "torch._ops._OpNamespace" [arrowhead="empty", arrowtail="none"];
"torch._prims.context.TorchRefsMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._prims.rng_prims.register_run_and_save_rng_state_op.RunAndSaveRngState" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._prims.rng_prims.register_run_with_rng_state_op.RunWithRngState" -> "torch._ops.HigherOrderOperator" [arrowhead="empty", arrowtail="none"];
"torch._prims_common.wrappers.backwards_not_supported.BackwardsNotSupported" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.fake_tensor.FakeCopyMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.fake_tensor.FakeTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.fake_utils.CrossRefFakeMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.functional_tensor.CppFunctionalizeAPI" -> "torch._subclasses.functional_tensor.BaseFunctionalizeAPI" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.functional_tensor.FunctionalTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.functional_tensor.FunctionalTensorMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.functional_tensor.FunctorchFunctionalizeAPI" -> "torch._subclasses.functional_tensor.BaseFunctionalizeAPI" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.functional_tensor.PythonFunctionalizeAPI" -> "torch._subclasses.functional_tensor.BaseFunctionalizeAPI" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.meta_utils._CustomViewFunc" -> "torch._subclasses.meta_utils.ViewFunc" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.meta_utils._FakeTensorViewFunc" -> "torch._subclasses.meta_utils.ViewFunc" [arrowhead="empty", arrowtail="none"];
"torch._subclasses.schema_check_mode.SchemaCheckMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch._vendor.packaging.version.Version" -> "torch._vendor.packaging.version._BaseVersion" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU3d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvAdd2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvAddReLU2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBn3d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvBnReLU3d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU3d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.LinearBn1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.LinearLeakyReLU" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.LinearReLU" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused.LinearTanh" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.modules.fused._FusedModule" -> "torch.nn.modules.container.Sequential" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn1d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn1d" -> "torch.nn.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn2d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn2d" -> "torch.nn.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn3d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn3d" -> "torch.nn.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU1d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU3d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvBn3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU1d" -> "torch.ao.nn.qat.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d" -> "torch.ao.nn.qat.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused.ConvReLU3d" -> "torch.ao.nn.qat.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU" -> "torch.ao.nn.intrinsic.modules.fused._FusedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU" -> "torch.ao.nn.qat.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU" -> "torch.ao.nn.quantized.dynamic.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d" -> "torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d" -> "torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAdd2d" -> "torch.ao.nn.quantized.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAddReLU2d" -> "torch.ao.nn.quantized.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d" -> "torch.ao.nn.quantized.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d" -> "torch.ao.nn.quantized.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d" -> "torch.ao.nn.quantized.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearLeakyReLU" -> "torch.ao.nn.quantized.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearReLU" -> "torch.ao.nn.quantized.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearTanh" -> "torch.ao.nn.quantized.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.dynamic.modules.linear.Linear" -> "torch.ao.nn.qat.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv1d" -> "torch.ao.nn.qat.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv1d" -> "torch.nn.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv2d" -> "torch.ao.nn.qat.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv2d" -> "torch.nn.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv3d" -> "torch.ao.nn.qat.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv.Conv3d" -> "torch.nn.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.conv._ConvNd" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.embedding_ops.Embedding" -> "torch.nn.modules.sparse.Embedding" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.embedding_ops.EmbeddingBag" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.qat.modules.linear.Linear" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantizable.modules.activation.MultiheadAttention" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantizable.modules.rnn.LSTM" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantizable.modules.rnn.LSTMCell" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantizable.modules.rnn._LSTMLayer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv1d" -> "torch.ao.nn.quantized.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv2d" -> "torch.ao.nn.quantized.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.Conv3d" -> "torch.ao.nn.quantized.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose1d" -> "torch.ao.nn.quantized.modules.conv.ConvTranspose1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose2d" -> "torch.ao.nn.quantized.modules.conv.ConvTranspose2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.conv.ConvTranspose3d" -> "torch.ao.nn.quantized.modules.conv.ConvTranspose3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.linear.Linear" -> "torch.ao.nn.quantized.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.GRU" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.GRUCell" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.LSTM" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.LSTMCell" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.PackedParameter" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNCell" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.dynamic.modules.rnn.RNNCellBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.DeQuantize" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.Quantize" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.ELU" -> "torch.nn.modules.activation.ELU" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.Hardswish" -> "torch.nn.modules.activation.Hardswish" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.LeakyReLU" -> "torch.nn.modules.activation.LeakyReLU" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.MultiheadAttention" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.PReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.ReLU6" -> "torch.nn.modules.activation.ReLU" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.Sigmoid" -> "torch.nn.modules.activation.Sigmoid" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.activation.Softmax" -> "torch.nn.modules.activation.Softmax" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d" -> "torch.ao.nn.quantized.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d" -> "torch.ao.nn.quantized.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.batchnorm._BatchNorm" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.Conv1d" -> "torch.ao.nn.quantized.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.Conv2d" -> "torch.ao.nn.quantized.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.Conv3d" -> "torch.ao.nn.quantized.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose1d" -> "torch.ao.nn.quantized.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose2d" -> "torch.ao.nn.quantized.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv.ConvTranspose3d" -> "torch.ao.nn.quantized.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv._ConvNd" -> "torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.conv._ConvTransposeNd" -> "torch.ao.nn.quantized.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.dropout.Dropout" -> "torch.nn.modules.dropout.Dropout" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.embedding_ops.Embedding" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.embedding_ops.EmbeddingBag" -> "torch.ao.nn.quantized.modules.embedding_ops.Embedding" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.functional_modules.FXFloatFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.functional_modules.QFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.linear.Linear" -> "torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.linear.LinearPackedParams" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.normalization.GroupNorm" -> "torch.nn.modules.normalization.GroupNorm" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm1d" -> "torch.nn.modules.instancenorm.InstanceNorm1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm2d" -> "torch.nn.modules.instancenorm.InstanceNorm2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.normalization.InstanceNorm3d" -> "torch.nn.modules.instancenorm.InstanceNorm3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.normalization.LayerNorm" -> "torch.nn.modules.normalization.LayerNorm" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.rnn.LSTM" -> "torch.ao.nn.quantizable.modules.rnn.LSTM" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.modules.utils.WeightedQuantizedModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv1d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv1d" -> "torch.nn.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv2d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv2d" -> "torch.nn.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv3d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.Conv3d" -> "torch.nn.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose1d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose1d" -> "torch.nn.modules.conv.ConvTranspose1d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose2d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose2d" -> "torch.nn.modules.conv.ConvTranspose2d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose3d" -> "torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv.ConvTranspose3d" -> "torch.nn.modules.conv.ConvTranspose3d" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv._ConvNd" -> "torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv._ConvNd" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" -> "torch.ao.nn.quantized.reference.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.conv._ConvTransposeNd" -> "torch.nn.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.linear.Linear" -> "torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.linear.Linear" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.GRU" -> "torch.ao.nn.quantized.reference.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.GRUCell" -> "torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.LSTM" -> "torch.ao.nn.quantized.reference.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.LSTMCell" -> "torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNBase" -> "torch.nn.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNCell" -> "torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.rnn.RNNCellBase" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.sparse.Embedding" -> "torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.sparse.Embedding" -> "torch.nn.modules.sparse.Embedding" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.sparse.EmbeddingBag" -> "torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.sparse.EmbeddingBag" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.quantized.reference.modules.utils.ReferenceQuantizedModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.sparse.quantized.dynamic.linear.Linear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.sparse.quantized.linear.Linear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.nn.sparse.quantized.linear.LinearPackedParams" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite.Logger" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite.OutputLogger" -> "torch.ao.ns._numeric_suite.Logger" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite.Shadow" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite.ShadowLogger" -> "torch.ao.ns._numeric_suite.Logger" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite_fx.NSTracer" -> "torch.ao.quantization.fx.tracer.QuantizationTracer" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite_fx.OutputComparisonLogger" -> "torch.ao.ns._numeric_suite_fx.OutputLogger" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns._numeric_suite_fx.OutputLogger" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.ns.fx.n_shadows_utils.create_submodule_from_subgraph.M" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" -> "torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier._Container" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.data_sparsifier.data_norm_sparsifier.DataNormSparsifier" -> "torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.pruner.FPGM_pruner.FPGMPruner" -> "torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" -> "torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.pruner.lstm_saliency_pruner.LSTMSaliencyPruner" -> "torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.pruner.parametrization.FakeStructuredSparsity" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning._experimental.pruner.saliency_pruner.SaliencyPruner" -> "torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning.scheduler.cubic_scheduler.CubicSL" -> "torch.ao.pruning.scheduler.base_scheduler.BaseScheduler" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning.scheduler.lambda_scheduler.LambdaSL" -> "torch.ao.pruning.scheduler.base_scheduler.BaseScheduler" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning.sparsifier.nearly_diagonal_sparsifier.NearlyDiagonalSparsifier" -> "torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning.sparsifier.utils.FakeSparsity" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.pruning.sparsifier.weight_norm_sparsifier.WeightNormSparsifier" -> "torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization._DerivedObserverOrFakeQuantize" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization._correct_bias.MeanShadowLogger" -> "torch.ao.ns._numeric_suite.Logger" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" -> "torch.ao.quantization.fake_quantize.FakeQuantizeBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fake_quantize.FakeQuantize" -> "torch.ao.quantization.fake_quantize.FakeQuantizeBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fake_quantize.FakeQuantizeBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize" -> "torch.ao.quantization.fake_quantize.FakeQuantize" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize" -> "torch.ao.quantization.fake_quantize.FakeQuantize" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._decomposed.FakeQuantPerChannel" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._equalize._InputEqualizationObserver" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._equalize._WeightEqualizationObserver" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._model_report.detector.DynamicStaticDetector" -> "torch.ao.quantization.fx._model_report.detector.DetectorBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._model_report.detector.InputWeightEqualizationDetector" -> "torch.ao.quantization.fx._model_report.detector.DetectorBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._model_report.detector.OutlierDetector" -> "torch.ao.quantization.fx._model_report.detector.DetectorBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._model_report.detector.PerChannelDetector" -> "torch.ao.quantization.fx._model_report.detector.DetectorBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx._model_report.model_report_observer.ModelReportObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.fuse_handler.DefaultFuseHandler" -> "torch.ao.quantization.fx.fuse_handler.FuseHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.graph_module.FusedGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.graph_module.ObservedGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.graph_module.ObservedStandaloneGraphModule" -> "torch.ao.quantization.fx.graph_module.ObservedGraphModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.graph_module.QuantizedGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.BatchNormQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.BinaryOpQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.CatQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.ConvReluQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.CopyNodeQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.CustomModuleQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.DefaultNodeQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.EmbeddingQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.FixedQParamsOpQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.GeneralTensorShapeOpQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.LinearReLUQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.RNNDynamicQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler.StandaloneModuleQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.quantize_handler._get_quantize_handler_cls.ConfigurableQuantizeHandler" -> "torch.ao.quantization.fx.quantize_handler.QuantizeHandler" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.tracer.QuantizationTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.fx.tracer.ScopeContextManager" -> "torch.fx.proxy.ScopeContextManager" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.FixedQParamsObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.HistogramObserver" -> "torch.ao.quantization.observer.UniformQuantizationObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.MinMaxObserver" -> "torch.ao.quantization.observer.UniformQuantizationObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.MovingAverageMinMaxObserver" -> "torch.ao.quantization.observer.MinMaxObserver" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver" -> "torch.ao.quantization.observer.PerChannelMinMaxObserver" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.NoopObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.ObserverBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.PerChannelMinMaxObserver" -> "torch.ao.quantization.observer.UniformQuantizationObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.PlaceholderObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.RecordingObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.ReuseInputObserver" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.observer.UniformQuantizationObserverBase" -> "torch.ao.quantization.observer.ObserverBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.pt2e._numeric_debugger.OutputLogger" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.pt2e.duplicate_dq_pass.DuplicateDQPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.pt2e.export_utils._WrapperModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.pt2e.port_metadata_pass.PortNodeMetaForQDQ" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.composable_quantizer.ComposableQuantizer" -> "torch.ao.quantization.quantizer.quantizer.Quantizer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.embedding_quantizer.EmbeddingQuantizer" -> "torch.ao.quantization.quantizer.quantizer.Quantizer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.quantizer.DerivedQuantizationSpec" -> "torch.ao.quantization.quantizer.quantizer.QuantizationSpecBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.quantizer.FixedQParamsQuantizationSpec" -> "torch.ao.quantization.quantizer.quantizer.QuantizationSpecBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.quantizer.QuantizationSpec" -> "torch.ao.quantization.quantizer.quantizer.QuantizationSpecBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.quantizer.SharedQuantizationSpec" -> "torch.ao.quantization.quantizer.quantizer.QuantizationSpecBase" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.x86_inductor_quantizer.X86InductorQuantizer" -> "torch.ao.quantization.quantizer.quantizer.Quantizer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.x86_inductor_quantizer._X86InductorQuantizationAnnotation" -> "torch.ao.quantization.quantizer.quantizer.QuantizationAnnotation" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.xnnpack_quantizer.XNNPACKQuantizer" -> "torch.ao.quantization.quantizer.quantizer.Quantizer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.quantizer.xpu_inductor_quantizer.XPUInductorQuantizer" -> "torch.ao.quantization.quantizer.x86_inductor_quantizer.X86InductorQuantizer" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.autograd._functions.tensor.Resize" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.autograd._functions.tensor.Type" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.autograd.forward_ad._set_fwd_grad_enabled" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.forward_ad.dual_level" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function.BackwardCFunction" -> "torch.autograd.function.FunctionCtx" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function.BackwardCFunction" -> "torch.autograd.function._HookMixin" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function.Function" -> "torch.autograd.function._SingleLevelFunction" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function.InplaceFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function.NestedIOFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function._SingleLevelFunction" -> "torch.autograd.function.FunctionCtx" [arrowhead="empty", arrowtail="none"];
"torch.autograd.function._SingleLevelFunction" -> "torch.autograd.function._HookMixin" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode._force_original_view_tracking" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode._unsafe_preserve_version_counter" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode.enable_grad" -> "torch.utils._contextlib._NoParamDecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode.inference_mode" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode.no_grad" -> "torch.utils._contextlib._NoParamDecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode.set_grad_enabled" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.grad_mode.set_multithreading_enabled" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph._CloneArgBeforeMutateMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph._MultiHandle" -> "torch.utils.hooks.RemovableHandle" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph._swap_with_cloned" -> "torch.autograd.graph.saved_tensors_hooks" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu" -> "torch.autograd.graph.saved_tensors_hooks" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.BFloat16Storage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.BoolStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ByteStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.CharStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ComplexDoubleStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ComplexFloatStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.DoubleStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.FloatStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.HalfStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.IntStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.LongStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.ShortStorage" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda._CudaLegacyStorage" -> "torch.storage._LegacyStorage" [arrowhead="empty", arrowtail="none"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.device_of" -> "torch.autograd.graph.save_on_cpu.__init__.torch.cuda.device" [arrowhead="empty", arrowtail="none"];
"torch.autograd.profiler_util.FunctionEvent" -> "torch.autograd.profiler_util.FormattedTimesMixin" [arrowhead="empty", arrowtail="none"];
"torch.autograd.profiler_util.FunctionEventAvg" -> "torch.autograd.profiler_util.FormattedTimesMixin" [arrowhead="empty", arrowtail="none"];
"torch.backends._nnapi.prepare.NnapiModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.backends._nnapi.prepare.convert_model_to_nnapi.NnapiInterfaceWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.backends._nnapi.prepare.process_for_nnapi.ShapeComputeModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.backends.cudnn.CudnnModule" -> "torch.backends.PropModule" [arrowhead="empty", arrowtail="none"];
"torch.backends.mkldnn.MkldnnModule" -> "torch.backends.PropModule" [arrowhead="empty", arrowtail="none"];
"torch.backends.opt_einsum.OptEinsumModule" -> "torch.backends.PropModule" [arrowhead="empty", arrowtail="none"];
"torch.cpu.amp.autocast_mode.autocast" -> "torch.amp.autocast_mode.autocast" [arrowhead="empty", arrowtail="none"];
"torch.cpu.amp.grad_scaler.GradScaler" -> "torch.amp.grad_scaler.GradScaler" [arrowhead="empty", arrowtail="none"];
"torch.cuda._sanitizer.CUDASanitizerDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.cuda._sanitizer.UnsynchronizedAccessError" -> "torch.cuda._sanitizer.SynchronizationError" [arrowhead="empty", arrowtail="none"];
"torch.cuda.amp.autocast_mode.autocast" -> "torch.amp.autocast_mode.autocast" [arrowhead="empty", arrowtail="none"];
"torch.cuda.amp.grad_scaler.GradScaler" -> "torch.amp.grad_scaler.GradScaler" [arrowhead="empty", arrowtail="none"];
"torch.cuda.graphs.make_graphed_callables.make_graphed_autograd_function.Graphed" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.cuda.memory.CUDAPluggableAllocator" -> "torch.cuda.memory._CUDAAllocator" [arrowhead="empty", arrowtail="none"];
"torch.cuda.streams.ExternalStream" -> "torch.cuda.streams.Stream" [arrowhead="empty", arrowtail="none"];
"torch.distributed._composable.replicate._ReplicateState" -> "torch.distributed._composable_state._State" [arrowhead="empty", arrowtail="none"];
"torch.distributed._functional_collectives.AsyncCollectiveTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.distributed._functional_collectives._FromTorchTensor" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharded_optim.api.ShardedOptimizer" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensor" -> "torch.distributed._shard.sharded_tensor.api.ShardedTensorBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensorBase" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharding_spec.api.DevicePlacementSpec" -> "torch.distributed._shard.sharding_spec.api.PlacementSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharding_spec.api.EnumerableShardingSpec" -> "torch.distributed._shard.sharding_spec.api.ShardingSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed._shard.sharding_spec.chunk_sharding_spec.ChunkShardingSpec" -> "torch.distributed._shard.sharding_spec.api.ShardingSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.fsdp2_mem_tracker.FSDPMemTracker" -> "torch.distributed._tools.mem_tracker.MemTracker" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.fsdp2_mem_tracker._FSDPModState" -> "torch.distributed._tools.mem_tracker._State" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.fsdp2_mem_tracker._FSDPRefType" -> "torch.distributed._tools.mem_tracker._RefType" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.ilp_utils.Node" -> "torch.distributed._tools.ilp_utils.ModStats" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.mem_tracker.MemTracker" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.mem_tracker._MemRefType" -> "torch.distributed._tools.mem_tracker._RefType" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.mem_tracker._ModState" -> "torch.distributed._tools.mem_tracker._State" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.memory_tracker.MemoryProfileDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.runtime_estimator.RuntimeEstimator" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.distributed._tools.sac_estimator.SACEstimator" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.ActivationWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.CheckpointWrapper" -> "torch.distributed.algorithms._checkpoint.checkpoint_wrapper.ActivationWrapper" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.OffloadWrapper" -> "torch.distributed.algorithms._checkpoint.checkpoint_wrapper.ActivationWrapper" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms._comm_hooks.default_hooks.LowPrecisionState" -> "torch.distributed.algorithms._comm_hooks.default_hooks.DefaultState" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms._optimizer_overlap.optimizer_overlap._OverlappedStandardOptimizer" -> "torch.distributed.algorithms._optimizer_overlap.optimizer_overlap.OverlappedOptimizer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms.model_averaging.averagers.PeriodicModelAverager" -> "torch.distributed.algorithms.model_averaging.averagers.ModelAverager" [arrowhead="empty", arrowtail="none"];
"torch.distributed.algorithms.model_averaging.hierarchical_model_averager.HierarchicalModelAverager" -> "torch.distributed.algorithms.model_averaging.averagers.ModelAverager" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint._fsspec_filesystem.FileSystem" -> "torch.distributed.checkpoint.filesystem.FileSystemBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint._fsspec_filesystem.FsspecReader" -> "torch.distributed.checkpoint.filesystem.FileSystemReader" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint._fsspec_filesystem.FsspecWriter" -> "torch.distributed.checkpoint.filesystem.FileSystemWriter" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.default_planner.DefaultLoadPlanner" -> "torch.distributed.checkpoint.planner.LoadPlanner" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.default_planner.DefaultSavePlanner" -> "torch.distributed.checkpoint.planner.SavePlanner" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.default_planner._EmptyStateDictLoadPlanner" -> "torch.distributed.checkpoint.default_planner.DefaultLoadPlanner" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem.FileSystem" -> "torch.distributed.checkpoint.filesystem.FileSystemBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem.FileSystemReader" -> "torch.distributed.checkpoint.storage.StorageReader" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem.FileSystemWriter" -> "torch.distributed.checkpoint.filesystem._FileSystemWriter" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem.FileSystemWriter" -> "torch.distributed.checkpoint.staging.BlockingAsyncStager" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem._FileSystemWriter" -> "torch.distributed.checkpoint.storage.StorageWriter" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem._OverlappingCpuLoader" -> "torch.distributed.checkpoint.filesystem._TensorLoader" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.filesystem._SerialCpuLoader" -> "torch.distributed.checkpoint.filesystem._TensorLoader" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.format_utils.BroadcastingTorchSaveReader" -> "torch.distributed.checkpoint.storage.StorageReader" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner" -> "torch.distributed.checkpoint.default_planner.DefaultLoadPlanner" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.optimizer._ReaderWithOffset" -> "torch.distributed.checkpoint.default_planner.DefaultLoadPlanner" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.staging.BlockingAsyncStager" -> "torch.distributed.checkpoint.staging.AsyncStager" [arrowhead="empty", arrowtail="none"];
"torch.distributed.checkpoint.state_dict._StateDictInfo" -> "torch.distributed.checkpoint.state_dict.StateDictOptions" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.agent.server.api.SimpleElasticAgent" -> "torch.distributed.elastic.agent.server.api.ElasticAgent" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" -> "torch.distributed.elastic.agent.server.api.SimpleElasticAgent" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.metrics.api.ConsoleMetricHandler" -> "torch.distributed.elastic.metrics.api.MetricHandler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.metrics.api.NullMetricHandler" -> "torch.distributed.elastic.metrics.api.MetricHandler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.multiprocessing.api.DefaultLogsSpecs" -> "torch.distributed.elastic.multiprocessing.api.LogsSpecs" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.multiprocessing.api.MultiprocessContext" -> "torch.distributed.elastic.multiprocessing.api.PContext" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.multiprocessing.api.SubprocessContext" -> "torch.distributed.elastic.multiprocessing.api.PContext" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.api.RendezvousClosedError" -> "torch.distributed.elastic.rendezvous.api.RendezvousError" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.api.RendezvousConnectionError" -> "torch.distributed.elastic.rendezvous.api.RendezvousError" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.api.RendezvousGracefulExitError" -> "torch.distributed.elastic.rendezvous.api.RendezvousError" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.api.RendezvousStateError" -> "torch.distributed.elastic.rendezvous.api.RendezvousError" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.api.RendezvousTimeoutError" -> "torch.distributed.elastic.rendezvous.api.RendezvousError" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" -> "torch.distributed.elastic.rendezvous.api.RendezvousHandler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousStateHolder" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousOpExecutor" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler" -> "torch.distributed.elastic.rendezvous.api.RendezvousHandler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.rendezvous.static_tcp_rendezvous.StaticTCPRendezvous" -> "torch.distributed.elastic.rendezvous.api.RendezvousHandler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerClient" -> "torch.distributed.elastic.timer.api.TimerClient" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerRequest" -> "torch.distributed.elastic.timer.api.TimerRequest" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.timer.local_timer.LocalTimerClient" -> "torch.distributed.elastic.timer.api.TimerClient" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.timer.local_timer.LocalTimerServer" -> "torch.distributed.elastic.timer.api.TimerServer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.timer.local_timer.MultiprocessingRequestQueue" -> "torch.distributed.elastic.timer.api.RequestQueue" [arrowhead="empty", arrowtail="none"];
"torch.distributed.elastic.utils.data.elastic_distributed_sampler.ElasticDistributedSampler" -> "torch.utils.data.distributed.DistributedSampler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._common_utils._FSDPState" -> "torch.distributed._composable_state._State" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._common_utils._UninitializedDeviceHandle" -> "torch.distributed.fsdp._common_utils._FSDPDeviceHandle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._flat_param.FlatParameter" -> "torch.nn.parameter.Parameter" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._flat_param._FlatParameterMeta" -> "torch.nn.parameter._ParameterMeta" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_api.CPUOffloadPolicy" -> "torch.distributed.fsdp._fully_shard._fsdp_api.OffloadPolicy" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_common.DDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_common.DataParallelMeshInfo" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_common.FSDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_common.DataParallelMeshInfo" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_common.HSDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_common.DDPMeshInfo" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_common.HSDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_common.FSDPMeshInfo" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.RegisterPostBackwardFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" -> "torch.distributed._composable_state._State" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp._fully_shard._fully_shard._UnshardHandleImpl" -> "torch.distributed.fsdp._fully_shard._fully_shard.UnshardHandle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.FullOptimStateDictConfig" -> "torch.distributed.fsdp.api.OptimStateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.FullStateDictConfig" -> "torch.distributed.fsdp.api.StateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.LocalOptimStateDictConfig" -> "torch.distributed.fsdp.api.OptimStateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.LocalStateDictConfig" -> "torch.distributed.fsdp.api.StateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.ShardedOptimStateDictConfig" -> "torch.distributed.fsdp.api.OptimStateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.api.ShardedStateDictConfig" -> "torch.distributed.fsdp.api.StateDictConfig" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel" -> "torch.distributed.fsdp._common_utils._FSDPState" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.sharded_grad_scaler.ShardedGradScaler" -> "torch.amp.grad_scaler.GradScaler" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.sharded_grad_scaler._GeneralMultiDeviceReplicator" -> "torch.amp.grad_scaler._MultiDeviceReplicator" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.wrap.CustomPolicy" -> "torch.distributed.fsdp.wrap._Policy" [arrowhead="empty", arrowtail="none"];
"torch.distributed.fsdp.wrap.ModuleWrapPolicy" -> "torch.distributed.fsdp.wrap._Policy" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.api.remote_module.RemoteModule" -> "torch.distributed.nn.api.remote_module._RemoteModule" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.api.remote_module._RemoteModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._AllGather" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._AllGatherBase" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._AllReduce" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._AlltoAll" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._AlltoAllSingle" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._Broadcast" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._Gather" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._Reduce" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._Reduce_Scatter" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.nn.functional._Scatter" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.named_optimizer._NamedOptimizer" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.optimizer._ScriptLocalOptimizer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.post_localSGD_optimizer.PostLocalSGDOptimizer" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.zero_redundancy_optimizer.ZeroRedundancyOptimizer" -> "torch.distributed.algorithms.join.Joinable" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.zero_redundancy_optimizer.ZeroRedundancyOptimizer" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.optim.zero_redundancy_optimizer._ZeROJoinHook" -> "torch.distributed.algorithms.join.JoinHook" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR.DetachExecutor" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR.LossWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR.Pipe" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR.PipeSequential" -> "torch.nn.modules.container.Sequential" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR.TrivialLossWrapper" -> "torch.distributed.pipelining._IR.LossWrapper" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining._IR._direct_serialization_deserialize.DummyModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.microbatch._LossReducer" -> "torch.distributed.pipelining.microbatch._CustomReducer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.PipelineScheduleMulti" -> "torch.distributed.pipelining.schedules._PipelineSchedule" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.PipelineScheduleSingle" -> "torch.distributed.pipelining.schedules._PipelineSchedule" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.Schedule1F1B" -> "torch.distributed.pipelining.schedules.PipelineScheduleSingle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.ScheduleGPipe" -> "torch.distributed.pipelining.schedules.PipelineScheduleSingle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.ScheduleInterleaved1F1B" -> "torch.distributed.pipelining.schedules.PipelineScheduleMulti" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.ScheduleInterleavedZeroBubble" -> "torch.distributed.pipelining.schedules.PipelineScheduleMulti" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.ScheduleLoopedBFS" -> "torch.distributed.pipelining.schedules.PipelineScheduleMulti" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules.ScheduleZBVZeroBubble" -> "torch.distributed.pipelining.schedules.PipelineScheduleMulti" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules._PipelineScheduleRuntime" -> "torch.distributed.pipelining.schedules.PipelineScheduleMulti" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.schedules._ScheduleForwardOnly" -> "torch.distributed.pipelining.schedules.PipelineScheduleSingle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.stage.PipelineStage" -> "torch.distributed.pipelining.stage._PipelineStageBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed.pipelining.stage._PipelineStage" -> "torch.distributed.pipelining.stage._PipelineStageBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed.rpc.server_process_global_profiler._server_process_global_profile" -> "torch.autograd.profiler_legacy.profile" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._api.DTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._api._FromTorchTensor" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._api._ToTorchTensor" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._op_schema.OpStrategy" -> "torch.distributed.tensor._op_schema.StrategyType" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._op_schema.TupleStrategy" -> "torch.distributed.tensor._op_schema.StrategyType" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._embedding_ops._MaskPartial" -> "torch.distributed.tensor.placement_types.Partial" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._math_ops._NormPartial" -> "torch.distributed.tensor.placement_types.Partial" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.Broadcast" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.Flatten" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.InputDim" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.NewDim" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.Repeat" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.Singleton" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._ops._view_ops.Split" -> "torch.distributed.tensor._ops._view_ops.DimSpec" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._random.OffsetBasedRNGTracker" -> "torch.distributed.tensor._random._RNGStateTracker" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._redistribute.Redistribute" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor._shards_wrapper.LocalShardsWrapper" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.debug._comm_mode.CommDebugMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" -> "torch.distributed._tools.mod_tracker.ModTracker" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._attention._AllGatherRotater" -> "torch.distributed.tensor.experimental._attention._RingRotater" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._attention._AllToAllRotater" -> "torch.distributed.tensor.experimental._attention._RingRotater" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._attention._AttentionContextParallel" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._attention._RoundRobinLoadBalancer" -> "torch.distributed.tensor.experimental._attention._LoadBalancer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._attention._SequentialSharder" -> "torch.distributed.tensor.experimental._attention._LoadBalancer" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.experimental._tp_transform._TensorParallelTransformPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.fsdp.DTensorExtensions" -> "torch.distributed.fsdp._fsdp_extensions.FSDPExtensions" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.style.ColwiseParallel" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.style.PrepareModuleInput" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.style.PrepareModuleOutput" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.style.RowwiseParallel" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.parallel.style.SequenceParallel" -> "torch.distributed.tensor.parallel.style.ParallelStyle" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.placement_types.Partial" -> "torch.distributed.tensor.placement_types.Placement" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.placement_types.Replicate" -> "torch.distributed.tensor.placement_types.Placement" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.placement_types.Shard" -> "torch.distributed.tensor.placement_types.Placement" [arrowhead="empty", arrowtail="none"];
"torch.distributed.tensor.placement_types._StridedShard" -> "torch.distributed.tensor.placement_types.Shard" [arrowhead="empty", arrowtail="none"];
"torch.distributions.bernoulli.Bernoulli" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.beta.Beta" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.binomial.Binomial" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.cauchy.Cauchy" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.chi2.Chi2" -> "torch.distributions.gamma.Gamma" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Boolean" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Cat" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._CorrCholesky" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Dependent" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._DependentProperty" -> "torch.distributions.constraints._Dependent" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._GreaterThan" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._GreaterThanEq" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._HalfOpenInterval" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._IndependentConstraint" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._IntegerGreaterThan" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._IntegerInterval" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._IntegerLessThan" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Interval" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._LessThan" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._LowerCholesky" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._LowerTriangular" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Multinomial" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._OneHot" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._PositiveDefinite" -> "torch.distributions.constraints._Symmetric" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._PositiveSemidefinite" -> "torch.distributions.constraints._Symmetric" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Real" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Simplex" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Square" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Stack" -> "torch.distributions.constraints.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.distributions.constraints._Symmetric" -> "torch.distributions.constraints._Square" [arrowhead="empty", arrowtail="none"];
"torch.distributions.continuous_bernoulli.ContinuousBernoulli" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.dirichlet.Dirichlet" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.dirichlet._Dirichlet" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.distributions.exp_family.ExponentialFamily" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.exponential.Exponential" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.fishersnedecor.FisherSnedecor" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.geometric.Geometric" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.gumbel.Gumbel" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.half_cauchy.HalfCauchy" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.half_normal.HalfNormal" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.independent.Independent" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.inverse_gamma.InverseGamma" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.kumaraswamy.Kumaraswamy" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.laplace.Laplace" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.lkj_cholesky.LKJCholesky" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.log_normal.LogNormal" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.logistic_normal.LogisticNormal" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.mixture_same_family.MixtureSameFamily" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.multinomial.Multinomial" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.multivariate_normal.MultivariateNormal" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.negative_binomial.NegativeBinomial" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.normal.Normal" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.one_hot_categorical.OneHotCategorical" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.one_hot_categorical.OneHotCategoricalStraightThrough" -> "torch.distributions.one_hot_categorical.OneHotCategorical" [arrowhead="empty", arrowtail="none"];
"torch.distributions.pareto.Pareto" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.poisson.Poisson" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.relaxed_bernoulli.RelaxedBernoulli" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.relaxed_categorical.ExpRelaxedCategorical" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.relaxed_categorical.RelaxedOneHotCategorical" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.studentT.StudentT" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transformed_distribution.TransformedDistribution" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.AbsTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.AffineTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.CatTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.ComposeTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.CorrCholeskyTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.CumulativeDistributionTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.ExpTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.IndependentTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.LowerCholeskyTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.PositiveDefiniteTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.PowerTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.ReshapeTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.SigmoidTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.SoftmaxTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.SoftplusTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.StackTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.StickBreakingTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms.TanhTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.transforms._InverseTransform" -> "torch.distributions.transforms.Transform" [arrowhead="empty", arrowtail="none"];
"torch.distributions.uniform.Uniform" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.utils._lazy_property_and_property" -> "torch.distributions.utils.lazy_property" [arrowhead="empty", arrowtail="none"];
"torch.distributions.von_mises.VonMises" -> "torch.distributions.distribution.Distribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.weibull.Weibull" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="empty", arrowtail="none"];
"torch.distributions.wishart.Wishart" -> "torch.distributions.exp_family.ExponentialFamily" [arrowhead="empty", arrowtail="none"];
"torch.export._safeguard.AutogradStateOpsFailSafeguard" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.export._trace._WrapperModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.export._trace._non_strict_export._tuplify_outputs._aot_export_non_strict.Wrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.export._unlift._StatefulGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.export.dynamic_shapes._Constraint" -> "torch.export.dynamic_shapes._ConstraintTarget" [arrowhead="empty", arrowtail="none"];
"torch.export.dynamic_shapes._DerivedConstraint" -> "torch.export.dynamic_shapes._ConstraintTarget" [arrowhead="empty", arrowtail="none"];
"torch.export.dynamic_shapes._DerivedDim" -> "torch.export.dynamic_shapes._Dim" [arrowhead="empty", arrowtail="none"];
"torch.export.dynamic_shapes._RelaxedConstraint" -> "torch.export.dynamic_shapes._ConstraintTarget" [arrowhead="empty", arrowtail="none"];
"torch.export.dynamic_shapes._StaticDim" -> "torch.export.dynamic_shapes._Dim" [arrowhead="empty", arrowtail="none"];
"torch.export.unflatten.InterpreterModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.export.unflatten.InterpreterModuleDispatcher" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.export.unflatten.UnflattenedModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx._lazy_graph_module._LazyGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.fx._symbolic_trace.PHWithMeta" -> "torch.fx._symbolic_trace.PHBase" [arrowhead="empty", arrowtail="none"];
"torch.fx._symbolic_trace.Tracer" -> "torch.fx.proxy.TracerBase" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.const_fold.FoldedGraphModule" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.meta_tracer.MetaAttribute" -> "torch.fx.experimental.meta_tracer.MetaProxy" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.meta_tracer.MetaDeviceAttribute" -> "torch.fx.experimental.meta_tracer.MetaAttribute" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.meta_tracer.MetaProxy" -> "torch.fx.proxy.Proxy" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.meta_tracer.MetaTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.ApplyBroadcasting" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinConstraintD" -> "torch.fx.experimental.migrate_gradual_types.constraint.BinaryConstraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinConstraintT" -> "torch.fx.experimental.migrate_gradual_types.constraint.BinaryConstraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.BinaryConstraint" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcConv" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcMaxPool" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.CalcProduct" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.CanReshape" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.Conj" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.DGreatestUpperBound" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.Disj" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.F" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.GetItem" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.GetItemTensor" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.IndexSelect" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.Prod" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.T" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.TGreatestUpperBound" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.migrate_gradual_types.constraint.Transpose" -> "torch.fx.experimental.migrate_gradual_types.constraint.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.normalize.NormalizeArgs" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.normalize.NormalizeOperators" -> "torch.fx.experimental.schema_type_annotation.AnnotateTypesWithSchema" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.optimization.remove_dropout.DropoutRemover" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor.DecompositionInterpreter" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor.PreDispatchTorchFunctionMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor.PythonKeyTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor.TorchFunctionMetadataMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor._GraphAppendingTracerEx" -> "torch.fx.proxy.GraphAppendingTracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer.__init__.AttrProxy" -> "torch.fx.experimental.proxy_tensor._AttrProxy" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.rewriter.RewritingTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.rewriter._rewrite.rewrite_module.RewrittenModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.schema_type_annotation.AnnotateTypesWithSchema" -> "torch.fx.interpreter.Transformer" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.DynamicDimConstraintPrinter" -> "torch.utils._sympy.printers.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.EqualityConstraint" -> "torch.fx.experimental.symbolic_shapes.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.LoggingShapeGuardPrinter" -> "torch.fx.experimental.symbolic_shapes.ShapeGuardPythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.RelaxedUnspecConstraint" -> "torch.fx.experimental.symbolic_shapes.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.ShapeGuardPrinter" -> "torch.fx.experimental.symbolic_shapes.ShapeGuardPythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.ShapeGuardPythonPrinter" -> "torch.fx.experimental.symbolic_shapes._ShapeGuardPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.ShapeGuardPythonPrinter" -> "torch.utils._sympy.printers.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext" -> "torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.StatelessSymbolicContext" -> "torch.fx.experimental.symbolic_shapes.SymbolicContext" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint" -> "torch.fx.experimental.symbolic_shapes.Constraint" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.SubclassSymbolicContext" -> "torch.fx.experimental.symbolic_shapes.StatefulSymbolicContext" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes.SymExprPrinter" -> "torch.utils._sympy.printers.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.symbolic_shapes._PythonMsgPrinter" -> "torch.utils._sympy.printers.PythonPrinter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.unification.match.VarDispatcher" -> "torch.fx.experimental.unification.match.Dispatcher" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.unification.multipledispatch.dispatcher.MethodDispatcher" -> "torch.fx.experimental.unification.multipledispatch.dispatcher.Dispatcher" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.validator.BisectValidationException" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.validator.PopulateValidator" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.experimental.validator.ValidationException" -> "torch._dynamo.exc.TorchDynamoException" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph._PyTreeCodeGen" -> "torch.fx.graph.CodeGen" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph_module.GraphModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph_module.GraphModule.__new__.GraphModuleImpl" -> "torch.fx.graph_module.GraphModule" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph_module.GraphModule.__new__.GraphModuleImpl" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph_module._CodeOnlyModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx.graph_module._deserialize_graph_module.KeepModules" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.interpreter.Transformer" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.interpreter.Transformer.__init__.TransformerTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.backends.cudagraphs.CudaGraphsSupport" -> "torch.fx.passes.operator_support.OperatorSupport" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.dialect.common.cse_pass.CSEPass" -> "torch.fx.passes.infra.pass_base.PassBase" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.fake_tensor_prop.FakeTensorProp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.operator_support.OperatorSupport" -> "torch.fx.passes.operator_support.OperatorSupportBase" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.operator_support.create_op_support.FunctionalOperatorSupport" -> "torch.fx.passes.operator_support.OperatorSupportBase" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.reinplace._FunctionalizationMetadataProp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.shape_prop.ShapeProp" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.splitter_base._SplitterBase._draw_graph_based_on_node_support.CustomDrawer" -> "torch.fx.passes.graph_drawer.FxGraphDrawer" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.utils.common.HolderModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.fx.passes.utils.matcher_with_name_node_map_utils.SubgraphMatcherWithNameNodeMap" -> "torch.fx.passes.utils.matcher_utils.SubgraphMatcher" [arrowhead="empty", arrowtail="none"];
"torch.fx.proxy.Attribute" -> "torch.fx.proxy.Proxy" [arrowhead="empty", arrowtail="none"];
"torch.fx.proxy.GraphAppendingTracer" -> "torch.fx.proxy.TracerBase" [arrowhead="empty", arrowtail="none"];
"torch.fx.proxy.MetaProxy" -> "torch.fx.proxy.Proxy" [arrowhead="empty", arrowtail="none"];
"torch.fx.proxy.ParameterProxy" -> "torch.fx.proxy.Proxy" [arrowhead="empty", arrowtail="none"];
"torch.jit._script.OrderedModuleDict" -> "torch.jit._script.OrderedDictWrapper" [arrowhead="empty", arrowtail="none"];
"torch.jit._script.RecursiveScriptModule" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.jit._script.ScriptModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.jit._trace.ONNXTracedModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.jit._trace.TopLevelTracedModule" -> "torch.jit._trace.TracedModule" [arrowhead="empty", arrowtail="none"];
"torch.jit._trace.TracedModule" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.jit._trace.TracedModule.__init__.QualnameWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.ExprBuilder" -> "torch.jit.frontend.Builder" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.FrontendTypeError" -> "torch.jit.frontend.FrontendError" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.NotSupportedError" -> "torch.jit.frontend.FrontendError" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.StmtBuilder" -> "torch.jit.frontend.Builder" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.UnsupportedNodeError" -> "torch.jit.frontend.NotSupportedError" [arrowhead="empty", arrowtail="none"];
"torch.jit.frontend.WithItemBuilder" -> "torch.jit.frontend.Builder" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedGRU" -> "torch.jit.quantized.QuantizedRNNBase" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedGRUCell" -> "torch.jit.quantized.QuantizedRNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedLSTM" -> "torch.jit.quantized.QuantizedRNNBase" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedLSTMCell" -> "torch.jit.quantized.QuantizedRNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedLinear" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedLinearFP16" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedRNNBase" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedRNNCell" -> "torch.jit.quantized.QuantizedRNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.jit.quantized.QuantizedRNNCellBase" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.masked._ops._combine_input_and_mask.Combine" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor._ops_refs._MaskedContiguous" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor._ops_refs._MaskedToDense" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor._ops_refs._MaskedToSparse" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor._ops_refs._MaskedToSparseCsr" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor._ops_refs._MaskedWhere" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor.core.MaskedTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor.core.MaskedTensor._from_values.Constructor" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.masked.maskedtensor.core.MaskedTensor.get_data.GetData" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.multiprocessing.spawn.ProcessExitedException" -> "torch.multiprocessing.spawn.ProcessException" [arrowhead="empty", arrowtail="none"];
"torch.multiprocessing.spawn.ProcessRaisedException" -> "torch.multiprocessing.spawn.ProcessException" [arrowhead="empty", arrowtail="none"];
"torch.multiprocessing.spawn.SpawnContext" -> "torch.multiprocessing.spawn.ProcessContext" [arrowhead="empty", arrowtail="none"];
"torch.nested._internal.nested_tensor.NestedTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nested._internal.nested_tensor.ViewBufferFromNested" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nested._internal.nested_tensor.ViewNestedFromBuffer" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.attention.bias.CausalBias" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nn.cpp.ModuleWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules._functions.BackwardHookFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules._functions.CrossMapLRN2d" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules._functions.SyncBatchNorm" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.CELU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.ELU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.GELU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.GLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Hardshrink" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Hardsigmoid" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Hardswish" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Hardtanh" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.LeakyReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.LogSigmoid" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.LogSoftmax" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Mish" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.MultiheadAttention" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.PReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.RReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.ReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.ReLU6" -> "torch.nn.modules.activation.Hardtanh" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.SELU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.SiLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Sigmoid" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softmax" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softmax2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softmin" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softplus" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softshrink" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Softsign" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Tanh" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Tanhshrink" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.activation.Threshold" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.BatchNorm3d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm1d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm1d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm2d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm2d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm3d" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.LazyBatchNorm3d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm.SyncBatchNorm" -> "torch.nn.modules.batchnorm._BatchNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm._BatchNorm" -> "torch.nn.modules.batchnorm._NormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm._LazyNormBase" -> "torch.nn.modules.batchnorm._NormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm._LazyNormBase" -> "torch.nn.modules.lazy.LazyModuleMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.batchnorm._NormBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.channelshuffle.ChannelShuffle" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.Container" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.ModuleDict" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.ModuleList" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.ParameterDict" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.ParameterList" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.container.Sequential" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.Conv1d" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.Conv2d" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.Conv3d" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.ConvTranspose1d" -> "torch.nn.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.nn.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.ConvTranspose3d" -> "torch.nn.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv1d" -> "torch.nn.modules.conv.Conv1d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv1d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv2d" -> "torch.nn.modules.conv.Conv2d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv2d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv3d" -> "torch.nn.modules.conv.Conv3d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConv3d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose1d" -> "torch.nn.modules.conv.ConvTranspose1d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose1d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose2d" -> "torch.nn.modules.conv.ConvTranspose2d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose2d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose3d" -> "torch.nn.modules.conv.ConvTranspose3d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv.LazyConvTranspose3d" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv._ConvNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv._ConvTransposeMixin" -> "torch.nn.modules.conv._ConvTransposeNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv._ConvTransposeNd" -> "torch.nn.modules.conv._ConvNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.conv._LazyConvXdMixin" -> "torch.nn.modules.lazy.LazyModuleMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.distance.CosineSimilarity" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.distance.PairwiseDistance" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.AlphaDropout" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.Dropout1d" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.Dropout2d" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.Dropout3d" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout.FeatureAlphaDropout" -> "torch.nn.modules.dropout._DropoutNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.dropout._DropoutNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.flatten.Flatten" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.flatten.Unflatten" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.fold.Fold" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.fold.Unfold" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.InstanceNorm1d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.InstanceNorm2d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.InstanceNorm3d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm1d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm1d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm2d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm2d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm3d" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm.LazyInstanceNorm3d" -> "torch.nn.modules.instancenorm._InstanceNorm" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.instancenorm._InstanceNorm" -> "torch.nn.modules.batchnorm._NormBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.Bilinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.Identity" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.LazyLinear" -> "torch.nn.modules.lazy.LazyModuleMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.LazyLinear" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.linear.NonDynamicallyQuantizableLinear" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.BCELoss" -> "torch.nn.modules.loss._WeightedLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.BCEWithLogitsLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.CTCLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.CosineEmbeddingLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.CrossEntropyLoss" -> "torch.nn.modules.loss._WeightedLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.GaussianNLLLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.HingeEmbeddingLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.HuberLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.KLDivLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.L1Loss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.MSELoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.MarginRankingLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.MultiLabelMarginLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.MultiLabelSoftMarginLoss" -> "torch.nn.modules.loss._WeightedLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.MultiMarginLoss" -> "torch.nn.modules.loss._WeightedLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.NLLLoss" -> "torch.nn.modules.loss._WeightedLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.NLLLoss2d" -> "torch.nn.modules.loss.NLLLoss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.PoissonNLLLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.SmoothL1Loss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.SoftMarginLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.TripletMarginLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss.TripletMarginWithDistanceLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss._Loss" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.loss._WeightedLoss" -> "torch.nn.modules.loss._Loss" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.normalization.CrossMapLRN2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.normalization.GroupNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.normalization.LocalResponseNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.normalization.RMSNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.CircularPad1d" -> "torch.nn.modules.padding._CircularPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.CircularPad2d" -> "torch.nn.modules.padding._CircularPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.CircularPad3d" -> "torch.nn.modules.padding._CircularPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ConstantPad1d" -> "torch.nn.modules.padding._ConstantPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ConstantPad2d" -> "torch.nn.modules.padding._ConstantPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ConstantPad3d" -> "torch.nn.modules.padding._ConstantPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReflectionPad1d" -> "torch.nn.modules.padding._ReflectionPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReflectionPad2d" -> "torch.nn.modules.padding._ReflectionPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReflectionPad3d" -> "torch.nn.modules.padding._ReflectionPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReplicationPad1d" -> "torch.nn.modules.padding._ReplicationPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReplicationPad2d" -> "torch.nn.modules.padding._ReplicationPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ReplicationPad3d" -> "torch.nn.modules.padding._ReplicationPadNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ZeroPad1d" -> "torch.nn.modules.padding.ConstantPad1d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ZeroPad2d" -> "torch.nn.modules.padding.ConstantPad2d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding.ZeroPad3d" -> "torch.nn.modules.padding.ConstantPad3d" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding._CircularPadNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding._ConstantPadNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding._ReflectionPadNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.padding._ReplicationPadNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pixelshuffle.PixelShuffle" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pixelshuffle.PixelUnshuffle" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveAvgPool1d" -> "torch.nn.modules.pooling._AdaptiveAvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.nn.modules.pooling._AdaptiveAvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveAvgPool3d" -> "torch.nn.modules.pooling._AdaptiveAvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveMaxPool1d" -> "torch.nn.modules.pooling._AdaptiveMaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveMaxPool2d" -> "torch.nn.modules.pooling._AdaptiveMaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AdaptiveMaxPool3d" -> "torch.nn.modules.pooling._AdaptiveMaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AvgPool1d" -> "torch.nn.modules.pooling._AvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AvgPool2d" -> "torch.nn.modules.pooling._AvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.AvgPool3d" -> "torch.nn.modules.pooling._AvgPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.FractionalMaxPool2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.FractionalMaxPool3d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.LPPool1d" -> "torch.nn.modules.pooling._LPPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.LPPool2d" -> "torch.nn.modules.pooling._LPPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.LPPool3d" -> "torch.nn.modules.pooling._LPPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxPool1d" -> "torch.nn.modules.pooling._MaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxPool2d" -> "torch.nn.modules.pooling._MaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxPool3d" -> "torch.nn.modules.pooling._MaxPoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxUnpool1d" -> "torch.nn.modules.pooling._MaxUnpoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxUnpool2d" -> "torch.nn.modules.pooling._MaxUnpoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling.MaxUnpool3d" -> "torch.nn.modules.pooling._MaxUnpoolNd" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._AdaptiveAvgPoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._AdaptiveMaxPoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._AvgPoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._LPPoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._MaxPoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.pooling._MaxUnpoolNd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.GRU" -> "torch.nn.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.GRUCell" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.LSTM" -> "torch.nn.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.LSTMCell" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.RNN" -> "torch.nn.modules.rnn.RNNBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.RNNBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.RNNCell" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.rnn.RNNCellBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.sparse.Embedding" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.transformer.Transformer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.transformer.TransformerDecoder" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.transformer.TransformerDecoderLayer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.transformer.TransformerEncoder" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.transformer.TransformerEncoderLayer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.upsampling.Upsample" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.upsampling.UpsamplingBilinear2d" -> "torch.nn.modules.upsampling.Upsample" [arrowhead="empty", arrowtail="none"];
"torch.nn.modules.upsampling.UpsamplingNearest2d" -> "torch.nn.modules.upsampling.Upsample" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.DistributedDataParallelCPU" -> "torch.nn.parallel.distributed.DistributedDataParallel" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel._functions.Broadcast" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel._functions.Gather" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel._functions.ReduceAddCoalesced" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel._functions.Scatter" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.data_parallel.DataParallel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.distributed.DistributedDataParallel" -> "torch.distributed.algorithms.join.Joinable" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.distributed.DistributedDataParallel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.distributed._DDPJoinHook" -> "torch.distributed.algorithms.join.JoinHook" [arrowhead="empty", arrowtail="none"];
"torch.nn.parallel.distributed._DDPSink" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.Buffer" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.Parameter" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.UninitializedBuffer" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.UninitializedBuffer" -> "torch.nn.parameter.UninitializedTensorMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.parameter.Parameter" [arrowhead="empty", arrowtail="none"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.parameter.UninitializedTensorMixin" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.conv_expanded_weights.ConvPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.embedding_expanded_weights.EmbeddingPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.expanded_weights_impl.ExpandedWeight" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.group_norm_expanded_weights.GroupNormPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.instance_norm_expanded_weights.InstanceNormPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.layer_norm_expanded_weights.LayerNormPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils._expanded_weights.linear_expanded_weights.LinearPerSampleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.parametrizations._Orthogonal" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.parametrizations._SpectralNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.parametrizations._WeightNorm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.parametrize.ParametrizationList" -> "torch.nn.modules.container.ModuleList" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.CustomFromMask" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.Identity" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.L1Unstructured" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.LnStructured" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.PruningContainer" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.RandomStructured" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.nn.utils.prune.RandomUnstructured" -> "torch.nn.utils.prune.BasePruningMethod" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal._exporter_legacy.ResolvedExportOptions" -> "torch.onnx._internal._exporter_legacy.ExportOptions" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._diagnostic.TorchScriptOnnxExportDiagnostic" -> "torch.onnx._internal.diagnostics.infra.context.Diagnostic" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FindOperatorOverloadsInOnnxRegistry" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FindOpschemaMatchedSymbolicFunction" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FxGraphToOnnx" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FxNodeInsertTypePromotion" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FxNodeToOnnx" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._FxPass" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._MissingCustomSymbolicFunction" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._MissingStandardSymbolicFunction" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._NoSymbolicFunctionForCallFunction" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._NodeMissingOnnxShapeInference" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._OpLevelDebugging" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._OperatorSupportedInNewerOpsetVersion" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._POERules" -> "torch.onnx._internal.diagnostics.infra._infra.RuleCollection" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics._rules._UnsupportedFxNodeAnalysis" -> "torch.onnx._internal.diagnostics.infra._infra.Rule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.diagnostics.infra._infra.PatchedPropertyBag" -> "torch.onnx._internal.diagnostics.infra.sarif._property_bag.PropertyBag" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._capture_strategies.JitTraceConvertStrategy" -> "torch.onnx._internal.exporter._capture_strategies.CaptureStrategy" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._capture_strategies.JitTraceConvertStrategy._capture.WrappedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._capture_strategies.LegacyDynamoStrategy" -> "torch.onnx._internal.exporter._capture_strategies.CaptureStrategy" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._capture_strategies.TorchExportNonStrictStrategy" -> "torch.onnx._internal.exporter._capture_strategies.CaptureStrategy" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._capture_strategies.TorchExportStrategy" -> "torch.onnx._internal.exporter._capture_strategies.CaptureStrategy" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._errors.ConversionError" -> "torch.onnx.errors.OnnxExporterError" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._errors.DispatchError" -> "torch.onnx._internal.exporter._errors.ConversionError" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._errors.GraphConstructionError" -> "torch.onnx._internal.exporter._errors.ConversionError" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.exporter._errors.TorchExportError" -> "torch.onnx.errors.OnnxExporterError" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.analysis.unsupported_nodes.UnsupportedFxNodesAnalysis" -> "torch.onnx._internal.fx._pass.Analysis" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.analysis.unsupported_nodes.UnsupportedFxNodesAnalysisResult" -> "torch.onnx._internal.fx._pass.AnalysisResult" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.decomposition_skip.InstanceNormDecompSkip" -> "torch.onnx._internal.fx.decomposition_skip.DecompSkip" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.decomposition_skip.UpsampleBilinear2DDecompSkip" -> "torch.onnx._internal.fx.decomposition_skip.DecompSkip" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.decomposition_skip.UpsampleTrilinear3DDecompSkip" -> "torch.onnx._internal.fx.decomposition_skip.DecompSkip" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.diagnostics.Diagnostic" -> "torch.onnx._internal.diagnostics.infra.context.Diagnostic" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.diagnostics.infra.context.DiagnosticContext" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.diagnostics.UnsupportedFxNodeDiagnostic" -> "torch.onnx._internal.fx.diagnostics.Diagnostic" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.dynamo_graph_extractor.DynamoExport" -> "torch.onnx._internal._exporter_legacy.FXGraphExtractor" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.dynamo_graph_extractor.DynamoFlattenOutputStep" -> "torch.onnx._internal.io_adapter.FlattenOutputStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.fx_symbolic_graph_extractor.FXSymbolicTracer" -> "torch.onnx._internal._exporter_legacy.FXGraphExtractor" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.fx_symbolic_graph_extractor.ModuleExpansionTracer" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.decomp.Decompose" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.functionalization.Functionalize" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.functionalization.RemoveInputMutation" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.modularization.Modularize" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.modularization._LeafNode" -> "torch.onnx._internal.fx.passes.modularization._IRNode" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.modularization._ModuleNode" -> "torch.onnx._internal.fx.passes.modularization._IRNode" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.readability.RestoreParameterAndBufferNames" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.AllOrAnyReductionTypePromotionRule" -> "torch.onnx._internal.fx.passes.type_promotion.ReductionTypePromotionRule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.DivElementwiseTypePromotionRule" -> "torch.onnx._internal.fx.passes.type_promotion.ElementwiseTypePromotionRule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.ElementwiseTypePromotionRule" -> "torch.onnx._internal.fx.passes.type_promotion.TypePromotionRule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.InsertTypePromotion" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.ReductionTypePromotionRule" -> "torch.onnx._internal.fx.passes.type_promotion.TypePromotionRule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion.SumLikeReductionTypePromotionRule" -> "torch.onnx._internal.fx.passes.type_promotion.ReductionTypePromotionRule" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion._OpTraceDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter" -> "torch.fx.interpreter.Interpreter" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.virtualization.MovePlaceholderToFront" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.fx.passes.virtualization.ReplaceGetAttrWithPlaceholder" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.BindInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.ConvertComplexToRealRepresentationInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.ConvertComplexToRealRepresentationOutputStep" -> "torch.onnx._internal.io_adapter.OutputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.FlattenInputWithTreeSpecValidationInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.FlattenOutputStep" -> "torch.onnx._internal.io_adapter.OutputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.FlattenOutputWithTreeSpecValidationOutputStep" -> "torch.onnx._internal.io_adapter.OutputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.LiftParametersAndBuffersIntoArgsInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.MergeKwargsIntoArgsInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.PrependParamsAndBuffersAotAutogradOutputStep" -> "torch.onnx._internal.io_adapter.OutputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.PrependParamsBuffersConstantAotAutogradInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.RemoveNonTensorInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.io_adapter.RemoveNoneInputStep" -> "torch.onnx._internal.io_adapter.InputAdaptStep" [arrowhead="empty", arrowtail="none"];
"torch.onnx._internal.onnxruntime.OrtOperatorSupport" -> "torch.fx.passes.operator_support.OperatorSupport" [arrowhead="empty", arrowtail="none"];
"torch.onnx.errors.SymbolicValueError" -> "torch.onnx.errors.OnnxExporterError" [arrowhead="empty", arrowtail="none"];
"torch.onnx.errors.UnsupportedOperatorError" -> "torch.onnx.errors.OnnxExporterError" [arrowhead="empty", arrowtail="none"];
"torch.optim._adafactor.Adafactor" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.adadelta.Adadelta" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.adagrad.Adagrad" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.adam.Adam" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.adamax.Adamax" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.adamw.AdamW" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.asgd.ASGD" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.lbfgs.LBFGS" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.ChainedScheduler" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.ConstantLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.CosineAnnealingLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.CosineAnnealingWarmRestarts" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.CyclicLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.ExponentialLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.LambdaLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.LinearLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.MultiStepLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.MultiplicativeLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.OneCycleLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.PolynomialLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.ReduceLROnPlateau" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.SequentialLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler.StepLR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.lr_scheduler._LRScheduler" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.optim.nadam.NAdam" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.radam.RAdam" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.rmsprop.RMSprop" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.rprop.Rprop" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.sgd.SGD" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.sparse_adam.SparseAdam" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.optim.swa_utils.AveragedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.optim.swa_utils.SWALR" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="empty", arrowtail="none"];
"torch.overrides.BaseTorchFunctionMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.package._package_pickler.PackagePickler" -> "torch.package._package_pickler._PyTorchLegacyPickler" [arrowhead="empty", arrowtail="none"];
"torch.package.importer.OrderedImporter" -> "torch.package.importer.Importer" [arrowhead="empty", arrowtail="none"];
"torch.package.importer._SysImporter" -> "torch.package.importer.Importer" [arrowhead="empty", arrowtail="none"];
"torch.package.package_importer.PackageImporter" -> "torch.package.importer.Importer" [arrowhead="empty", arrowtail="none"];
"torch.package.package_importer._ExternNode" -> "torch.package.package_importer._PathNode" [arrowhead="empty", arrowtail="none"];
"torch.package.package_importer._ModuleNode" -> "torch.package.package_importer._PathNode" [arrowhead="empty", arrowtail="none"];
"torch.package.package_importer._PackageNode" -> "torch.package.package_importer._PathNode" [arrowhead="empty", arrowtail="none"];
"torch.profiler._memory_profiler.TensorKey" -> "torch.profiler._memory_profiler.Key" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.Conv2dBiasFollowedByBatchNorm2dPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.ExtraCUDACopyPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.FP32MatMulPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.ForLoopIndexingPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.GradNotSetToNonePattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.MatMulDimInFP16Pattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.NamePattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.OptimizerSingleTensorPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler._pattern_matcher.SynchronizedDataLoaderPattern" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="empty", arrowtail="none"];
"torch.profiler.profiler.ExecutionTraceObserver" -> "torch.profiler.profiler._ITraceObserver" [arrowhead="empty", arrowtail="none"];
"torch.profiler.profiler.profile" -> "torch.profiler.profiler._KinetoProfile" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_buffer_reader" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_buffer_writer" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_file" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_zipfile_reader" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_zipfile_writer_buffer" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization._open_zipfile_writer_file" -> "torch.serialization._opener" [arrowhead="empty", arrowtail="none"];
"torch.serialization.safe_globals" -> "torch._weights_only_unpickler._safe_globals" [arrowhead="empty", arrowtail="none"];
"torch.sparse.semi_structured.SparseSemiStructuredTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.sparse.semi_structured.SparseSemiStructuredTensorCUSPARSELT" -> "torch.sparse.semi_structured.SparseSemiStructuredTensor" [arrowhead="empty", arrowtail="none"];
"torch.sparse.semi_structured.SparseSemiStructuredTensorCUTLASS" -> "torch.sparse.semi_structured.SparseSemiStructuredTensor" [arrowhead="empty", arrowtail="none"];
"torch.storage.UntypedStorage" -> "torch.storage._StorageBase" [arrowhead="empty", arrowtail="none"];
"torch.storage._LegacyStorage" -> "torch.storage.TypedStorage" [arrowhead="empty", arrowtail="none"];
"torch.testing._comparison.BooleanPair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._comparison.NonePair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._comparison.NumberPair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._comparison.ObjectPair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._comparison.TensorLikePair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autocast_test_lists.TestAutocast" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.CubeGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.ForwardHasDefaultArgs" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.MulGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpyCube" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpyCubeNotComposable" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpyExp_" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpyMul" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpySort" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.NumpyTake" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.ScaleGradGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.Select" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.SelectGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.SortGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.TakeGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.autograd_function_db.ZeroGradientsGenVmap" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.CPUTestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.CUDATestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.DeviceTypeTestBase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.HPUTestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.LazyTestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.MPSTestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.PrivateUse1TestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.XPUTestBase" -> "torch.testing._internal.common_device_type.DeviceTypeTestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.dtypesIfCPU" -> "torch.testing._internal.common_device_type.dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.dtypesIfCUDA" -> "torch.testing._internal.common_device_type.dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.dtypesIfHPU" -> "torch.testing._internal.common_device_type.dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.dtypesIfMPS" -> "torch.testing._internal.common_device_type.dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.dtypesIfPRIVATEUSE1" -> "torch.testing._internal.common_device_type.dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.ops" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipCPUIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipCUDAIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipGPUIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipHPUIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipLazyIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipMPSIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipMetaIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipPRIVATEUSE1If" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipXLAIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_device_type.skipXPUIf" -> "torch.testing._internal.common_device_type.skipIf" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.CompositeModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.CompositeParamModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.FakeSequential" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.NestedSequentialModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.UnitModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_dist_composable.UnitParamModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.DistributedTestBase" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.DynamoDistributedMultiProcTestCase" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.DynamoDistributedSingleProcTestCase" -> "torch._dynamo.test_case.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.MultiProcContinousTest" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.MultiProcessTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.MultiThreadedTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.SaveForwardInputsModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_distributed.SaveForwardInputsModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.AlwaysWrapNestedWrappedModule" -> "torch.testing._internal.common_fsdp.NestedWrappedModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.DoubleLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.DummyDDP" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.FSDPTest" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.FSDPTestModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.FSDPTestMultiThread" -> "torch.testing._internal.common_distributed.MultiThreadedTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.MLP" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.MLPStack" -> "torch.nn.modules.container.Sequential" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.MixtureOfExperts" -> "torch.testing._internal.common_fsdp.NestedWrappedModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.ModuleWithDelay" -> "torch.testing._internal.common_fsdp.FSDPTestModel" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.NestedLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.NestedWrappedModule" -> "torch.testing._internal.common_fsdp.FSDPTestModel" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.NestedWrappedModuleWithDelay" -> "torch.testing._internal.common_fsdp.ModuleWithDelay" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.NonUniformReqGradNWM" -> "torch.testing._internal.common_fsdp.NestedWrappedModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.SkipModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.SkipModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_fsdp.TransformerWithSharedParams" -> "torch.testing._internal.common_fsdp.FSDPTestModel" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_jit.JitCommonTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations.ForeachSampleInput" -> "torch.testing._internal.opinfo.core.SampleInput" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool1d" -> "torch.testing._internal.common_methods_invocations._TestParamsMaxPoolBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool2d" -> "torch.testing._internal.common_methods_invocations._TestParamsMaxPoolBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations._TestParamsMaxPool3d" -> "torch.testing._internal.common_methods_invocations._TestParamsMaxPoolBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations.foreach_max_sample_func" -> "torch.testing._internal.common_methods_invocations.foreach_inputs_sample_func" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations.foreach_norm_sample_func" -> "torch.testing._internal.common_methods_invocations.foreach_inputs_sample_func" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_methods_invocations.foreach_pointwise_sample_func" -> "torch.testing._internal.common_methods_invocations.foreach_inputs_sample_func" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_modules.modules" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.CriterionTest" -> "torch.testing._internal.common_nn.InputVariableMixin" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.CriterionTest" -> "torch.testing._internal.common_nn.TestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.ModuleTest" -> "torch.testing._internal.common_nn.TestBase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.NNTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.NewModuleTest" -> "torch.testing._internal.common_nn.InputVariableMixin" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.NewModuleTest" -> "torch.testing._internal.common_nn.ModuleTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn._create_basic_net.Layer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn._create_basic_net.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_nn.wrap_functional.FunctionalModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_optimizers.optims" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dActivation" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dBias" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dPadBias" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dPool" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dPoolFlatten" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.ImplementedSparsifier" -> "torch.ao.pruning.sparsifier.base_sparsifier.BaseSparsifier" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.LSTMLayerNormLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.LSTMLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.LinearActivation" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.LinearActivationFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.LinearBias" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.MockSparseLinear" -> "torch.nn.modules.linear.Linear" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.SimpleConv2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_pruning.SimpleLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ActivationsTestModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedConvBnModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedNestedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedSkipQuantModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedSubNestedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvBNReLU" -> "torch.nn.modules.container.Sequential" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvBnAddReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvBnModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvBnReLUModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvReluAddModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvReluConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ConvTransposeModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.DenseTopMLP" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.DummyObserver" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.EmbBagWrapper" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.EmbeddingBagModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.EmbeddingModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalConvReluConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalConvReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalLinearAddModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalLinearReluLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.FunctionalLinearReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.InnerModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearAddModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearBnLeakyReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearModelWithSubmodule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearReluAddModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearReluLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.LinearTanhModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualConvLinearQATModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualConvLinearSymmQATModel" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualDropoutQATModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualLinearDynamicQATModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ManualLinearQATModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelForFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelForFusionWithBias" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelForLinearBNFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelMultipleOps" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelWithFunctionals" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ModelWithSequentialFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.NestedModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.NormalizationTestModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.PT2EQuantizationTestCase" -> "torch.testing._internal.common_quantization.QuantizationTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.PT2EQuantizationTestCase._get_pt2e_quantized_linear.M" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.QuantStubModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.QuantSubModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.QuantizationLiteTestCase" -> "torch.testing._internal.common_quantization.QuantizationTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.QuantizationTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.RNNCellDynamicModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.RNNDynamicModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.ResNetBase" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SingleLayerFunctionalConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SingleLayerFunctionalLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SingleLayerLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SkipQuantModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SparseNNModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SubModelForFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.SubModelWithoutFusion" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.AddInplaceAdd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.AddMulScalar" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ControlFlow" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dPropAnnotaton" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dThenConv1d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithCat" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithObsSharingOps" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoCat" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinear" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinearPermute" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvBnReLU2dAndLinearReLU" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvLinearWPermute" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvMaxPool2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvWithAdaptiveAvgPool2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.EmbeddingConvLinearModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.EmbeddingModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.GroupwiseConv2d" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.LinearReluModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.MulInplaceMul" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.ThreeAdd" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TestHelperModules.TwoLinearModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TwoLayerConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TwoLayerFunctionalConvModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TwoLayerFunctionalLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.DiagTensorBelow" -> "torch.testing._internal.common_subclass.WrapperTensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.NonWrapperTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.SparseTensor" -> "torch.testing._internal.common_subclass.WrapperTensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.SubclassWithTensorFactory" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.WrapperTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.WrapperTensorWithCustomSizes" -> "torch.testing._internal.common_subclass.WrapperTensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_subclass.WrapperTensorWithCustomStrides" -> "torch.testing._internal.common_subclass.WrapperTensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.CrossRefMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.NestedTensorTestCase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.ObjectPair" -> "torch.testing._internal.common_utils.UnittestPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.RelaxedBooleanPair" -> "torch.testing._comparison.BooleanPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.RelaxedNumberPair" -> "torch.testing._comparison.NumberPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.SetPair" -> "torch.testing._internal.common_utils.UnittestPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.StringPair" -> "torch.testing._internal.common_utils.UnittestPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.TensorOrArrayPair" -> "torch.testing._comparison.TensorLikePair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.TestCaseBase" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.TestGradients" -> "torch.testing._internal.common_utils.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.TypePair" -> "torch.testing._internal.common_utils.UnittestPair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.TypedStoragePair" -> "torch.testing._comparison.TensorLikePair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.UnittestPair" -> "torch.testing._comparison.Pair" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.decorateIf" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.parametrize" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.reparametrize" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.common_utils.swap" -> "torch.testing._internal.common_utils._TestParametrizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.composite_compliance.generate_cct_and_mode.CompositeCompliantTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.composite_compliance.generate_cct_and_mode.CompositeCompliantTensorMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.custom_tensor.ConstantExtraMetadataTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.data.network1.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.data.network2.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._shard.sharded_tensor.ShardedTensorTestBase" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel1" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel2" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._shard.test_common.SimpleMegatronLM" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.Attention" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.DTensorOpTestBase" -> "torch.testing._internal.common_distributed.MultiThreadedTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.DTensorTestBase" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.MLPModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.MLPStacked" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.RMSNormPython" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.Transformer" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.CommonDdpComparisonTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.CudaDdpComparisonTest" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.CommonDdpComparisonTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.CommonDdpComparisonTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.BatchNormNet" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.ControlFlowToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DictOutputModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_ignore_params_arg.TestModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_native_mixed_precision.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_new_tensor_in_fwd.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_different_graph_across_ranks.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_broadcast_buffer.NetWithBuffers" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_build_debug_param_to_name_mapping_requires_grad.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_control_flow_different_across_ranks.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_create_graph.Model" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_device.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_forward_backward_hook.DummyTestModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_namedtuple.NamedTupleModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_remove_autograd_hooks.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_remove_autograd_hooks.SimulateError" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_returns_tensor_with_no_grad.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_shared_grad_acc_unused_params.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sink_noclone.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sink_noclone.OpPatcher" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_static_graph_nested_types.NestedOutputModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_input_exception.ExceptionModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs.UnusedParamModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs_stop_iteration_sync_bn.ModelWithComm" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_unused_params_rebuild_buckets_exception.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_zero_output_features.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_detect_ddp_is_actually_static.ToyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_stateless_api_with_ddp.MockModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_static_graph_multi_forward.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.LargeNet" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.Net" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.NetWithBuffers" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.Task" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.TestDistBackend" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.TwoLinLayerNet" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.distributed_test._FC2" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.nn.api.remote_module_test.CommonRemoteModuleTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.nn.api.remote_module_test.CudaRemoteModuleTest" -> "torch.testing._internal.distributed.nn.api.remote_module_test.CommonRemoteModuleTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.nn.api.remote_module_test.MyModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest" -> "torch.testing._internal.distributed.nn.api.remote_module_test.CommonRemoteModuleTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.nn.api.remote_module_test.ThreeWorkersRemoteModuleTest" -> "torch.testing._internal.distributed.nn.api.remote_module_test.CommonRemoteModuleTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.CommonDistAutogradTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.CudaDistAutogradTest" -> "torch.testing._internal.distributed.rpc.dist_autograd_test.CommonDistAutogradTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest" -> "torch.testing._internal.distributed.rpc.dist_autograd_test.CommonDistAutogradTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.MyBackwardFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.TestDebugInfoFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_grad_copy_sparse_indices_extra_ref.MyFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.MyFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.MyFuncSingleGrad" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy.NonContGradFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy_sparse.MyFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy_sparse.NonContGradFunc" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.SimulateBackwardError" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeAgentDistAutogradTest" -> "torch.testing._internal.distributed.rpc.dist_autograd_test.CommonDistAutogradTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest.MyLocalCompute" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.TensorPipeCudaDistAutogradTest.MyRemoteCompute" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_autograd_test.WrapperModule" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.FailingOptimizer" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.dist_optimizer_test.OptimizerFailingOnConstructor" -> "torch.optim.optimizer.Optimizer" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.examples.parameter_server_test.ParameterServerTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.ReinforcementLearningRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.faulty_agent_rpc_test.FaultyAgentRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.jit.rpc_test.FutureTypingTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyModuleInterface" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModule" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModuleWithRRefs" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.CudaRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.MyConvNetForMNIST" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.MyEmbeddingBagModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest" -> "torch.testing._internal.distributed.rpc.rpc_test.RpcTestCommon" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_pg_init_no_rpc_init.MyModel" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentCudaRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentCudaRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_test.RpcTestCommon" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest" -> "torch.testing._internal.distributed.rpc.rpc_test.RpcTestCommon" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture" -> "torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.distributed.rpc_utils.SpawnHelper" -> "torch.testing._internal.common_distributed.MultiProcessTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.jit_metaprogramming_utils.create_script_module.script_module.TheModule" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.jit_utils.JitTestCase" -> "torch.testing._internal.common_jit.JitCommonTestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.logging_tensor.LoggingTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.logging_tensor.LoggingTensorMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.logging_tensor.LoggingTensorReentrant" -> "torch.testing._internal.logging_tensor.LoggingTensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.logging_utils.LoggingTestCase" -> "torch._dynamo.test_case.TestCase" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.BinaryUfuncInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.ForeachFuncInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.ReductionOpInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.ShapeFuncInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.SkipRule" -> "torch.testing._internal.opinfo.core.SampleRule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.SpectralFuncInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.UnaryUfuncInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.core.XFailRule" -> "torch.testing._internal.opinfo.core.SampleRule" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.definitions.fft.SpectralFuncPythonRefInfo" -> "torch.testing._internal.opinfo.core.SpectralFuncInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.refs.ElementwiseBinaryPythonRefInfo" -> "torch.testing._internal.opinfo.core.BinaryUfuncInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.refs.ElementwiseUnaryPythonRefInfo" -> "torch.testing._internal.opinfo.core.UnaryUfuncInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.refs.PythonRefInfo" -> "torch.testing._internal.opinfo.core.OpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.refs.ReductionPythonRefInfo" -> "torch.testing._internal.opinfo.core.ReductionOpInfo" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.opinfo.utils._dynamic_dispatch_dtypes" -> "torch.testing._internal.common_dtype._dispatch_dtypes" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.optests.generate_tests.OpCheckMode" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.quantization_torch_package_models.LinearReluFunctional" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.quantization_torch_package_models.LinearReluFunctionalChild" -> "torch.nn.modules.module.Module" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.subclasses.WrapperSubclass" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.two_tensor.TwoTensor" -> "torch._tensor.Tensor" [arrowhead="empty", arrowtail="none"];
"torch.testing._internal.two_tensor.TwoTensorMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.utils._config_module.ConfigModule.patch.ConfigPatch" -> "torch.utils._config_module.ContextDecorator" [arrowhead="empty", arrowtail="none"];
"torch.utils._config_module.install_config_module.ConfigModuleInstance" -> "torch.utils._config_module.ConfigModule" [arrowhead="empty", arrowtail="none"];
"torch.utils._contextlib._NoParamDecoratorContextManager" -> "torch.utils._contextlib._DecoratorContextManager" [arrowhead="empty", arrowtail="none"];
"torch.utils._device.DeviceContext" -> "torch.overrides.TorchFunctionMode" [arrowhead="empty", arrowtail="none"];
"torch.utils._python_dispatch.BaseTorchDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.utils._pytree.LeafSpec" -> "torch.utils._pytree.TreeSpec" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.functions.CleanDiv" -> "torch.utils._sympy.functions.FloorDiv" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.functions.Max" -> "torch.utils._sympy.functions.MinMaxBase" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.functions.Min" -> "torch.utils._sympy.functions.MinMaxBase" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.printers.CppPrinter" -> "torch.utils._sympy.printers.ExprPrinter" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.printers.PythonPrinter" -> "torch.utils._sympy.printers.ExprPrinter" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.reference.OptimizedPythonReferenceAnalysis" -> "torch.utils._sympy.reference.PythonReferenceAnalysis" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.reference.PythonReferenceAnalysis" -> "torch.utils._sympy.reference.ReferenceAnalysis" [arrowhead="empty", arrowtail="none"];
"torch.utils._sympy.value_ranges.ValueRangeAnalysis" -> "torch.utils._sympy.value_ranges.SymPyValueRangeAnalysis" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.op_fuzzers.binary.BinaryOpFuzzer" -> "torch.utils.benchmark.utils.fuzzer.Fuzzer" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.op_fuzzers.sparse_binary.BinaryOpSparseFuzzer" -> "torch.utils.benchmark.utils.fuzzer.Fuzzer" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.op_fuzzers.sparse_unary.UnaryOpSparseFuzzer" -> "torch.utils.benchmark.utils.fuzzer.Fuzzer" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.op_fuzzers.spectral.SpectralOpFuzzer" -> "torch.utils.benchmark.utils.fuzzer.Fuzzer" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.op_fuzzers.unary.UnaryOpFuzzer" -> "torch.utils.benchmark.utils.fuzzer.Fuzzer" [arrowhead="empty", arrowtail="none"];
"torch.utils.benchmark.utils.sparse_fuzzer.FuzzedSparseTensor" -> "torch.utils.benchmark.utils.fuzzer.FuzzedTensor" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint.CheckpointFunction" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint._CachedTorchDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint._CachingTorchDispatchMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint._NoopSaveInputs" -> "torch.autograd.function.Function" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint._checkpoint_hook" -> "torch.autograd.graph.saved_tensors_hooks" [arrowhead="empty", arrowtail="none"];
"torch.utils.checkpoint._recomputation_hook" -> "torch.autograd.graph.saved_tensors_hooks" [arrowhead="empty", arrowtail="none"];
"torch.utils.cpp_extension.BuildExtension.with_options.cls_with_options" -> "torch.utils.cpp_extension.BuildExtension" [arrowhead="empty", arrowtail="none"];
"torch.utils.data._utils.fetch._IterableDatasetFetcher" -> "torch.utils.data._utils.fetch._BaseDatasetFetcher" [arrowhead="empty", arrowtail="none"];
"torch.utils.data._utils.fetch._MapDatasetFetcher" -> "torch.utils.data._utils.fetch._BaseDatasetFetcher" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataloader._InfiniteConstantSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataloader._MultiProcessingDataLoaderIter" -> "torch.utils.data.dataloader._BaseDataLoaderIter" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataloader._SingleProcessDataLoaderIter" -> "torch.utils.data.dataloader._BaseDataLoaderIter" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes._typing._DataPipeMeta" -> "torch.utils.data.datapipes._typing.GenericMeta" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes._typing._IterDataPipeMeta" -> "torch.utils.data.datapipes._typing._DataPipeMeta" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureA" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureF" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureAdd" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureCall" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrame" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureInitial" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrameWithDataPipeOps" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrame" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureF" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureGetAttr" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureGetItem" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureInitial" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureVariable" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureMul" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureSetItem" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureSub" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureVariable" -> "torch.utils.data.datapipes.dataframe.dataframes.Capture" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.CaptureVariableAssign" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureF" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracedOps" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracer" -> "torch.utils.data.datapipes.dataframe.dataframes.CaptureDataFrameWithDataPipeOps" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.dataframes.DataFrameTracer" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.ConcatDataFramesPipe" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.DataFramesAsTuplesPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.ExampleAggregateAsDataFrames" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.FilterDataFramesPipe" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.PerRowDataFramesPipe" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.datapipes.ShuffleDataFramesPipe" -> "torch.utils.data.datapipes.datapipe.DFIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.dataframe.structures.DataChunkDF" -> "torch.utils.data.datapipes.datapipe.DataChunk" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe.DFIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.dataset.IterableDataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe.MapDataPipe" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe._IterDataPipeSerializationWrapper" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe._IterDataPipeSerializationWrapper" -> "torch.utils.data.datapipes.datapipe._DataPipeSerializationWrapper" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe._MapDataPipeSerializationWrapper" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.datapipe._MapDataPipeSerializationWrapper" -> "torch.utils.data.datapipes.datapipe._DataPipeSerializationWrapper" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.callable.CollatorIterDataPipe" -> "torch.utils.data.datapipes.iter.callable.MapperIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.callable.MapperIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combinatorics.SamplerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combinatorics.ShufflerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining.ConcaterIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining.DemultiplexerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining.ForkerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining.MultiplexerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining.ZipperIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining._ChildDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining._DemultiplexerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining._DemultiplexerIterDataPipe" -> "torch.utils.data.datapipes.iter.combining._ContainerTemplate" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining._ForkerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.combining._ForkerIterDataPipe" -> "torch.utils.data.datapipes.iter.combining._ContainerTemplate" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.filelister.FileListerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.fileopener.FileOpenerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.grouping.BatcherIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.grouping.GrouperIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.grouping.UnBatcherIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.routeddecoder.RoutedDecoderIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.selecting.FilterIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe" -> "torch.utils.data.datapipes.iter.sharding._ShardingIterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.sharding._ShardingIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.streamreader.StreamReaderIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.iter.utils.IterableWrapperIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.callable.MapperMapDataPipe" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.combinatorics.ShufflerIterDataPipe" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.combining.ConcaterMapDataPipe" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.combining.ZipperMapDataPipe" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.grouping.BatcherMapDataPipe" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.datapipes.map.utils.SequenceWrapperMapDataPipe" -> "torch.utils.data.datapipes.datapipe.MapDataPipe" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.ChainDataset" -> "torch.utils.data.dataset.IterableDataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.ConcatDataset" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.IterableDataset" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.StackDataset" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.Subset" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.dataset.TensorDataset" -> "torch.utils.data.dataset.Dataset" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.distributed.DistributedSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.sampler.BatchSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.sampler.RandomSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.sampler.SequentialSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.sampler.SubsetRandomSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.data.sampler.WeightedRandomSampler" -> "torch.utils.data.sampler.Sampler" [arrowhead="empty", arrowtail="none"];
"torch.utils.flop_counter._FlopCounterMode" -> "torch.utils._python_dispatch.TorchDispatchMode" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnBatchNorm" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnConv1d" -> "torch.utils.mkldnn._MkldnnConvNd" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnConv2d" -> "torch.utils.mkldnn._MkldnnConvNd" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnConv3d" -> "torch.utils.mkldnn._MkldnnConvNd" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnLinear" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn.MkldnnPrelu" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.utils.mkldnn._MkldnnConvNd" -> "torch.jit._script.ScriptModule" [arrowhead="empty", arrowtail="none"];
"torch.utils.tensorboard._pytorch_graph.NodePy" -> "torch.utils.tensorboard._pytorch_graph.NodeBase" [arrowhead="empty", arrowtail="none"];
"torch.utils.tensorboard._pytorch_graph.NodePyIO" -> "torch.utils.tensorboard._pytorch_graph.NodePy" [arrowhead="empty", arrowtail="none"];
"torch.utils.tensorboard._pytorch_graph.NodePyOP" -> "torch.utils.tensorboard._pytorch_graph.NodePy" [arrowhead="empty", arrowtail="none"];
"torch.xpu.device_of" -> "torch.xpu.device" [arrowhead="empty", arrowtail="none"];
"torch._decomp.decompositions_for_rng.PhiloxState" -> "torch._decomp.decompositions_for_rng.PhiloxStateTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="running_state", style="solid"];
"torch._decomp.decompositions_for_rng.PhiloxState" -> "torch._decomp.decompositions_for_rng.PhiloxStateTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fwd_state", style="solid"];
"torch._decomp.decompositions_for_rng.PhiloxState" -> "torch._decomp.decompositions_for_rng.PhiloxStateTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bwd_state", style="solid"];
"torch._dynamo.bytecode_analysis.FixedPointBox" -> "torch._dynamo.bytecode_analysis.StackSize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fixed_point", style="solid"];
"torch._dynamo.bytecode_transformation.Instruction" -> "torch._dynamo.symbolic_convert.BlockStackEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="inst", style="solid"];
"torch._dynamo.bytecode_transformation.Instruction" -> "torch._dynamo.symbolic_convert.BlockStackEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="target", style="solid"];
"torch._dynamo.bytecode_transformation.Instruction" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="current_instruction", style="solid"];
"torch._dynamo.bytecode_transformation.Instruction" -> "torch._dynamo.symbolic_convert.SpeculationEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="inst", style="solid"];
"torch._dynamo.convert_frame.CatchErrorsWrapper" -> "torch._dynamo.eval_frame._TorchDynamoContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prior", style="solid"];
"torch._dynamo.convert_frame.ConvertFrameAssert" -> "torch._dynamo.convert_frame.ConvertFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_inner_convert", style="solid"];
"torch._dynamo.eval_frame.DisableContext" -> "torch.distributed.tensor.parallel.fsdp.DTensorExtensions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="post_unflatten_transform", style="solid"];
"torch._dynamo.eval_frame.DynamoStance" -> "torch._dynamo.decorators.set_stance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stance", style="solid"];
"torch._dynamo.eval_frame.DynamoStance" -> "torch._dynamo.decorators.set_stance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prev", style="solid"];
"torch._dynamo.eval_frame.OptimizedModule" -> "torch.distributed.tensor.parallel.fsdp.DTensorExtensions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="post_unflatten_transform", style="solid"];
"torch._dynamo.eval_frame.OptimizedModule" -> "torch.nn.modules.module.Module" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_compiled_call_impl", style="solid"];
"torch._dynamo.graph_region_tracker.GraphRegionTracker" -> "torch._dynamo.output_graph.OutputGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="region_tracker", style="solid"];
"torch._dynamo.graph_region_tracker.InputPickler" -> "torch._dynamo.graph_region_tracker.GraphRegionTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_pickler", style="solid"];
"torch._dynamo.guards.GuardManagerWrapper" -> "torch._dynamo.guards.CheckFunctionManager" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="guard_manager", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.Config" -> "torch._dynamo.guards.PyExprCSEPass" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_config", style="solid"];
"torch._dynamo.output_graph.OutputGraph" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output", style="solid"];
"torch._dynamo.output_graph.VariableTrackerCache" -> "torch._dynamo.output_graph.OutputGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="variable_tracker_cache", style="solid"];
"torch._dynamo.profiler.ProfileMetrics" -> "torch._dynamo.profiler.ProfileResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="captured", style="solid"];
"torch._dynamo.profiler.ProfileMetrics" -> "torch._dynamo.profiler.ProfileResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="total", style="solid"];
"torch._dynamo.replay_record.ExecutionRecorder" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="exec_recorder", style="solid"];
"torch._dynamo.side_effects.SideEffects" -> "torch._dynamo.output_graph.OutputGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="side_effects", style="solid"];
"torch._dynamo.source.AttrProxySource" -> "torch._dynamo.variables.builder.VariableBuilder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._dynamo.source.AttrSource" -> "torch._dynamo.variables.builder.VariableBuilder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._dynamo.source.AttrSource" -> "torch._dynamo.variables.builder.VariableBuilder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._dynamo.source.OptimizerSource" -> "torch._dynamo.variables.builder.VariableBuilder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._dynamo.source.TensorProperty" -> "torch._dynamo.source.TensorPropertySource" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prop", style="solid"];
"torch._dynamo.symbolic_convert.LocalState" -> "torch._dynamo.symbolic_convert.DistributedState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="local_state", style="solid"];
"torch._dynamo.types.GuardFn" -> "torch._dynamo.types.GuardedCode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="guard_manager", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.code_context.CodeContextDict" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="code_context", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.mutation_guard.GenerationTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dynamic_classes", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.mutation_guard.GenerationTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="generation_values", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.mutation_guard.MutationTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="db", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.resume_execution.ContinueExecutionCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cache", style="solid"];
"torch._dynamo.utils.ExactWeakKeyDictionary" -> "torch._dynamo.resume_execution.ContinueExecutionCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="generated_code_metadata", style="solid"];
"torch._dynamo.variables.base.AttributeMutationExisting" -> "torch._dynamo.variables.user_defined.MutableMappingVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mutation_type", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.codegen.GraphOutputEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="variable", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.symbolic_convert.InliningInstructionTranslator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbolic_result", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kw_names", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.variables.lazy.LazySymNodeFormatString" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fmt_var", style="solid"];
"torch._dynamo.variables.ctx_manager.ContextMangerState" -> "torch._dynamo.variables.ctx_manager.ContextWrappingVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state", style="solid"];
"torch._dynamo.variables.dicts.ConstDictVariable" -> "torch._dynamo.variables.misc.InspectBoundArgumentsVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bound_arguments_var", style="solid"];
"torch._dynamo.variables.dicts.ConstDictVariable" -> "torch._dynamo.variables.user_defined.MutableMappingVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="generic_dict_vt", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.symbolic_convert.InliningInstructionTranslator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbolic_result", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kw_names", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.variables.lazy.LazyCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.variables.lazy.LazySymNodeFormatString" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fmt_var", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.symbolic_convert.InliningInstructionTranslator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbolic_result", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kw_names", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.variables.lazy.LazyCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.variables.lazy.LazySymNodeFormatString" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fmt_var", style="solid"];
"torch._dynamo.variables.lazy.LazyVariableTracker" -> "torch._dynamo.variables.user_defined.MutableMappingVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="generic_dict_vt", style="solid"];
"torch._dynamo.variables.lists.ListVariable" -> "torch._dynamo.side_effects.SideEffects" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ca_final_callbacks_var", style="solid"];
"torch._dynamo.variables.lists.SizeVariable" -> "torch._dynamo.variables.tensor.SymNodeVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_tensor_var", style="solid"];
"torch._dynamo.variables.torch.TorchInGraphFunctionVariable" -> "torch._dynamo.variables.tensor.SymNodeVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_tensor_var", style="solid"];
"torch._dynamo.variables.torch_function.SymbolicTorchFunctionState" -> "torch._dynamo.symbolic_convert.InstructionTranslator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbolic_torch_function_state", style="solid"];
"torch._dynamo.variables.torch_function.SymbolicTorchFunctionState" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbolic_torch_function_state", style="solid"];
"torch._dynamo.variables.user_defined.UserDefinedObjectVariable" -> "torch._dynamo.variables.lazy.LazyCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.user_defined.UserDefinedObjectVariable" -> "torch._dynamo.variables.tensor.SymNodeVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_tensor_var", style="solid"];
"torch._export.converter.ExplainTS2FXGraphConverter._DictMock" -> "torch._export.converter.ExplainTS2FXGraphConverter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="name_to_node", style="solid"];
"torch._export.db.case.SupportLevel" -> "torch._export.db.case.ExportCase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="support_level", style="solid"];
"torch._export.db.examples.cond_branch_class_method.MySubModule" -> "torch._export.db.examples.cond_branch_class_method.CondBranchClassMethod" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="subm", style="solid"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch._export.pass_infra.proxy_value.ProxyValue" -> "torch._export.passes.functionalize_side_effectful_ops_pass._FunctionalizeSideEffectfulOpsPass" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dep_token", style="solid"];
"torch._export.pass_infra.proxy_value.ProxyValue" -> "torch._export.passes.functionalize_side_effectful_ops_pass._FunctionalizeSideEffectfulOpsPass" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dep_token", style="solid"];
"torch._export.serde.schema.ExportedProgram" -> "torch._export.serde.serialize._SerializedProgram" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="exported_program", style="solid"];
"torch._export.serde.schema.Node" -> "torch._export.serde.aoti_schema.ExternKernelNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._export.serde.schema.Node" -> "torch._inductor.ir.ExternKernelNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._export.serde.serialize.GraphState" -> "torch._export.serde.serialize.GraphModuleSerializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph_state", style="solid"];
"torch._export.serde.serialize.GraphState" -> "torch._export.serde.serialize.GraphModuleSerializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph_state", style="solid"];
"torch._export.serde.union._UnionTag" -> "torch._export.serde.union._Union" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_type", style="solid"];
"torch._functorch._aot_autograd.autograd_cache.CompiledForward" -> "torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compiled_fw", style="solid"];
"torch._functorch._aot_autograd.schemas.ViewAndMutationMeta" -> "torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="runtime_metadata", style="solid"];
"torch._functorch._aot_autograd.schemas.ViewAndMutationMeta" -> "torch._functorch._aot_autograd.runtime_wrappers.AOTDispatchAutograd.post_compile.CompiledFunction" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch._functorch._aot_autograd.schemas.ViewAndMutationMeta" -> "torch._functorch._aot_autograd.schemas.SubclassMeta" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fw_metadata", style="solid"];
"torch._guards.GlobalContext" -> "torch._guards.TracingContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="global_context", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.guards.GuardCodeList" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="guard", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.DeterministicAlgorithmsVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.DualLevelContextManager" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.FSDPParamGroupUseTrainingStateVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.GradIncrementNestingCtxManagerVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.GradModeVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.JvpIncrementNestingCtxManagerVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.TorchFunctionDisableVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.Guard" -> "torch._dynamo.variables.ctx_manager.VmapIncrementNestingCtxManagerVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_guards_singleton", style="solid"];
"torch._guards.GuardsContext" -> "torch._guards.TracingContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="guards_context", style="solid"];
"torch._guards.GuardsSet" -> "torch._dynamo.eval_frame.ExportResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="guards", style="solid"];
"torch._guards.GuardsSet" -> "torch._guards.GuardsContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dynamo_guards", style="solid"];
"torch._guards.GuardsSet" -> "torch._guards.GuardsContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dynamo_guards", style="solid"];
"torch._guards.HopDispatchSetCache" -> "torch._guards.TracingContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hop_dispatch_set_cache", style="solid"];
"torch._guards.ModuleContext" -> "torch._guards.TracingContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module_context", style="solid"];
"torch._guards.SLoc" -> "torch._guards.ShapeGuard" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sloc", style="solid"];
"torch._guards.SLoc" -> "torch.fx.experimental.symbolic_shapes.ValueRangesSLoc" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lower", style="solid"];
"torch._guards.SLoc" -> "torch.fx.experimental.symbolic_shapes.ValueRangesSLoc" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="upper", style="solid"];
"torch._guards.Source" -> "torch._dynamo.output_graph.VariableTrackerCacheKey" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._guards.Source" -> "torch._dynamo.variables.builder.GraphArg" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._guards.Source" -> "torch._dynamo.variables.builder.TrackedFake" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._guards.Source" -> "torch._guards.ChainedSource" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="base", style="solid"];
"torch._guards.Source" -> "torch._guards.DuplicateInputs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_source_a", style="solid"];
"torch._guards.Source" -> "torch._guards.DuplicateInputs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_source_b", style="solid"];
"torch._guards.Source" -> "torch._guards.Guard" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="originating_source", style="solid"];
"torch._guards.TracingContext" -> "torch._dynamo.output_graph.OutputGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracing_context", style="solid"];
"torch._higher_order_ops.triton_kernel_wrap.Intermediate" -> "torch._higher_order_ops.triton_kernel_wrap.Op" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ret", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHMetadata" -> "torch._inductor.autoheuristic.autoheuristic.AutoHeuristic" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch._inductor.codecache.DLLWrapper" -> "torch._inductor.autotune_process.CUDABenchmarkRequest" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="DLL", style="solid"];
"torch._inductor.codecache.DLLWrapper" -> "torch._inductor.codegen.rocm.rocm_benchmark_request.ROCmBenchmarkRequest" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="DLL", style="solid"];
"torch._inductor.codegen.common.BracesBuffer" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loops_code", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cse", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cse", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_cse", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_recps_cse", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cse", style="solid"];
"torch._inductor.codegen.common.CSE" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cse", style="solid"];
"torch._inductor.codegen.common.CppWrapperKernelArgs" -> "torch._inductor.codegen.cpp.CppWrapperKernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.CppWrapperKernelArgs" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.CppWrapperKernelArgs" -> "torch._inductor.codegen.cpp_template_kernel.CppTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.KernelArgs" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.KernelArgs" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.KernelArgs" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="args", style="solid"];
"torch._inductor.codegen.common.OpOverrides" -> "torch._inductor.codegen.cuda.cuda_kernel.CUDAKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.common.OpOverrides" -> "torch._inductor.codegen.rocm.rocm_kernel.ROCmKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.common.OptimizationContext" -> "torch._inductor.codegen.cpp.RecordOptimizationContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="opt_ctx", style="solid"];
"torch._inductor.codegen.common.WorkspaceZeroMode" -> "torch._inductor.codegen.common.WorkspaceArg" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_mode", style="solid"];
"torch._inductor.codegen.cpp.CppOverrides" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.cpp.CppTile2DOverrides" -> "torch._inductor.codegen.cpp.CppTile2DKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.cpp.CppVecOverrides" -> "torch._inductor.codegen.cpp.CppVecKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.cpp.CppWrapperKernelGroup" -> "torch._inductor.codegen.cpp.CppScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_group", style="solid"];
"torch._inductor.codegen.cpp.KernelGroup" -> "torch._inductor.codegen.cpp.CppScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_group", style="solid"];
"torch._inductor.codegen.cpp.LoopNest" -> "torch._inductor.codegen.cpp.CppKernelProxy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loop_nest", style="solid"];
"torch._inductor.codegen.cpp.WorkSharing" -> "torch._inductor.codegen.cpp.KernelGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ws", style="solid"];
"torch._inductor.codegen.cuda.cuda_cpp_scheduling.CUDACPPScheduling" -> "torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_cuda_cpp_scheduling", style="solid"];
"torch._inductor.codegen.debug_utils.DebugPrinterManager" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="debug_printer", style="solid"];
"torch._inductor.codegen.debug_utils.IntermediateValueDebuggingLevel" -> "torch._inductor.codegen.debug_utils.DebugPrinterManager" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="debug_printer_level", style="solid"];
"torch._inductor.codegen.halide.HalideKernel" -> "torch._inductor.codegen.halide.HalideScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_type", style="solid"];
"torch._inductor.codegen.halide.HalideOverrides" -> "torch._inductor.codegen.halide.HalideKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.memory_planning.Allocation" -> "torch._inductor.codegen.memory_planning.BufferGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="allocation", style="solid"];
"torch._inductor.codegen.memory_planning.AllocationPools" -> "torch._inductor.codegen.memory_planning.MemoryPlanner" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pools", style="solid"];
"torch._inductor.codegen.memory_planning.BufferGroup" -> "torch._inductor.codegen.memory_planning.PoolMemoryPlanningLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="group", style="solid"];
"torch._inductor.codegen.memory_planning.LiveRange" -> "torch._inductor.codegen.memory_planning.Allocation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="live_range", style="solid"];
"torch._inductor.codegen.memory_planning.LiveRange" -> "torch._inductor.codegen.memory_planning.BufferGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="live_range", style="solid"];
"torch._inductor.codegen.memory_planning.LiveRange" -> "torch._inductor.codegen.memory_planning.BufferGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="live_range", style="solid"];
"torch._inductor.codegen.memory_planning.TemporalSplit" -> "torch._inductor.codegen.memory_planning.AllocationPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch._inductor.codegen.memory_planning.TemporalSplit" -> "torch._inductor.codegen.memory_planning.SpatialSplit" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="left", style="solid"];
"torch._inductor.codegen.memory_planning.TemporalSplit" -> "torch._inductor.codegen.memory_planning.SpatialSplit" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="right", style="solid"];
"torch._inductor.codegen.multi_kernel.MultiKernelState" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="multi_kernel_state", style="solid"];
"torch._inductor.codegen.rocm.rocm_cpp_scheduling.ROCmCPPScheduling" -> "torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_rocm_cpp_scheduling", style="solid"];
"torch._inductor.codegen.simd.SIMDKernel" -> "torch._inductor.codegen.simd.SIMDScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_type", style="solid"];
"torch._inductor.codegen.triton.BlockParameters" -> "torch._inductor.codegen.triton.BlockPtrOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="params", style="solid"];
"torch._inductor.codegen.triton.CooperativeReductionWorkspaceCache" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cooperative_reduction_workspace_cache", style="solid"];
"torch._inductor.codegen.triton.HelperFunctions" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="helper_functions", style="solid"];
"torch._inductor.codegen.triton.TritonCSE" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cse", style="solid"];
"torch._inductor.codegen.triton.TritonKernelOverrides" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="overrides", style="solid"];
"torch._inductor.codegen.triton.TritonScheduling" -> "torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_triton_scheduling", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel.RoundRobinDispatch" -> "torch._inductor.codegen.triton_combo_kernel.ComboKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dispatch_class", style="solid"];
"torch._inductor.codegen.triton_combo_kernel.ComboKernel.SequentialDispatch" -> "torch._inductor.codegen.triton_combo_kernel.ComboKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dispatch_class", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" -> "torch._inductor.codegen.wrapper.CommBufferLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wrapper", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" -> "torch._inductor.codegen.wrapper.EnterSubgraphLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wrapper", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" -> "torch._inductor.codegen.wrapper.ExitSubgraphLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wrapper", style="solid"];
"torch._inductor.codegen.wrapper.PythonWrapperCodegen" -> "torch._inductor.codegen.wrapper.MemoryPlanningLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wrapper", style="solid"];
"torch._inductor.compile_fx._CompileFxKwargs" -> "torch._inductor.output_code.CompiledFxGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_kwargs", style="solid"];
"torch._inductor.cpu_vec_isa.InvalidVecISA" -> "torch._inductor.codegen.cpp.CppVecKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vec_isa", style="solid"];
"torch._inductor.cpu_vec_isa.VecAVX2" -> "torch._inductor.codegen.cpp.CppVecKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vec_isa", style="solid"];
"torch._inductor.cpu_vec_isa.VecISA" -> "torch._inductor.codegen.cpp.CppKernelProxy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="picked_vec_isa", style="solid"];
"torch._inductor.cudagraph_trees.CUDAGraphTreeManager" -> "torch._inductor.cudagraph_trees.TreeManagerContainer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tree_manager", style="solid"];
"torch._inductor.cudagraph_utils.FunctionID" -> "torch._inductor.cudagraph_utils.WrappedFunction" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="id", style="solid"];
"torch._inductor.dependencies.ReadWrites" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="read_writes", style="solid"];
"torch._inductor.fx_passes.dedupe_symint_uses._SymHashingDict" -> "torch._inductor.fx_passes.joint_graph.UniformValueConstantFolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symint_nodes", style="solid"];
"torch._inductor.graph.GraphLowering" -> "torch._inductor.codegen.wrapper.EnterSubgraphLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch._inductor.graph.GraphLowering" -> "torch._inductor.subgraph_lowering.PointwiseSubgraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root_graph", style="solid"];
"torch._inductor.ir.Buffer" -> "torch._inductor.codegen.cpp_template.CppTemplate" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_node", style="solid"];
"torch._inductor.ir.Buffer" -> "torch._inductor.codegen.cuda.cuda_template.CUDATemplate" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_node", style="solid"];
"torch._inductor.ir.Buffer" -> "torch._inductor.codegen.rocm.rocm_template.ROCmTemplate" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_node", style="solid"];
"torch._inductor.ir.Buffer" -> "torch._inductor.codegen.wrapper.CommBufferLine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._inductor.ir.Buffer" -> "torch._inductor.scheduler.SchedulerBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._inductor.ir.CommBufferType" -> "torch._inductor.ir.CommBufferLayout" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="comm_buffer_type", style="solid"];
"torch._inductor.ir.ComputedBuffer" -> "torch._inductor.ir.StorageBox" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="data", style="solid"];
"torch._inductor.ir.ComputedBuffer" -> "torch._inductor.kernel.flex_attention.JointOutputResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="grad_input", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.codegen.cuda.cuda_kernel.LayoutArg" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.ir.BaseView" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="data", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.ir.MutableBox" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="data", style="solid"];
"torch._inductor.ir.Layout" -> "torch._inductor.ir.ReinterpretView" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layout", style="solid"];
"torch._inductor.ir.Loops" -> "torch._inductor.ir.ComputedBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="data", style="solid"];
"torch._inductor.loop_body.LoopBodyBlock" -> "torch._inductor.loop_body.LoopBody" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root_block", style="solid"];
"torch._inductor.memory.MemoryPlanningInfoForBuffer" -> "torch._inductor.memory.FreeableInputBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mpi_buffer", style="solid"];
"torch._inductor.memory.MemoryPlanningInfoForBuffer" -> "torch._inductor.scheduler.SchedulerBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mpi_buffer", style="solid"];
"torch._inductor.memory.MemoryPlanningInfoForNode" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mpi_node", style="solid"];
"torch._inductor.metrics.CachedMetricsDeltas" -> "torch._inductor.output_code.CompiledFxGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metrics_deltas", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="autotune_local", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="autotune_remote", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bundled_autotune", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_graph", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="triton", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="aot_autograd", style="solid"];
"torch._inductor.mock_cache._GlobalItemStats" -> "torch._inductor.mock_cache._GlobalStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dynamo_pgo", style="solid"];
"torch._inductor.ops_handler.KernelFormatterHandler" -> "torch._inductor.virtualized._V" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="KernelFormatterHandler", style="solid"];
"torch._inductor.ops_handler.MockHandler" -> "torch._inductor.ops_handler.SimpleCSEHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mock", style="solid"];
"torch._inductor.ops_handler.MockHandler" -> "torch._inductor.virtualized._V" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="MockHandler", style="solid"];
"torch._inductor.ops_handler.WrapperHandler" -> "torch._inductor.virtualized._V" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="WrapperHandler", style="solid"];
"torch._inductor.pattern_matcher.Match" -> "torch._inductor.fx_passes.micro_pipeline_tp._AllGatherMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="match", style="solid"];
"torch._inductor.pattern_matcher.Match" -> "torch._inductor.fx_passes.micro_pipeline_tp._ReduceScatterMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="match", style="solid"];
"torch._inductor.pattern_matcher.MatchContext" -> "torch._inductor.pattern_matcher.Match" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ctx", style="solid"];
"torch._inductor.pattern_matcher.PatternExpr" -> "torch._inductor.pattern_matcher.Match" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pattern", style="solid"];
"torch._inductor.pattern_matcher.PatternExpr" -> "torch._inductor.pattern_matcher.PatternEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pattern", style="solid"];
"torch._inductor.runtime.coordinate_descent_tuner.CoordescTuner" -> "torch._inductor.runtime.triton_heuristics.CachingAutotuner" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="coordesc_tuner", style="solid"];
"torch._inductor.runtime.hints.ReductionHint" -> "torch._inductor.ir.Reduction" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_hint", style="solid"];
"torch._inductor.runtime.hints.ReductionHint" -> "torch._inductor.ir.Scan" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_hint", style="solid"];
"torch._inductor.runtime.hints.ReductionHint" -> "torch._inductor.ir.Sort" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_hint", style="solid"];
"torch._inductor.scheduler.BaseSchedulerNode" -> "torch._inductor.memory.topological_sort_bfs.NodeWithPriority" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._inductor.scheduler.BaseSchedulerNode" -> "torch._inductor.scheduler.SchedulerBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="defining_op", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.scheduler.SchedulerBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.select_algorithm.BenchmarkTensors" -> "torch._inductor.select_algorithm.AutotuneArgs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="triton", style="solid"];
"torch._inductor.select_algorithm.BenchmarkTensors" -> "torch._inductor.select_algorithm.AutotuneArgs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="extern", style="solid"];
"torch._inductor.sizevars.SizeVarAllocator" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sizevars", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_prefix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_suffix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="parallel_reduction_prefix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="parallel_reduction_suffix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="local_reduction_init", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="local_reduction_stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="non_parallel_reduction_prefix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="preloads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="poststores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp.CppKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cuda.cutlass_epilogue_gen.CutlassEVTEpilogueArgumentFormatter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cuda.cutlass_epilogue_gen.CutlassEVTEpilogueTypeFormatter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.halide.HalideKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.halide.HalideKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.halide.HalideKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.halide.HalideKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="indexing_code_dom", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.simd.SIMDKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="body", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.simd.SIMDKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="indexing_code", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="post_loop_combine", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="post_loop_store", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="imports", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="header", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prefix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="suffix", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wrapper_call", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_autotune_defs", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_autotune_calls", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="subgraph_definitions", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.ops_handler.KernelFormatterHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.SubgraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="body", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.SubgraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.SubgraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="indexing_code", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.SubgraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.SubgraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="body", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="compute", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="indexing_code", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loads", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stores", style="solid"];
"torch._library.fake_impl.FakeImplHolder" -> "torch._library.simple_registry.SimpleOperatorEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_impl", style="solid"];
"torch._library.simple_registry.GenericTorchDispatchRuleHolder" -> "torch._library.simple_registry.SimpleOperatorEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="torch_dispatch_rules", style="solid"];
"torch._library.utils.Kernel" -> "torch._library.fake_impl.FakeImplHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel", style="solid"];
"torch._ops.OpOverload" -> "torch._inductor.fx_passes.reinplace.ViewOp" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="target", style="solid"];
"torch._ops.OpOverload" -> "torch._subclasses.fake_tensor.DataDependentOutputException" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="func", style="solid"];
"torch._ops.OpOverload" -> "torch._subclasses.fake_tensor.DynamicOutputShapeException" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="func", style="solid"];
"torch._ops.OpOverload" -> "torch._subclasses.fake_tensor.UnsupportedOperatorException" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="func", style="solid"];
"torch._ops.OpOverload" -> "torch.distributed.tensor._op_schema.OpSchema" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="op", style="solid"];
"torch._ops._PyOpNamespace" -> "torch._ops._Ops" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_higher_order_op_namespace", style="solid"];
"torch._sources.SourceContext" -> "torch._sources.ParsedDef" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ctx", style="solid"];
"torch._subclasses._fake_tensor_utils._DeconstructedSymNode" -> "torch._subclasses._fake_tensor_utils._DeconstructedSymType" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorConverter" -> "torch._subclasses.fake_tensor.FakeTensorMode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_converter", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._dynamo.compiled_autograd.AutogradCompilerInstance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._subclasses.fake_tensor.FakeTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.distributed._tools.runtime_estimator.RuntimeEstimator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.export._trace.ExportArtifact" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.onnx._internal._exporter_legacy.ONNXFakeContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.SymNumberMemoDescriptor" -> "torch._subclasses.fake_tensor.FakeTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nonzero_memo", style="solid"];
"torch._subclasses.fake_tensor.SymNumberMemoDescriptor" -> "torch._subclasses.fake_tensor.FakeTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="item_memo", style="solid"];
"torch._subclasses.fake_tensor.SymNumberMemoDescriptor" -> "torch._subclasses.fake_tensor.FakeTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unique_memo", style="solid"];
"torch._subclasses.fake_tensor.TensorMetadata" -> "torch._inductor.codecache.TensorMetadataAndValues" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor_metadata", style="solid"];
"torch._subclasses.functional_tensor.FunctionalTensorMode" -> "torch._subclasses.functional_tensor.PythonFunctionalizeAPI" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mode", style="solid"];
"torch._subclasses.meta_utils.MetaConverter" -> "torch._subclasses.fake_tensor.FakeTensorConverter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="meta_converter", style="solid"];
"torch._subclasses.meta_utils.MetaTensorDescriber" -> "torch._subclasses.meta_utils.MetaConverter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="describer", style="solid"];
"torch._tensor.Tensor" -> "torch._functorch._aot_autograd.schemas.TensorAlias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="alias", style="solid"];
"torch._tensor.Tensor" -> "torch._numpy._ndarray.ndarray" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch._subclasses.functional_tensor.FunctionalTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="elem", style="solid"];
"torch._tensor.Tensor" -> "torch._tensor.Tensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="real", style="solid"];
"torch._tensor.Tensor" -> "torch._tensor.Tensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="imag", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.nn.quantized.modules.Quantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scale", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.nn.quantized.modules.Quantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_point", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fake_quantize.FakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scale", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fake_quantize.FakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_point", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fake_quantize.FakeQuantizeBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fake_quant_enabled", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fake_quantize.FakeQuantizeBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="observer_enabled", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fx._model_report.model_report_observer.ModelReportObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="average_batch_activation_range", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.fx._model_report.model_report_observer.ModelReportObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="comp_percentile", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.FixedQParamsObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scale", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.FixedQParamsObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_point", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.HistogramObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="histogram", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.HistogramObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="min_val", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.HistogramObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="max_val", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.MinMaxObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="min_val", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.MinMaxObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="max_val", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.observer.UniformQuantizationObserverBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="eps", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.pt2e._numeric_debugger.QuantizationComparisonResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="actual", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.quantization.pt2e._numeric_debugger.QuantizationComparisonResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ref", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed._functional_collectives.AsyncCollectiveTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="elem", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed._shard.sharded_tensor.shard.Shard" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.fsdp._fully_shard._fsdp_collectives.AllGatherResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="all_gather_output", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.AllReduceState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="all_reduce_input", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.ReduceScatterState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduce_scatter_input", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.tensor._api.DTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_local_tensor", style="solid"];
"torch._tensor.Tensor" -> "torch.nested._internal.nested_tensor.NestedTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_values", style="solid"];
"torch._tensor.Tensor" -> "torch.nested._internal.nested_tensor.NestedTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_offsets", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.attention.flex_attention.BlockMask" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kv_num_blocks", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.attention.flex_attention.BlockMask" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kv_indices", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.parameter.UninitializedBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.utils.parametrizations._Orthogonal" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="base", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.utils.parametrize.ParametrizationList" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="original", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.utils.rnn.PackedSequence_" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="data", style="solid"];
"torch._tensor.Tensor" -> "torch.nn.utils.rnn.PackedSequence_" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="batch_sizes", style="solid"];
"torch._tensor.Tensor" -> "torch.onnx._internal.exporter._core.TorchTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="raw", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.composite_compliance.generate_cct_and_mode.CompositeCompliantTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="elem", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.FeatureSet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dense_features", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.FeatureSet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="values", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyClass" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="obj", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.logging_tensor.LoggingTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="elem", style="solid"];
"torch._tensor.Tensor" -> "torch.utils.data.sampler.WeightedRandomSampler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weights", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU2d" -> "torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU2d" -> "torch.ao.nn.quantized.modules.batchnorm.BatchNorm2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_NNI_BN_RELU_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU3d" -> "torch.ao.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.BNReLU3d" -> "torch.ao.nn.quantized.modules.batchnorm.BatchNorm3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_NNI_BN_RELU_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvAdd2d" -> "torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAdd2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvAddReLU2d" -> "torch.ao.nn.intrinsic.quantized.modules.conv_add.ConvAddReLU2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU1d" -> "torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU2d" -> "torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.ConvReLU3d" -> "torch.ao.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearLeakyReLU" -> "torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearLeakyReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearReLU" -> "torch.ao.nn.intrinsic.qat.modules.linear_relu.LinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearReLU" -> "torch.ao.nn.intrinsic.quantized.dynamic.modules.linear_relu.LinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearReLU" -> "torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.intrinsic.modules.fused.LinearTanh" -> "torch.ao.nn.intrinsic.quantized.modules.linear_relu.LinearTanh" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.quantizable.modules.activation.MultiheadAttention" -> "torch.ao.nn.quantized.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.quantizable.modules.rnn.LSTM" -> "torch.ao.nn.quantized.modules.rnn.LSTM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.ao.nn.quantizable.modules.rnn.LSTMCell" -> "torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cell", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" -> "torch.ao.nn.quantizable.modules.rnn._LSTMLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_fw", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" -> "torch.ao.nn.quantizable.modules.rnn._LSTMLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_fw", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" -> "torch.ao.nn.quantizable.modules.rnn._LSTMLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_bw", style="solid"];
"torch.ao.nn.quantizable.modules.rnn._LSTMSingleLayer" -> "torch.ao.nn.quantizable.modules.rnn._LSTMLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_bw", style="solid"];
"torch.ao.nn.quantized.modules.embedding_ops.EmbeddingPackedParams" -> "torch.ao.nn.quantized.modules.embedding_ops.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_packed_params", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="q_scaling_product", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fgate_cx", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="igate_cgate", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fgate_cx_igate_cgate", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ogate_cy", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="skip_add", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cat", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="skip_add", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cat", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelWithFunctionals" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mycat", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelWithFunctionals" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="myadd", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelWithFunctionals" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="myadd_relu", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ModelWithFunctionals" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mymatmul", style="solid"];
"torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="myop", style="solid"];
"torch.ao.nn.quantized.modules.linear.LinearPackedParams" -> "torch.ao.nn.quantized.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_packed_params", style="solid"];
"torch.ao.nn.sparse.quantized.linear.LinearPackedParams" -> "torch.ao.nn.sparse.quantized.dynamic.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_packed_params", style="solid"];
"torch.ao.nn.sparse.quantized.linear.LinearPackedParams" -> "torch.ao.nn.sparse.quantized.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_packed_params", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier._Container" -> "torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_container", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier._Container" -> "torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_container", style="solid"];
"torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier._Container" -> "torch.ao.pruning._experimental.data_sparsifier.base_data_sparsifier.BaseDataSparsifier" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_container", style="solid"];
"torch.ao.quantization.backend_config.backend_config.DTypeWithConstraints" -> "torch.ao.quantization.backend_config.backend_config.DTypeConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_dtype_with_constraints", style="solid"];
"torch.ao.quantization.backend_config.backend_config.DTypeWithConstraints" -> "torch.ao.quantization.backend_config.backend_config.DTypeConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_dtype_with_constraints", style="solid"];
"torch.ao.quantization.backend_config.backend_config.DTypeWithConstraints" -> "torch.ao.quantization.backend_config.backend_config.DTypeConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_dtype_with_constraints", style="solid"];
"torch.ao.quantization.fx.custom_config.PrepareCustomConfig" -> "torch.ao.quantization.fx.utils.ObservedGraphModuleAttrs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prepare_custom_config", style="solid"];
"torch.ao.quantization.observer.MovingAverageMinMaxObserver" -> "torch.ao.quantization.fake_quantize.FakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="activation_post_process", style="solid"];
"torch.ao.quantization.observer.PerChannelMinMaxObserver" -> "torch.ao.quantization.fx._equalize._InputEqualizationObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_obs", style="solid"];
"torch.ao.quantization.observer.PerChannelMinMaxObserver" -> "torch.ao.quantization.fx._equalize._WeightEqualizationObserver" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_col_obs", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.ao.quantization.stubs.QuantWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.sparse.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.ActivationsTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedSkipQuantModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.ManualDropoutQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.ManualLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.QuantStubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig_mapping.QConfigMapping" -> "torch.ao.quantization.fx.utils.ObservedGraphModuleAttrs" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="qconfig_mapping", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer_utils.QuantizationConfig" -> "torch.ao.quantization.quantizer.xnnpack_quantizer_utils.OperatorConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="config", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant_q", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant_k", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant_v", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.ao.quantization.stubs.QuantWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ActivationsTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ManualDropoutQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ManualLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.DeQuantStub" -> "torch.testing._internal.common_quantization.QuantStubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dequant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant_attn_output", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant_attn_output_weights", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.ao.quantization.stubs.QuantWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ActivationsTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ManualDropoutQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ManualLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantStub" -> "torch.testing._internal.common_quantization.QuantStubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="quant", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedSkipQuantModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedSubNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedSubNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.QuantSubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.ao.quantization.stubs.QuantWrapper" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.autograd.grad_mode.set_multithreading_enabled" -> "torch.testing._internal.distributed.multi_threaded_pg.ProcessLocalGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_ctx", style="solid"];
"torch.autograd.graph.Node" -> "torch.autograd.graph.GradientEdge" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.StreamContext" -> "torch.cuda.graphs.graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stream_ctx", style="solid"];
"torch.autograd.graph.save_on_cpu.__init__.torch.cuda.device" -> "torch._dynamo.device_interface.CudaInterface" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="device", style="solid"];
"torch.autograd.graph.saved_tensors_hooks" -> "torch.distributed._tools.sac_estimator.SACEstimator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_saved_tensor_hook_ctx", style="solid"];
"torch.autograd.profiler._ProfilerStats" -> "torch.autograd.profiler.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_stats", style="solid"];
"torch.autograd.profiler.profile" -> "torch.profiler.profiler._KinetoProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="profiler", style="solid"];
"torch.autograd.profiler.record_function" -> "torch.profiler.profiler.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="step_rec_fn", style="solid"];
"torch.autograd.profiler.record_function" -> "torch.profiler.profiler.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="step_rec_fn", style="solid"];
"torch.autograd.profiler_util.EventList" -> "torch.autograd.profiler.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_function_events", style="solid"];
"torch.autograd.profiler_util.EventList" -> "torch.autograd.profiler.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_old_function_events", style="solid"];
"torch.autograd.profiler_util.EventList" -> "torch.autograd.profiler_legacy.profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="function_events", style="solid"];
"torch.autograd.profiler_util.EventList" -> "torch.distributed.rpc.server_process_global_profiler._server_process_global_profile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="function_events", style="solid"];
"torch.autograd.profiler_util.Interval" -> "torch.autograd.profiler_util.FunctionEvent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="time_range", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.cudnn.CudnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="enabled", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.cudnn.CudnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="deterministic", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.cudnn.CudnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="benchmark", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.cudnn.CudnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="allow_tf32", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.mkldnn.MkldnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="enabled", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.mkldnn.MkldnnModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="deterministic", style="solid"];
"torch.backends.ContextProp" -> "torch.backends.opt_einsum.OptEinsumModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="enabled", style="solid"];
"torch.backends._nnapi.serializer.DimOrder" -> "torch.backends._nnapi.serializer.Operand" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dim_order", style="solid"];
"torch.backends.cuda.cuFFTPlanCacheAttrContextProp" -> "torch.backends.cuda.cuFFTPlanCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="size", style="solid"];
"torch.backends.cuda.cuFFTPlanCacheAttrContextProp" -> "torch.backends.cuda.cuFFTPlanCache" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="max_size", style="solid"];
"torch.backends.quantized._QEngineProp" -> "torch.backends.quantized.QuantizedEngine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="engine", style="solid"];
"torch.backends.quantized._SupportedQEnginesProp" -> "torch.backends.quantized.QuantizedEngine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="supported_engines", style="solid"];
"torch.backends.xeon.run_cpu._CPUinfo" -> "torch.backends.xeon.run_cpu._Launcher" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cpuinfo", style="solid"];
"torch.backends.xnnpack._XNNPACKEnabled" -> "torch.backends.xnnpack.XNNPACKEngine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="enabled", style="solid"];
"torch.cuda._sanitizer.AccessType" -> "torch.cuda._sanitizer.Access" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="type", style="solid"];
"torch.cuda._sanitizer.CUDASanitizerDispatchMode" -> "torch.cuda._sanitizer.CUDASanitizer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dispatch", style="solid"];
"torch.cuda._sanitizer.EventHandler" -> "torch.cuda._sanitizer.CUDASanitizerDispatchMode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="event_handler", style="solid"];
"torch.cuda._sanitizer.StreamSynchronizations" -> "torch.cuda._sanitizer.EventHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="syncs", style="solid"];
"torch.cuda._sanitizer._TensorsAccessed" -> "torch.cuda._sanitizer.EventHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensors_accessed", style="solid"];
"torch.distributed._functional_collectives.AsyncCollectiveTensor" -> "torch.distributed.tensor.experimental._attention._AllGatherRotater" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_aggregated_buffer", style="solid"];
"torch.distributed._functional_collectives.AsyncCollectiveTensor" -> "torch.distributed.tensor.experimental._attention._AllToAllRotater" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_buffer", style="solid"];
"torch.distributed._shard.metadata.ShardMetadata" -> "torch.distributed._shard.sharded_tensor.shard.Shard" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensor" -> "torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel1" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sharded_tensor1", style="solid"];
"torch.distributed._shard.sharded_tensor.api.ShardedTensor" -> "torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel2" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sharded_tensor2", style="solid"];
"torch.distributed._shard.sharded_tensor.metadata.ShardedTensorMetadata" -> "torch.distributed._shard.sharded_tensor.api.ShardedTensorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_metadata", style="solid"];
"torch.distributed._shard.sharded_tensor.metadata.TensorProperties" -> "torch.distributed._shard.sharded_tensor.metadata.ShardedTensorMetadata" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor_properties", style="solid"];
"torch.distributed._shard.sharding_spec.api.ShardingSpec" -> "torch.distributed._shard.sharded_tensor.api.ShardedTensorBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_sharding_spec", style="solid"];
"torch.distributed._tools.ilp_utils.ModOrder" -> "torch.distributed._tools.ilp_utils.ModuleInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod_order", style="solid"];
"torch.distributed._tools.memory_tracker.MemoryProfileDispatchMode" -> "torch.distributed._tools.memory_tracker.MemoryTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="profile_mode", style="solid"];
"torch.distributed._tools.mod_tracker.ModTracker" -> "torch.distributed._tools.mem_tracker.MemTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_mod_tracker", style="solid"];
"torch.distributed._tools.mod_tracker.ModTracker" -> "torch.distributed._tools.runtime_estimator.RuntimeEstimator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_mod_tracker", style="solid"];
"torch.distributed._tools.mod_tracker.ModTracker" -> "torch.distributed._tools.sac_estimator.SACEstimator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_mod_tracker", style="solid"];
"torch.distributed.algorithms.ddp_comm_hooks.optimizer_overlap_hooks._OptimizerHookState" -> "torch.distributed.algorithms._optimizer_overlap.optimizer_overlap._OverlappedStandardOptimizer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_opt_hook_state", style="solid"];
"torch.distributed.checkpoint._fsspec_filesystem.FileSystem" -> "torch.distributed.checkpoint._fsspec_filesystem.FsspecReader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fs", style="solid"];
"torch.distributed.checkpoint._fsspec_filesystem.FileSystem" -> "torch.distributed.checkpoint._fsspec_filesystem.FsspecWriter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fs", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystem" -> "torch.distributed.checkpoint.filesystem.FileSystemReader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fs", style="solid"];
"torch.distributed.checkpoint.filesystem.FileSystem" -> "torch.distributed.checkpoint.filesystem._FileSystemWriter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fs", style="solid"];
"torch.distributed.checkpoint.metadata.ChunkStorageMetadata" -> "torch.distributed.checkpoint.planner.TensorWriteData" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="chunk", style="solid"];
"torch.distributed.checkpoint.metadata.Metadata" -> "torch.distributed.checkpoint.format_utils.DynamicMetaLoadPlanner" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch.distributed.checkpoint.metadata.Metadata" -> "torch.distributed.checkpoint.optimizer._ReaderWithOffset" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch.distributed.checkpoint.metadata.MetadataIndex" -> "torch.distributed.checkpoint.planner.ReadItem" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dest_index", style="solid"];
"torch.distributed.checkpoint.metadata.MetadataIndex" -> "torch.distributed.checkpoint.planner.ReadItem" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="storage_index", style="solid"];
"torch.distributed.checkpoint.metadata.MetadataIndex" -> "torch.distributed.checkpoint.planner.WriteItem" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="index", style="solid"];
"torch.distributed.checkpoint.metadata.MetadataIndex" -> "torch.distributed.checkpoint.storage.WriteResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="index", style="solid"];
"torch.distributed.checkpoint.metadata.TensorProperties" -> "torch.distributed.checkpoint.metadata.TensorStorageMetadata" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="properties", style="solid"];
"torch.distributed.checkpoint.metadata.TensorProperties" -> "torch.distributed.checkpoint.planner.TensorWriteData" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="properties", style="solid"];
"torch.distributed.checkpoint.metadata.TensorStorageMetadata" -> "torch.distributed.tensor._shards_wrapper.LocalShardsWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_storage_meta", style="solid"];
"torch.distributed.checkpoint.planner.LoadItemType" -> "torch.distributed.checkpoint.planner.ReadItem" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="type", style="solid"];
"torch.distributed.checkpoint.planner.WriteItemType" -> "torch.distributed.checkpoint.planner.WriteItem" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="type", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.distributed.fsdp._fully_shard._fsdp_common.DataParallelMeshInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.distributed.tensor._collective_utils.MeshTopoInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.distributed.tensor._dtensor_spec.DTensorSpec" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.distributed.tensor._op_schema.OpInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.distributed.tensor.experimental._tp_transform._TensorParallelTransformPass" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerGroup" -> "torch.distributed.elastic.agent.server.api.SimpleElasticAgent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_worker_group", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerState" -> "torch.distributed.elastic.agent.server.api.RunResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state", style="solid"];
"torch.distributed.elastic.agent.server.health_check_server.HealthCheckServer" -> "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_health_check_server", style="solid"];
"torch.distributed.elastic.events.api.EventSource" -> "torch.distributed.elastic.events.api.Event" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch.distributed.elastic.events.api.NodeState" -> "torch.distributed.elastic.events.api.RdzvEvent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node_state", style="solid"];
"torch.distributed.elastic.multiprocessing.api.MultiprocessContext" -> "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_pcontext", style="solid"];
"torch.distributed.elastic.multiprocessing.api.SubprocessContext" -> "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_pcontext", style="solid"];
"torch.distributed.elastic.multiprocessing.tail_log.TailLog" -> "torch.distributed.elastic.multiprocessing.api.PContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_stdout_tail", style="solid"];
"torch.distributed.elastic.multiprocessing.tail_log.TailLog" -> "torch.distributed.elastic.multiprocessing.api.PContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_stderr_tail", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousHandler" -> "torch.distributed.elastic.agent.server.api.WorkerSpec" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="rdzv_handler", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_bootstrap_store_info", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_backend", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_settings", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_settings", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_settings", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="settings", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousSettings" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="timeout", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_op_executor", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDesc" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_this_node", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDesc" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_node", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDesc" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._NodeDescGenerator" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_node_desc_generator", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousState" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousState" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._BackendRendezvousStateHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousState" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousStateHolder" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state_holder", style="solid"];
"torch.distributed.elastic.rendezvous.dynamic_rendezvous._RendezvousStateHolder" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous._DistributedRendezvousOpExecutor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state_holder", style="solid"];
"torch.distributed.elastic.rendezvous.utils._PeriodicTimer" -> "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_keep_alive_timer", style="solid"];
"torch.distributed.elastic.rendezvous.utils._PeriodicTimer._Context" -> "torch.distributed.elastic.rendezvous.utils._PeriodicTimer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_ctx", style="solid"];
"torch.distributed.elastic.timer.file_based_local_timer.FileTimerServer" -> "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_worker_watchdog", style="solid"];
"torch.distributed.fsdp._common_utils._FSDPDeviceHandle" -> "torch.distributed.fsdp._common_utils._FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_device_handle", style="solid"];
"torch.distributed.fsdp._common_utils._FSDPDeviceHandle" -> "torch.distributed.fsdp._flat_param.FlatParamHandle" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_device_handle", style="solid"];
"torch.distributed.fsdp._common_utils._FSDPState" -> "torch.distributed.fsdp._optim_utils.FSDPParamInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state", style="solid"];
"torch.distributed.fsdp._flat_param.FlatParamHandle" -> "torch.distributed.fsdp._optim_utils.FSDPParamInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="handle", style="solid"];
"torch.distributed.fsdp._flat_param.FlatParameter" -> "torch.distributed.fsdp._flat_param.FlatParamHandle" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="flat_param", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.TrainingState" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_training_state", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.ExtensionsData" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_extensions_data", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPCommContext" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="comm_ctx", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPCommContext" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_comm_ctx", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_state.FSDPStateContext" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state_ctx", style="solid"];
"torch.distributed.fsdp._trace_utils._ExecutionInfo" -> "torch.distributed.fsdp._trace_utils._ExecOrderTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="exec_info", style="solid"];
"torch.distributed.fsdp.api.OptimStateDictConfig" -> "torch.distributed.fsdp._common_utils._FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_optim_state_dict_config", style="solid"];
"torch.distributed.fsdp.api.OptimStateDictConfig" -> "torch.distributed.fsdp.api.StateDictSettings" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="optim_state_dict_config", style="solid"];
"torch.distributed.fsdp.api.StateDictConfig" -> "torch.distributed.fsdp._common_utils._FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state_dict_config", style="solid"];
"torch.distributed.fsdp.api.StateDictConfig" -> "torch.distributed.fsdp.api.StateDictSettings" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state_dict_config", style="solid"];
"torch.distributed.fsdp.api.StateDictType" -> "torch.distributed.fsdp._common_utils._FSDPState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_state_dict_type", style="solid"];
"torch.distributed.fsdp.api.StateDictType" -> "torch.distributed.fsdp.api.StateDictSettings" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="state_dict_type", style="solid"];
"torch.distributed.optim.zero_redundancy_optimizer._OverlapInfo" -> "torch.distributed.optim.zero_redundancy_optimizer.ZeroRedundancyOptimizer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_overlap_info", style="solid"];
"torch.distributed.pipelining._IR.DetachExecutor" -> "torch.distributed.pipelining._IR.Pipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="executor", style="solid"];
"torch.distributed.pipelining._IR.SplitPoint" -> "torch.distributed.pipelining._IR.PipeSplitWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="SplitPoint", style="solid"];
"torch.distributed.pipelining.schedules._ComputationType" -> "torch.distributed.pipelining.schedules._Action" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="computation_type", style="solid"];
"torch.distributed.remote_device._remote_device" -> "torch.distributed._shard.sharding_spec.api.DevicePlacementSpec" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="device", style="solid"];
"torch.distributed.rpc.api.RRef" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Agent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="agent_rref", style="solid"];
"torch.distributed.tensor._dispatch.OpDispatcher" -> "torch.distributed.tensor._api.DTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_op_dispatcher", style="solid"];
"torch.distributed.tensor._dtensor_spec.DTensorSpec" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_sharding_spec", style="solid"];
"torch.distributed.tensor._dtensor_spec.DTensorSpec" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_sharding_spec", style="solid"];
"torch.distributed.tensor._dtensor_spec.DTensorSpec" -> "torch.distributed.tensor._api.DTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_spec", style="solid"];
"torch.distributed.tensor._op_schema.OpSchema" -> "torch.distributed.tensor._op_schema.OpInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="schema", style="solid"];
"torch.distributed.tensor._op_schema.OpSchema" -> "torch.distributed.tensor._op_schema.OutputSharding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="redistribute_schema", style="solid"];
"torch.distributed.tensor._ops._embedding_ops.MaskBuffer" -> "torch.distributed.tensor._ops._embedding_ops._MaskPartial" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mask_buffer", style="solid"];
"torch.distributed.tensor._ops._view_ops.DimSpec" -> "torch.distributed.tensor._ops._view_ops.Broadcast" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dim", style="solid"];
"torch.distributed.tensor._ops._view_ops.DimSpec" -> "torch.distributed.tensor._ops._view_ops.Repeat" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_dim", style="solid"];
"torch.distributed.tensor._ops._view_ops.DimSpec" -> "torch.distributed.tensor._ops._view_ops.Split" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_dim", style="solid"];
"torch.distributed.tensor._sharding_prop.LocalLRUCache" -> "torch.distributed.tensor._sharding_prop.ShardingPropagator" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="propagate_op_sharding", style="solid"];
"torch.distributed.tensor._sharding_prop.ShardingPropagator" -> "torch.distributed.tensor._dispatch.OpDispatcher" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sharding_propagator", style="solid"];
"torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" -> "torch.distributed.tensor.debug._comm_mode.CommDebugMode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="advanced_module_tracker", style="solid"];
"torch.distributed.tensor.experimental._attention._RotateMethod" -> "torch.distributed.tensor.experimental._attention._ContextParallelOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="rotate_method", style="solid"];
"torch.distributions.beta.Beta" -> "torch.distributions.lkj_cholesky.LKJCholesky" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_beta", style="solid"];
"torch.distributions.beta.Beta" -> "torch.distributions.lkj_cholesky.LKJCholesky" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_beta", style="solid"];
"torch.distributions.binomial.Binomial" -> "torch.distributions.multinomial.Multinomial" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_binomial", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.multinomial.Multinomial" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.multinomial.Multinomial" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.one_hot_categorical.OneHotCategorical" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.one_hot_categorical.OneHotCategorical" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.relaxed_categorical.ExpRelaxedCategorical" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.categorical.Categorical" -> "torch.distributions.relaxed_categorical.ExpRelaxedCategorical" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categorical", style="solid"];
"torch.distributions.chi2.Chi2" -> "torch.distributions.studentT.StudentT" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_chi2", style="solid"];
"torch.distributions.chi2.Chi2" -> "torch.distributions.wishart.Wishart" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dist_chi2", style="solid"];
"torch.distributions.chi2.Chi2" -> "torch.distributions.wishart.Wishart" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dist_chi2", style="solid"];
"torch.distributions.dirichlet.Dirichlet" -> "torch.distributions.beta.Beta" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dirichlet", style="solid"];
"torch.distributions.dirichlet.Dirichlet" -> "torch.distributions.beta.Beta" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dirichlet", style="solid"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.fishersnedecor.FisherSnedecor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_gamma1", style="solid"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.fishersnedecor.FisherSnedecor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_gamma1", style="solid"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.fishersnedecor.FisherSnedecor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_gamma2", style="solid"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.fishersnedecor.FisherSnedecor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_gamma2", style="solid"];
"torch.distributions.gamma.Gamma" -> "torch.distributions.studentT.StudentT" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_chi2", style="solid"];
"torch.distributions.independent.Independent" -> "torch.distributions.transformed_distribution.TransformedDistribution" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="base_dist", style="solid"];
"torch.export._trace.ATenExportArtifact" -> "torch.export._trace.ExportArtifact" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="aten", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="signature", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch._export.serde.serialize.GraphModuleDeserializer.Result" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="signature", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch.export._trace.ATenExportArtifact" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sig", style="solid"];
"torch.export.graph_signature.InputKind" -> "torch.export.graph_signature.InputSpec" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kind", style="solid"];
"torch.export.graph_signature.OutputKind" -> "torch.export.graph_signature.OutputSpec" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kind", style="solid"];
"torch.export.unflatten._IVals" -> "torch.export.unflatten.UnflattenedModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ivals", style="solid"];
"torch.futures.Future" -> "torch.testing._internal.distributed.rpc.examples.parameter_server_test.BatchUpdateParameterServer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="future_model", style="solid"];
"torch.fx._symbolic_trace.Tracer" -> "torch.distributed.fsdp._trace_utils.TracingConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch.fx.experimental.accelerator_partitioner.DAG" -> "torch.fx.experimental.accelerator_partitioner.PartitionResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dag", style="solid"];
"torch.fx.experimental.partitioner_utils.PartitionMode" -> "torch.fx.experimental.partitioner_utils.PartitionerConfig" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mode", style="solid"];
"torch.fx.experimental.proxy_tensor.PreDispatchTorchFunctionMode" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="proxy_function_mode", style="solid"];
"torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode" -> "torch._dynamo.compiled_autograd.AutogradCompilerInstance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="proxy_mode", style="solid"];
"torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode" -> "torch.fx.experimental.proxy_tensor.DecompositionInterpreter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mode", style="solid"];
"torch.fx.experimental.proxy_tensor.ProxyTorchDispatchMode" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="proxy_mode", style="solid"];
"torch.fx.experimental.proxy_tensor.PythonKeyTracer" -> "torch._dynamo.compiled_autograd.AutogradCompilerInstance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.fx.experimental.proxy_tensor.PythonKeyTracer" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.fx.experimental.proxy_tensor.PythonKeyTracer" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.fx.experimental.proxy_tensor.TorchFunctionMetadataMode" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="torch_fn_metadata_mode", style="solid"];
"torch.fx.experimental.proxy_tensor._GraphAppendingTracerEx" -> "torch.fx.experimental.proxy_tensor.DecompositionInterpreter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.fx.experimental.proxy_tensor._SymNodeDict" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symnode_tracker", style="solid"];
"torch.fx.experimental.symbolic_shapes.DimConstraints" -> "torch.fx.experimental.symbolic_shapes.ShapeEnv" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dim_constraints", style="solid"];
"torch.fx.experimental.symbolic_shapes.DynamicDimConstraintPrinter" -> "torch.fx.experimental.symbolic_shapes.DimConstraints" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dcp", style="solid"];
"torch.fx.experimental.symbolic_shapes.PropagateUnbackedSymInts" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="interpreter", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnv" -> "torch._dynamo.compiled_autograd.AutogradCompilerInstance" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="shape_env", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnv" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="shape_env", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnvSettings" -> "torch.fx.experimental.symbolic_shapes.ShapeEnv" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="settings", style="solid"];
"torch.fx.experimental.validator.TranslationValidator" -> "torch.fx.experimental.symbolic_shapes.ShapeEnv" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="validator", style="solid"];
"torch.fx.experimental.validator._Z3Ops" -> "torch.fx.experimental.validator.SympyToZ3" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_ops", style="solid"];
"torch.fx.graph.CodeGen" -> "torch.fx.graph.Graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_codegen", style="solid"];
"torch.fx.graph.CodeGen" -> "torch.fx.graph.Graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_codegen", style="solid"];
"torch.fx.graph.Graph" -> "torch._dynamo.output_graph.SubgraphTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._export.converter.TS2FXGraphConverter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._functorch.fx_minifier.ReproState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._inductor.loop_body.LightTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._inductor.loop_body.LoopBodyBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch._inductor.pattern_matcher.MatchContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.distributed.pipelining._utils.PipeInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.export.unflatten.UnflattenedModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.experimental.symbolic_shapes.ShapeEnv" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.interpreter.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="new_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.passes.split_module.Partition" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.passes.split_utils.Component" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.proxy.TracerBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph._FindNodesLookupTable" -> "torch.fx.graph.Graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_find_nodes_lookup_table", style="solid"];
"torch.fx.graph._Namespace" -> "torch._inductor.pattern_matcher.PatternPrettyPrinter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="namespace", style="solid"];
"torch.fx.graph._Namespace" -> "torch.fx.graph.Graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_graph_namespace", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._dynamo.eval_frame.ExportResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._export.serde.serialize.GraphModuleDeserializer.Result" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="orig_gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._inductor.ir.Subgraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.ao.pruning._experimental.pruner.base_structured_sparsifier.BaseStructuredSparsifier" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="traced", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.export._trace.ATenExportArtifact" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.export.exported_program.ExportedProgram" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.experimental.accelerator_partitioner.PartitionResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module_with_submodules", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.experimental.const_fold.FoldedGraphModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="const_subgraph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.splitter_base.SplitResult" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="split_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.interpreter.Interpreter" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="interpreter", style="solid"];
"torch.fx.interpreter.Transformer.__init__.TransformerTracer" -> "torch.fx.interpreter.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch.fx.node.Node" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportInterpreter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.ddp_fusion.CommBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="comm_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._AllGatherMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="shard_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._AllGatherMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ag_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._AllGatherMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="res_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._Matmul" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="A_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._Matmul" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="B_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._ReduceScatterMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._ReduceScatterMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="rs_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._ReduceScatterMatch" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="res_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._ScaledMatmul" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="A_scale_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.micro_pipeline_tp._ScaledMatmul" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="B_scale_node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="current_node", style="solid"];
"torch.fx.node.Node" -> "torch._subclasses._fake_tensor_utils._DeconstructedSymNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_node", style="solid"];
"torch.fx.node.Node" -> "torch.ao.ns.fx.ns_types.NSSubgraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="start_node", style="solid"];
"torch.fx.node.Node" -> "torch.ao.ns.fx.ns_types.NSSubgraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="end_node", style="solid"];
"torch.fx.node.Node" -> "torch.ao.ns.fx.ns_types.NSSubgraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="base_op_node", style="solid"];
"torch.fx.node.Node" -> "torch.export.unflatten._SubmoduleEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="parent_call_module", style="solid"];
"torch.fx.node.Node" -> "torch.fx.graph.Graph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_root", style="solid"];
"torch.fx.node.Node" -> "torch.fx.subgraph_rewriter.Match" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="anchor", style="solid"];
"torch.fx.node.Node" -> "torch.fx.subgraph_rewriter.ReplacedPatterns" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="anchor", style="solid"];
"torch.fx.passes.infra.partitioner._DependencyViewer" -> "torch.fx.passes.infra.partitioner.CapabilityBasedPartitioner" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dependency_viewer", style="solid"];
"torch.fx.proxy.Proxy" -> "torch._dynamo.output_graph.OutputGraph" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="backward_state_proxy", style="solid"];
"torch.fx.proxy.Proxy" -> "torch.fx.experimental._backward_state.BackwardState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="proxy", style="solid"];
"torch.fx.proxy.Proxy" -> "torch.fx.experimental.proxy_tensor._ProxyTensor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="proxy", style="solid"];
"torch.fx.proxy.Scope" -> "torch._inductor.loop_body.LightTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scope", style="solid"];
"torch.fx.proxy.Scope" -> "torch.ao.quantization.fx.tracer.QuantizationTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scope", style="solid"];
"torch.fx.proxy.Scope" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scope", style="solid"];
"torch.fx.proxy.Scope" -> "torch.fx.proxy.GraphAppendingTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scope", style="solid"];
"torch.fx.proxy.Scope" -> "torch.fx.proxy.TracerBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scope", style="solid"];
"torch.fx.traceback.NodeSource.NodeInfo" -> "torch.fx.traceback.NodeSource" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node_info", style="solid"];
"torch.jit._script.OrderedDictWrapper" -> "torch.jit._script.RecursiveScriptModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_parameters", style="solid"];
"torch.jit._script.OrderedDictWrapper" -> "torch.jit._script.RecursiveScriptModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_buffers", style="solid"];
"torch.jit._script.OrderedModuleDict" -> "torch.jit._script.RecursiveScriptModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_modules", style="solid"];
"torch.jit._script.RecursiveScriptModule" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="constants", style="solid"];
"torch.jit._script.RecursiveScriptModule" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="example_inputs", style="solid"];
"torch.library.Library" -> "torch._TritonLibrary" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lib", style="solid"];
"torch.library.Library" -> "torch._library.custom_ops.CustomOpDef" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_lib", style="solid"];
"torch.library.Library" -> "torch._library.fake_impl.FakeImplHolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lib", style="solid"];
"torch.multiprocessing.queue.ConnectionWrapper" -> "torch.multiprocessing.queue.Queue" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_reader", style="solid"];
"torch.multiprocessing.queue.ConnectionWrapper" -> "torch.multiprocessing.queue.Queue" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_writer", style="solid"];
"torch.multiprocessing.queue.ConnectionWrapper" -> "torch.multiprocessing.queue.SimpleQueue" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_reader", style="solid"];
"torch.multiprocessing.queue.ConnectionWrapper" -> "torch.multiprocessing.queue.SimpleQueue" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_writer", style="solid"];
"torch.multiprocessing.queue.SimpleQueue" -> "torch.multiprocessing.pool.Pool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_inqueue", style="solid"];
"torch.multiprocessing.queue.SimpleQueue" -> "torch.multiprocessing.pool.Pool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_outqueue", style="solid"];
"torch.multiprocessing.reductions.StorageWeakRef" -> "torch._inductor.cudagraph_trees.StorageWeakRefWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ref", style="solid"];
"torch.multiprocessing.reductions.StorageWeakRef" -> "torch._inductor.cudagraph_trees.StorageWeakRefWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ref", style="solid"];
"torch.multiprocessing.spawn.ProcessContext" -> "torch.distributed.elastic.multiprocessing.api.MultiprocessContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_pc", style="solid"];
"torch.nn.cpp.OrderedDictWrapper" -> "torch.nn.cpp.ModuleWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_parameters", style="solid"];
"torch.nn.cpp.OrderedDictWrapper" -> "torch.nn.cpp.ModuleWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_buffers", style="solid"];
"torch.nn.cpp.OrderedDictWrapper" -> "torch.nn.cpp.ModuleWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_modules", style="solid"];
"torch.nn.modules.activation.ELU" -> "torch.testing._internal.common_quantization.ActivationsTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="elu", style="solid"];
"torch.nn.modules.activation.GELU" -> "torch.testing._internal.distributed._shard.test_common.SimpleMegatronLM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gelu", style="solid"];
"torch.nn.modules.activation.GELU" -> "torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gelu", style="solid"];
"torch.nn.modules.activation.Hardswish" -> "torch.testing._internal.common_quantization.ActivationsTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hardswish", style="solid"];
"torch.nn.modules.activation.Hardtanh" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithObsSharingOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hardtanh", style="solid"];
"torch.nn.modules.activation.LeakyReLU" -> "torch.testing._internal.common_quantization.LinearBnLeakyReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="leaky_relu", style="solid"];
"torch.nn.modules.activation.MultiheadAttention" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.activation.MultiheadAttention" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="self_attn", style="solid"];
"torch.nn.modules.activation.MultiheadAttention" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="multihead_attn", style="solid"];
"torch.nn.modules.activation.MultiheadAttention" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="self_attn", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_fsdp.DoubleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.Conv2dPadBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="af1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="af1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="af1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.LinearActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_pruning.LinearActivationFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvBnAddReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ConvReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.FunctionalConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.FunctionalLinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.InnerModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.InnerModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu2", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.LinearReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.LinearReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.LinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.LinearReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu2", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu3", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu4", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu2", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu2", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu1", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu2", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.SubModelWithoutFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvBnReLU2dAndLinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.common_quantization.TestHelperModules.LinearReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.data.network2.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.distributed._tensor.common_dtensor.MLPModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_zero_output_features.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_static_graph_multi_forward.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.ReLU" -> "torch.testing._internal.distributed.distributed_test.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.activation.Sigmoid" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_gate", style="solid"];
"torch.nn.modules.activation.Sigmoid" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="forget_gate", style="solid"];
"torch.nn.modules.activation.Sigmoid" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_gate", style="solid"];
"torch.nn.modules.activation.Tanh" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cell_gate", style="solid"];
"torch.nn.modules.activation.Tanh" -> "torch.testing._internal.common_pruning.Conv2dPadBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act2", style="solid"];
"torch.nn.modules.activation.Tanh" -> "torch.testing._internal.common_pruning.LinearActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="act2", style="solid"];
"torch.nn.modules.activation.Tanh" -> "torch.testing._internal.common_quantization.LinearTanhModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tanh", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.nn.modules.batchnorm.LazyBatchNorm1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.common_fsdp.TransformerWithSharedParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.common_quantization.LinearBnLeakyReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1d", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn3", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.common_quantization.ModelForLinearBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm1d" -> "torch.testing._internal.distributed.distributed_test.BatchNormNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.nn.modules.batchnorm.LazyBatchNorm2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.AnnotatedConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ConvBnAddReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn2", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn2", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn1", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.SubModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm3d" -> "torch.nn.modules.batchnorm.LazyBatchNorm3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm3d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn3", style="solid"];
"torch.nn.modules.batchnorm.BatchNorm3d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn2", style="solid"];
"torch.nn.modules.container.ModuleDict" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="igates", style="solid"];
"torch.nn.modules.container.ModuleDict" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hgates", style="solid"];
"torch.nn.modules.container.ModuleDict" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gates", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.ao.nn.quantizable.modules.rnn.LSTM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layers", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.ao.nn.quantized.dynamic.modules.rnn.GRU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_all_weight_values", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.ao.nn.quantized.dynamic.modules.rnn.LSTM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_all_weight_values", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_all_weight_values", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_all_weight_values", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tail", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.nn.modules.transformer.TransformerDecoder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layers", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.nn.modules.transformer.TransformerEncoder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layers", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.testing._internal.distributed._tensor.common_dtensor.MLPStacked" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layers", style="solid"];
"torch.nn.modules.container.ModuleList" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layers", style="solid"];
"torch.nn.modules.container.ParameterList" -> "torch.distributed._composable.replicate._ReplicateState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_param_list", style="solid"];
"torch.nn.modules.container.ParameterList" -> "torch.distributed._composable.replicate._ReplicateState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_orig_module", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_dist_composable.NestedSequentialModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq1", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_dist_composable.NestedSequentialModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq2", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_dist_composable.UnitModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_dist_composable.UnitParamModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_fsdp.MixtureOfExperts" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_fsdp.NestedWrappedModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_fsdp.NonUniformReqGradNWM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dPadBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.LinearActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.LinearActivationFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.LinearBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.SimpleConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_pruning.SimpleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_quantization.DenseTopMLP" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dense_mlp", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_quantization.DenseTopMLP" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="top_mlp", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="features", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="classifier", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="seq", style="solid"];
"torch.nn.modules.container.Sequential" -> "torch.testing._internal.distributed.rpc.rpc_test.MyConvNetForMNIST" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net", style="solid"];
"torch.nn.modules.conv.Conv1d" -> "torch.nn.modules.conv.LazyConv1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.Conv1d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv3", style="solid"];
"torch.nn.modules.conv.Conv1d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dThenConv1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1d", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.nn.modules.conv.LazyConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPadBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPadBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d3", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.SimpleConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_pruning.SimpleConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.AnnotatedConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.AnnotatedConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvBnAddReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvBnAddReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvBnModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvBnReLUModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ConvReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelForFusionWithBias" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ModelWithSequentialFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.SubModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.SubModelWithoutFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dPropAnnotaton" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dThenConv1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2d", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithCat" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithCat" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithObsSharingOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoCat" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoCat" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinearPermute" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvLinearWPermute" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvMaxPool2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithAdaptiveAvgPool2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.EmbeddingConvLinearModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TestHelperModules.GroupwiseConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TwoLayerConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.Conv2d" -> "torch.testing._internal.common_quantization.TwoLayerConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.Conv3d" -> "torch.nn.modules.conv.LazyConv3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.Conv3d" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.ConvTranspose1d" -> "torch.nn.modules.conv.LazyConvTranspose1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.ConvTranspose1d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.nn.modules.conv.LazyConvTranspose2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.testing._internal.common_quantization.AnnotatedConvTransposeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.testing._internal.common_quantization.ConvTransposeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.nn.modules.conv.ConvTranspose2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="convt", style="solid"];
"torch.nn.modules.conv.ConvTranspose3d" -> "torch.nn.modules.conv.LazyConvTranspose3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.conv.ConvTranspose3d" -> "torch.testing._internal.common_quantization.ModelForConvTransposeBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv3", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout1", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout2", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout3", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout1", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout2", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.testing._internal.common_quantization.ManualDropoutQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.testing._internal.distributed._tensor.common_dtensor.Attention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="resid_dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="resid_dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout", style="solid"];
"torch.nn.modules.dropout.Dropout" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dropout", style="solid"];
"torch.nn.modules.flatten.Flatten" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="flatten", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm1d" -> "torch.nn.modules.instancenorm.LazyInstanceNorm1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm1d" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="instance_norm1d", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm2d" -> "torch.nn.modules.instancenorm.LazyInstanceNorm2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm2d" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="instance_norm2d", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm3d" -> "torch.nn.modules.instancenorm.LazyInstanceNorm3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.instancenorm.InstanceNorm3d" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="instance_norm3d", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.ao.nn.quantized.modules.functional_modules.FloatFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="activation_post_process", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.ao.nn.quantized.modules.functional_modules.QFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="activation_post_process", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_fsdp.TransformerWithSharedParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="downsample", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="downsample", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvTWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.nn.modules.linear.Identity" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="relu", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch._export.db.examples.class_method.ClassMethod" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.qat.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear_Q", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear_K", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear_V", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.quantizable.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_proj", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.sparse.quantized.dynamic.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.ao.nn.sparse.quantized.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="head", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.linear.LazyLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.nn.parallel.distributed.DistributedDataParallel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.CompositeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.CompositeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.CompositeParamModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.NestedSequentialModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.UnitModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.UnitModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_dist_composable.UnitParamModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_distributed.SaveForwardInputsModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.DoubleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.DoubleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.MLP" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_proj", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.MLP" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_proj", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.NestedLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nested_linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.NestedLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nested_linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.SkipModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.SkipModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_fsdp.TransformerWithSharedParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_proj", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LSTMLayerNormLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LSTMLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LinearActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LinearActivation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LinearActivationFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LinearActivationFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.LinearActivationFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear3", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.SimpleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_pruning.SimpleLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.AnnotatedSkipQuantModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.InnerModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.InnerModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearBnLeakyReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearModelWithSubmodule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearReluAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.LinearTanhModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualConvLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualDropoutQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualLinearDynamicQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualLinearDynamicQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ManualLinearQATModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ModelForLinearBNFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.NestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.PT2EQuantizationTestCase._get_pt2e_quantized_linear.M" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.QuantStubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.QuantSubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.SingleLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.SkipQuantModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dPropAnnotaton" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinearPermute" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithTwoLinearPermute" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvBnReLU2dAndLinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvLinearWPermute" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.EmbeddingConvLinearModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.LinearReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.TwoLinearModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TestHelperModules.TwoLinearModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.data.network1.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.data.network2.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._shard.test_common.SimpleMegatronLM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._shard.test_common.SimpleMegatronLM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.Attention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wq", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.Attention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wk", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.Attention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wv", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.Attention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="wo", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="w1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="w2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.MLPModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.MLPModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.BatchNormNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.BatchNormNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.ControlFlowToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.ControlFlowToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_ignore_params_arg.TestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_ignore_params_arg.TestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_ignore_params_arg.TestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin_layer", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_native_mixed_precision.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="m", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_new_tensor_in_fwd.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_new_tensor_in_fwd.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_different_graph_across_ranks.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_different_graph_across_ranks.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_broadcast_buffer.NetWithBuffers" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="a", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_broadcast_buffer.NetWithBuffers" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_build_debug_param_to_name_mapping_requires_grad.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_control_flow_different_across_ranks.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_control_flow_different_across_ranks.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_device.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_forward_backward_hook.DummyTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_has_finalized.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_namedtuple.NamedTupleModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_remove_autograd_hooks.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_returns_tensor_with_no_grad.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_returns_tensor_with_no_grad.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_shared_grad_acc_unused_params.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_shared_grad_acc_unused_params.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sink_noclone.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_static_graph_nested_types.NestedOutputModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs_stop_iteration_sync_bn.ModelWithComm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_unused_params_rebuild_buckets_exception.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_unused_params_rebuild_buckets_exception.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_zero_output_features.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_zero_output_features.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_detect_ddp_is_actually_static.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_detect_ddp_is_actually_static.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="net2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nn1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nn2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nn3", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_grads_same_across_ranks_with_no_sync.SimpleConditionalModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nn4", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_stateless_api_with_ddp.MockModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_static_graph_multi_forward.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.LargeNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.LargeNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc3", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.NetWithBuffers" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="a", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.NetWithBuffers" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.TwoLinLayerNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="a", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.TwoLinLayerNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="a", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="c", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.distributed_test._FC2" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.rpc.examples.parameter_server_test.BatchUpdateParameterServer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="model", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="affine1", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="affine2", style="solid"];
"torch.nn.modules.linear.Linear" -> "torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_pg_init_no_rpc_init.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.nn.modules.linear.NonDynamicallyQuantizableLinear" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_proj", style="solid"];
"torch.nn.modules.loss.L1Loss" -> "torch.testing._internal.distributed.rpc.examples.parameter_server_test.Trainer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="loss_fn", style="solid"];
"torch.nn.modules.module.Module" -> "torch._export.db.case.ExportCase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="model", style="solid"];
"torch.nn.modules.module.Module" -> "torch._export.pass_base._ExportPassBaseDeprecatedDoNotUse.ExportTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.nn.modules.module.Module" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch._export.serde.serialize.GraphModuleDeserializer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="igates", style="solid"];
"torch.nn.modules.module.Module" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hgates", style="solid"];
"torch.nn.modules.module.Module" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="gates", style="solid"];
"torch.nn.modules.module.Module" -> "torch.ao.quantization.stubs.QuantWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed._composable.replicate._ReplicateState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._flat_param.ParamInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._flat_param.SharedParamInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._flat_param.SharedParamInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prim_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._fully_shard._fsdp_param.ParamModuleInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._trace_utils._ParamUsageInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.export.unflatten._SubmoduleEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="parent_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.export.unflatten._SubmoduleEntry" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.fx._symbolic_trace.Tracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.nn.modules.module.Module" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.nn.modules.module.Module" -> "torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lstm", style="solid"];
"torch.nn.modules.module.Module" -> "torch.testing._internal.common_quantization.RNNDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.module.Module" -> "torch.testing._internal.common_quantization.RNNDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.module.Module" -> "torch.testing._internal.distributed.distributed_test.DDPUnevenTestInput" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="model", style="solid"];
"torch.nn.modules.normalization.GroupNorm" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="group_norm", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm1", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm2", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.transformer.TransformerDecoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm3", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm1", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.nn.modules.transformer.TransformerEncoderLayer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm2", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.testing._internal.common_pruning.LSTMLayerNormLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.testing._internal.common_quantization.NormalizationTestModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_norm", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="norm", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="attention_norm", style="solid"];
"torch.nn.modules.normalization.LayerNorm" -> "torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ffn_norm", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlatten" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="avg_pool", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_pruning.Conv2dPoolFlattenFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="avg_pool", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_quantization.ModelMultipleOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="avgpool", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_quantization.ResNetBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="avgpool", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_quantization.TestHelperModules.Conv2dWithObsSharingOps" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="adaptive_avg_pool2d", style="solid"];
"torch.nn.modules.pooling.AdaptiveAvgPool2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvWithAdaptiveAvgPool2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="adaptive_avg_pool2d", style="solid"];
"torch.nn.modules.pooling.MaxPool2d" -> "torch.testing._internal.common_pruning.Conv2dPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="maxpool", style="solid"];
"torch.nn.modules.pooling.MaxPool2d" -> "torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="maxpool", style="solid"];
"torch.nn.modules.pooling.MaxPool2d" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvMaxPool2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pool", style="solid"];
"torch.nn.modules.rnn.GRU" -> "torch.ao.nn.quantized.dynamic.modules.rnn.GRU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.rnn.GRUCell" -> "torch.testing._internal.common_quantization.RNNCellDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.rnn.LSTM" -> "torch.ao.nn.quantizable.modules.rnn.LSTM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.rnn.LSTM" -> "torch.ao.nn.quantized.dynamic.modules.rnn.LSTM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.rnn.LSTM" -> "torch.testing._internal.common_pruning.LSTMLayerNormLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lstm", style="solid"];
"torch.nn.modules.rnn.LSTM" -> "torch.testing._internal.common_pruning.LSTMLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lstm", style="solid"];
"torch.nn.modules.rnn.LSTMCell" -> "torch.ao.nn.quantizable.modules.rnn.LSTMCell" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.rnn.LSTMCell" -> "torch.testing._internal.common_quantization.RNNCellDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.rnn.RNNBase" -> "torch.ao.nn.quantized.dynamic.modules.rnn.RNNBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.rnn.RNNCell" -> "torch.testing._internal.common_quantization.RNNCellDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.rnn.RNNCell" -> "torch.testing._internal.common_quantization.RNNCellDynamicModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.ao.nn.qat.modules.embedding_ops.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.common_fsdp.TransformerWithSharedParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="embed_tokens", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.common_quantization.DeFusedEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.common_quantization.EmbeddingModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.common_quantization.TestHelperModules.EmbeddingConvLinearModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.common_quantization.TestHelperModules.EmbeddingModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tok_embeddings", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="pos_embeddings", style="solid"];
"torch.nn.modules.sparse.Embedding" -> "torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="embedding", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.ao.nn.qat.modules.embedding_ops.EmbeddingBag" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_FLOAT_MODULE", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.common_quantization.EmbBagWrapper" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb_bag", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.common_quantization.EmbeddingBagModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.common_quantization.ManualEmbeddingBagLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="emb", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="em", style="solid"];
"torch.nn.modules.sparse.EmbeddingBag" -> "torch.testing._internal.distributed.rpc.rpc_test.MyEmbeddingBagModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="eb", style="solid"];
"torch.nn.modules.transformer.Transformer" -> "torch.testing._internal.common_fsdp.TransformerWithSharedParams" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="transformer", style="solid"];
"torch.nn.modules.transformer.TransformerDecoder" -> "torch.nn.modules.transformer.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="decoder", style="solid"];
"torch.nn.modules.transformer.TransformerEncoder" -> "torch.nn.modules.transformer.Transformer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="encoder", style="solid"];
"torch.nn.parallel.distributed.DistributedDataParallel" -> "torch.distributed._composable.replicate._ReplicateState" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_ddp", style="solid"];
"torch.nn.parallel.distributed.DistributedDataParallel" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.nn.parallel.distributed.DistributedDataParallel" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hybrid_module", style="solid"];
"torch.nn.parallel.distributed._BufferCommHook" -> "torch.nn.parallel.distributed.DistributedDataParallel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="buffer_hook", style="solid"];
"torch.nn.parallel.distributed._BufferCommHookLocation" -> "torch.nn.parallel.distributed._BufferCommHook" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="buffer_comm_hook_location", style="solid"];
"torch.nn.parameter.Buffer" -> "torch.testing._internal.common_nn._create_basic_net.Layer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_dummy_buf", style="solid"];
"torch.nn.parameter.Buffer" -> "torch.testing._internal.common_nn._create_basic_net.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dummy_buf", style="solid"];
"torch.nn.parameter.Parameter" -> "torch._dynamo.variables.lists.ListVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="class_type", style="solid"];
"torch.nn.parameter.Parameter" -> "torch._dynamo.variables.lists.SizeVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="class_type", style="solid"];
"torch.nn.parameter.Parameter" -> "torch._dynamo.variables.lists.TupleVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="class_type", style="solid"];
"torch.nn.parameter.Parameter" -> "torch._dynamo.variables.torch.TorchInGraphFunctionVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="class_type", style="solid"];
"torch.nn.parameter.Parameter" -> "torch._dynamo.variables.user_defined.UserDefinedObjectVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="class_type", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.nn.intrinsic.qat.modules.conv_fused._ConvBnNd" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.nn.intrinsic.qat.modules.linear_fused.LinearBn1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.nn.quantized.reference.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.nn.quantized.reference.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scale", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="scale", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_point", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.ao.quantization._learnable_fake_quantize._LearnableFakeQuantize" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_point", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sharded_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_unsharded_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_sharded_post_forward_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="q_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="q_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="k_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="k_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="v_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="v_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_proj_weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_proj_bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_k", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_k", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_v", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.MultiheadAttention" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_v", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.activation.PReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.batchnorm._NormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.batchnorm._NormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.container.ModuleDict" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.container.ModuleDict" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.container.ModuleDict" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.container.ModuleDict" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.conv._ConvNd" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.conv._ConvNd" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.conv._ConvNd" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Bilinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Bilinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.Linear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.NonDynamicallyQuantizableLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.linear.NonDynamicallyQuantizableLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.normalization.GroupNorm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.normalization.GroupNorm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.normalization.LayerNorm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.normalization.LayerNorm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.normalization.RMSNorm" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_ih", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_hh", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_ih", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.rnn.RNNCellBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias_hh", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.Embedding" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.modules.sparse.EmbeddingBag" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.nn.parameter.UninitializedParameter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cls_to_become", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.common_dist_composable.CompositeParamModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="p", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.common_dist_composable.UnitParamModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="p", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.common_nn._create_basic_net.Layer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="layer_dummy_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.common_nn._create_basic_net.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dummy_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel1" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="random_tensor1", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel2" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="random_tensor2", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed._tensor.common_dtensor.RMSNormPython" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_native_mixed_precision.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="p", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_create_graph.Model" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="p", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_shared_grad_acc_unused_params.ToyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_input_exception.ExceptionModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="no_grad_param", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.distributed_test.Task" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="p", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.quantization_torch_package_models.LinearReluFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="w1", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.quantization_torch_package_models.LinearReluFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b1", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.quantization_torch_package_models.LinearReluFunctionalChild" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="w1", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.quantization_torch_package_models.LinearReluFunctionalChild" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="b1", style="solid"];
"torch.nn.parameter.UninitializedBuffer" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="running_mean", style="solid"];
"torch.nn.parameter.UninitializedBuffer" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="running_var", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.batchnorm._LazyNormBase" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConv3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose1d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose2d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv.LazyConvTranspose3d" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.conv._LazyConvXdMixin" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.linear.LazyLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch.nn.parameter.UninitializedParameter" -> "torch.nn.modules.linear.LazyLinear" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bias", style="solid"];
"torch.nn.utils._named_member_accessor.NamedMemberAccessor" -> "torch.nn.utils.stateless._ReparametrizeModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="accessor", style="solid"];
"torch.onnx._experimental.ExportOptions" -> "torch.onnx.verification.GraphInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="export_options", style="solid"];
"torch.onnx._internal._exporter_legacy.OnnxRegistry" -> "torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="onnx_registry", style="solid"];
"torch.onnx._internal._exporter_legacy.ResolvedExportOptions" -> "torch.onnx._internal.onnxruntime.OrtBackend" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_resolved_onnx_exporter_options", style="solid"];
"torch.onnx._internal.diagnostics._rules._FindOperatorOverloadsInOnnxRegistry" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="find_operator_overloads_in_onnx_registry", style="solid"];
"torch.onnx._internal.diagnostics._rules._FindOpschemaMatchedSymbolicFunction" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="find_opschema_matched_symbolic_function", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxGraphToOnnx" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_graph_to_onnx", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxNodeInsertTypePromotion" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_node_insert_type_promotion", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxNodeToOnnx" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_node_to_onnx", style="solid"];
"torch.onnx._internal.diagnostics._rules._FxPass" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_pass", style="solid"];
"torch.onnx._internal.diagnostics._rules._MissingCustomSymbolicFunction" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="missing_custom_symbolic_function", style="solid"];
"torch.onnx._internal.diagnostics._rules._MissingStandardSymbolicFunction" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="missing_standard_symbolic_function", style="solid"];
"torch.onnx._internal.diagnostics._rules._NoSymbolicFunctionForCallFunction" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="no_symbolic_function_for_call_function", style="solid"];
"torch.onnx._internal.diagnostics._rules._NodeMissingOnnxShapeInference" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="node_missing_onnx_shape_inference", style="solid"];
"torch.onnx._internal.diagnostics._rules._OpLevelDebugging" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="op_level_debugging", style="solid"];
"torch.onnx._internal.diagnostics._rules._OperatorSupportedInNewerOpsetVersion" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="operator_supported_in_newer_opset_version", style="solid"];
"torch.onnx._internal.diagnostics._rules._UnsupportedFxNodeAnalysis" -> "torch.onnx._internal.diagnostics._rules._POERules" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unsupported_fx_node_analysis", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.DiagnosticOptions" -> "torch.onnx._internal._exporter_legacy.ExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="diagnostic_options", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.DiagnosticOptions" -> "torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="diagnostic_options", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.DiagnosticOptions" -> "torch.onnx._internal.diagnostics.infra.context.DiagnosticContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="options", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Level" -> "torch.onnx._internal.diagnostics.infra.context.Diagnostic" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="level", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Location" -> "torch.onnx._internal.diagnostics.infra._infra.StackFrame" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="location", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Location" -> "torch.onnx._internal.diagnostics.infra._infra.ThreadFlowLocation" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="location", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Rule" -> "torch.onnx._internal.diagnostics.infra.context.Diagnostic" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="rule", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Stack" -> "torch.onnx._internal.diagnostics._diagnostic.TorchScriptOnnxExportDiagnostic" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="python_call_stack", style="solid"];
"torch.onnx._internal.diagnostics.infra._infra.Stack" -> "torch.onnx._internal.diagnostics._diagnostic.TorchScriptOnnxExportDiagnostic" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="cpp_call_stack", style="solid"];
"torch.onnx._internal.diagnostics.infra.context.DiagnosticContext" -> "torch.onnx._internal.diagnostics._diagnostic.ExportDiagnosticEngine" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_background_context", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact_location.ArtifactLocation" -> "torch.onnx._internal.diagnostics.infra.sarif._artifact_change.ArtifactChange" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="artifact_location", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._artifact_location.ArtifactLocation" -> "torch.onnx._internal.diagnostics.infra.sarif._attachment.Attachment" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="artifact_location", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._message.Message" -> "torch.onnx._internal.diagnostics.infra.sarif._notification.Notification" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="message", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._message.Message" -> "torch.onnx._internal.diagnostics.infra.sarif._result.Result" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="message", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._property_bag.PropertyBag" -> "torch.onnx._internal.diagnostics.infra.sarif._result.Result" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="properties", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._region.Region" -> "torch.onnx._internal.diagnostics.infra.sarif._replacement.Replacement" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="deleted_region", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_configuration.ReportingConfiguration" -> "torch.onnx._internal.diagnostics.infra.sarif._configuration_override.ConfigurationOverride" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="configuration", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_reference.ReportingDescriptorReference" -> "torch.onnx._internal.diagnostics.infra.sarif._configuration_override.ConfigurationOverride" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="descriptor", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_reference.ReportingDescriptorReference" -> "torch.onnx._internal.diagnostics.infra.sarif._reporting_descriptor_relationship.ReportingDescriptorRelationship" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="target", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool.Tool" -> "torch.onnx._internal.diagnostics.infra.sarif._conversion.Conversion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tool", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool.Tool" -> "torch.onnx._internal.diagnostics.infra.sarif._run.Run" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tool", style="solid"];
"torch.onnx._internal.diagnostics.infra.sarif._tool_component.ToolComponent" -> "torch.onnx._internal.diagnostics.infra.sarif._tool.Tool" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="driver", style="solid"];
"torch.onnx._internal.exporter._schemas.TypeConstraintParam" -> "torch.onnx._internal.exporter._schemas.Parameter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="type_constraint", style="solid"];
"torch.onnx._internal.fx._pass.PackageInfo" -> "torch.onnx._internal.fx._pass.GraphModuleOnnxMeta" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="package_info", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.fx._pass.Transform" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.dynamo_graph_extractor.DynamoExport" -> "torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fx_tracer", style="solid"];
"torch.onnx._internal.fx.dynamo_graph_extractor._PyTreeExtensionContext" -> "torch.onnx._internal.fx.dynamo_graph_extractor.DynamoFlattenOutputStep" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_pytree_extension_context", style="solid"];
"torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher" -> "torch.onnx._internal._exporter_legacy.ResolvedExportOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="onnxfunction_dispatcher", style="solid"];
"torch.onnx._internal.fx.passes.modularization._ModuleStackMeta" -> "torch.onnx._internal.fx.passes.modularization._LeafNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_stack_meta", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter" -> "torch.onnx._internal.fx.passes.type_promotion.InsertTypePromotion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="interpreter", style="solid"];
"torch.onnx._internal.io_adapter.InputAdapter" -> "torch.onnx._internal._exporter_legacy.FXGraphExtractor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_adapter", style="solid"];
"torch.onnx._internal.io_adapter.OutputAdapter" -> "torch.onnx._internal._exporter_legacy.FXGraphExtractor" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="output_adapter", style="solid"];
"torch.onnx._internal.onnxruntime.OrtExecutionInfoForAllGraphModules" -> "torch.onnx._internal.onnxruntime.OrtBackend" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_all_ort_execution_info", style="solid"];
"torch.onnx._internal.onnxruntime.OrtOperatorSupport" -> "torch.onnx._internal.onnxruntime.OrtBackend" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_supported_ops", style="solid"];
"torch.onnx.verification.GraphInfoPrettyPrinter" -> "torch.onnx.verification.GraphInfoPrettyPrinter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="upper_printer", style="solid"];
"torch.onnx.verification.GraphInfoPrettyPrinter" -> "torch.onnx.verification.GraphInfoPrettyPrinter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lower_printer", style="solid"];
"torch.onnx.verification.OnnxBackend" -> "torch.onnx.verification.VerificationOptions" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="backend", style="solid"];
"torch.optim.adam.Adam" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Agent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.sgd.SGD" -> "torch.testing._internal.distributed.rpc.examples.parameter_server_test.BatchUpdateParameterServer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.package._digraph.DiGraph" -> "torch.package.package_exporter.PackageExporter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dependency_graph", style="solid"];
"torch.package._directory_reader.DirectoryReader" -> "torch.package.package_importer.PackageImporter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zip_reader", style="solid"];
"torch.package._mangling.PackageMangler" -> "torch.package.package_importer.PackageImporter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_mangler", style="solid"];
"torch.package.importer.OrderedImporter" -> "torch.package.package_exporter.PackageExporter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="importer", style="solid"];
"torch.package.package_exporter._ModuleProviderAction" -> "torch.package.package_exporter._PatternInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="action", style="solid"];
"torch.package.package_importer._PackageNode" -> "torch.package.package_importer.PackageImporter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.profiler._memory_profiler.CategoryDict" -> "torch.profiler._memory_profiler.MemoryProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_categories", style="solid"];
"torch.profiler._memory_profiler.DataFlowGraph" -> "torch.profiler._memory_profiler.MemoryProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_data_flow_graph", style="solid"];
"torch.profiler._memory_profiler.MemoryProfileTimeline" -> "torch.profiler.profiler._KinetoProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mem_tl", style="solid"];
"torch.profiler._memory_profiler.OpTree" -> "torch.profiler._memory_profiler.MemoryProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_op_tree", style="solid"];
"torch.profiler._memory_profiler.SizeMap" -> "torch.profiler._memory_profiler.MemoryProfile" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_size_map", style="solid"];
"torch.profiler._memory_profiler._Storage" -> "torch.profiler._memory_profiler.TensorKey" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="storage", style="solid"];
"torch.profiler.profiler.profile" -> "torch._dynamo.profiler.Profiler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="prof", style="solid"];
"torch.storage.UntypedStorage" -> "torch.storage.TypedStorage" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_untyped_storage", style="solid"];
"torch.storage.UntypedStorage" -> "torch.storage.TypedStorage" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_untyped_storage", style="solid"];
"torch.testing._internal.common_dist_composable.UnitModule" -> "torch.testing._internal.common_dist_composable.CompositeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="u1", style="solid"];
"torch.testing._internal.common_dist_composable.UnitModule" -> "torch.testing._internal.common_dist_composable.CompositeModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="u2", style="solid"];
"torch.testing._internal.common_dist_composable.UnitModule" -> "torch.testing._internal.common_dist_composable.CompositeParamModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="u1", style="solid"];
"torch.testing._internal.common_dist_composable.UnitModule" -> "torch.testing._internal.common_dist_composable.CompositeParamModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="u2", style="solid"];
"torch.testing._internal.common_distributed.SaveForwardInputsModule" -> "torch.testing._internal.common_distributed.SaveForwardInputsModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="c1", style="solid"];
"torch.testing._internal.common_distributed.SaveForwardInputsModule" -> "torch.testing._internal.common_distributed.SaveForwardInputsModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="c2", style="solid"];
"torch.testing._internal.common_dtype._dispatch_dtypes" -> "torch.testing._internal.opinfo.core.ForeachFuncInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dtypes", style="solid"];
"torch.testing._internal.common_fsdp.NestedLinear" -> "torch.testing._internal.common_fsdp.SkipModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nested_linear", style="solid"];
"torch.testing._internal.common_fsdp.SkipModule" -> "torch.testing._internal.common_fsdp.SkipModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear_skip", style="solid"];
"torch.testing._internal.common_nn._create_basic_net.Layer" -> "torch.testing._internal.common_nn._create_basic_net.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="l1", style="solid"];
"torch.testing._internal.common_quantization.DenseTopMLP" -> "torch.testing._internal.common_quantization.SparseNNModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dense_top", style="solid"];
"torch.testing._internal.common_quantization.EmbBagWrapper" -> "torch.testing._internal.common_quantization.SparseNNModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="model_sparse", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.FunctionalConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.FunctionalConvReluConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.FunctionalConvReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.SingleLayerFunctionalConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.TwoLayerFunctionalConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalConv2d" -> "torch.testing._internal.common_quantization.TwoLayerFunctionalConvModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv2", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.FunctionalLinearAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.FunctionalLinearAddModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.FunctionalLinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.FunctionalLinearReluLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.FunctionalLinearReluModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.SingleLayerFunctionalLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.TwoLayerFunctionalLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear1", style="solid"];
"torch.testing._internal.common_quantization.FunctionalLinear" -> "torch.testing._internal.common_quantization.TwoLayerFunctionalLinearModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="linear2", style="solid"];
"torch.testing._internal.common_quantization.InnerModule" -> "torch.testing._internal.common_quantization.SkipQuantModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.testing._internal.common_quantization.AnnotatedNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.testing._internal.common_quantization.AnnotatedSubNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.testing._internal.common_quantization.NestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.LinearReluModel" -> "torch.testing._internal.common_quantization.QuantSubModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.SubModelForFusion" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub1", style="solid"];
"torch.testing._internal.common_quantization.SubModelWithoutFusion" -> "torch.testing._internal.common_quantization.ModelForFusion" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.testing._internal.common_quantization.TestHelperModules.ConvWithBNRelu" -> "torch.testing._internal.common_quantization.TestHelperModules.ConvBnReLU2dAndLinearReLU" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="conv_bn_relu", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" -> "torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" -> "torch.testing._internal.common_quantization.AnnotatedNestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" -> "torch.testing._internal.common_quantization.LinearModelWithSubmodule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="subm", style="solid"];
"torch.testing._internal.common_quantization.TwoLayerLinearModel" -> "torch.testing._internal.common_quantization.NestedModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub2", style="solid"];
"torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel2" -> "torch.testing._internal.distributed._shard.sharded_tensor._test_st_common.MyShardedModel1" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="submodule", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.Attention" -> "torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="attention", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.FeedForward" -> "torch.testing._internal.distributed._tensor.common_dtensor.TransformerBlock" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="feed_forward", style="solid"];
"torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="hybrid_module", style="solid"];
"torch.testing._internal.distributed.distributed_test.BatchNormNet" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bn", style="solid"];
"torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.MyModel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sub_module", style="solid"];
"torch.testing._internal.distributed.distributed_test.EmbeddingNetDifferentParams" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="embedding_net", style="solid"];
"torch.testing._internal.distributed.distributed_test.Task" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs.UnusedParamModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="t0", style="solid"];
"torch.testing._internal.distributed.distributed_test.Task" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs.UnusedParamModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="t1", style="solid"];
"torch.testing._internal.distributed.distributed_test.TwoLinLayerNet" -> "torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_ddp_multiple_nested_unused_params_error.SubModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lin", style="solid"];
"torch.testing._internal.distributed.distributed_test.UnusedParamTwoLinLayerNet" -> "torch.testing._internal.distributed.distributed_test.DictOutputModule" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.testing._internal.distributed.distributed_test._FC2" -> "torch.testing._internal.distributed.distributed_test.Net" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fc2", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.DummyEnv" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Observer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="env", style="solid"];
"torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Policy" -> "torch.testing._internal.distributed.rpc.examples.reinforcement_learning_rpc_test.Agent" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="policy", style="solid"];
"torch.testing._internal.opinfo.core.SpectralFuncInfo" -> "torch.testing._internal.opinfo.definitions.fft.SpectralFuncPythonRefInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="torch_opinfo", style="solid"];
"torch.testing._internal.quantization_torch_package_models.LinearReluFunctionalChild" -> "torch.testing._internal.quantization_torch_package_models.LinearReluFunctional" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="child", style="solid"];
"torch.utils._content_store.ContentStoreReader" -> "torch._dynamo.debug_utils.InputReader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="store", style="solid"];
"torch.utils._content_store.ContentStoreWriter" -> "torch._dynamo.debug_utils.InputWriter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="store", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.bounds.BoundVars" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unbounded_vars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.common.CSE" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="invalidated_stores", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="must_keep_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="store_buffer_names", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="removed_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.common.Kernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="inplaced_to_remove", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_utils.CppCSEVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dependent_itervars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="declared_int_array_vars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="used_cached_devices", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="used_cached_dtypes", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="used_cached_layouts", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="used_cached_memory_formats", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="used_cond_predicate", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.triton.TritonCSEVariable" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mask_vars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="outside_loop_vars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.triton.TritonKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="autotune_hints", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.triton.TritonSymbols" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="reduction_types", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.triton.TritonSymbols" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="block_types", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="kernel_autotune_names", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unbacked_symbol_decls", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="allocated", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="freed", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_meta_vars", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.codegen.wrapper.PythonWrapperCodegen" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="already_codegened_subgraphs", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.dependencies.FreeUnbackedSymbolsOpsHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="symbols", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.fx_passes.joint_graph.UniformValueConstantFolder" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="indexing_op_packets", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.fx_utils.FakeTensorUpdater" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="processed_hashes", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="bound_unbacked_symbols", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="zero_dim_cpu_tensor_list", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="removed_operations", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="removed_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="removed_inplace_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mutated_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="never_reuse_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="inplaced_to_remove", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mutated_inputs", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="nodes_prefer_channels_last", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_warned_fallback", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="aligned_inputs", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="no_fuse_buffer_names", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.graph.GraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="all_codegen_kernel_names", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.ir.TritonTemplateBuffer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="allowed_prologue_inps", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.ops_handler.OpCounterCSE" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_used_ops", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.pattern_matcher._TargetExpr" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="fns_set", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ancestors", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="last_usage", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unmet_dependencies", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.ForeachKernelSchedulerNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="origins", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.OutputNode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="unmet_dependencies", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.Scheduler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="completed_operations", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.Scheduler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="available_buffer_names", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.Scheduler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="logged_slow_fusion", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.scheduler.Scheduler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="buffer_names_to_free", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.select_algorithm.TritonTemplateCaller" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="allowed_prologue_inps", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.subgraph_lowering.PointwiseSubgraphLowering" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mutated_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.virtualized.NullKernelHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="removed_buffers", style="solid"];
"torch.utils._ordered_set.OrderedSet" -> "torch._inductor.virtualized.NullKernelHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="inplaced_to_remove", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch._functorch._aot_autograd.schemas.GraphSignature" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch._functorch._aot_autograd.schemas.GraphSignature" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch._library.autograd.supports_tensorlist.Metadata" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="input_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.export._trace.ExportArtifact" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.export.exported_program.ModuleCallSignature" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.export.exported_program.ModuleCallSignature" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="out_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.fx.graph._PyTreeInfo" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="in_spec", style="solid"];
"torch.utils._sympy.functions.FloorDiv" -> "torch._inductor.codegen.cpp.CppVecKernel" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="weight_recp_vec_range", style="solid"];
"torch.utils._sympy.value_ranges.ValueRangeAnalysis" -> "torch._inductor.codegen.common.Kernel.__enter__.CSEProxy" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vr_analysis", style="solid"];
"torch.utils._sympy.value_ranges.ValueRanges" -> "torch.fx.experimental.symbolic_shapes.StrictMinMaxConstraint" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="vr", style="solid"];
"torch.utils._sympy.value_ranges.ValueRanges" -> "torch.utils._sympy.value_ranges.ValueRanges" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="ExprVR", style="solid"];
"torch.utils._sympy.value_ranges.ValueRanges" -> "torch.utils._sympy.value_ranges.ValueRanges" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="BoolVR", style="solid"];
"torch.utils._traceback.CapturedTraceback" -> "torch.fx.experimental.symbolic_shapes.RuntimeAssert" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stack", style="solid"];
"torch.utils.benchmark.utils.common.TaskSpec" -> "torch.utils.benchmark.utils.common.Measurement" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="task_spec", style="solid"];
"torch.utils.benchmark.utils.common.TaskSpec" -> "torch.utils.benchmark.utils.timer.Timer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_task_spec", style="solid"];
"torch.utils.benchmark.utils.common.TaskSpec" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="task_spec", style="solid"];
"torch.utils.benchmark.utils.timer.CPPTimer" -> "torch.utils.benchmark.utils.timer.Timer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_timer", style="solid"];
"torch.utils.benchmark.utils.timer.Language" -> "torch.utils.benchmark.utils.timer.Timer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_language", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="baseline_inclusive_stats", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="baseline_exclusive_stats", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stmt_inclusive_stats", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCounts" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="stmt_exclusive_stats", style="solid"];
"torch.utils.data._utils.fetch._IterableDatasetFetcher" -> "torch.utils.data.dataloader._SingleProcessDataLoaderIter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dataset_fetcher", style="solid"];
"torch.utils.data._utils.fetch._MapDatasetFetcher" -> "torch.utils.data.dataloader._SingleProcessDataLoaderIter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_dataset_fetcher", style="solid"];
"torch.utils.data.dataloader._MultiProcessingDataLoaderIter" -> "torch.utils.data.dataloader.DataLoader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_iterator", style="solid"];
"torch.utils.data.dataloader._SingleProcessDataLoaderIter" -> "torch.utils.data.dataloader.DataLoader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_iterator", style="solid"];
"torch.utils.data.datapipes._hook_iterator._SnapshotState" -> "torch.utils.data.datapipes.datapipe.IterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_snapshot_state", style="solid"];
"torch.utils.data.datapipes._typing._DataPipeType" -> "torch.utils.data.datapipes._typing._DataPipeMeta" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="type", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.callable.MapperIterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.combinatorics.SamplerIterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.grouping.BatcherIterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.MapDataPipe" -> "torch.utils.data.datapipes.map.callable.MapperMapDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.MapDataPipe" -> "torch.utils.data.datapipes.map.grouping.BatcherMapDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe._IterDataPipeSerializationWrapper" -> "torch.utils.data.dataloader.DataLoader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dataset", style="solid"];
"torch.utils.data.datapipes.datapipe._MapDataPipeSerializationWrapper" -> "torch.utils.data.dataloader.DataLoader" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dataset", style="solid"];
"torch.utils.data.datapipes.utils.decoder.Decoder" -> "torch.utils.data.datapipes.iter.routeddecoder.RoutedDecoderIterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="decoder", style="solid"];
"torch.utils.data.sampler.SequentialSampler" -> "torch.utils.data.datapipes.iter.combinatorics.SamplerIterDataPipe" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="sampler", style="solid"];
"torch.utils.flop_counter._FlopCounterMode" -> "torch.utils.flop_counter.FlopCounterMode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mode", style="solid"];
"torch.utils.hipify.hipify_python.TrieNode" -> "torch.utils.hipify.hipify_python.Trie" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.distributed._tools.mod_tracker.ModTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_pre_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.distributed._tools.mod_tracker.ModTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_post_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_pre_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_post_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.distributed.tensor.debug._comm_mode._CommModeModuleTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_bw_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.utils.module_tracker.ModuleTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_pre_handle", style="solid"];
"torch.utils.hooks.RemovableHandle" -> "torch.utils.module_tracker.ModuleTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fw_post_handle", style="solid"];
"torch.utils.module_tracker.ModuleTracker" -> "torch.utils.flop_counter.FlopCounterMode" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="mod_tracker", style="solid"];
"torch.utils.tensorboard.writer.FileWriter" -> "torch.utils.tensorboard.writer.SummaryWriter" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="file_writer", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch._guards.TracingContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor_to_context", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch._subclasses.meta_utils.MetaTensorDescriber" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lookup_tensor", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch._subclasses.meta_utils.MetaTensorDescriber" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="lookup_storage", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.distributed._tools.fsdp2_mem_tracker.FSDPMemTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_fsdp_mod_to_saved_methods", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.distributed._tools.mem_tracker.MemTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="memory_tracking", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.distributed._tools.mem_tracker.MemTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_param_to_grad_hook_handles", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.distributed._tools.mem_tracker.MemTracker" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="_WINFO", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor_tracker", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.fx.experimental.proxy_tensor.PythonKeyTracer" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="script_object_tracker", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.fx.experimental.proxy_tensor._GraphAppendingTracerEx" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="tensor_tracker", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.fx.experimental.proxy_tensor._GraphAppendingTracerEx" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="script_object_tracker", style="solid"];
"torch.utils.weak.WeakIdKeyDictionary" -> "torch.testing._internal.logging_tensor.LoggingTensorHandler" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="memo", style="solid"];
"torch.xpu.device" -> "torch._dynamo.device_interface.XpuInterface" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="device", style="solid"];
"torch.xpu.streams.Event" -> "torch._dynamo.device_interface.XpuInterface" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="Event", style="solid"];
"torch.xpu.streams.Stream" -> "torch._dynamo.device_interface.XpuInterface" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="Stream", style="solid"];
"torch.xpu.streams.Stream" -> "torch.xpu.StreamContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="src_prev_stream", style="solid"];
"torch.xpu.streams.Stream" -> "torch.xpu.StreamContext" [arrowhead="diamond", arrowtail="none", fontcolor="green", label="dst_prev_stream", style="solid"];
"torch._dynamo.convert_frame.ConvertFrameProtocol" -> "torch._dynamo.convert_frame.CatchErrorsWrapper" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_torchdynamo_orig_callable", style="solid"];
"torch._dynamo.exc.UserErrorType" -> "torch._dynamo.exc.UserError" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="error_type", style="solid"];
"torch._dynamo.guards.CheckFunctionManager" -> "torch._dynamo.guards.GuardBuilder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="check_fn_manager", style="solid"];
"torch._dynamo.guards.DeletedGuardManagerWrapper" -> "torch._dynamo.guards.CheckFunctionManager" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="guard_manager", style="solid"];
"torch._dynamo.guards.GuardManagerWrapper" -> "torch._dynamo.guards.GuardBuilder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="guard_manager", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.Config" -> "torch._dynamo.guards.PyExprCSEPass.ExprCounter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_config", style="solid"];
"torch._dynamo.guards.PyExprCSEPass.Config" -> "torch._dynamo.guards.PyExprCSEPass.Replacer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_config", style="solid"];
"torch._dynamo.hooks.Hooks" -> "torch._dynamo.convert_frame.CatchErrorsWrapper" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="hooks", style="solid"];
"torch._dynamo.hooks.Hooks" -> "torch._dynamo.convert_frame.ConvertFrame" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_hooks", style="solid"];
"torch._dynamo.symbolic_convert.InstructionTranslatorBase" -> "torch._dynamo.symbolic_convert.InliningInstructionTranslator" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="parent", style="solid"];
"torch._dynamo.symbolic_convert.SpeculationLog" -> "torch._dynamo.symbolic_convert.InstructionTranslatorBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="speculation_log", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.distributed.BackwardHookVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.distributed.BackwardHookVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="user_hooks", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.distributed.BackwardHookVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="user_pre_hooks", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.functions.FunctoolsPartialVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="func", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.iter.FilterVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fn", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.iter.MapVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fn", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.iter.RepeatIteratorVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="item", style="solid"];
"torch._dynamo.variables.base.VariableTracker" -> "torch._dynamo.variables.misc.InspectSignatureVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="inspected", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable._HashableTracker" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.constant.ConstantVariable" -> "torch._dynamo.variables.lists.DequeVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="maxlen", style="solid"];
"torch._dynamo.variables.dicts.ConstDictVariable" -> "torch._dynamo.variables.dicts.DictView" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="dv_dict", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable._HashableTracker" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.dicts.FrozensetVariable" -> "torch._dynamo.variables.lists.DequeVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="maxlen", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.variables.dicts.ConstDictVariable._HashableTracker" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="vt", style="solid"];
"torch._dynamo.variables.dicts.SetVariable" -> "torch._dynamo.variables.lists.DequeVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="maxlen", style="solid"];
"torch._dynamo.variables.iter.IteratorVariable" -> "torch._dynamo.variables.iter.CycleIteratorVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="iterator", style="solid"];
"torch._dynamo.variables.lazy.LazyCache" -> "torch._dynamo.variables.lazy.LazyVariableTracker" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_cache", style="solid"];
"torch._dynamo.variables.misc.InspectSignatureVariable" -> "torch._dynamo.variables.misc.InspectBoundArgumentsVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="signature", style="solid"];
"torch._dynamo.variables.tensor.SymNodeVariable" -> "torch._dynamo.variables.lazy.LazySymNodeFormatString" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="sym_node_var", style="solid"];
"torch._dynamo.variables.tensor.TensorVariable" -> "torch._dynamo.variables.tensor.DataPtrVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="from_tensor", style="solid"];
"torch._dynamo.variables.tensor.TensorVariable" -> "torch._dynamo.variables.tensor.UntypedStorageVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="from_tensor", style="solid"];
"torch._functorch._aot_autograd.schemas.AOTConfig" -> "torch._functorch._aot_autograd.autograd_cache.AOTAutogradCacheDetails" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="aot_config", style="solid"];
"torch._guards.Source" -> "torch._dynamo.variables.builder.VariableBuilder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="source", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHContext" -> "torch._inductor.autoheuristic.autoheuristic.AutoHeuristic" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="context", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHContext" -> "torch._inductor.autoheuristic.learned_heuristic_controller.LearnedHeuristicController" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="context", style="solid"];
"torch._inductor.autoheuristic.autoheuristic_utils.AHMetadata" -> "torch._inductor.autoheuristic.learned_heuristic_controller.LearnedHeuristicController" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch._inductor.autotune_process.CUDABenchmarkRequest" -> "torch._inductor.codegen.cuda.cuda_kernel.CUDATemplateCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="bmreq", style="solid"];
"torch._inductor.autotune_process.CppBenchmarkRequest" -> "torch._inductor.codegen.cpp_template_kernel.CppTemplateCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="bmreq", style="solid"];
"torch._inductor.autotune_process.TritonBenchmarkRequest" -> "torch._inductor.select_algorithm.TritonTemplateCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="bmreq", style="solid"];
"torch._inductor.codegen.common.BracesBuffer" -> "torch._inductor.codegen.cpp.CppKernelProxy" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="reduction_suffix", style="solid"];
"torch._inductor.codegen.common.KernelArgs" -> "torch._inductor.codegen.cpp_utils.LocalBufferContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="kernel_args", style="solid"];
"torch._inductor.codegen.cuda.cuda_template.CUDATemplate" -> "torch._inductor.ir.CUDATemplateBuffer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="template", style="solid"];
"torch._inductor.codegen.rocm.rocm_benchmark_request.ROCmBenchmarkRequest" -> "torch._inductor.codegen.rocm.rocm_kernel.ROCmTemplateCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="bmreq", style="solid"];
"torch._inductor.codegen.simd.IterationRanges" -> "torch._inductor.codegen.simd.IterationRangesEntry" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="parent", style="solid"];
"torch._inductor.codegen.simd_kernel_features.SIMDKernelFeatures" -> "torch._inductor.codegen.simd.SIMDKernel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="features", style="solid"];
"torch._inductor.cudagraph_trees.CUDAGraphNode" -> "torch._inductor.cudagraph_trees.CUDAGraphTreeManager" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="current_node", style="solid"];
"torch._inductor.cudagraph_trees.CUDAGraphNode" -> "torch._inductor.cudagraph_trees.CUDAGraphTreeManager" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="current_node", style="solid"];
"torch._inductor.cudagraph_trees.CUDAWarmupNode" -> "torch._inductor.cudagraph_trees.CUDAGraphTreeManager" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="current_node", style="solid"];
"torch._inductor.cudagraph_trees.GraphID" -> "torch._inductor.cudagraph_trees.CUDAGraphNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="id", style="solid"];
"torch._inductor.cudagraph_trees.GraphID" -> "torch._inductor.cudagraph_trees.CUDAWarmupNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="id", style="solid"];
"torch._inductor.cudagraph_utils.WrappedFunction" -> "torch._inductor.cudagraph_trees.CUDAGraphNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="wrapped_function", style="solid"];
"torch._inductor.cudagraph_utils.WrappedFunction" -> "torch._inductor.cudagraph_trees.CUDAWarmupNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="wrapped_function", style="solid"];
"torch._inductor.debug.DebugContext" -> "torch._inductor.debug.DebugFormatter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="handler", style="solid"];
"torch._inductor.graph.GraphLowering" -> "torch._inductor.graph.SubgraphLowering" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="parent", style="solid"];
"torch._inductor.ir.ChoiceCaller" -> "torch._inductor.select_algorithm.ErrorFromChoice" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="choice", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.ir.Conditional" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="predicate", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.ir.MutationLayoutSHOULDREMOVE" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="target", style="solid"];
"torch._inductor.ir.IRNode" -> "torch._inductor.ir.TMADescriptor" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._inductor.ir.Layout" -> "torch._inductor.codegen.cpp_template.CppTemplate" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="layout", style="solid"];
"torch._inductor.ir.Layout" -> "torch._inductor.codegen.cuda.cuda_template.CUDATemplate" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="layout", style="solid"];
"torch._inductor.ir.Layout" -> "torch._inductor.codegen.rocm.rocm_template.ROCmTemplate" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="layout", style="solid"];
"torch._inductor.ir.Layout" -> "torch._inductor.ir.ChoiceCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="layout", style="solid"];
"torch._inductor.ir.MultiOutput" -> "torch._inductor.ir.FallbackKernel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="outputs", style="solid"];
"torch._inductor.ir.Operation" -> "torch._inductor.ir.MutationOutput" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mutating_node", style="solid"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.Conditional" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="true_subgraph", style="solid"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.Conditional" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="false_subgraph", style="solid"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.InvokeSubgraph" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="subgraph", style="solid"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.WhileLoop" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="cond_subgraph", style="solid"];
"torch._inductor.ir.Subgraph" -> "torch._inductor.ir.WhileLoop" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="body_subgraph", style="solid"];
"torch._inductor.loop_body.InterpreterShim" -> "torch._inductor.loop_body.InterpreterShim" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch._inductor.loop_body.LoopBody" -> "torch._inductor.bounds.BoundVars" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="loop_body", style="solid"];
"torch._inductor.loop_body.LoopBody" -> "torch._inductor.loop_body.LoopBodyBlock" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="body", style="solid"];
"torch._inductor.pattern_matcher.PatternExpr" -> "torch._inductor.pattern_matcher.ListOf" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="pattern", style="solid"];
"torch._inductor.pattern_matcher._TargetExpr" -> "torch._inductor.pattern_matcher.RepeatedExpr" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="inner_pattern", style="solid"];
"torch._inductor.scheduler.BaseSchedulerNode" -> "torch._inductor.scheduler.WhyNoFuse" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="node1", style="solid"];
"torch._inductor.scheduler.BaseSchedulerNode" -> "torch._inductor.scheduler.WhyNoFuse" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="node2", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.codegen.cuda.cuda_cpp_scheduling.CUDACPPScheduling" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.codegen.cuda_combined_scheduling.CUDACombinedScheduling" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.codegen.rocm.rocm_cpp_scheduling.ROCmCPPScheduling" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.scheduler.Scheduler" -> "torch._inductor.scheduler.BaseSchedulerNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="scheduler", style="solid"];
"torch._inductor.select_algorithm.ExternKernelChoice" -> "torch._inductor.select_algorithm.ExternKernelCaller" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="choice", style="solid"];
"torch._inductor.select_algorithm.TritonTemplateKernel.load_input.StoreOutputSubstitution" -> "torch._inductor.select_algorithm.TritonTemplateKernel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="ops_handler", style="solid"];
"torch._inductor.utils.IndentedBuffer" -> "torch._inductor.codegen.cpp_wrapper_cpu.CppWrapperCpu" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="prefix", style="solid"];
"torch._lazy.closure.AsyncClosureHandler" -> "torch._lazy.device_context.DeviceContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="async_closure_handler", style="solid"];
"torch._lazy.closure.ClosureHandler" -> "torch._lazy.device_context.DeviceContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="closure_handler", style="solid"];
"torch._library.fake_class_registry.FakeScriptObject" -> "torch._library.fake_class_registry.FakeScriptMethod" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="self_fake_obj", style="solid"];
"torch._ops.HigherOrderOperator" -> "torch._dynamo.variables.higher_order_ops.TorchHigherOrderOperatorVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="value", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._guards.TracingContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch._subclasses.fake_tensor.FakeCopyMode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fake_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._subclasses.fake_tensor.FakeTensorMode" -> "torch.fx.experimental.proxy_tensor._MakefxTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fake_tensor_mode", style="solid"];
"torch._tensor.Tensor" -> "torch._functorch._aot_autograd.functional_utils.FunctionalTensorMetadataEq" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch._lobpcg.LOBPCG" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="X", style="solid"];
"torch._tensor.Tensor" -> "torch.amp.grad_scaler._MultiDeviceReplicator" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="master", style="solid"];
"torch._tensor.Tensor" -> "torch.ao.nn.quantized.modules.activation.PReLU" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="weight", style="solid"];
"torch._tensor.Tensor" -> "torch.autograd.grad_mode._unsafe_preserve_version_counter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch.backends._nnapi.prepare.NnapiModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="ser_model", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.distributed_c10d.P2POp" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.distributed_c10d._CollOp" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tensor", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.fsdp.sharded_grad_scaler._GeneralMultiDeviceReplicator" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="master", style="solid"];
"torch._tensor.Tensor" -> "torch.distributed.pipelining.stage._RecvInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="buffer", style="solid"];
"torch._tensor.Tensor" -> "torch.testing._internal.torchbind_impls.register_fake_classes.FakeContainsTensor" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="t", style="solid"];
"torch.ao.quantization.backend_config.backend_config.ObservationType" -> "torch.ao.quantization.backend_config.backend_config.BackendPatternConfig" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="observation_type", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.linear.Linear" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.linear.Linear" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.linear.Linear" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.nn.modules.linear.Linear" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.AnnotatedConvBnModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.EmbeddingWithStaticLinear" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.RNNCellDynamicModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.RNNDynamicModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.qconfig.QConfig" -> "torch.testing._internal.common_quantization.TwoLayerLinearModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="qconfig", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer_utils.QuantizationConfig" -> "torch.ao.quantization.quantizer.x86_inductor_quantizer.X86InductorQuantizer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="global_config", style="solid"];
"torch.ao.quantization.quantizer.xnnpack_quantizer_utils.QuantizationConfig" -> "torch.ao.quantization.quantizer.xnnpack_quantizer.XNNPACKQuantizer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="global_config", style="solid"];
"torch.autograd.function.BackwardCFunction" -> "torch._dynamo.external_utils.FakeBackwardCFunction" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="real", style="solid"];
"torch.autograd.graph._MultiHandle" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_pre_forward_hook_handle", style="solid"];
"torch.autograd.graph._MultiHandle" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_post_forward_hook_handle", style="solid"];
"torch.autograd.profiler.profile" -> "torch.profiler._utils.BasicEvaluation" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="profile", style="solid"];
"torch.cpu.Stream" -> "torch.cpu.StreamContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="prev_stream", style="solid"];
"torch.cpu.Stream" -> "torch.cpu.StreamContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="prev_stream", style="solid"];
"torch.cuda._sanitizer.Access" -> "torch.cuda._sanitizer.UnsynchronizedAccessError" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="current_access", style="solid"];
"torch.cuda._sanitizer.Access" -> "torch.cuda._sanitizer.UnsynchronizedAccessError" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="previous_access", style="solid"];
"torch.distributed._shard.sharding_spec.api.ShardingSpec" -> "torch.distributed._shard.sharded_tensor.api.ShardedTensor" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_sharding_spec", style="solid"];
"torch.distributed._tools.mem_tracker._RefType" -> "torch.distributed._tools.mem_tracker._WeakRefInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="reftype", style="solid"];
"torch.distributed.algorithms._checkpoint.checkpoint_wrapper.CheckpointImpl" -> "torch.distributed.algorithms._checkpoint.checkpoint_wrapper.CheckpointWrapper" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="checkpoint_impl", style="solid"];
"torch.distributed.algorithms.model_averaging.averagers.ModelAverager" -> "torch.distributed.optim.post_localSGD_optimizer.PostLocalSGDOptimizer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="averager", style="solid"];
"torch.distributed.checkpoint.metadata.Metadata" -> "torch.distributed.checkpoint.default_planner.DefaultSavePlanner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="metadata", style="solid"];
"torch.distributed.checkpoint.planner.SavePlan" -> "torch.distributed.checkpoint.default_planner.DefaultSavePlanner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="plan", style="solid"];
"torch.distributed.checkpoint.planner.SavePlan" -> "torch.distributed.checkpoint.default_planner.DefaultSavePlanner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="plan", style="solid"];
"torch.distributed.checkpoint.storage.StorageReader" -> "torch.distributed.checkpoint._checkpointer._Checkpointer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="storage_reader", style="solid"];
"torch.distributed.checkpoint.storage.StorageWriter" -> "torch.distributed.checkpoint._checkpointer._Checkpointer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="storage_writer", style="solid"];
"torch.distributed.device_mesh.DeviceMesh" -> "torch.testing._internal.distributed._tensor.common_dtensor.DTensorConverter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mesh", style="solid"];
"torch.distributed.elastic.agent.server.api.WorkerSpec" -> "torch.distributed.elastic.agent.server.api.WorkerGroup" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="spec", style="solid"];
"torch.distributed.elastic.metrics.api.MetricHandler" -> "torch.distributed.elastic.metrics.api.MetricStream" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="handler", style="solid"];
"torch.distributed.elastic.multiprocessing.api.LogsSpecs" -> "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_logs_specs", style="solid"];
"torch.distributed.elastic.rendezvous.api.RendezvousStoreInfo" -> "torch.distributed.elastic.rendezvous.api.RendezvousInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_bootstrap_store_info", style="solid"];
"torch.distributed.elastic.timer.api.RequestQueue" -> "torch.distributed.elastic.timer.api.TimerServer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_request_queue", style="solid"];
"torch.distributed.fsdp._common_utils.TrainingState" -> "torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="training_state", style="solid"];
"torch.distributed.fsdp._flat_param.HandleShardingStrategy" -> "torch.distributed.fsdp._flat_param.FlatParamHandle" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_sharding_strategy", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.MixedPrecisionPolicy" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mp_policy", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.MixedPrecisionPolicy" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mp_policy", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.MixedPrecisionPolicy" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_mp_policy", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_api.OffloadPolicy" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="offload_policy", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.FSDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mesh_info", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.FSDPMeshInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="mesh_info", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_common.TrainingState" -> "torch.distributed.fsdp._fully_shard._fsdp_param_group.FSDPParamGroup" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_training_state", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_param.ParamModuleInfo" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_module_info", style="solid"];
"torch.distributed.fsdp._fully_shard._fsdp_state.FSDPState" -> "torch.distributed.fsdp._fully_shard._fsdp_state.FSDPStateContext" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="iter_forward_root", style="solid"];
"torch.distributed.launcher.api.LaunchConfig" -> "torch.distributed.launcher.api.elastic_launch" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_config", style="solid"];
"torch.distributed.pipelining._utils.PipeInfo" -> "torch.distributed.pipelining.stage._PipelineStage" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="pipe_info", style="solid"];
"torch.distributed.pipelining.stage._PipelineStageBase" -> "torch.distributed.pipelining.schedules.PipelineScheduleSingle" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_stage", style="solid"];
"torch.distributed.rpc.api.RRef" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="remote_em_rref", style="solid"];
"torch.distributed.rpc.api.RRef" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="remote_net_rref", style="solid"];
"torch.distributed.rpc.api.RRef" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="remote_em_rref", style="solid"];
"torch.distributed.rpc.api.RRef" -> "torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="remote_net_rref", style="solid"];
"torch.distributed.tensor.placement_types.Shard" -> "torch.distributed.fsdp._fully_shard._fsdp_param.FSDPParam" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fsdp_placement", style="solid"];
"torch.distributions.transforms.Transform" -> "torch.distributions.transforms._InverseTransform" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_inv", style="solid"];
"torch.export._draft_export.DraftExportReport" -> "torch.export.exported_program.ExportedProgram" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_report", style="solid"];
"torch.export._draft_export.FailureType" -> "torch.export._draft_export.FailureReport" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="failure_type", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch._export.passes.collect_tracepoints_pass.CollectTracepointsPass" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="sig", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch._export.serde.serialize.GraphModuleSerializer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph_signature", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch.distributed.tensor.experimental._tp_transform._TensorParallelTransformPass" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph_signature", style="solid"];
"torch.export.graph_signature.ExportGraphSignature" -> "torch.export.exported_program.ExportedProgram" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_graph_signature", style="solid"];
"torch.export.unflatten.UnflattenedModule" -> "torch.fx.graph.Graph" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="owning_module", style="solid"];
"torch.fx._symbolic_trace.Tracer" -> "torch._inductor.subgraph_lowering.TracingOpsHandler" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="tracer", style="solid"];
"torch.fx._symbolic_trace.Tracer" -> "torch.fx.graph.Graph" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_tracer_cls", style="solid"];
"torch.fx.experimental.proxy_tensor._ModuleStackTracer.__init__.AttrProxy" -> "torch.fx.experimental.proxy_tensor._ModuleStackTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="proxy_type", style="solid"];
"torch.fx.experimental.symbolic_shapes.ShapeEnv" -> "torch._inductor.sizevars.SizeVarAllocator" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="shape_env", style="solid"];
"torch.fx.graph.Graph" -> "torch._inductor.fx_utils.FakeTensorUpdater" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.export.unflatten.InterpreterModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.export.unflatten._ModuleFrame" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="flat_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.experimental.optimization.MklSubgraph" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="fx_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.experimental.proxy_tensor.DecompositionInterpreter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="new_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.graph_module.GraphModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.graph_module.GraphModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.interpreter.Transformer.__init__.TransformerTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.passes.utils.matcher_utils.SubgraphMatcher" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="pattern", style="solid"];
"torch.fx.graph.Graph" -> "torch.fx.proxy.GraphAppendingTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._dynamo.output_graph.WrapperBackend" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._inductor.codecache.FxGraphHashDetails" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch._inductor.output_code.CompiledFxGraphConstantsWithGm" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.ao.ns.fx.graph_matcher._NSGraphMatchableSubgraphsIterator" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.ao.quantization.fx._model_report.model_report.ModelReport" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_model", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.distributed.pipelining._IR.Pipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="split_gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.experimental.accelerator_partitioner.Partitioner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.experimental.proxy_tensor._ModuleStackTracer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="scope_root", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.graph_transform_observer.GraphTransformObserver" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="gm", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.infra.partitioner.CapabilityBasedPartitioner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="graph_module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.net_min_base._MinimizerBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.splitter_base.FxNetAccNodesFinder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.splitter_base._SplitterBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.fx.passes.tools_common.FxNetAccFusionsFinder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.onnx._internal.fx._pass.Analysis" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.onnx._internal.fx.passes.modularization.Modularize" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.fx.graph_module.GraphModule" -> "torch.onnx._internal.fx.passes.modularization._ModuleNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_reference_module", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.pre_grad.NormalizedLinearNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.fx_passes.pre_grad.NormalizedMatmulNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.fx.node.Node" -> "torch._inductor.loop_body.InterpreterShim" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="current_node", style="solid"];
"torch.fx.node.Node" -> "torch.fx.experimental.accelerator_partitioner.DAGNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="submodule_node", style="solid"];
"torch.fx.node.Node" -> "torch.fx.proxy.Proxy" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="node", style="solid"];
"torch.fx.node.Node" -> "torch.onnx._internal.fx.passes.modularization._LeafNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_node", style="solid"];
"torch.fx.passes.net_min_base._MinimizerSettingBase" -> "torch.fx.passes.net_min_base._MinimizerBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="settings", style="solid"];
"torch.fx.passes.operator_support.OperatorSupportBase" -> "torch.fx.passes.infra.partitioner.CapabilityBasedPartitioner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="operator_support", style="solid"];
"torch.fx.passes.operator_support.OperatorSupportBase" -> "torch.fx.passes.splitter_base.FxNetAccNodesFinder" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="operator_support", style="solid"];
"torch.fx.passes.operator_support.OperatorSupportBase" -> "torch.fx.passes.splitter_base._SplitterBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="operator_support", style="solid"];
"torch.fx.passes.splitter_base._SplitterSettingBase" -> "torch.fx.passes.splitter_base._SplitterBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="settings", style="solid"];
"torch.fx.proxy.Proxy" -> "torch._dynamo.variables.distributed.BackwardHookVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="proxy", style="solid"];
"torch.fx.proxy.Proxy" -> "torch._dynamo.variables.tensor.TensorVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="proxy", style="solid"];
"torch.fx.proxy.Proxy" -> "torch.fx.proxy.Attribute" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="root", style="solid"];
"torch.fx.proxy.Scope" -> "torch.fx.proxy.ScopeContextManager" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_scope", style="solid"];
"torch.fx.tensor_type.TensorType" -> "torch.fx.tensor_type.TensorType" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="__origin__", style="solid"];
"torch.jit._monkeytype_config.JitTypeTraceStore" -> "torch.jit._monkeytype_config.JitTypeTraceConfig" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="s", style="solid"];
"torch.library.Library" -> "torch._custom_op.impl.CustomOp" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_lib", style="solid"];
"torch.nn.attention.bias.CausalVariant" -> "torch.nn.attention.bias.CausalBias" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="variant", style="solid"];
"torch.nn.modules.module.Module" -> "torch._dynamo.eval_frame.OptimizedModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_orig_mod", style="solid"];
"torch.nn.modules.module.Module" -> "torch._dynamo.variables.nn_module.NNModuleVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="value", style="solid"];
"torch.nn.modules.module.Module" -> "torch._functorch.make_functional.FunctionalModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="stateless_model", style="solid"];
"torch.nn.modules.module.Module" -> "torch._functorch.make_functional.FunctionalModuleWithBuffers" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="stateless_model", style="solid"];
"torch.nn.modules.module.Module" -> "torch.ao.pruning._experimental.activation_sparsifier.activation_sparsifier.ActivationSparsifier" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="model", style="solid"];
"torch.nn.modules.module.Module" -> "torch.backends._nnapi.prepare.NnapiModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="shape_compute_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed._tools.fsdp2_mem_tracker.FSDPMemTracker" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_root_mod", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._flat_param.FlatParamHandle" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_fully_sharded_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp._trace_utils._ExecutionInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="curr_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.fsdp.fully_sharded_data_parallel.FullyShardedDataParallel" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_fsdp_wrapped_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.distributed.pipelining.stage._PipelineStageBase" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="submod", style="solid"];
"torch.nn.modules.module.Module" -> "torch.fx.experimental.accelerator_partitioner.Partitioner" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="torch_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.fx.interpreter.Interpreter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.onnx._internal.fx.passes.readability.RestoreParameterAndBufferNames" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="original_nn_module", style="solid"];
"torch.nn.modules.module.Module" -> "torch.testing._internal.common_fsdp.ModuleWithDelay" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="module", style="solid"];
"torch.nn.parameter.Parameter" -> "torch.testing._internal.distributed.nn.api.remote_module_test.MyModule" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="param1", style="solid"];
"torch.nn.utils.parametrizations._OrthMaps" -> "torch.nn.utils.parametrizations._Orthogonal" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="orthogonal_map", style="solid"];
"torch.onnx._internal._exporter_legacy.OnnxRegistry" -> "torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="onnx_registry", style="solid"];
"torch.onnx._internal._exporter_legacy.ResolvedExportOptions" -> "torch.onnx._internal._exporter_legacy.Exporter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="options", style="solid"];
"torch.onnx._internal.diagnostics.infra.context.Diagnostic" -> "torch.onnx._internal.diagnostics.infra.context.RuntimeErrorWithDiagnostic" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="diagnostic", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.fx._pass.Analysis" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.fx.fx_onnx_interpreter.FxOnnxInterpreter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.fx.onnxfunction_dispatcher.OnnxFunctionDispatcher" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.diagnostics.DiagnosticContext" -> "torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="diagnostic_context", style="solid"];
"torch.onnx._internal.fx.passes.modularization._ModuleStackMeta" -> "torch.onnx._internal.fx.passes.modularization._ModuleNode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_stack_meta", style="solid"];
"torch.onnx._internal.fx.passes.type_promotion.TypePromotionTable" -> "torch.onnx._internal.fx.passes.type_promotion._TypePromotionInterpreter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="type_promotion_table", style="solid"];
"torch.optim.lr_scheduler.LRScheduler" -> "torch.optim.lr_scheduler._enable_get_lr_call" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="o", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.distributed.optim.post_localSGD_optimizer.PostLocalSGDOptimizer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optim", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.CyclicLR" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.LRScheduler" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.LambdaLR" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.MultiplicativeLR" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.OneCycleLR" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.ReduceLROnPlateau" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.optim.lr_scheduler.SequentialLR" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optimizer", style="solid"];
"torch.optim.optimizer.Optimizer" -> "torch.testing._internal.common_optimizers.OptimizerInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="optim_cls", style="solid"];
"torch.package._digraph.DiGraph" -> "torch.package.package_exporter.PackagingError" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="dependency_graph", style="solid"];
"torch.package.importer.Importer" -> "torch.package._package_pickler.PackagePickler" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="importer", style="solid"];
"torch.package.importer.Importer" -> "torch.package._package_unpickler.PackageUnpickler" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_importer", style="solid"];
"torch.package.importer._SysImporter" -> "torch.package.package_exporter.PackageExporter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="importer", style="solid"];
"torch.profiler._memory_profiler.OpTree" -> "torch.profiler._memory_profiler.DataFlowGraph" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_op_tree", style="solid"];
"torch.profiler.profiler.profile" -> "torch.profiler._pattern_matcher.Pattern" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="prof", style="solid"];
"torch.storage.UntypedStorage" -> "torch._dynamo.variables.tensor.UntypedStorageVariable" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="example_value", style="solid"];
"torch.testing._internal.common_dtype._dispatch_dtypes" -> "torch.testing._internal.common_modules.ModuleInfo" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="dtypes", style="solid"];
"torch.testing._internal.distributed._tensor.common_dtensor.ModelArgs" -> "torch.testing._internal.distributed._tensor.common_dtensor.Transformer" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="model_args", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyClass" -> "torch.testing._internal.distributed.rpc.rpc_test.MyClass" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="other", style="solid"];
"torch.testing._internal.distributed.rpc.rpc_test.MyClass" -> "torch.testing._internal.distributed.rpc.rpc_test.MyClass" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="other", style="solid"];
"torch.utils._pytree.LeafSpec" -> "torch.onnx._internal.io_adapter.FlattenInputWithTreeSpecValidationInputStep" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_spec", style="solid"];
"torch.utils._pytree.LeafSpec" -> "torch.onnx._internal.io_adapter.FlattenOutputWithTreeSpecValidationOutputStep" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch._functorch._aot_autograd.utils.PytreeThunk" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.onnx._internal.io_adapter.FlattenInputWithTreeSpecValidationInputStep" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.onnx._internal.io_adapter.FlattenOutputWithTreeSpecValidationOutputStep" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.testing._internal.distributed._tensor.common_dtensor.DTensorConverter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="flatten_args_spec", style="solid"];
"torch.utils._pytree.TreeSpec" -> "torch.testing._internal.distributed._tensor.common_dtensor.DTensorConverter" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="flatten_kwargs_spec", style="solid"];
"torch.utils.benchmark.utils.compare.Colorize" -> "torch.utils.benchmark.utils.compare.Table" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_colorize", style="solid"];
"torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.Serialization" -> "torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CopyIfCallgrind" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="_serialization", style="solid"];
"torch.utils.data.datapipes.datapipe.DataChunk" -> "torch.utils.data.datapipes.iter.grouping.GrouperIterDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="wrapper_class", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.combining._ChildDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="main_datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.combining._ForkerIterDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="main_datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.filelister.FileListerIterDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.grouping.UnBatcherIterDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="datapipe", style="solid"];
"torch.utils.data.datapipes.datapipe.IterDataPipe" -> "torch.utils.data.datapipes.iter.sharding.ShardingFilterIterDataPipe" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="source_datapipe", style="solid"];
"torch.utils.data.dataset.Dataset" -> "torch.utils.data.distributed.DistributedSampler" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="dataset", style="solid"];
"torch.utils.flop_counter.FlopCounterMode" -> "torch.utils.flop_counter._FlopCounterMode" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="counter", style="solid"];
"torch.utils.weak.WeakIdRef" -> "torch.utils.weak.WeakIdKeyDictionary" [arrowhead="odiamond", arrowtail="none", fontcolor="green", label="ref_type", style="solid"];
}
